count=101
* Necessary and Sufficient Conditions for Optimal Decision Trees using Dynamic Programming
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/1d5fce9627e15c84db572a66e029b1fc-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/1d5fce9627e15c84db572a66e029b1fc-Paper-Conference.pdf)]
    * Title: Necessary and Sufficient Conditions for Optimal Decision Trees using Dynamic Programming
    * Year: `2023`
    * Authors: Jacobus van der Linden, Mathijs de Weerdt, Emir Demirović
    * Abstract: Global optimization of decision trees has shown to be promising in terms of accuracy, size, and consequently human comprehensibility. However, many of the methods used rely on general-purpose solvers for which scalability remains an issue.Dynamic programming methods have been shown to scale much better because they exploit the tree structure by solving subtrees as independent subproblems. However, this only works when an objective can be optimized separately for subtrees.We explore this relationship in detail and show the necessary and sufficient conditions for such separability and generalize previous dynamic programming approaches into a framework that can optimize any combination of separable objectives and constraints.Experiments on five application domains show the general applicability of this framework, while outperforming the scalability of general-purpose solvers by a large margin.
count=85
* Safety Verification of Decision-Tree Policies in Continuous Time
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/2f89a23a19d1617e7fb16d4f7a049ce2-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/2f89a23a19d1617e7fb16d4f7a049ce2-Paper-Conference.pdf)]
    * Title: Safety Verification of Decision-Tree Policies in Continuous Time
    * Year: `2023`
    * Authors: Christian Schilling, Anna Lukina, Emir Demirović, Kim Larsen
    * Abstract: Decision trees have gained popularity as interpretable surrogate models for learning-based control policies. However, providing safety guarantees for systems controlled by decision trees is an open challenge. We show that the problem is undecidable even for systems with the simplest dynamics, and PSPACE-complete for finite-horizon properties. The latter can be verified for discrete-time systems via bounded model checking. However, for continuous-time systems, such an approach requires discretization, thereby weakening the guarantees for the original system. This paper presents the first algorithm to directly verify decision-tree controlled system in continuous time. The key aspect of our method is exploiting the decision-tree structure to propagate a set-based approximation through the decision nodes. We demonstrate the effectiveness of our approach by verifying safety of several decision trees distilled to imitate neural-network policies for nonlinear systems.
count=81
* Provably efficient, succinct, and precise explanations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/30d4e6422cd65c7913bc9ce62e078b79-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/30d4e6422cd65c7913bc9ce62e078b79-Paper.pdf)]
    * Title: Provably efficient, succinct, and precise explanations
    * Year: `2021`
    * Authors: Guy Blanc, Jane Lange, Li-Yang Tan
    * Abstract: We consider the problem of explaining the predictions of an arbitrary blackbox model $f$: given query access to $f$ and an instance $x$, output a small set of $x$'s features that in conjunction essentially determines $f(x)$. We design an efficient algorithm with provable guarantees on the succinctness and precision of the explanations that it returns. Prior algorithms were either efficient but lacked such guarantees, or achieved such guarantees but were inefficient. We obtain our algorithm via a connection to the problem of {\sl implicitly} learning decision trees. The implicit nature of this learning task allows for efficient algorithms even when the complexity of~$f$ necessitates an intractably large surrogate decision tree. We solve the implicit learning problem by bringing together techniques from learning theory, local computation algorithms, and complexity theory. Our approach of “explaining by implicit learning” shares elements of two previously disparate methods for post-hoc explanations, global and local explanations, and we make the case that it enjoys advantages of both.
count=81
* Tree in Tree: from Decision Trees to Decision Graphs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/71f6278d140af599e06ad9bf1ba03cb0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/71f6278d140af599e06ad9bf1ba03cb0-Paper.pdf)]
    * Title: Tree in Tree: from Decision Trees to Decision Graphs
    * Year: `2021`
    * Authors: Bingzhao Zhu, Mahsa Shoaran
    * Abstract: Decision trees have been widely used as classifiers in many machine learning applications thanks to their lightweight and interpretable decision process. This paper introduces Tree in Tree decision graph (TnT), a framework that extends the conventional decision tree to a more generic and powerful directed acyclic graph. TnT constructs decision graphs by recursively growing decision trees inside the internal or leaf nodes instead of greedy training. The time complexity of TnT is linear to the number of nodes in the graph, therefore it can construct decision graphs on large datasets. Compared to decision trees, we show that TnT achieves better classification performance with reduced model size, both as a stand-alone classifier and as a base-estimator in bagging/AdaBoost ensembles. Our proposed model is a novel, more efficient and accurate alternative to the widely-used decision trees.
count=79
* Harnessing the power of choices in decision tree learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/fddad60891bdf85aac8041f80ed022df-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/fddad60891bdf85aac8041f80ed022df-Paper-Conference.pdf)]
    * Title: Harnessing the power of choices in decision tree learning
    * Year: `2023`
    * Authors: Guy Blanc, Jane Lange, Chirag Pabbaraju, Colin Sullivan, Li-Yang Tan, Mo Tiwari
    * Abstract: We propose a simple generalization of standard and empirically successful decision tree learning algorithms such as ID3, C4.5, and CART. These algorithms, which have been central to machine learning for decades, are greedy in nature: they grow a decision tree by iteratively splitting on the best attribute. Our algorithm, Top-$k$, considers the $k$ best attributes as possible splits instead of just the single best attribute. We demonstrate, theoretically and empirically, the power of this simple generalization. We first prove a greediness hierarchy theorem showing that for every $k\in \mathbb{N}$, Top-$(k+1)$ can be dramatically more powerful than Top-$k$: there are data distributions for which the former achieves accuracy $1-\epsilon$, whereas the latter only achieves accuracy $\frac{1}{2}+\epsilon$. We then show, through extensive experiments, that Top-$k$ outperforms the two main approaches to decision tree learning: classic greedy algorithms and more recent ``optimal decision tree'' algorithms. On one hand, Top-$k$ consistently enjoys significant accuracy gains over greedy algorithms across a wide range of benchmarks. On the other hand, Top-$k$ is markedly more scalable than optimal decision tree algorithms and is able to handle dataset and feature set sizes that remain far beyond the reach of these algorithms. The code to reproduce our results is available at https://github.com/SullivanC19/pydl8.5-topk.
count=68
* Learning Decision Trees Recurrently Through Communication
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Alaniz_Learning_Decision_Trees_Recurrently_Through_Communication_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Alaniz_Learning_Decision_Trees_Recurrently_Through_Communication_CVPR_2021_paper.pdf)]
    * Title: Learning Decision Trees Recurrently Through Communication
    * Year: `2021`
    * Authors: Stephan Alaniz, Diego Marcos, Bernt Schiele, Zeynep Akata
    * Abstract: Integrated interpretability without sacrificing the prediction accuracy of decision making algorithms has the potential of greatly improving their value to the user. Instead of assigning a label to an image directly, we propose to learn iterative binary sub-decisions, inducing sparsity and transparency in the decision making process. The key aspect of our model is its ability to build a decision tree whose structure is encoded into the memory representation of a Recurrent Neural Network jointly learned by two models communicating through message passing. In addition, our model assigns a semantic meaning to each decision in the form of binary attributes, providing concise, semantic and relevant rationalizations to the user. On three benchmark image classification datasets, including the large-scale ImageNet, our model generates human interpretable binary decision sequences explaining the predictions of the network while maintaining state-of-the-art accuracy.
count=62
* Feature Learning for Interpretable, Performant Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/d1b4076ae067dd23bad5ac2693547a01-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/d1b4076ae067dd23bad5ac2693547a01-Paper-Conference.pdf)]
    * Title: Feature Learning for Interpretable, Performant Decision Trees
    * Year: `2023`
    * Authors: Jack Good, Torin Kovach, Kyle Miller, Artur Dubrawski
    * Abstract: Decision trees are regarded for high interpretability arising from their hierarchical partitioning structure built on simple decision rules. However, in practice, this is not realized because axis-aligned partitioning of realistic data results in deep trees, and because ensemble methods are used to mitigate overfitting. Even then, model complexity and performance remain sensitive to transformation of the input, and extensive expert crafting of features from the raw data is common. We propose the first system to alternate sparse feature learning with differentiable decision tree construction to produce small, interpretable trees with good performance. We benchmark against conventional tree-based models and demonstrate several notions of interpretation of a model and its predictions.
count=60
* Verifiable Reinforcement Learning via Policy Extraction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/e6d8545daa42d5ced125a4bf747b3688-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf)]
    * Title: Verifiable Reinforcement Learning via Policy Extraction
    * Year: `2018`
    * Authors: Osbert Bastani, Yewen Pu, Armando Solar-Lezama
    * Abstract: While deep reinforcement learning has successfully solved many challenging control tasks, its real-world applicability has been limited by the inability to ensure the safety of learned policies. We propose an approach to verifiable reinforcement learning by training decision tree policies, which can represent complex policies (since they are nonparametric), yet can be efficiently verified using existing techniques (since they are highly structured). The challenge is that decision tree policies are difficult to train. We propose VIPER, an algorithm that combines ideas from model compression and imitation learning to learn decision tree policies guided by a DNN policy (called the oracle) and its Q-function, and show that it substantially outperforms two baselines. We use VIPER to (i) learn a provably robust decision tree policy for a variant of Atari Pong with a symbolic state space, (ii) learn a decision tree policy for a toy game based on Pong that provably never loses, and (iii) learn a provably stable decision tree policy for cart-pole. In each case, the decision tree policy achieves performance equal to that of the original DNN policy.
count=57
* A Scalable Deterministic Global Optimization Algorithm for Training Optimal Decision Tree
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/37771cc0be272368102a37f202bb88d8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/37771cc0be272368102a37f202bb88d8-Paper-Conference.pdf)]
    * Title: A Scalable Deterministic Global Optimization Algorithm for Training Optimal Decision Tree
    * Year: `2022`
    * Authors: Kaixun Hua, Jiayang Ren, Yankai Cao
    * Abstract: The training of optimal decision tree via mixed-integer programming (MIP) has attracted much attention in recent literature. However, for large datasets, state-of-the-art approaches struggle to solve the optimal decision tree training problems to a provable global optimal solution within a reasonable time. In this paper, we reformulate the optimal decision tree training problem as a two-stage optimization problem and propose a tailored reduced-space branch and bound algorithm to train optimal decision tree for the classification tasks with continuous features. We present several structure-exploiting lower and upper bounding methods. The computation of bounds can be decomposed into the solution of many small-scale subproblems and can be naturally parallelized. With these bounding methods, we prove that our algorithm can converge by branching only on variables representing the optimal decision tree structure, which is invariant to the size of datasets. Moreover, we propose a novel sample reduction method that can predetermine the cost of part of samples at each BB node. Combining the sample reduction method with the parallelized bounding strategies, our algorithm can be extremely scalable. Our algorithm can find global optimal solutions on dataset with over 245,000 samples (1000 cores, less than 1% optimality gap, within 2 hours). We test 21 real-world datasets from UCI Repository. The results reveal that for datasets with over 7,000 samples, our algorithm can, on average, improve the training accuracy by 3.6% and testing accuracy by 2.8%, compared to the current state-of-the-art.
count=56
* Fair and Optimal Decision Trees: A Dynamic Programming Approach
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/fe248e22b241ae5a9adf11493c8c12bc-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/fe248e22b241ae5a9adf11493c8c12bc-Paper-Conference.pdf)]
    * Title: Fair and Optimal Decision Trees: A Dynamic Programming Approach
    * Year: `2022`
    * Authors: Jacobus van der Linden, Mathijs de Weerdt, Emir Demirović
    * Abstract: Interpretable and fair machine learning models are required for many applications, such as credit assessment and in criminal justice. Decision trees offer this interpretability, especially when they are small. Optimal decision trees are of particular interest because they offer the best performance possible for a given size. However, state-of-the-art algorithms for fair and optimal decision trees have scalability issues, often requiring several hours to find such trees even for small datasets. Previous research has shown that dynamic programming (DP) performs well for optimizing decision trees because it can exploit the tree structure. However, adding a global fairness constraint to a DP approach is not straightforward, because the global constraint violates the condition that subproblems should be independent. We show how such a constraint can be incorporated by introducing upper and lower bounds on final fairness values for partial solutions of subproblems, which enables early comparison and pruning. Our results show that our model can find fair and optimal trees several orders of magnitude faster than previous methods, and now also for larger datasets that were previously beyond reach. Moreover, we show that with this substantial improvement our method can find the full Pareto front in the trade-off between accuracy and fairness.
count=56
* Universal guarantees for decision tree induction via a higher-order splitting criterion
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/6b5617315c9ac918215fc7514bef514b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/6b5617315c9ac918215fc7514bef514b-Paper.pdf)]
    * Title: Universal guarantees for decision tree induction via a higher-order splitting criterion
    * Year: `2020`
    * Authors: Guy Blanc, Neha Gupta, Jane Lange, Li-Yang Tan
    * Abstract: We propose a simple extension of {\sl top-down decision tree learning heuristics} such as ID3, C4.5, and CART. Our algorithm achieves provable guarantees for all target functions $f: \{-1,1\}^n \to \{-1,1\}$ with respect to the uniform distribution, circumventing impossibility results showing that existing heuristics fare poorly even for simple target functions. The crux of our extension is a new splitting criterion that takes into account the correlations between $f$ and {\sl small subsets} of its attributes. The splitting criteria of existing heuristics (e.g. Gini impurity and information gain), in contrast, are based solely on the correlations between $f$ and its {\sl individual} attributes. Our algorithm satisfies the following guarantee: for all target functions $f : \{-1,1\}^n \to \{-1,1\}$, sizes $s\in \N$, and error parameters $\eps$, it constructs a decision tree of size $s^{\tilde{O}((\log s)^2/\eps^2)}$ that achieves error $\le O(\opt_s) + \eps$, where $\opt_s$ denotes the error of the optimal size-$s$ decision tree for $f$. A key technical notion that drives our analysis is the {\sl noise stability} of $f$, a well-studied smoothness measure of $f$.
count=55
* Decision trees as partitioning machines to characterize their generalization properties
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/d2a10b0bd670e442b1d3caa3fbf9e695-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/d2a10b0bd670e442b1d3caa3fbf9e695-Paper.pdf)]
    * Title: Decision trees as partitioning machines to characterize their generalization properties
    * Year: `2020`
    * Authors: Jean-Samuel Leboeuf, Frédéric LeBlanc, Mario Marchand
    * Abstract: Decision trees are popular machine learning models that are simple to build and easy to interpret. Even though algorithms to learn decision trees date back to almost 50 years, key properties affecting their generalization error are still weakly bounded. Hence, we revisit binary decision trees on real-valued features from the perspective of partitions of the data. We introduce the notion of partitioning function, and we relate it to the growth function and to the VC dimension. Using this new concept, we are able to find the exact VC dimension of decision stumps, which is given by the largest integer $d$ such that $2\ell \ge \binom{d}{\floor{\frac{d}{2}}}$, where $\ell$ is the number of real-valued features. We provide a recursive expression to bound the partitioning functions, resulting in a upper bound on the growth function of any decision tree structure. This allows us to show that the VC dimension of a binary tree structure with $N$ internal nodes is of order $N \log(N\ell)$. Finally, we elaborate a pruning algorithm based on these results that performs better than the CART algorithm on a number of datasets, with the advantage that no cross-validation is required.
count=53
* Interpreting CNNs via Decision Trees
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Interpreting_CNNs_via_Decision_Trees_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Interpreting_CNNs_via_Decision_Trees_CVPR_2019_paper.pdf)]
    * Title: Interpreting CNNs via Decision Trees
    * Year: `2019`
    * Authors: Quanshi Zhang,  Yu Yang,  Haotian Ma,  Ying Nian Wu
    * Abstract: This paper aims to quantitatively explain the rationales of each prediction that is made by a pre-trained convolutional neural network (CNN). We propose to learn a decision tree, which clarifies the specific reason for each prediction made by the CNN at the semantic level. I.e., the decision tree decomposes feature representations in high conv-layers of the CNN into elementary concepts of object parts. In this way, the decision tree tells people which object parts activate which filters for the prediction and how much each object part contributes to the prediction score. Such semantic and quantitative explanations for CNN predictions have specific values beyond the traditional pixel-level analysis of CNNs. More specifically, our method mines all potential decision modes of the CNN, where each mode represents a typical case of how the CNN uses object parts for prediction. The decision tree organizes all potential decision modes in a coarse-to-fine manner to explain CNN predictions at different fine-grained levels. Experiments have demonstrated the effectiveness of the proposed method.
count=51
* Decision Trees with Short Explainable Rules
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/500637d931d4feb99d5cce84af1f53ba-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/500637d931d4feb99d5cce84af1f53ba-Paper-Conference.pdf)]
    * Title: Decision Trees with Short Explainable Rules
    * Year: `2022`
    * Authors: Victor Feitosa Souza, Ferdinando Cicalese, Eduardo Laber, Marco Molinaro
    * Abstract: Decision trees are widely used in many settings where interpretable models are preferred or required. As confirmed by recent empirical studies, the interpretability/explanability of a decision tree critically depends on some of its structural parameters, like size and the average/maximum depth of its leaves. There is indeed a vast literature on the design and analysis of decision tree algorithms that aim at optimizing these parameters.This paper contributes to this important line of research: we propose as a novel criterion of measuring the interpretability of a decision tree, the sparsity of the set of attributes that are (on average) required to explain the classification of the examples. We give a tight characterization of the best possible guarantees achievable by a decision tree built to optimize both our newmeasure (which we call the {\em explanation size}) and the more classical measures of worst-case and average depth. In particular, we give an algorithm that guarantees $O(\ln n )$-approximation (hence optimal if $P \neq NP$) for the minimization of both the average/worst-case explanation size and the average/worst-case depth. In addition to our theoretical contributions, experiments with 20 real datasets show that our algorithm has accuracy competitive with CART while producing trees that allow for much simpler explanations.
count=49
* Convex Polytope Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/285a25c17f351708754cdb6d56f3962e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/285a25c17f351708754cdb6d56f3962e-Paper.pdf)]
    * Title: Convex Polytope Trees
    * Year: `2021`
    * Authors: Mohammadreza Armandpour, Ali Sadeghian, Mingyuan Zhou
    * Abstract: A decision tree is commonly restricted to use a single hyperplane to split the covariate space at each of its internal nodes. It often requires a large number of nodes to achieve high accuracy. In this paper, we propose convex polytope trees (CPT) to expand the family of decision trees by an interpretable generalization of their decision boundary. The splitting function at each node of CPT is based on the logical disjunction of a community of differently weighted probabilistic linear decision-makers, which also geometrically corresponds to a convex polytope in the covariate space. We use a nonparametric Bayesian prior at each node to infer the community's size, encouraging simpler decision boundaries by shrinking the number of polytope facets. We develop a greedy method to efficiently construct CPT and scalable end-to-end training algorithms for the tree parameters when the tree structure is given. We empirically demonstrate the efficiency of CPT over existing state-of-the-art decision trees in several real-world classification and regression tasks from diverse domains.
count=48
* On Computing Probabilistic Explanations for Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/b8963f6a0a72e686dfa98ac3e7260f73-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/b8963f6a0a72e686dfa98ac3e7260f73-Paper-Conference.pdf)]
    * Title: On Computing Probabilistic Explanations for Decision Trees
    * Year: `2022`
    * Authors: Marcelo Arenas, Pablo Barceló, Miguel Romero Orth, Bernardo Subercaseaux
    * Abstract: Formal XAI (explainable AI) is a growing area that focuses on computing explanations with mathematical guarantees for the decisions made by ML models. Inside formal XAI, one of the most studied cases is that of explaining the choices taken by decision trees, as they are traditionally deemed as one of the most interpretable classes of models. Recent work has focused on studying the computation of sufficient reasons, a kind of explanation in which given a decision tree $T$ and an instance $x$, one explains the decision $T(x)$ by providing a subset $y$ of the features of $x$ such that for any other instance $z$ compatible with $y$, it holds that $T(z) = T(x)$, intuitively meaning that the features in $y$ are already enough to fully justify the classification of $x$ by $T$. It has been argued, however, that sufficient reasons constitute a restrictive notion of explanation. For such a reason, the community has started to study their probabilistic counterpart, in which one requires that the probability of $T(z) = T(x)$ must be at least some value $\delta \in (0, 1]$, where $z$ is a random instance that is compatible with $y$. Our paper settles the computational complexity of $\delta$-sufficient-reasons over decision trees, showing that both (1) finding $\delta$-sufficient-reasons that are minimal in size, and (2) finding $\delta$-sufficient-reasons that are minimal inclusion-wise, do not admit polynomial-time algorithms (unless P = NP). This is in stark contrast with the deterministic case ($\delta = 1$) where inclusion-wise minimal sufficient-reasons are easy to compute. By doing this, we answer two open problems originally raised by Izza et al., and extend the hardness of explanations for Boolean circuits presented by W{\"a}ldchen et al. to the more restricted case of decision trees. On the positive side, we identify structural restrictions of decision trees that make the problem tractable, and show how SAT solvers might be able to tackle these problems in practical settings.
count=45
* Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Straehle_Weakly_Supervised_Learning_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Straehle_Weakly_Supervised_Learning_2013_ICCV_paper.pdf)]
    * Title: Weakly Supervised Learning of Image Partitioning Using Decision Trees with Structured Split Criteria
    * Year: `2013`
    * Authors: Christoph Straehle, Ullrich Koethe, Fred A. Hamprecht
    * Abstract: We propose a scheme that allows to partition an image into a previously unknown number of segments, using only minimal supervision in terms of a few must-link and cannotlink annotations. We make no use of regional data terms, learning instead what constitutes a likely boundary between segments. Since boundaries are only implicitly specified through cannot-link constraints, this is a hard and nonconvex latent variable problem. We address this problem in a greedy fashion using a randomized decision tree on features associated with interpixel edges. We use a structured purity criterion during tree construction and also show how a backtracking strategy can be used to prevent the greedy search from ending up in poor local optima. The proposed strategy is compared with prior art on natural images.
count=42
* Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Dong_Robust_Neural_Routing_Through_Space_Partitions_for_Camera_Relocalization_in_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Dong_Robust_Neural_Routing_Through_Space_Partitions_for_Camera_Relocalization_in_CVPR_2021_paper.pdf)]
    * Title: Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments
    * Year: `2021`
    * Authors: Siyan Dong, Qingnan Fan, He Wang, Ji Shi, Li Yi, Thomas Funkhouser, Baoquan Chen, Leonidas J. Guibas
    * Abstract: Localizing the camera in a known indoor environment is a key building block for scene mapping, robot navigation, AR, etc. Recent advances estimate the camera pose via optimization over the 2D/3D-3D correspondences established between the coordinates in 2D/3D camera space and 3D world space. Such a mapping is estimated with either a convolution neural network or a decision tree using only the static input image sequence, which makes these approaches vulnerable to dynamic indoor environments that are quite common yet challenging in the real world. To address the aforementioned issues, in this paper, we propose a novel outlier-aware neural tree which bridges the two worlds, deep learning and decision tree approaches. It builds on three important blocks: (a) a hierarchical space partition over the indoor scene to construct the decision tree; (b) a neural routing function, implemented as a deep classification network, employed for better 3D scene understanding; and (c) an outlier rejection module used to filter out dynamic points during the hierarchical routing process. Our proposed algorithm is evaluated on the RIO-10 benchmark developed for camera relocalization in dynamic indoor environments. It achieves robust neural routing through space partitions and outperforms the state-of-the-art approaches by around 30% on camera pose accuracy, while running comparably fast for evaluation.
count=41
* Efficient Non-greedy Optimization of Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/1579779b98ce9edb98dd85606f2c119d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/1579779b98ce9edb98dd85606f2c119d-Paper.pdf)]
    * Title: Efficient Non-greedy Optimization of Decision Trees
    * Year: `2015`
    * Authors: Mohammad Norouzi, Maxwell Collins, Matthew A. Johnson, David J. Fleet, Pushmeet Kohli
    * Abstract: Decision trees and randomized forests are widely used in computer vision and machine learning. Standard algorithms for decision tree induction optimize the split functions one node at a time according to some splitting criteria. This greedy procedure often leads to suboptimal trees. In this paper, we present an algorithm for optimizing the split functions at all levels of the tree jointly with the leaf parameters, based on a global objective. We show that the problem of finding optimal linear-combination (oblique) splits for decision trees is related to structured prediction with latent variables, and we formulate a convex-concave upper bound on the tree's empirical loss. Computing the gradient of the proposed surrogate objective with respect to each training exemplar is O(d^2), where d is the tree depth, and thus training deep trees is feasible. The use of stochastic gradient descent for optimization enables effective training with large datasets. Experiments on several classification benchmarks demonstrate that the resulting non-greedy decision trees outperform greedy decision tree baselines.
count=40
* Optimal Sparse Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/ac52c626afc10d4075708ac4c778ddfc-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/ac52c626afc10d4075708ac4c778ddfc-Paper.pdf)]
    * Title: Optimal Sparse Decision Trees
    * Year: `2019`
    * Authors: Xiyang Hu, Cynthia Rudin, Margo Seltzer
    * Abstract: Decision tree algorithms have been among the most popular algorithms for interpretable (transparent) machine learning since the early 1980's. The problem that has plagued decision tree algorithms since their inception is their lack of optimality, or lack of guarantees of closeness to optimality: decision tree algorithms are often greedy or myopic, and sometimes produce unquestionably suboptimal models. Hardness of decision tree optimization is both a theoretical and practical obstacle, and even careful mathematical programming approaches have not been able to solve these problems efficiently. This work introduces the first practical algorithm for optimal decision trees for binary variables. The algorithm is a co-design of analytical bounds that reduce the search space and modern systems techniques, including data structures and a custom bit-vector library. We highlight possible steps to improving the scalability and speed of future generations of this algorithm based on insights from our theory and experiments.
count=40
* A Communication-Efficient Parallel Algorithm for Decision Tree
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/10a5ab2db37feedfdeaab192ead4ac0e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/10a5ab2db37feedfdeaab192ead4ac0e-Paper.pdf)]
    * Title: A Communication-Efficient Parallel Algorithm for Decision Tree
    * Year: `2016`
    * Authors: Qi Meng, Guolin Ke, Taifeng Wang, Wei Chen, Qiwei Ye, Zhi-Ming Ma, Tie-Yan Liu
    * Abstract: Decision tree (and its extensions such as Gradient Boosting Decision Trees and Random Forest) is a widely used machine learning algorithm, due to its practical effectiveness and model interpretability. With the emergence of big data, there is an increasing need to parallelize the training process of decision tree. However, most existing attempts along this line suffer from high communication costs. In this paper, we propose a new algorithm, called \emph{Parallel Voting Decision Tree (PV-Tree)}, to tackle this challenge. After partitioning the training data onto a number of (e.g., $M$) machines, this algorithm performs both local voting and global voting in each iteration. For local voting, the top-$k$ attributes are selected from each machine according to its local data. Then, the indices of these top attributes are aggregated by a server, and the globally top-$2k$ attributes are determined by a majority voting among these local candidates. Finally, the full-grained histograms of the globally top-$2k$ attributes are collected from local machines in order to identify the best (most informative) attribute and its split point. PV-Tree can achieve a very low communication cost (independent of the total number of attributes) and thus can scale out very well. Furthermore, theoretical analysis shows that this algorithm can learn a near optimal decision tree, since it can find the best attribute with a large probability. Our experiments on real-world datasets show that PV-Tree significantly outperforms the existing parallel decision tree algorithms in the tradeoff between accuracy and efficiency.
count=36
* Decision Tree for Locally Private Estimation with Public Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/88237ac4e9941b1be5c6d3c1ad408184-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/88237ac4e9941b1be5c6d3c1ad408184-Paper-Conference.pdf)]
    * Title: Decision Tree for Locally Private Estimation with Public Data
    * Year: `2023`
    * Authors: Yuheng Ma, Han Zhang, Yuchao Cai, Hanfang Yang
    * Abstract: We propose conducting locally differentially private (LDP) estimation with the aid of a small amount of public data to enhance the performance of private estimation. Specifically, we introduce an efficient algorithm called Locally differentially Private Decision Tree (LPDT) for LDP regression. We first use the public data to grow a decision tree partition and then fit an estimator according to the partition privately. From a theoretical perspective, we show that LPDT is $\varepsilon$-LDP and has a mini-max optimal convergence rate under a mild assumption of similarity between public and private data, whereas the lower bound of the convergence rate of LPDT without public data is strictly slower, which implies that the public data helps to improve the convergence rates of LDP estimation. We conduct experiments on both synthetic and real-world data to demonstrate the superior performance of LPDT compared with other state-of-the-art LDP regression methods. Moreover, we show that LPDT remains effective despite considerable disparities between public and private data.
count=36
* Coresets for Decision Trees of Signals
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/fea9c11c4ad9a395a636ed944a28b51a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/fea9c11c4ad9a395a636ed944a28b51a-Paper.pdf)]
    * Title: Coresets for Decision Trees of Signals
    * Year: `2021`
    * Authors: Ibrahim Jubran, Ernesto Evgeniy Sanches Shayda, Ilan I Newman, Dan Feldman
    * Abstract: A $k$-decision tree $t$ (or $k$-tree) is a recursive partition of a matrix (2D-signal) into $k\geq 1$ block matrices (axis-parallel rectangles, leaves) where each rectangle is assigned a real label. Its regression or classification loss to a given matrix $D$ of $N$ entries (labels) is the sum of squared differences over every label in $D$ and its assigned label by $t$.Given an error parameter $\varepsilon\in(0,1)$, a $(k,\varepsilon)$-coreset $C$ of $D$ is a small summarization that provably approximates this loss to \emph{every} such tree, up to a multiplicative factor of $1\pm\varepsilon$. In particular, the optimal $k$-tree of $C$ is a $(1+\varepsilon)$-approximation to the optimal $k$-tree of $D$.We provide the first algorithm that outputs such a $(k,\varepsilon)$-coreset for \emph{every} such matrix $D$. The size $|C|$ of the coreset is polynomial in $k\log(N)/\varepsilon$, and its construction takes $O(Nk)$ time.This is by forging a link between decision trees from machine learning -- to partition trees in computational geometry. Experimental results on \texttt{sklearn} and \texttt{lightGBM} show that applying our coresets on real-world data-sets boosts the computation time of random forests and their parameter tuning by up to x$10$, while keeping similar accuracy. Full open source code is provided.
count=35
* Exploring the Whole Rashomon Set of Sparse Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/5afaa8b4dd18eb1eed055d2d821b58ae-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/5afaa8b4dd18eb1eed055d2d821b58ae-Paper-Conference.pdf)]
    * Title: Exploring the Whole Rashomon Set of Sparse Decision Trees
    * Year: `2022`
    * Authors: Rui Xin, Chudi Zhong, Zhi Chen, Takuya Takagi, Margo Seltzer, Cynthia Rudin
    * Abstract: In any given machine learning problem, there may be many models that could explain the data almost equally well. However, most learning algorithms return only one of these models, leaving practitioners with no practical way to explore alternative models that might have desirable properties beyond what could be expressed within a loss function. The Rashomon set is the set of these all almost-optimal models. Rashomon sets can be extremely complicated, particularly for highly nonlinear function classes that allow complex interaction terms, such as decision trees. We provide the first technique for completely enumerating the Rashomon set for sparse decision trees; in fact, our work provides the first complete enumeration of any Rashomon set for a non-trivial problem with a highly nonlinear discrete function class. This allows the user an unprecedented level of control over model choice among all models that are approximately equally good. We represent the Rashomon set in a specialized data structure that supports efficient querying and sampling. We show three applications of the Rashomon set: 1) it can be used to study variable importance for the set of almost-optimal trees (as opposed to a single tree), 2) the Rashomon set for accuracy enables enumeration of the Rashomon sets for balanced accuracy and F1-score, and 3) the Rashomon set for a full dataset can be used to produce Rashomon sets constructed with only subsets of the data set. Thus, we are able to examine Rashomon sets across problems with a new lens, enabling users to choose models rather than be at the mercy of an algorithm that produces only a single model.
count=35
* Certifying Robustness to Programmable Data Bias in Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/dcf531edc9b229acfe0f4b87e1e278dd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/dcf531edc9b229acfe0f4b87e1e278dd-Paper.pdf)]
    * Title: Certifying Robustness to Programmable Data Bias in Decision Trees
    * Year: `2021`
    * Authors: Anna Meyer, Aws Albarghouthi, Loris D'Antoni
    * Abstract: Datasets can be biased due to societal inequities, human biases, under-representation of minorities, etc. Our goal is to certify that models produced by a learning algorithm are pointwise-robust to dataset biases. This is a challenging problem: it entails learning models for a large, or even infinite, number of datasets, ensuring that they all produce the same prediction. We focus on decision-tree learning due to the interpretable nature of the models. Our approach allows programmatically specifying \emph{bias models} across a variety of dimensions (e.g., label-flipping or missing data), composing types of bias, and targeting bias towards a specific group. To certify robustness, we use a novel symbolic technique to evaluate a decision-tree learner on a large, or infinite, number of datasets, certifying that each and every dataset produces the same prediction for a specific test point. We evaluate our approach on datasets that are commonly used in the fairness literature, and demonstrate our approach's viability on a range of bias models.
count=35
* A Scalable MIP-based Method for Learning Optimal Multivariate Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/1373b284bc381890049e92d324f56de0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/1373b284bc381890049e92d324f56de0-Paper.pdf)]
    * Title: A Scalable MIP-based Method for Learning Optimal Multivariate Decision Trees
    * Year: `2020`
    * Authors: Haoran Zhu, Pavankumar Murali, Dzung Phan, Lam Nguyen, Jayant Kalagnanam
    * Abstract: Several recent publications report advances in training optimal decision trees (ODTs) using mixed-integer programs (MIPs), due to algorithmic advances in integer programming and a growing interest in addressing the inherent suboptimality of heuristic approaches such as CART. In this paper, we propose a novel MIP formulation, based on 1-norm support vector machine model, to train a binary oblique ODT for classification problems. We further present techniques, such as cutting planes, to tighten its linear relaxation, to improve run times to reach optimality. Using 36 datasets from the University of California Irvine Machine Learning Repository, we demonstrate that our training approach outperforms its counterparts from literature in terms of out-of-sample performance (around 10% improvement in mean out-of-sample testing accuracy). Towards our goal of developing a scalable framework to train multivariate ODT on large datasets, we propose a new linear programming based data selection method to choose a subset of the data, and use it to train a decision tree through our proposed MIP model. We conclude this paper with extensive numerical testing results, that showcase the generalization performance of our new MIP formulation, and the improvement in mean out-of-sample accuracy on large datasets.
count=34
* Estimating decision tree learnability with polylogarithmic sample complexity
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/439d8c975f26e5005dcdbf41b0d84161-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/439d8c975f26e5005dcdbf41b0d84161-Paper.pdf)]
    * Title: Estimating decision tree learnability with polylogarithmic sample complexity
    * Year: `2020`
    * Authors: Guy Blanc, Neha Gupta, Jane Lange, Li-Yang Tan
    * Abstract: We show that top-down decision tree learning heuristics (such as ID3, C4.5, and CART) are amenable to highly efficient {\sl learnability estimation}: for monotone target functions, the error of the decision tree hypothesis constructed by these heuristics can be estimated with {\sl polylogarithmically} many labeled examples, exponentially smaller than the number necessary to run these heuristics, and indeed, exponentially smaller than information-theoretic minimum required to learn a good decision tree. This adds to a small but growing list of fundamental learning algorithms that have been shown to be amenable to learnability estimation. En route to this result, we design and analyze sample-efficient {\sl minibatch} versions of top-down decision tree learning heuristics and show that they achieve the same provable guarantees as the full-batch versions. We further give ``active local'' versions of these heuristics: given a test point $x^\star$, we show how the label $T(x^\star)$ of the decision tree hypothesis $T$ can be computed with polylogarithmically many labeled examples, exponentially smaller than the number necessary to learn~$T$.
count=33
* The Utility of Explainable AI in Ad Hoc Human-Machine Teaming
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/05d74c48b5b30514d8e9bd60320fc8f6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/05d74c48b5b30514d8e9bd60320fc8f6-Paper.pdf)]
    * Title: The Utility of Explainable AI in Ad Hoc Human-Machine Teaming
    * Year: `2021`
    * Authors: Rohan Paleja, Muyleng Ghuy, Nadun Ranawaka Arachchige, Reed Jensen, Matthew Gombolay
    * Abstract: Recent advances in machine learning have led to growing interest in Explainable AI (xAI) to enable humans to gain insight into the decision-making of machine learning models. Despite this recent interest, the utility of xAI techniques has not yet been characterized in human-machine teaming. Importantly, xAI offers the promise of enhancing team situational awareness (SA) and shared mental model development, which are the key characteristics of effective human-machine teams. Rapidly developing such mental models is especially critical in ad hoc human-machine teaming, where agents do not have a priori knowledge of others' decision-making strategies. In this paper, we present two novel human-subject experiments quantifying the benefits of deploying xAI techniques within a human-machine teaming scenario. First, we show that xAI techniques can support SA ($p<0.05)$. Second, we examine how different SA levels induced via a collaborative AI policy abstraction affect ad hoc human-machine teaming performance. Importantly, we find that the benefits of xAI are not universal, as there is a strong dependence on the composition of the human-machine team. Novices benefit from xAI providing increased SA ($p<0.05$) but are susceptible to cognitive overhead ($p<0.05$). On the other hand, expert performance degrades with the addition of xAI-based support ($p<0.05$), indicating that the cost of paying attention to the xAI outweighs the benefits obtained from being provided additional information to enhance SA. Our results demonstrate that researchers must deliberately design and deploy the right xAI techniques in the right scenario by carefully considering human-machine team composition and how the xAI method augments SA.
count=33
* Foundations of Symbolic Languages for Model Interpretability
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/60cb558c40e4f18479664069d9642d5a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/60cb558c40e4f18479664069d9642d5a-Paper.pdf)]
    * Title: Foundations of Symbolic Languages for Model Interpretability
    * Year: `2021`
    * Authors: Marcelo Arenas, Daniel Báez, Pablo Barceló, Jorge Pérez, Bernardo Subercaseaux
    * Abstract: Several queries and scores have recently been proposed to explain individual predictions over ML models. Examples include queries based on “anchors”, which are parts of an instance that are sufficient to justify its classification, and “feature-perturbation” scores such as SHAP. Given the need for flexible, reliable, and easy-to-apply interpretability methods for ML models, we foresee the need for developing declarative languages to naturally specify different explainability queries. We do this in a principled way by rooting such a language in a logic called FOIL, which allows for expressing many simple but important explainability queries, and might serve as a core for more expressive interpretability languages. We study the computational complexity of FOIL queries over two classes of ML models often deemed to be easily interpretable: decision trees and more general decision diagrams. Since the number of possible inputs for an ML model is exponential in its dimension, tractability of the FOIL evaluation problem is delicate but can be achieved by either restricting the structure of the models, or the fragment of FOIL being evaluated. We also present a prototype implementation of FOIL wrapped in a high-level declarative language and perform experiments showing that such a language can be used in practice.
count=32
* Multi-Label Learning of Part Detectors for Heavily Occluded Pedestrian Detection
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Zhou_Multi-Label_Learning_of_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhou_Multi-Label_Learning_of_ICCV_2017_paper.pdf)]
    * Title: Multi-Label Learning of Part Detectors for Heavily Occluded Pedestrian Detection
    * Year: `2017`
    * Authors: Chunluan Zhou, Junsong Yuan
    * Abstract: Detecting pedestrians that are partially occluded remains a challenging problem due to variations and uncertainties of partial occlusion patterns. Following a commonly used framework of handling partial occlusions by part detection, we propose a multi-label learning approach to jointly learn part detectors to capture partial occlusion patterns. The part detectors share a set of decision trees via boosting to exploit part correlations and also reduce the computational cost of applying these part detectors. The learned decision trees capture the overall distribution of all the parts. When used as a pedestrian detector individually, our part detectors learned jointly show better performance than their counterparts learned separately in different occlusion situations. The learned part detectors can be further integrated to better detect partially occluded pedestrians. Experiments on the Caltech dataset show state-of-the-art performance of our approach for detecting heavily occluded pedestrians.
count=32
* On the Gini-impurity Preservation For Privacy Random Forests
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/8d6b1d775014eff18256abeb207202ad-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/8d6b1d775014eff18256abeb207202ad-Paper-Conference.pdf)]
    * Title: On the Gini-impurity Preservation For Privacy Random Forests
    * Year: `2023`
    * Authors: XinRan Xie, Man-Jie Yuan, Xuetong Bai, Wei Gao, Zhi-Hua Zhou
    * Abstract: Random forests have been one successful ensemble algorithms in machine learning. Various techniques have been utilized to preserve the privacy of random forests from anonymization, differential privacy, homomorphic encryption, etc., whereas it rarely takes into account some crucial ingredients of learning algorithm. This work presents a new encryption to preserve data's Gini impurity, which plays a crucial role during the construction of random forests. Our basic idea is to modify the structure of binary search tree to store several examples in each node, and encrypt data features by incorporating label and order information. Theoretically, we prove that our scheme preserves the minimum Gini impurity in ciphertexts without decrypting, and present the security guarantee for encryption. For random forests, we encrypt data features based on our Gini-impurity-preserving scheme, and take the homomorphic encryption scheme CKKS to encrypt data labels due to their importance and privacy. We conduct extensive experiments to show the effectiveness, efficiency and security of our proposed method.
count=32
* Decision Jungles: Compact and Rich Models for Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/69adc1e107f7f7d035d7baf04342e1ca-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/69adc1e107f7f7d035d7baf04342e1ca-Paper.pdf)]
    * Title: Decision Jungles: Compact and Rich Models for Classification
    * Year: `2013`
    * Authors: Jamie Shotton, Toby Sharp, Pushmeet Kohli, Sebastian Nowozin, John Winn, Antonio Criminisi
    * Abstract: Randomized decision trees and forests have a rich history in machine learning and have seen considerable success in application, perhaps particularly so for computer vision. However, they face a fundamental limitation: given enough data, the number of nodes in decision trees will grow exponentially with depth. For certain applications, for example on mobile or embedded processors, memory is a limited resource, and so the exponential growth of trees limits their depth, and thus their potential accuracy. This paper proposes decision jungles, revisiting the idea of ensembles of rooted decision directed acyclic graphs (DAGs), and shows these to be compact and powerful discriminative models for classification. Unlike conventional decision trees that only allow one path to every node, a DAG in a decision jungle allows multiple paths from the root to each leaf. We present and compare two new node merging algorithms that jointly optimize both the features and the structure of the DAGs efficiently. During training, node splitting and node merging are driven by the minimization of exactly the same objective function, here the weighted sum of entropies at the leaves. Results on varied datasets show that, compared to decision forests and several other baselines, decision jungles require dramatically less memory while considerably improving generalization.
count=31
* Context-Sensitive Decision Forests for Object Detection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/bcbe3365e6ac95ea2c0343a2395834dd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/bcbe3365e6ac95ea2c0343a2395834dd-Paper.pdf)]
    * Title: Context-Sensitive Decision Forests for Object Detection
    * Year: `2012`
    * Authors: Peter Kontschieder, Samuel Bulò, Antonio Criminisi, Pushmeet Kohli, Marcello Pelillo, Horst Bischof
    * Abstract: In this paper we introduce Context-Sensitive Decision Forests - A new perspective to exploit contextual information in the popular decision forest framework for the object detection problem. They are tree-structured classifiers with the ability to access intermediate prediction (here: classification and regression) information during training and inference time. This intermediate prediction is available to each sample, which allows us to develop context-based decision criteria, used for refining the prediction process. In addition, we introduce a novel split criterion which in combination with a priority based way of constructing the trees, allows more accurate regression mode selection and hence improves the current context information. In our experiments, we demonstrate improved results for the task of pedestrian detection on the challenging TUD data set when compared to state-of-the-art methods.
count=29
* Fast Supervised Hashing with Decision Trees for High-Dimensional Data
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Lin_Fast_Supervised_Hashing_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Lin_Fast_Supervised_Hashing_2014_CVPR_paper.pdf)]
    * Title: Fast Supervised Hashing with Decision Trees for High-Dimensional Data
    * Year: `2014`
    * Authors: Guosheng Lin, Chunhua Shen, Qinfeng Shi, Anton van den Hengel, David Suter
    * Abstract: Supervised hashing aims to map the original features to compact binary codes that are able to preserve label based similarity in the Hamming space. Non-linear hash functions have demonstrated their advantage over linear ones due to their powerful generalization capability. In the literature, kernel functions are typically used to achieve non-linearity in hashing, which achieve encouraging retrieval performance at the price of slow evaluation and training time. Here we propose to use boosted decision trees for achieving non-linearity in hashing, which are fast to train and evaluate, hence more suitable for hashing with high dimensional data. In our approach, we first propose sub-modular formulations for the hashing binary code inference problem and an efficient GraphCut based block search method for solving large-scale inference. Then we learn hash functions by training boosted decision trees to fit the binary codes. Experiments demonstrate that our proposed method significantly outperforms most state-of-the-art methods in retrieval precision and training time. Especially for high-dimensional data, our method is orders of magnitude faster than many methods in terms of training time.
count=29
* Semi-Supervised Learning with Decision Trees: Graph Laplacian Tree Alternating Optimization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/104f7b25495a0e40e65fb7c7eee37ed9-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/104f7b25495a0e40e65fb7c7eee37ed9-Paper-Conference.pdf)]
    * Title: Semi-Supervised Learning with Decision Trees: Graph Laplacian Tree Alternating Optimization
    * Year: `2022`
    * Authors: Arman Zharmagambetov, Miguel A. Carreira-Perpinan
    * Abstract: Semi-supervised learning seeks to learn a machine learning model when only a small amount of the available data is labeled. The most widespread approach uses a graph prior, which encourages similar instances to have similar predictions. This has been very successful with models ranging from kernel machines to neural networks, but has remained inapplicable to decision trees, for which the optimization problem is much harder. We solve this based on a reformulation of the problem which requires iteratively solving two simpler problems: a supervised tree learning problem, which can be solved by the Tree Alternating Optimization algorithm; and a label smoothing problem, which can be solved through a sparse linear system. The algorithm is scalable and highly effective even with very few labeled instances, and makes it possible to learn accurate, interpretable models based on decision trees in such situations.
count=28
* When Do Neural Nets Outperform Boosted Trees on Tabular Data?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/f06d5ebd4ff40b40dd97e30cee632123-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/f06d5ebd4ff40b40dd97e30cee632123-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: When Do Neural Nets Outperform Boosted Trees on Tabular Data?
    * Year: `2023`
    * Authors: Duncan McElfresh, Sujay Khandagale, Jonathan Valverde, Vishak Prasad C, Ganesh Ramakrishnan, Micah Goldblum, Colin White
    * Abstract: Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and question the importance of this debate. To this end, we conduct the largest tabular data analysis to date, comparing 19 algorithms across 176 datasets, and we find that the 'NN vs. GBDT' debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than choosing between NNs and GBDTs. Next, we analyze dozens of metafeatures to determine what \emph{properties} of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better than NNs at handling skewed or heavy-tailed feature distributions and other forms of dataset irregularities. Our insights act as a guide for practitioners to determine which techniques may work best on their dataset. Finally, with the goal of accelerating tabular data research, we release the TabZilla Benchmark Suite: a collection of the 36 'hardest' of the datasets we study. Our benchmark suite, codebase, and all raw results are available at https://github.com/naszilla/tabzilla.
count=27
* Neural Prototype Trees for Interpretable Fine-Grained Image Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.pdf)]
    * Title: Neural Prototype Trees for Interpretable Fine-Grained Image Recognition
    * Year: `2021`
    * Authors: Meike Nauta, Ron van Bree, Christin Seifert
    * Abstract: Prototype-based methods use interpretable representations to address the black-box nature of deep learning models, in contrast to post-hoc explanation methods that only approximate such models. We propose the Neural Prototype Tree (ProtoTree), an intrinsically interpretable deep learning method for fine-grained image recognition. ProtoTree combines prototype learning with decision trees, and thus results in a globally interpretable model by design. Additionally, ProtoTree can locally explain a single prediction by outlining a decision path through the tree. Each node in our binary tree contains a trainable prototypical part. The presence or absence of this learned prototype in an image determines the routing through a node. Decision making is therefore similar to human reasoning: Does the bird have a red throat? And an elongated beak? Then it's a hummingbird! We tune the accuracy-interpretability trade-off using ensemble methods, pruning and binarizing. We apply pruning without sacrificing accuracy, resulting in a small tree with only 8 learned prototypes along a path to classify a bird from 200 species. An ensemble of 5 ProtoTrees achieves competitive accuracy on the CUB-200- 2011 and Stanford Cars data sets. Code is available at https://github.com/M-Nauta/ProtoTree.
count=27
* Learning Online Smooth Predictors for Realtime Camera Planning Using Recurrent Decision Trees
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Chen_Learning_Online_Smooth_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Chen_Learning_Online_Smooth_CVPR_2016_paper.pdf)]
    * Title: Learning Online Smooth Predictors for Realtime Camera Planning Using Recurrent Decision Trees
    * Year: `2016`
    * Authors: Jianhui Chen, Hoang M. Le, Peter Carr, Yisong Yue, James J. Little
    * Abstract: We study the problem of online prediction for realtime camera planning, where the goal is to predict smooth trajectories that correctly track and frame objects of interest (e.g., players in a basketball game). The conventional approach for training predictors does not directly consider temporal consistency, and often produces undesirable jitter. Although post-hoc smoothing (e.g., via a Kalman filter) can mitigate this issue to some degree, it is not ideal due to overly stringent modeling assumptions (e.g., Gaussian noise). We propose a recurrent decision tree framework that can directly incorporate temporal consistency into a data-driven predictor, as well as a learning algorithm that can efficiently learn such temporally smooth models. Our approach does not require any post-processing, making online smooth predictions much easier to generate when the noise model is unknown. We apply our approach to sports broadcasting: given noisy player detections, we learn where the camera should look based on human demonstrations. Our experiments exhibit significant improvements over conventional baselines and showcase the practicality of our approach.
count=27
* Tree Variational Autoencoders
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/ac58b418745b3e5f10c80110c963969f-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/ac58b418745b3e5f10c80110c963969f-Paper-Conference.pdf)]
    * Title: Tree Variational Autoencoders
    * Year: `2023`
    * Authors: Laura Manduchi, Moritz Vandenhirtz, Alain Ryser, Julia Vogt
    * Abstract: We propose Tree Variational Autoencoder (TreeVAE), a new generative hierarchical clustering model that learns a flexible tree-based posterior distribution over latent variables. TreeVAE hierarchically divides samples according to their intrinsic characteristics, shedding light on hidden structures in the data. It adapts its architecture to discover the optimal tree for encoding dependencies between latent variables. The proposed tree-based generative architecture enables lightweight conditional inference and improves generative performance by utilizing specialized leaf decoders. We show that TreeVAE uncovers underlying clusters in the data and finds meaningful hierarchical relations between the different groups on a variety of datasets, including real-world imaging data. We present empirically that TreeVAE provides a more competitive log-likelihood lower bound than the sequential counterparts. Finally, due to its generative nature, TreeVAE is able to generate new samples from the discovered clusters via conditional sampling.
count=27
* Mondrian Forests: Efficient Online Random Forests
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/d1dc3a8270a6f9394f88847d7f0050cf-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/d1dc3a8270a6f9394f88847d7f0050cf-Paper.pdf)]
    * Title: Mondrian Forests: Efficient Online Random Forests
    * Year: `2014`
    * Authors: Balaji Lakshminarayanan, Daniel M. Roy, Yee Whye Teh
    * Abstract: Ensembles of randomized decision trees, usually referred to as random forests, are widely used for classification and regression tasks in machine learning and statistics. Random forests achieve competitive predictive performance and are computationally efficient to train and test, making them excellent candidates for real-world prediction tasks. The most popular random forest variants (such as Breiman's random forest and extremely randomized trees) operate on batches of training data. Online methods are now in greater demand. Existing online random forests, however, require more training data than their batch counterpart to achieve comparable predictive performance. In this work, we use Mondrian processes (Roy and Teh, 2009) to construct ensembles of random decision trees we call Mondrian forests. Mondrian forests can be grown in an incremental/online fashion and remarkably, the distribution of online Mondrian forests is the same as that of batch Mondrian forests. Mondrian forests achieve competitive predictive performance comparable with existing online random forests and periodically re-trained batch random forests, while being more than an order of magnitude faster, thus representing a better computation vs accuracy tradeoff.
count=26
* R(Det)2: Randomized Decision Routing for Object Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Li_RDet2_Randomized_Decision_Routing_for_Object_Detection_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RDet2_Randomized_Decision_Routing_for_Object_Detection_CVPR_2022_paper.pdf)]
    * Title: R(Det)2: Randomized Decision Routing for Object Detection
    * Year: `2022`
    * Authors: Yali Li, Shengjin Wang
    * Abstract: In the paradigm of object detection, the decision head is an important part, which affects detection performance significantly. Yet how to design a high-performance decision head remains to be an open issue. In this paper, we propose a novel approach to combine decision trees and deep neural networks in an end-to-end learning manner for object detection. First, we disentangle the decision choices and prediction values by plugging soft decision trees into neural networks. To facilitate the effective learning, we propose the randomized decision routing with node selective and associative losses, which can boost the feature representative learning and network decision simultaneously. Second, we develop the decision head for object detection with narrow branches to generate the routing probabilities and masks, for the purpose of obtaining divergent decisions from different nodes. We name this approach as the randomized decision routing for object detection, abbreviated as R(Det)^2. Experiments on MS-COCO dataset demonstrate that R(Det)^2 is effective to improve the detection performance. Equipped with existing detectors, it achieves 1.4~ 3.6% AP improvement. Code will be released soon.
count=26
* Single Target Tracking Using Adaptive Clustered Decision Trees and Dynamic Multi-Level Appearance Models
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Xiao_Single_Target_Tracking_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Xiao_Single_Target_Tracking_2015_CVPR_paper.pdf)]
    * Title: Single Target Tracking Using Adaptive Clustered Decision Trees and Dynamic Multi-Level Appearance Models
    * Year: `2015`
    * Authors: Jingjing Xiao, Rustam Stolkin, Ales Leonardis
    * Abstract: This paper presents a method for single target tracking of arbitrary objects in challenging video sequences. Targets are modeled at three different levels of granularity (pixel level, parts-based level and bounding box level), which are cross-constrained to enable robust model relearning. The main contribution is an adaptive clustered decision tree method which dynamically selects the minimum combination of features necessary to sufficiently represent each target part at each frame, thereby providing robustness with computational efficiency. The adaptive clustered decision tree is implemented in two separate parts of the tracking algorithm: firstly to enable robust matching at the parts-based level between successive frames; and secondly to select the best superpixels for learning new parts of the target. We have tested the tracker using two different tracking benchmarks (VOT2013-2014 and CVPR2013 tracking challenges), based on two different test methodologies, and show it to be significantly more robust than the best state-of-the-art methods from both of those tracking challenges, while also offering competitive tracking precision.
count=26
* A Path to Simpler Models Starts With Noise
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/0a49935d2b3d3342ca08d6db0adcfa34-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/0a49935d2b3d3342ca08d6db0adcfa34-Paper-Conference.pdf)]
    * Title: A Path to Simpler Models Starts With Noise
    * Year: `2023`
    * Authors: Lesia Semenova, Harry Chen, Ronald Parr, Cynthia Rudin
    * Abstract: The Rashomon set is the set of models that perform approximately equally well on a given dataset, and the Rashomon ratio is the fraction of all models in a given hypothesis space that are in the Rashomon set. Rashomon ratios are often large for tabular datasets in criminal justice, healthcare, lending, education, and in other areas, which has practical implications about whether simpler models can attain the same level of accuracy as more complex models. An open question is why Rashomon ratios often tend to be large. In this work, we propose and study a mechanism of the data generation process, coupled with choices usually made by the analyst during the learning process, that determines the size of the Rashomon ratio. Specifically, we demonstrate that noisier datasets lead to larger Rashomon ratios through the way that practitioners train models. Additionally, we introduce a measure called pattern diversity, which captures the average difference in predictions between distinct classification patterns in the Rashomon set, and motivate why it tends to increase with label noise. Our results explain a key aspect of why simpler models often tend to perform as well as black box models on complex, noisier datasets.
count=26
* SketchBoost: Fast Gradient Boosted Decision Tree for Multioutput Problems
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/a36c3dbe676fa8445715a31a90c66ab3-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/a36c3dbe676fa8445715a31a90c66ab3-Paper-Conference.pdf)]
    * Title: SketchBoost: Fast Gradient Boosted Decision Tree for Multioutput Problems
    * Year: `2022`
    * Authors: Leonid Iosipoi, Anton Vakhrushev
    * Abstract: Gradient Boosted Decision Tree (GBDT) is a widely-used machine learning algorithm that has been shown to achieve state-of-the-art results on many standard data science problems. We are interested in its application to multioutput problems when the output is highly multidimensional. Although there are highly effective GBDT implementations, their scalability to such problems is still unsatisfactory. In this paper, we propose novel methods aiming to accelerate the training process of GBDT in the multioutput scenario. The idea behind these methods lies in the approximate computation of a scoring function used to find the best split of decision trees. These methods are implemented in SketchBoost, which itself is integrated into our easily customizable Python-based GPU implementation of GBDT called Py-Boost. Our numerical study demonstrates that SketchBoost speeds up the training process of GBDT by up to over 40 times while achieving comparable or even better performance.
count=25
* Robust Visual Tracking Using Oblique Random Forests
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Zhang_Robust_Visual_Tracking_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Robust_Visual_Tracking_CVPR_2017_paper.pdf)]
    * Title: Robust Visual Tracking Using Oblique Random Forests
    * Year: `2017`
    * Authors: Le Zhang, Jagannadan Varadarajan, Ponnuthurai Nagaratnam Suganthan, Narendra Ahuja, Pierre Moulin
    * Abstract: Random forest has emerged as a powerful classification technique with promising results in various vision tasks including image classification, pose estimation and object detection. However, current techniques have shown little improvements in visual tracking as they mostly rely on piece wise orthogonal hyperplanes to create decision nodes and lack a robust incremental learning mechanism that is much needed for online tracking. In this paper, we propose a discriminative tracker based on a novel incremental oblique random forest. Unlike conventional orthogonal decision trees that use a single feature and heuristic measures to obtain a split at each node, we propose to use a more powerful proximal SVM to obtain oblique hyperplanes to capture the geometric structure of the data better. The resulting decision surface is not restricted to be axis aligned and hence has the ability to represent and classify the input data better. Furthermore, in order to generalize to online tracking scenarios, we derive incremental update steps that enable the hyperplanes in each node to be updated recursively, efficiently and in a closed-form fashion. We demonstrate the effectiveness of our method using two large scale benchmark datasets (OTB-51 and OTB-100) and show that our method gives competitive results on several challenging cases by relying on simple HOG features as well as in combination with more sophisticated deep neural network based models. The implementations of the proposed random forest are available at https://github.com/ZhangLeUestc/ Incremental-Oblique-Random-Forest.
count=25
* Positive-Unlabeled Learning using Random Forests via Recursive Greedy Risk Minimization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/98257285340854262185500e59bc0f28-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/98257285340854262185500e59bc0f28-Paper-Conference.pdf)]
    * Title: Positive-Unlabeled Learning using Random Forests via Recursive Greedy Risk Minimization
    * Year: `2022`
    * Authors: Jonathan Wilton, Abigail Koay, Ryan Ko, Miao Xu, Nan Ye
    * Abstract: The need to learn from positive and unlabeled data, or PU learning, arises in many applications and has attracted increasing interest. While random forests are known to perform well on many tasks with positive and negative data, recent PU algorithms are generally based on deep neural networks, and the potential of tree-based PU learning is under-explored. In this paper, we propose new random forest algorithms for PU-learning. Key to our approach is a new interpretation of decision tree algorithms for positive and negative data as \emph{recursive greedy risk minimization algorithms}. We extend this perspective to the PU setting to develop new decision tree learning algorithms that directly minimizes PU-data based estimators for the expected risk. This allows us to develop an efficient PU random forest algorithm, PU extra trees. Our approach features three desirable properties: it is robust to the choice of the loss function in the sense that various loss functions lead to the same decision trees; it requires little hyperparameter tuning as compared to neural network based PU learning; it supports a feature importance that directly measures a feature's contribution to risk minimization. Our algorithms demonstrate strong performance on several datasets. Our code is available at \url{https://github.com/puetpaper/PUExtraTrees}.
count=24
* Tracking-by-Segmentation With Online Gradient Boosting Decision Tree
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Son_Tracking-by-Segmentation_With_Online_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Son_Tracking-by-Segmentation_With_Online_ICCV_2015_paper.pdf)]
    * Title: Tracking-by-Segmentation With Online Gradient Boosting Decision Tree
    * Year: `2015`
    * Authors: Jeany Son, Ilchae Jung, Kayoung Park, Bohyung Han
    * Abstract: We propose an online tracking algorithm that adaptively models target appearances based on an online gradient boosting decision tree. Our algorithm is particularly useful for non-rigid and/or articulated objects since it handles various deformations of the target effectively by integrating a classifier operating on individual patches and provides segmentation masks of the target as final results. The posterior of the target state is propagated over time by particle filtering, where the likelihood is computed based mainly on patch-level confidence map associated with a latent target state corresponding to each sample. Once tracking is completed in each frame, our gradient boosting decision tree is updated to adapt new data in a recursive manner. For effective evaluation of segmentation-based tracking algorithms, we construct a new ground-truth that contains pixel-level annotation of segmentation mask. We evaluate the performance of our tracking algorithm based on the measures for segmentation masks, where our algorithm illustrates superior accuracy compared to the state-of-the-art segmentation-based tracking methods.
count=24
* Lending Interaction Wings to Recommender Systems with Conversational Agents
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/58cd3b02902d79aea4b3b603fb0d0941-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/58cd3b02902d79aea4b3b603fb0d0941-Paper-Conference.pdf)]
    * Title: Lending Interaction Wings to Recommender Systems with Conversational Agents
    * Year: `2023`
    * Authors: Jiarui Jin, Xianyu Chen, Fanghua Ye, Mengyue Yang, Yue Feng, Weinan Zhang, Yong Yu, Jun Wang
    * Abstract: An intelligent conversational agent (a.k.a., chat-bot) could embrace conversational technologies to obtain user preferences online, to overcome inherent limitations of recommender systems trained over the offline historical user behaviors. In this paper, we propose CORE, a new offline-training and online-checking framework to plug a COnversational agent into REcommender systems. Unlike most prior conversational recommendation approaches that systemically combine conversational and recommender parts through a reinforcement learning framework, CORE bridges the conversational agent and recommender system through a unified uncertainty minimization framework, which can be easily applied to any existing recommendation approach. Concretely, CORE treats a recommender system as an offline estimator to produce an estimated relevance score for each item, while CORE regards a conversational agent as an online checker that checks these estimated scores in each online session. We define uncertainty as the sum of unchecked relevance scores. In this regard, the conversational agent acts to minimize uncertainty via querying either attributes or items. Towards uncertainty minimization, we derive the certainty gain of querying each attribute and item, and develop a novel online decision tree algorithm to decide what to query at each turn. Our theoretical analysis reveals the bound of the expected number of turns of CORE in a cold-start setting. Experimental results demonstrate that CORE can be seamlessly employed on a variety of recommendation approaches, and can consistently bring significant improvements in both hot-start and cold-start settings.
count=24
* MonoForest framework for tree ensemble analysis
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/1b9a80606d74d3da6db2f1274557e644-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/1b9a80606d74d3da6db2f1274557e644-Paper.pdf)]
    * Title: MonoForest framework for tree ensemble analysis
    * Year: `2019`
    * Authors: Igor Kuralenok, Vasilii Ershov, Igor Labutin
    * Abstract: In this work, we introduce a new decision tree ensemble representation framework: instead of using a graph model we transform each tree into a well-known polynomial form. We apply the new representation to three tasks: theoretical analysis, model reduction, and interpretation. The polynomial form of a tree ensemble allows a straightforward interpretation of the original model. In our experiments, it shows comparable results with state-of-the-art interpretation techniques. Another application of the framework is the ensemble-wise pruning: we can drop monomials from the polynomial, based on train data statistics. This way we reduce the model size up to 3 times without loss of its quality. It is possible to show the equivalence of tree shape classes that share the same polynomial. This fact gives us the ability to train a model in one tree's shape and exploit it in another, which is easier for computation or interpretation. We formulate a problem statement for optimal tree ensemble translation from one form to another and build a greedy solution to this problem.
count=23
* Alternating optimization of decision trees, with application to learning sparse oblique trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/185c29dc24325934ee377cfda20e414c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/185c29dc24325934ee377cfda20e414c-Paper.pdf)]
    * Title: Alternating optimization of decision trees, with application to learning sparse oblique trees
    * Year: `2018`
    * Authors: Miguel A. Carreira-Perpinan, Pooya Tavallali
    * Abstract: Learning a decision tree from data is a difficult optimization problem. The most widespread algorithm in practice, dating to the 1980s, is based on a greedy growth of the tree structure by recursively splitting nodes, and possibly pruning back the final tree. The parameters (decision function) of an internal node are approximately estimated by minimizing an impurity measure. We give an algorithm that, given an input tree (its structure and the parameter values at its nodes), produces a new tree with the same or smaller structure but new parameter values that provably lower or leave unchanged the misclassification error. This can be applied to both axis-aligned and oblique trees and our experiments show it consistently outperforms various other algorithms while being highly scalable to large datasets and trees. Further, the same algorithm can handle a sparsity penalty, so it can learn sparse oblique trees, having a structure that is a subset of the original tree and few nonzero parameters. This combines the best of axis-aligned and oblique trees: flexibility to model correlated data, low generalization error, fast inference and interpretable nodes that involve only a few features in their decision.
count=23
* Label Distribution Learning Forests
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/6e2713a6efee97bacb63e52c54f0ada0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/6e2713a6efee97bacb63e52c54f0ada0-Paper.pdf)]
    * Title: Label Distribution Learning Forests
    * Year: `2017`
    * Authors: Wei Shen, KAI ZHAO, Yilu Guo, Alan L. Yuille
    * Abstract: Label distribution learning (LDL) is a general learning framework, which assigns to an instance a distribution over a set of labels rather than a single label or multiple labels. Current LDL methods have either restricted assumptions on the expression form of the label distribution or limitations in representation learning, e.g., to learn deep features in an end-to-end manner. This paper presents label distribution learning forests (LDLFs) - a novel label distribution learning algorithm based on differentiable decision trees, which have several advantages: 1) Decision trees have the potential to model any general form of label distributions by a mixture of leaf node predictions. 2) The learning of differentiable decision trees can be combined with representation learning. We define a distribution-based loss function for a forest, enabling all the trees to be learned jointly, and show that an update function for leaf node predictions, which guarantees a strict decrease of the loss function, can be derived by variational bounding. The effectiveness of the proposed LDLFs is verified on several LDL tasks and a computer vision application, showing significant improvements to the state-of-the-art LDL methods.
count=22
* Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/22a25fc3da528794d52664dacc7bd470-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/22a25fc3da528794d52664dacc7bd470-Paper-Conference.pdf)]
    * Title: Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings
    * Year: `2023`
    * Authors: Klim Kireev, Maksym Andriushchenko, Carmela Troncoso, Nicolas Flammarion
    * Abstract: Research on adversarial robustness is primarily focused on image and text data. Yet, many scenarios in which lack of robustness can result in serious risks, such as fraud detection, medical diagnosis, or recommender systems often do not rely on images or text but instead on tabular data. Adversarial robustness in tabular data poses two serious challenges. First, tabular datasets often contain categorical features, and therefore cannot be tackled directly with existing optimization procedures. Second, in the tabular domain, algorithms that are not based on deep networks are widely used and offer great performance, but algorithms to enhance robustness are tailored to neural networks (e.g. adversarial training).In this paper, we tackle both challenges. We present a method that allows us to train adversarially robust deep networks for tabular data and to transfer this robustness to other classifiers via universal robust embeddings tailored to categorical data. These embeddings, created using a bilevel alternating minimization framework, can be transferred to boosted trees or random forests making them robust without the need for adversarial training while preserving their high accuracy on tabular data. We show that our methods outperform existing techniques within a practical threat model suitable for tabular data.
count=22
* Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/c43b987f23fd5ea840df2b2be426315c-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/c43b987f23fd5ea840df2b2be426315c-Paper-Conference.pdf)]
    * Title: Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction
    * Year: `2023`
    * Authors: Ruoyu Li, Qing Li, Yu Zhang, Dan Zhao, Yong Jiang, Yong Yang
    * Abstract: Many security applications require unsupervised anomaly detection, as malicious data are extremely rare and often only unlabeled normal data are available for training (i.e., zero-positive). However, security operators are concerned about the high stakes of trusting black-box models due to their lack of interpretability. In this paper, we propose a post-hoc method to globally explain a black-box unsupervised anomaly detection model via rule extraction.First, we propose the concept of distribution decomposition rules that decompose the complex distribution of normal data into multiple compositional distributions. To find such rules, we design an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. By merging these two types of rules into a rule set, we can present the inferential process of the unsupervised black-box model in a human-understandable way, and build a surrogate rule-based model for online deployment at the same time. We conduct comprehensive experiments on the explanation of four distinct unsupervised anomaly detection models on various real-world datasets. The evaluation shows that our method outperforms existing methods in terms of diverse metrics including fidelity, correctness and robustness.
count=21
* Local Decorrelation For Improved Pedestrian Detection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/46ba9f2a6976570b0353203ec4474217-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/46ba9f2a6976570b0353203ec4474217-Paper.pdf)]
    * Title: Local Decorrelation For Improved Pedestrian Detection
    * Year: `2014`
    * Authors: Woonhyun Nam, Piotr Dollar, Joon Hee Han
    * Abstract: Even with the advent of more sophisticated, data-hungry methods, boosted decision trees remain extraordinarily successful for fast rigid object detection, achieving top accuracy on numerous datasets. While effective, most boosted detectors use decision trees with orthogonal (single feature) splits, and the topology of the resulting decision boundary may not be well matched to the natural topology of the data. Given highly correlated data, decision trees with oblique (multiple feature) splits can be effective. Use of oblique splits, however, comes at considerable computational expense. Inspired by recent work on discriminative decorrelation of HOG features, we instead propose an efficient feature transform that removes correlations in local neighborhoods. The result is an overcomplete but locally decorrelated representation ideally suited for use with orthogonal decision trees. In fact, orthogonal trees with our locally decorrelated features outperform oblique trees trained over the original features at a fraction of the computational cost. The overall improvement in accuracy is dramatic: on the Caltech Pedestrian Dataset, we reduce false positives nearly tenfold over the previous state-of-the-art.
count=20
* Self-Born Wiring for Neural Trees
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Self-Born_Wiring_for_Neural_Trees_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Self-Born_Wiring_for_Neural_Trees_ICCV_2021_paper.pdf)]
    * Title: Self-Born Wiring for Neural Trees
    * Year: `2021`
    * Authors: Ying Chen, Feng Mao, Jie Song, Xinchao Wang, Huiqiong Wang, Mingli Song
    * Abstract: Neural trees aim at integrating deep neural networks and decision trees so as to bring the best of the two worlds, including representation learning from the former and faster inference from the latter. In this paper, we introduce a novel approach, termed as Self-born Wiring (SeBoW), to learn neural trees from a mother deep neural network. In contrast to prior neural-tree approaches that either adopt a pre-defined structure or grow hierarchical layers in a progressive manner, task-adaptive neural trees in SeBoW evolve from a deep neural network through a construction-by-destruction process, enabling a global-level parameter optimization that further yields favorable results. Specifically, given a designated network configuration like VGG, SeBoW disconnects all the layers and derives isolated filter groups, based on which a global-level wiring process is conducted to attach a subset of filter groups, eventually bearing a lightweight neural tree. Extensive experiments demonstrate that, with a lower computational cost, SeBoW outperforms all prior neural trees by a significant margin and even achieves results on par with predominant non-tree networks like ResNets. Moreover, SeBoW proves its scalability to large-scale datasets like ImageNet, which has been barely explored by prior tree networks.
count=20
* Deep Neural Decision Forests
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Kontschieder_Deep_Neural_Decision_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Kontschieder_Deep_Neural_Decision_ICCV_2015_paper.pdf)]
    * Title: Deep Neural Decision Forests
    * Year: `2015`
    * Authors: Peter Kontschieder, Madalina Fiterau, Antonio Criminisi, Samuel Rota Bulo
    * Abstract: We present Deep Neural Decision Forests - a novel approach that unifies classification trees with the representation learning functionality known from deep convolutional networks, by training them in an end-to-end manner. To combine these two worlds, we introduce a stochastic and differentiable decision tree model, which steers the representation learning usually conducted in the initial layers of a (deep) convolutional network. Our model differs from conventional deep networks because a decision forest provides the final predictions and it differs from conventional decision forests since we propose a principled, joint and global optimization of split and leaf node parameters. We show experimental results on benchmark machine learning datasets like MNIST and ImageNet and find on-par or superior results when compared to state-of-the-art deep models. Most remarkably, we obtain Top5-Errors of only 7.84%/6.38% on ImageNet validation data when integrating our forests in a single-crop, single/seven model GoogLeNet architecture, respectively. Thus, even without any form of training data set augmentation we are improving on the 6.67% error obtained by the best GoogLeNet architecture (7 models, 144 crops).
count=20
* On the Safety of Interpretable Machine Learning: A Maximum Deviation Approach
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/402e12102d6ec3ea3df40ce1b23d423a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/402e12102d6ec3ea3df40ce1b23d423a-Paper-Conference.pdf)]
    * Title: On the Safety of Interpretable Machine Learning: A Maximum Deviation Approach
    * Year: `2022`
    * Authors: Dennis Wei, Rahul Nair, Amit Dhurandhar, Kush R. Varshney, Elizabeth Daly, Moninder Singh
    * Abstract: Interpretable and explainable machine learning has seen a recent surge of interest. We focus on safety as a key motivation behind the surge and make the relationship between interpretability and safety more quantitative. Toward assessing safety, we introduce the concept of maximum deviation via an optimization problem to find the largest deviation of a supervised learning model from a reference model regarded as safe. We then show how interpretability facilitates this safety assessment. For models including decision trees, generalized linear and additive models, the maximum deviation can be computed exactly and efficiently. For tree ensembles, which are not regarded as interpretable, discrete optimization techniques can still provide informative bounds. For a broader class of piecewise Lipschitz functions, we leverage the multi-armed bandit literature to show that interpretability produces tighter (regret) bounds on the maximum deviation. We present case studies, including one on mortgage approval, to illustrate our methods and the insights about models that may be obtained from deviation maximization.
count=20
* Fair Wrapping for Black-box Predictions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/876b45367d9069f0e91e359c57155ab1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/876b45367d9069f0e91e359c57155ab1-Paper-Conference.pdf)]
    * Title: Fair Wrapping for Black-box Predictions
    * Year: `2022`
    * Authors: Alexander Soen, Ibrahim M. Alabdulmohsin, Sanmi Koyejo, Yishay Mansour, Nyalleng Moorosi, Richard Nock, Ke Sun, Lexing Xie
    * Abstract: We introduce a new family of techniques to post-process (``wrap") a black-box classifier in order to reduce its bias. Our technique builds on the recent analysis of improper loss functions whose optimization can correct any twist in prediction, unfairness being treated as a twist. In the post-processing, we learn a wrapper function which we define as an $\alpha$-tree, which modifies the prediction. We provide two generic boosting algorithms to learn $\alpha$-trees. We show that our modification has appealing properties in terms of composition of $\alpha$-trees, generalization, interpretability, and KL divergence between modified and original predictions. We exemplify the use of our technique in three fairness notions: conditional value-at-risk, equality of opportunity, and statistical parity; and provide experiments on several readily available datasets.
count=20
* Robustness Verification of Tree-based Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/cd9508fdaa5c1390e9cc329001cf1459-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/cd9508fdaa5c1390e9cc329001cf1459-Paper.pdf)]
    * Title: Robustness Verification of Tree-based Models
    * Year: `2019`
    * Authors: Hongge Chen, Huan Zhang, Si Si, Yang Li, Duane Boning, Cho-Jui Hsieh
    * Abstract: We study the robustness verification problem of tree based models, including random forest (RF) and gradient boosted decision tree (GBDT). Formal robustness verification of decision tree ensembles involves finding the exact minimal adversarial perturbation or a guaranteed lower bound of it. Existing approaches cast this verification problem into a mixed integer linear programming (MILP) problem, which finds the minimal adversarial distortion in exponential time so is impractical for large ensembles. Although this verification problem is NP-complete in general, we give a more precise complexity characterization. We show that there is a simple linear time algorithm for verifying a single tree, and for tree ensembles the verification problem can be cast as a max-clique problem on a multi-partite boxicity graph. For low dimensional problems when boxicity can be viewed as constant, this reformulation leads to a polynomial time algorithm. For general problems, by exploiting the boxicity of the graph, we devise an efficient verification algorithm that can give tight lower bounds on robustness of decision tree ensembles, and allows iterative improvement and any-time termination. On RF/GBDT models trained on a variety of datasets, we significantly outperform the lower bounds obtained by relaxing the MILP formulation into a linear program (LP), and are hundreds times faster than solving MILPs to get the exact minimal adversarial distortion. Our proposed method is capable of giving tight robustness verification bounds on large GBDTs with hundreds of deep trees.
count=19
* Pushing the Envelope of Gradient Boosting Forests via Globally-Optimized Oblique Trees
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Gabidolla_Pushing_the_Envelope_of_Gradient_Boosting_Forests_via_Globally-Optimized_Oblique_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Gabidolla_Pushing_the_Envelope_of_Gradient_Boosting_Forests_via_Globally-Optimized_Oblique_CVPR_2022_paper.pdf)]
    * Title: Pushing the Envelope of Gradient Boosting Forests via Globally-Optimized Oblique Trees
    * Year: `2022`
    * Authors: Magzhan Gabidolla, Miguel Á. Carreira-Perpiñán
    * Abstract: Ensemble methods based on decision trees, such as Random Forests or boosted forests, have long been established as some of the most powerful, off-the-shelf machine learning models, and have been widely used in computer vision and other areas. In recent years, a specific form of boosting, gradient boosting (GB), has gained prominence. This is partly because of highly optimized implementations such as XGBoost or LightGBM, which incorporate many clever modifications and heuristics. However, one gaping hole remains unexplored in GB: the construction of individual trees. To date, all successful GB versions use axis-aligned trees trained in a suboptimal way via greedy recursive partitioning. We address this gap by using a more powerful type of trees (having hyperplane splits) and an algorithm that can optimize, globally over all the tree parameters, the objective function that GB dictates. We show, in several benchmarks of image and other data types, that GB forests of these stronger, well-optimized trees consistently exceed the test accuracy of axis-aligned forests from XGBoost, LightGBM and other strong baselines. Further, this happens using many fewer trees and sometimes even fewer parameters overall.
count=19
* Understanding Failures of Deep Networks via Robust Feature Extraction
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Singla_Understanding_Failures_of_Deep_Networks_via_Robust_Feature_Extraction_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Singla_Understanding_Failures_of_Deep_Networks_via_Robust_Feature_Extraction_CVPR_2021_paper.pdf)]
    * Title: Understanding Failures of Deep Networks via Robust Feature Extraction
    * Year: `2021`
    * Authors: Sahil Singla, Besmira Nushi, Shital Shah, Ece Kamar, Eric Horvitz
    * Abstract: Traditional evaluation metrics for learned models that report aggregate scores over a test set are insufficient for surfacing important and informative patterns of failure over features and instances. We introduce and study a method aimed at characterizing and explaining failures by identifying visual attributes whose presence or absence results in poor performance. In distinction to previous work that relies upon crowdsourced labels for visual attributes, we leverage the representation of a separate robust model to extract interpretable features and then harness these features to identify failure modes. We further propose a visualization method aimed at enabling humans to understand the meaning encoded in such features and we test the comprehensibility of the features. An evaluation of the methods on the ImageNet dataset demonstrates that: (i) the proposed workflow is effective for discovering important failure modes, (ii) the visualization techniques help humans to understand the extracted features, and (iii) the extracted insights can assist engineers with error analysis and debugging.
count=19
* Random Cuts are Optimal for Explainable k-Medians
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/d3408794e41dd23e34634344d662f5e9-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/d3408794e41dd23e34634344d662f5e9-Paper-Conference.pdf)]
    * Title: Random Cuts are Optimal for Explainable k-Medians
    * Year: `2023`
    * Authors: Konstantin Makarychev, Liren Shan
    * Abstract: We show that the RandomCoordinateCut algorithm gives the optimal competitive ratio for explainable $k$-medians in $\ell_1$. The problem of explainable $k$-medians was introduced by Dasgupta, Frost, Moshkovitz, and Rashtchian in 2020. Several groups of authors independently proposed a simple polynomial-time randomized algorithm for the problem and showed that this algorithm is $O(\log k \log\log k)$ competitive. We provide a tight analysis of the algorithm and prove that its competitive ratio is upper bounded by $2\ln k+2$. This bound matches the $\Omega(\log k)$ lower bound by Dasgupta et al (2020).
count=19
* Joints in Random Forests
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/8396b14c5dff55d13eea57487bf8ed26-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/8396b14c5dff55d13eea57487bf8ed26-Paper.pdf)]
    * Title: Joints in Random Forests
    * Year: `2020`
    * Authors: Alvaro Correia, Robert Peharz, Cassio P. de Campos
    * Abstract: Decision Trees (DTs) and Random Forests (RFs) are powerful discriminative learners and tools of central importance to the everyday machine learning practitioner and data scientist. Due to their discriminative nature, however, they lack principled methods to process inputs with missing features or to detect outliers, which requires pairing them with imputation techniques or a separate generative model. In this paper, we demonstrate that DTs and RFs can naturally be interpreted as generative models, by drawing a connection to Probabilistic Circuits, a prominent class of tractable probabilistic models. This reinterpretation equips them with a full joint distribution over the feature space and leads to Generative Decision Trees (GeDTs) and Generative Forests (GeFs), a family of novel hybrid generative-discriminative models. This family of models retains the overall characteristics of DTs and RFs while additionally being able to handle missing features by means of marginalisation. Under certain assumptions, frequently made for Bayes consistency results, we show that consistency in GeDTs and GeFs extend to any pattern of missing input features, if missing at random. Empirically, we show that our models often outperform common routines to treat missing data, such as K-nearest neighbour imputation, and moreover, that our models can naturally detect outliers by monitoring the marginal probability of input features.
count=19
* Sparse Learning with CART
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/85fc37b18c57097425b52fc7afbb6969-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/85fc37b18c57097425b52fc7afbb6969-Paper.pdf)]
    * Title: Sparse Learning with CART
    * Year: `2020`
    * Authors: Jason Klusowski
    * Abstract: Decision trees with binary splits are popularly constructed using Classification and Regression Trees (CART) methodology. For regression models, this approach recursively divides the data into two near-homogenous daughter nodes according to a split point that maximizes the reduction in sum of squares error (the impurity) along a particular variable. This paper aims to study the statistical properties of regression trees constructed with CART. In doing so, we find that the training error is governed by the Pearson correlation between the optimal decision stump and response data in each node, which we bound by constructing a prior distribution on the split points and solving a nonlinear optimization problem. We leverage this connection between the training error and Pearson correlation to show that CART with cost-complexity pruning achieves an optimal complexity/goodness-of-fit tradeoff when the depth scales with the logarithm of the sample size. Data dependent quantities, which adapt to the dimensionality and latent structure of the regression model, are seen to govern the rates of convergence of the prediction error.
count=18
* A Programmatic and Semantic Approach to Explaining and Debugging Neural Network Based Object Detectors
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Kim_A_Programmatic_and_Semantic_Approach_to_Explaining_and_Debugging_Neural_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Kim_A_Programmatic_and_Semantic_Approach_to_Explaining_and_Debugging_Neural_CVPR_2020_paper.pdf)]
    * Title: A Programmatic and Semantic Approach to Explaining and Debugging Neural Network Based Object Detectors
    * Year: `2020`
    * Authors: Edward Kim,  Divya Gopinath,  Corina Pasareanu,  Sanjit A. Seshia
    * Abstract: Even as deep neural networks have become very effective for tasks in vision and perception, it remains difficult to explain and debug their behavior. In this paper, we present a programmatic and semantic approach to explaining, understanding, and debugging the correct and incorrect behaviors of a neural network based perception system. Our approach is semantic in that it employs a high-level representation of the distribution of environment scenarios that the detector is intended to work on. It is programmatic in that the representation is a program in a domain-specific probabilistic programming language using which synthetic data can be generated to train and test the neural network. We present a framework that assesses the performance of the neural network to identify correct and incorrect detections, extracts rules from those results that semantically characterizes the correct and incorrect scenarios, and then specializes the probabilistic program with those rules in order to more precisely characterize the scenarios in which the neural network operates correctly or not, without human intervention. We demonstrate our results using the Scenic probabilistic programming language and a neural network-based object detector. Our experiments show that it is possible to automatically generate compact rules that significantly increase the correct detection rate (or conversely the incorrect detection rate) of the network and can thus help with debugging and understanding its behavior.
count=18
* Boosting with Tempered Exponential Measures
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/82d3258eb58ceac31744a88005b7ddef-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/82d3258eb58ceac31744a88005b7ddef-Paper-Conference.pdf)]
    * Title: Boosting with Tempered Exponential Measures
    * Year: `2023`
    * Authors: Richard Nock, Ehsan Amid, Manfred Warmuth
    * Abstract: One of the most popular ML algorithms, AdaBoost, can bederived from the dual of a relative entropyminimization problem subject to the fact that the positive weightson the examples sum to one. Essentially, harder examples receive higher probabilities. We generalize this setup to the recently introduced *temperedexponential measure*s (TEMs) where normalization is enforced on a specific power of the measure and not the measure itself.TEMs are indexed by a parameter $t$ and generalize exponential families ($t=1$). Our algorithm, $t$-AdaBoost, recovers AdaBoost as a special case ($t=1$). We show that $t$-AdaBoost retains AdaBoost's celebrated exponential convergence rate when $t\in [0,1)$ while allowing a slight improvement of the rate's hidden constant compared to $t=1$. $t$-AdaBoost partially computes on a generalization of classical arithmetic over the reals and brings notable properties like guaranteed bounded leveraging coefficients for $t\in [0,1)$. From the loss that $t$-AdaBoost minimizes (a generalization of the exponential loss), we show how to derive a new family of *tempered* losses for the induction of domain-partitioning classifiers like decision trees. Crucially, strict properness is ensured for all while their boosting rates span the full known spectrum. Experiments using $t$-AdaBoost+trees display that significant leverage can be achieved by tuning $t$.
count=18
* Smooth And Consistent Probabilistic Regression Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/8289889263db4a40463e3f358bb7c7a1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/8289889263db4a40463e3f358bb7c7a1-Paper.pdf)]
    * Title: Smooth And Consistent Probabilistic Regression Trees
    * Year: `2020`
    * Authors: Sami Alkhoury, Emilie Devijver, Marianne Clausel, Myriam Tami, Eric Gaussier, georges Oppenheim
    * Abstract: We propose here a generalization of regression trees, referred to as Probabilistic Regression (PR) trees, that adapt to the smoothness of the prediction function relating input and output variables while preserving the interpretability of the prediction and being robust to noise. In PR trees, an observation is associated to all regions of a tree through a probability distribution that reflects how far the observation is to a region. We show that such trees are consistent, meaning that their error tends to 0 when the sample size tends to infinity, a property that has not been established for similar, previous proposals as Soft trees and Smooth Transition Regression trees. We further explain how PR trees can be used in different ensemble methods, namely Random Forests and Gradient Boosted Trees. Lastly, we assess their performance through extensive experiments that illustrate their benefits in terms of performance, interpretability and robustness to noise.
count=18
* Minimal Variance Sampling in Stochastic Gradient Boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/5c8cb735a1ce65dac514233cbd5576d6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/5c8cb735a1ce65dac514233cbd5576d6-Paper.pdf)]
    * Title: Minimal Variance Sampling in Stochastic Gradient Boosting
    * Year: `2019`
    * Authors: Bulat Ibragimov, Gleb Gusev
    * Abstract: Stochastic Gradient Boosting (SGB) is a widely used approach to regularization of boosting models based on decision trees. It was shown that, in many cases, random sampling at each iteration can lead to better generalization performance of the model and can also decrease the learning time. Different sampling approaches were proposed, where probabilities are not uniform, and it is not currently clear which approach is the most effective. In this paper, we formulate the problem of randomization in SGB in terms of optimization of sampling probabilities to maximize the estimation accuracy of split scoring used to train decision trees.This optimization problem has a closed-form nearly optimal solution, and it leads to a new sampling technique, which we call Minimal Variance Sampling (MVS).The method both decreases the number of examples needed for each iteration of boosting and increases the quality of the model significantly as compared to the state-of-the art sampling methods. The superiority of the algorithm was confirmed by introducing MVS as a new default option for subsampling in CatBoost, a gradient boosting library achieving state-of-the-art quality on various machine learning tasks.
count=18
* Optimal Decision Tree with Noisy Outcomes
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/85f007f8c50dd25f5a45fca73cad64bd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/85f007f8c50dd25f5a45fca73cad64bd-Paper.pdf)]
    * Title: Optimal Decision Tree with Noisy Outcomes
    * Year: `2019`
    * Authors: Su Jia, viswanath nagarajan, Fatemeh Navidi, R Ravi
    * Abstract: A fundamental task in active learning involves performing a sequence of tests to identify an unknown hypothesis that is drawn from a known distribution. This problem, known as optimal decision tree induction, has been widely studied for decades and the asymptotically best-possible approximation algorithm has been devised for it. We study a generalization where certain test outcomes are noisy, even in the more general case when the noise is persistent, i.e., repeating the test on the scenario gives the same noisy output, disallowing simple repetition as a way to gain confidence. We design new approximation algorithms for both the non-adaptive setting, where the test sequence must be fixed a-priori, and the adaptive setting where the test sequence depends on the outcomes of prior tests. Previous work in the area assumed at most a constant number of noisy outcomes per test and per scenario and provided approximation ratios that were problem dependent (such as the minimum probability of a hypothesis). Our new approximation algorithms provide guarantees that are nearly best-possible and work for the general case of a large number of noisy outcomes per test or per hypothesis where the performance degrades smoothly with this number. Our results adapt and generalize methods used for submodular ranking and stochastic set cover. We evaluate the performance of our algorithms on two natural applications with noise: toxic chemical identification and active learning of linear classifiers. Despite our logarithmic theoretical approximation guarantees, our methods give solutions with cost very close to the information theoretic minimum, demonstrating the effectiveness of our methods.
count=18
* Tight Certificates of Adversarial Robustness for Randomly Smoothed Classifiers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/fa2e8c4385712f9a1d24c363a2cbe5b8-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/fa2e8c4385712f9a1d24c363a2cbe5b8-Paper.pdf)]
    * Title: Tight Certificates of Adversarial Robustness for Randomly Smoothed Classifiers
    * Year: `2019`
    * Authors: Guang-He Lee, Yang Yuan, Shiyu Chang, Tommi Jaakkola
    * Abstract: Strong theoretical guarantees of robustness can be given for ensembles of classifiers generated by input randomization. Specifically, an $\ell_2$ bounded adversary cannot alter the ensemble prediction generated by an additive isotropic Gaussian noise, where the radius for the adversary depends on both the variance of the distribution as well as the ensemble margin at the point of interest. We build on and considerably expand this work across broad classes of distributions. In particular, we offer adversarial robustness guarantees and associated algorithms for the discrete case where the adversary is $\ell_0$ bounded. Moreover, we exemplify how the guarantees can be tightened with specific assumptions about the function class of the classifier such as a decision tree. We empirically illustrate these results with and without functional restrictions across image and molecule datasets.
count=17
* Automatic Synthesis of Diverse Weak Supervision Sources for Behavior Analysis
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Tseng_Automatic_Synthesis_of_Diverse_Weak_Supervision_Sources_for_Behavior_Analysis_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Tseng_Automatic_Synthesis_of_Diverse_Weak_Supervision_Sources_for_Behavior_Analysis_CVPR_2022_paper.pdf)]
    * Title: Automatic Synthesis of Diverse Weak Supervision Sources for Behavior Analysis
    * Year: `2022`
    * Authors: Albert Tseng, Jennifer J. Sun, Yisong Yue
    * Abstract: Obtaining annotations for large training sets is expensive, especially in settings where domain knowledge is required, such as behavior analysis. Weak supervision has been studied to reduce annotation costs by using weak labels from task-specific labeling functions (LFs) to augment ground truth labels. However, domain experts still need to hand-craft different LFs for different tasks, limiting scalability. To reduce expert effort, we present AutoSWAP: a framework for automatically synthesizing data-efficient task-level LFs. The key to our approach is to efficiently represent expert knowledge in a reusable domain-specific language and more general domain-level LFs, with which we use state-of-the-art program synthesis techniques and a small labeled dataset to generate task-level LFs. Additionally, we propose a novel structural diversity cost that allows for efficient synthesis of diverse sets of LFs, further improving AutoSWAP's performance. We evaluate AutoSWAP in three behavior analysis domains and demonstrate that AutoSWAP outperforms existing approaches using only a fraction of the data. Our results suggest that AutoSWAP is an effective way to automatically generate LFs that can significantly reduce expert effort for behavior analysis.
count=17
* Alternating Decision Forests
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Schulter_Alternating_Decision_Forests_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Schulter_Alternating_Decision_Forests_2013_CVPR_paper.pdf)]
    * Title: Alternating Decision Forests
    * Year: `2013`
    * Authors: Samuel Schulter, Paul Wohlhart, Christian Leistner, Amir Saffari, Peter M. Roth, Horst Bischof
    * Abstract: This paper introduces a novel classification method termed Alternating Decision Forests (ADFs), which formulates the training of Random Forests explicitly as a global loss minimization problem. During training, the losses are minimized via keeping an adaptive weight distribution over the training samples, similar to Boosting methods. In order to keep the method as flexible and general as possible, we adopt the principle of employing gradient descent in function space, which allows to minimize arbitrary losses. Contrary to Boosted Trees, in our method the loss minimization is an inherent part of the tree growing process, thus allowing to keep the benefits of common Random Forests, such as, parallel processing. We derive the new classifier and give a discussion and evaluation on standard machine learning data sets. Furthermore, we show how ADFs can be easily integrated into an object detection application. Compared to both, standard Random Forests and Boosted Trees, ADFs give better performance in our experiments, while yielding more compact models in terms of tree depth.
count=17
* LightGBM: A Highly Efficient Gradient Boosting Decision Tree
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)]
    * Title: LightGBM: A Highly Efficient Gradient Boosting Decision Tree
    * Year: `2017`
    * Authors: Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu
    * Abstract: Gradient Boosting Decision Tree (GBDT) is a popular machine learning algorithm, and has quite a few effective implementations such as XGBoost and pGBRT. Although many engineering optimizations have been adopted in these implementations, the efficiency and scalability are still unsatisfactory when the feature dimension is high and data size is large. A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. To tackle this problem, we propose two novel techniques: \emph{Gradient-based One-Side Sampling} (GOSS) and \emph{Exclusive Feature Bundling} (EFB). With GOSS, we exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. We prove that, since the data instances with larger gradients play a more important role in the computation of information gain, GOSS can obtain quite accurate estimation of the information gain with a much smaller data size. With EFB, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features. We prove that finding the optimal bundling of exclusive features is NP-hard, but a greedy algorithm can achieve quite good approximation ratio (and thus can effectively reduce the number of features without hurting the accuracy of split point determination by much). We call our new GBDT implementation with GOSS and EFB \emph{LightGBM}. Our experiments on multiple public datasets show that, LightGBM speeds up the training process of conventional GBDT by up to over 20 times while achieving almost the same accuracy.
count=17
* Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/9fdb62f932adf55af2c0e09e55861964-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/9fdb62f932adf55af2c0e09e55861964-Paper.pdf)]
    * Title: Yggdrasil: An Optimized System for Training Deep Decision Trees at Scale
    * Year: `2016`
    * Authors: Firas Abuzaid, Joseph K. Bradley, Feynman T. Liang, Andrew Feng, Lee Yang, Matei Zaharia, Ameet S. Talwalkar
    * Abstract: Deep distributed decision trees and tree ensembles have grown in importance due to the need to model increasingly large datasets. However, PLANET, the standard distributed tree learning algorithm implemented in systems such as \xgboost and Spark MLlib, scales poorly as data dimensionality and tree depths grow. We present Yggdrasil, a new distributed tree learning method that outperforms existing methods by up to 24x. Unlike PLANET, Yggdrasil is based on vertical partitioning of the data (i.e., partitioning by feature), along with a set of optimized data structures to reduce the CPU and communication costs of training. Yggdrasil (1) trains directly on compressed data for compressible features and labels; (2) introduces efficient data structures for training on uncompressed data; and (3) minimizes communication between nodes by using sparse bitvectors. Moreover, while PLANET approximates split points through feature binning, Yggdrasil does not require binning, and we analytically characterize the impact of this approximation. We evaluate Yggdrasil against the MNIST 8M dataset and a high-dimensional dataset at Yahoo; for both, Yggdrasil is faster by up to an order of magnitude.
count=16
* On the Convergence of CART under Sufficient Impurity Decrease Condition
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/b418964bafb4fdd9aef9017301323a8a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/b418964bafb4fdd9aef9017301323a8a-Paper-Conference.pdf)]
    * Title: On the Convergence of CART under Sufficient Impurity Decrease Condition
    * Year: `2023`
    * Authors: Rahul Mazumder, Haoyue Wang
    * Abstract: The decision tree is a flexible machine-learning model that finds its success in numerous applications. It is usually fitted in a recursively greedy manner using CART. In this paper, we study the convergence rate of CART under a regression setting. First, we prove an upper bound on the prediction error of CART under a sufficient impurity decrease (SID) condition \cite{chi2020asymptotic} -- our result is an improvement over the known result by \cite{chi2020asymptotic} under a similar assumption. We show via examples that this error bound cannot be further improved by more than a constant or a log factor. Second, we introduce a few easy-to-check sufficient conditions of the SID condition. In particular, we show that the SID condition can be satisfied by an additive model when the component functions satisfy a ``locally reverse Poincare inequality". We discuss a few familiar function classes in non-parametric estimation to demonstrate the usefulness of this conception.
count=16
* Quantized Training of Gradient Boosting Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/77911ed9e6e864ca1a3d165b2c3cb258-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/77911ed9e6e864ca1a3d165b2c3cb258-Paper-Conference.pdf)]
    * Title: Quantized Training of Gradient Boosting Decision Trees
    * Year: `2022`
    * Authors: Yu Shi, Guolin Ke, Zhuoming Chen, Shuxin Zheng, Tie-Yan Liu
    * Abstract: Recent years have witnessed significant success in Gradient Boosting Decision Trees (GBDT) for a wide range of machine learning applications. Generally, a consensus about GBDT's training algorithms is gradients and statistics are computed based on high-precision floating points. In this paper, we investigate an essentially important question which has been largely ignored by the previous literature - how many bits are needed for representing gradients in training GBDT? To solve this mystery, we propose to quantize all the high-precision gradients in a very simple yet effective way in the GBDT's training algorithm. Surprisingly, both our theoretical analysis and empirical studies show that the necessary precisions of gradients without hurting any performance can be quite low, e.g., 2 or 3 bits. With low-precision gradients, most arithmetic operations in GBDT training can be replaced by integer operations of 8, 16, or 32 bits. Promisingly, these findings may pave the way for much more efficient training of GBDT from several aspects: (1) speeding up the computation of gradient statistics in histograms; (2) compressing the communication cost of high-precision statistical information during distributed training; (3) the inspiration of utilization and development of hardware architectures which well support low-precision computation for GBDT training. Benchmarked on CPUs, GPUs, and distributed clusters, we observe up to 2$\times$ speedup of our simple quantization strategy compared with SOTA GBDT systems on extensive datasets, demonstrating the effectiveness and potential of the low-precision training of GBDT. The code will be released to the official repository of LightGBM.
count=15
* Proto2Proto: Can You Recognize the Car, the Way I Do?
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Keswani_Proto2Proto_Can_You_Recognize_the_Car_the_Way_I_Do_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Keswani_Proto2Proto_Can_You_Recognize_the_Car_the_Way_I_Do_CVPR_2022_paper.pdf)]
    * Title: Proto2Proto: Can You Recognize the Car, the Way I Do?
    * Year: `2022`
    * Authors: Monish Keswani, Sriranjani Ramakrishnan, Nishant Reddy, Vineeth N Balasubramanian
    * Abstract: Prototypical methods have recently gained a lot of attention due to their intrinsic interpretable nature, which is obtained through the prototypes. With growing use cases of model reuse and distillation, there is a need to also study transfer of interpretability from one model to another. We present Proto2Proto, a novel method to transfer interpretability of one prototypical part network to another via knowledge distillation. Our approach aims to add interpretability to the "dark" knowledge transferred from the teacher to the shallower student model. We propose two novel losses: "Global Explanation" loss and "Patch-Prototype Correspondence" loss to facilitate such a transfer. Global Explanation loss forces the student prototypes to be close to teacher prototypes, and Patch-Prototype Correspondence loss enforces the local representations of the student to be similar to that of the teacher. Further, we propose three novel metrics to evaluate the student's proximity to the teacher as measures of interpretability transfer in our settings. We qualitatively and quantitatively demonstrate the effectiveness of our method on CUB-200-2011 and Stanford Cars datasets. Our experiments show that the proposed method indeed achieves interpretability transfer from teacher to student while simultaneously exhibiting competitive performance. The code is available at https://github.com/archmaester/proto2proto
count=15
* Tree-Like Decision Distillation
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Song_Tree-Like_Decision_Distillation_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Tree-Like_Decision_Distillation_CVPR_2021_paper.pdf)]
    * Title: Tree-Like Decision Distillation
    * Year: `2021`
    * Authors: Jie Song, Haofei Zhang, Xinchao Wang, Mengqi Xue, Ying Chen, Li Sun, Dacheng Tao, Mingli Song
    * Abstract: Knowledge distillation pursues a diminutive yet well-behaved student network by harnessing the knowledge learned by a cumbersome teacher model. Prior methods achieve this by making the student imitate shallow behaviors, such as soft targets, features, or attention, of the teacher. In this paper, we argue that what really matters for distillation is the intrinsic problem-solving process captured by the teacher. By dissecting the decision process in a layer-wise manner, we found that the decision-making procedure in the teacher model is conducted in a coarse-to-fine manner, where coarse-grained discrimination (e.g., animal vs vehicle) is attained in early layers, and fine-grained discrimination (e.g., dog vs cat, car vs truck) in latter layers. Motivated by this observation, we propose a new distillation method, dubbed as Tree-like Decision Distillation (TDD), to endow the student with the same problem-solving mechanism as that of the teacher. Extensive experiments demonstrated that TDD yields competitive performance compared to state of the arts. More importantly, it enjoys better interpretability due to its interpretable decision distillation instead of dark knowledge distillation.
count=15
* Visual Tracking Using Attention-Modulated Disintegration and Integration
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Choi_Visual_Tracking_Using_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Choi_Visual_Tracking_Using_CVPR_2016_paper.pdf)]
    * Title: Visual Tracking Using Attention-Modulated Disintegration and Integration
    * Year: `2016`
    * Authors: Jongwon Choi, Hyung Jin Chang, Jiyeoup Jeong, Yiannis Demiris, Jin Young Choi
    * Abstract: In this paper, we present a novel attention-modulated visual tracking algorithm that decomposes an object into multiple cognitive units, and trains multiple elementary trackers in order to modulate the distribution of attention according to various feature and kernel types. In the integration stage it recombines the units to memorize and recognize the target object effectively. With respect to the elementary trackers, we present a novel attentional feature-based correlation filter (AtCF) that focuses on distinctive attentional features. The effectiveness of the proposed algorithm is validated through experimental comparison with state-of-the-art methods on widely-used tracking benchmark datasets.
count=15
* Scene Graph Prediction With Limited Labels
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Chen_Scene_Graph_Prediction_With_Limited_Labels_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Scene_Graph_Prediction_With_Limited_Labels_ICCV_2019_paper.pdf)]
    * Title: Scene Graph Prediction With Limited Labels
    * Year: `2019`
    * Authors: Vincent S. Chen,  Paroma Varma,  Ranjay Krishna,  Michael Bernstein,  Christopher Re,  Li Fei-Fei
    * Abstract: Visual knowledge bases such as Visual Genome power numerous applications in computer vision, including visual question answering and captioning, but suffer from sparse, incomplete relationships. All scene graph models to date are limited to training on a small set of visual relationships that have thousands of training labels each. Hiring human annotators is expensive, and using textual knowledge base completion methods are incompatible with visual data. In this paper, we introduce a semi-supervised method that assigns probabilistic relationship labels to a large number of unlabeled images using few labeled examples. We analyze visual relationships to suggest two types of image-agnostic features that are used to generate noisy heuristics, whose outputs are aggregated using a factor graph-based generative model. With as few as 10 labeled examples per relationship, the generative model creates enough training data to train any existing state-of-the-art scene graph model. We demonstrate that our method outperforms all baseline approaches on scene graph prediction by5.16 recall@100 for PREDCLS. In our limited label setting, we define a complexity metric for relationships that serves as an indicator (R^2 = 0.778) for conditions under which our method succeeds over transfer learning, the de-facto approach for training with limited labels.
count=15
* Conditional Convolutional Neural Network for Modality-Aware Face Recognition
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Xiong_Conditional_Convolutional_Neural_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Xiong_Conditional_Convolutional_Neural_ICCV_2015_paper.pdf)]
    * Title: Conditional Convolutional Neural Network for Modality-Aware Face Recognition
    * Year: `2015`
    * Authors: Chao Xiong, Xiaowei Zhao, Danhang Tang, Karlekar Jayashree, Shuicheng Yan, Tae-Kyun Kim
    * Abstract: Faces in the wild are usually captured with various poses, illuminations and occlusions, and thus inherently multimodally distributed in many tasks. We propose a conditional Convolutional Neural Network, named as c-CNN, to handle multimodal face recognition. Different from traditional CNN that adopts fixed convolution kernels, samples in c-CNN are processed with dynamically activated sets of kernels. In particular, convolution kernels within each layer are only sparsely activated when a sample is passed through the network. For a given sample, the activations of convolution kernels in a certain layer are conditioned on its present intermediate representation and the activation status in the lower layers. The activated kernels across layers define the sample-specific adaptive routes that reveal the distribution of underlying modalities. Consequently, the proposed framework does not rely on any prior knowledge of modalities in contrast with most existing methods. To substantiate the generic framework, we introduce a special case of c-CNN via incorporating the conditional routing of the decision tree, which is evaluated with two problems of multimodality - multi-view face identification and occluded face verification. Extensive experiments demonstrate consistent improvements over the counterparts unaware of modalities.
count=15
* Linear tree shap
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/a5a3b1ef79520b7cd122d888673a3ebc-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/a5a3b1ef79520b7cd122d888673a3ebc-Paper-Conference.pdf)]
    * Title: Linear tree shap
    * Year: `2022`
    * Authors: peng yu, Albert Bifet, Jesse Read, Chao Xu
    * Abstract: Decision trees are well-known due to their ease of interpretability.To improve accuracy, we need to grow deep trees or ensembles of trees.These are hard to interpret, offsetting their original benefits. Shapley values have recently become a popular way to explain the predictions of tree-based machine learning models. It provides a linear weighting to features independent of the tree structure. The rise in popularity is mainly due to TreeShap, which solves a general exponential complexity problem in polynomial time. Following extensive adoption in the industry, more efficient algorithms are required. This paper presents a more efficient and straightforward algorithm: Linear TreeShap.Like TreeShap, Linear TreeShap is exact and requires the same amount of memory.
count=15
* Provably robust boosted decision stumps and trees against adversarial attacks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/4206e38996fae4028a26d43b24f68d32-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/4206e38996fae4028a26d43b24f68d32-Paper.pdf)]
    * Title: Provably robust boosted decision stumps and trees against adversarial attacks
    * Year: `2019`
    * Authors: Maksym Andriushchenko, Matthias Hein
    * Abstract: The problem of adversarial robustness has been studied extensively for neural networks. However, for boosted decision trees and decision stumps there are almost no results, even though they are widely used in practice (e.g. XGBoost) due to their accuracy, interpretability, and efficiency. We show in this paper that for boosted decision stumps the \textit{exact} min-max robust loss and test error for an $l_\infty$-attack can be computed in $O(T\log T)$ time per input, where $T$ is the number of decision stumps and the optimal update step of the ensemble can be done in $O(n^2\,T\log T)$, where $n$ is the number of data points. For boosted trees we show how to efficiently calculate and optimize an upper bound on the robust loss, which leads to state-of-the-art robust test error for boosted trees on MNIST (12.5\% for $\epsilon_\infty=0.3$), FMNIST (23.2\% for $\epsilon_\infty=0.1$), and CIFAR-10 (74.7\% for $\epsilon_\infty=8/255$). Moreover, the robust test error rates we achieve are competitive to the ones of provably robust convolutional networks. The code of all our experiments is available at \url{http://github.com/max-andr/provably-robust-boosting}.
count=15
* Learning Partially Observable Models Using Temporally Abstract Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/39461a19e9eddfb385ea76b26521ea48-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/39461a19e9eddfb385ea76b26521ea48-Paper.pdf)]
    * Title: Learning Partially Observable Models Using Temporally Abstract Decision Trees
    * Year: `2012`
    * Authors: Erik Talvitie
    * Abstract: This paper introduces timeline trees, which are partial models of partially observable environments. Timeline trees are given some specific predictions to make and learn a decision tree over history. The main idea of timeline trees is to use temporally abstract features to identify and split on features of key events, spread arbitrarily far apart in the past (whereas previous decision-tree-based methods have been limited to a finite suffix of history). Experiments demonstrate that timeline trees can learn to make high quality predictions in complex, partially observable environments with high-dimensional observations (e.g. an arcade game).
count=14
* KITRO: Refining Human Mesh by 2D Clues and Kinematic-tree Rotation
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_KITRO_Refining_Human_Mesh_by_2D_Clues_and_Kinematic-tree_Rotation_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_KITRO_Refining_Human_Mesh_by_2D_Clues_and_Kinematic-tree_Rotation_CVPR_2024_paper.pdf)]
    * Title: KITRO: Refining Human Mesh by 2D Clues and Kinematic-tree Rotation
    * Year: `2024`
    * Authors: Fengyuan Yang, Kerui Gu, Angela Yao
    * Abstract: 2D keypoints are commonly used as an additional cue to refine estimated 3D human meshes. Current methods optimize the pose and shape parameters with a reprojection loss on the provided 2D keypoints. Such an approach while simple and intuitive has limited effectiveness because the optimal solution is hard to find in ambiguous parameter space and may sacrifice depth. Additionally divergent gradients from distal joints complicate and deviate the refinement of proximal joints in the kinematic chain. To address these we introduce Kinematic-Tree Rotation (KITRO) a novel mesh refinement strategy that explicitly models depth and human kinematic-tree structure. KITRO treats refinement from a bone-wise perspective. Unlike previous methods which perform gradient-based optimizations our method calculates bone directions in closed form. By accounting for the 2D pose bone length and parent joint's depth the calculation results in two possible directions for each child joint. We then use a decision tree to trace binary choices for all bones along the human skeleton's kinematic-tree to select the most probable hypothesis. Our experiments across various datasets and baseline models demonstrate that KITRO significantly improves 3D joint estimation accuracy and achieves an ideal 2D fit simultaneously. Our code available at: https://github.com/MartaYang/KITRO.
count=14
* Learn to Categorize or Categorize to Learn? Self-Coding for Generalized Category Discovery
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/e6789e468c65a7816760a00a487d3c4e-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/e6789e468c65a7816760a00a487d3c4e-Paper-Conference.pdf)]
    * Title: Learn to Categorize or Categorize to Learn? Self-Coding for Generalized Category Discovery
    * Year: `2023`
    * Authors: Sarah Rastegar, Hazel Doughty, Cees Snoek
    * Abstract: In the quest for unveiling novel categories at test time, we confront the inherent limitations of traditional supervised recognition models that are restricted by a predefined category set. While strides have been made in the realms of self-supervised and open-world learning towards test-time category discovery, a crucial yet often overlooked question persists: what exactly delineates a category? In this paper, we conceptualize a category through the lens of optimization, viewing it as an optimal solution to a well-defined problem. Harnessing this unique conceptualization, we propose a novel, efficient and self-supervised method capable of discovering previously unknown categories at test time. A salient feature of our approach is the assignment of minimum length category codes to individual data instances, which encapsulates the implicit category hierarchy prevalent in real-world datasets. This mechanism affords us enhanced control over category granularity, thereby equipping our model to handle fine-grained categories adeptly. Experimental evaluations, bolstered by state-of-the-art benchmark comparisons, testify to the efficacy of our solution in managing unknown categories at test time. Furthermore, we fortify our proposition with a theoretical foundation, providing proof of its optimality. Our code is available at: https://github.com/SarahRastegar/InfoSieve.
count=14
* Deep Differentiable Logic Gate Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/0d3496dd0cec77a999c98d35003203ca-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/0d3496dd0cec77a999c98d35003203ca-Paper-Conference.pdf)]
    * Title: Deep Differentiable Logic Gate Networks
    * Year: `2022`
    * Authors: Felix Petersen, Christian Borgelt, Hilde Kuehne, Oliver Deussen
    * Abstract: Recently, research has increasingly focused on developing efficient neural network architectures. In this work, we explore logic gate networks for machine learning tasks by learning combinations of logic gates. These networks comprise logic gates such as "AND" and "XOR", which allow for very fast execution. The difficulty in learning logic gate networks is that they are conventionally non-differentiable and therefore do not allow training with gradient descent. Thus, to allow for effective training, we propose differentiable logic gate networks, an architecture that combines real-valued logics and a continuously parameterized relaxation of the network. The resulting discretized logic gate networks achieve fast inference speeds, e.g., beyond a million images of MNIST per second on a single CPU core.
count=14
* Greedy Approximation Algorithms for Active Sequential Hypothesis Testing
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/27e9661e033a73a6ad8cefcde965c54d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/27e9661e033a73a6ad8cefcde965c54d-Paper.pdf)]
    * Title: Greedy Approximation Algorithms for Active Sequential Hypothesis Testing
    * Year: `2021`
    * Authors: Kyra Gan, Su Jia, Andrew Li
    * Abstract: In the problem of \emph{active sequential hypothesis testing} (ASHT), a learner seeks to identify the \emph{true} hypothesis from among a known set of hypotheses. The learner is given a set of actions and knows the random distribution of the outcome of any action under any true hypothesis. Given a target error $\delta>0$, the goal is to sequentially select the fewest number of actions so as to identify the true hypothesis with probability at least $1 - \delta$. Motivated by applications in which the number of hypotheses or actions is massive (e.g., genomics-based cancer detection), we propose efficient (greedy, in fact) algorithms and provide the first approximation guarantees for ASHT, under two types of adaptivity. Both of our guarantees are independent of the number of actions and logarithmic in the number of hypotheses. We numerically evaluate the performance of our algorithms using both synthetic and real-world DNA mutation data, demonstrating that our algorithms outperform previously proposed heuristic policies by large margins.
count=14
* Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/477bdb55b231264bb53a7942fd84254d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/477bdb55b231264bb53a7942fd84254d-Paper.pdf)]
    * Title: Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations
    * Year: `2020`
    * Authors: Rohan Paleja, Andrew Silva, Letian Chen, Matthew Gombolay
    * Abstract: Resource scheduling and coordination is an NP-hard optimization requiring an efficient allocation of agents to a set of tasks with upper- and lower bound temporal and resource constraints. Due to the large-scale and dynamic nature of resource coordination in hospitals and factories, human domain experts manually plan and adjust schedules on the fly. To perform this job, domain experts leverage heterogeneous strategies and rules-of-thumb honed over years of apprenticeship. What is critically needed is the ability to extract this domain knowledge in a heterogeneous and interpretable apprenticeship learning framework to scale beyond the power of a single human expert, a necessity in safety-critical domains. We propose a personalized and interpretable apprenticeship scheduling algorithm that infers an interpretable representation of all human task demonstrators by extracting decision-making criteria via an inferred, personalized embedding non-parametric in the number of demonstrator types. We achieve near-perfect LfD accuracy in synthetic domains and 88.22\% accuracy on a planning domain with real-world data, outperforming baselines. Finally, our user study showed our methodology produces more interpretable and easier-to-use models than neural networks ($p < 0.05$).
count=14
* Cost efficient gradient boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/4fac9ba115140ac4f1c22da82aa0bc7f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/4fac9ba115140ac4f1c22da82aa0bc7f-Paper.pdf)]
    * Title: Cost efficient gradient boosting
    * Year: `2017`
    * Authors: Sven Peter, Ferran Diego, Fred A. Hamprecht, Boaz Nadler
    * Abstract: Many applications require learning classifiers or regressors that are both accurate and cheap to evaluate. Prediction cost can be drastically reduced if the learned predictor is constructed such that on the majority of the inputs, it uses cheap features and fast evaluations. The main challenge is to do so with little loss in accuracy. In this work we propose a budget-aware strategy based on deep boosted regression trees. In contrast to previous approaches to learning with cost penalties, our method can grow very deep trees that on average are nonetheless cheap to compute. We evaluate our method on a number of datasets and find that it outperforms the current state of the art by a large margin. Our algorithm is easy to implement and its learning time is comparable to that of the original gradient boosting. Source code is made available at http://github.com/svenpeter42/LightGBM-CEGB.
count=14
* Pruning Random Forests for Prediction on a Budget
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/3948ead63a9f2944218de038d8934305-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/3948ead63a9f2944218de038d8934305-Paper.pdf)]
    * Title: Pruning Random Forests for Prediction on a Budget
    * Year: `2016`
    * Authors: Feng Nan, Joseph Wang, Venkatesh Saligrama
    * Abstract: We propose to prune a random forest (RF) for resource-constrained prediction. We first construct a RF and then prune it to optimize expected feature cost & accuracy. We pose pruning RFs as a novel 0-1 integer program with linear constraints that encourages feature re-use. We establish total unimodularity of the constraint set to prove that the corresponding LP relaxation solves the original integer program. We then exploit connections to combinatorial optimization and develop an efficient primal-dual algorithm, scalable to large datasets. In contrast to our bottom-up approach, which benefits from good RF initialization, conventional methods are top-down acquiring features based on their utility value and is generally intractable, requiring heuristics. Empirically, our pruning algorithm outperforms existing state-of-the-art resource-constrained algorithms.
count=13
* VaRT: Variational Regression Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/8eff4196f50c43eda7bcf0f0cf87a0d0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/8eff4196f50c43eda7bcf0f0cf87a0d0-Paper-Conference.pdf)]
    * Title: VaRT: Variational Regression Trees
    * Year: `2023`
    * Authors: Sebastian Salazar
    * Abstract: Decision trees are a well-established tool in machine learning for classification and regression tasks. In this paper, we introduce a novel non-parametric Bayesian model that uses variational inference to approximate a posterior distribution over the space of stochastic decision trees. We evaluate the model's performance on 18 datasets and demonstrate its competitiveness with other state-of-the-art methods in regression tasks. We also explore its application to causal inference problems. We provide a fully vectorized implementation of our algorithm in PyTorch.
count=13
* MABSplit: Faster Forest Training Using Multi-Armed Bandits
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/08857467641ad82f635023d530605b4c-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/08857467641ad82f635023d530605b4c-Paper-Conference.pdf)]
    * Title: MABSplit: Faster Forest Training Using Multi-Armed Bandits
    * Year: `2022`
    * Authors: Mo Tiwari, Ryan Kang, Jaeyong Lee, Chris Piech, Ilan Shomorony, Sebastian Thrun, Martin J. Zhang
    * Abstract: Random forests are some of the most widely used machine learning models today, especially in domains that necessitate interpretability. We present an algorithm that accelerates the training of random forests and other popular tree-based learning methods. At the core of our algorithm is a novel node-splitting subroutine, dubbed MABSplit, used to efficiently find split points when constructing decision trees. Our algorithm borrows techniques from the multi-armed bandit literature to judiciously determine how to allocate samples and computational power across candidate split points. We provide theoretical guarantees that MABSplit improves the sample complexity of each node split from linear to logarithmic in the number of data points. In some settings, MABSplit leads to 100x faster training (an 99% reduction in training time) without any decrease in generalization performance. We demonstrate similar speedups when MABSplit is used across a variety of forest-based variants, such as Extremely Random Forests and Random Patches. We also show our algorithm can be used in both classification and regression tasks. Finally, we show that MABSplit outperforms existing methods in generalization performance and feature importance calculations under a fixed computational budget. All of our experimental results are reproducible via a one-line script at https://github.com/ThrunGroup/FastForest.
count=13
* Washing The Unwashable : On The (Im)possibility of Fairwashing Detection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/5b84864ff8474fd742c66f219b2eaac1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/5b84864ff8474fd742c66f219b2eaac1-Paper-Conference.pdf)]
    * Title: Washing The Unwashable : On The (Im)possibility of Fairwashing Detection
    * Year: `2022`
    * Authors: Ali Shahin Shamsabadi, Mohammad Yaghini, Natalie Dullerud, Sierra Wyllie, Ulrich Aïvodji, Aisha Alaagib, Sébastien Gambs, Nicolas Papernot
    * Abstract: The use of black-box models (e.g., deep neural networks) in high-stakes decision-making systems, whose internal logic is complex, raises the need for providing explanations about their decisions. Model explanation techniques mitigate this problem by generating an interpretable and high-fidelity surrogate model (e.g., a logistic regressor or decision tree) to explain the logic of black-box models. In this work, we investigate the issue of fairwashing, in which model explanation techniques are manipulated to rationalize decisions taken by an unfair black-box model using deceptive surrogate models. More precisely, we theoretically characterize and analyze fairwashing, proving that this phenomenon is difficult to avoid due to an irreducible factor---the unfairness of the black-box model. Based on the theory developed, we propose a novel technique, called FRAUD-Detect (FaiRness AUDit Detection), to detect fairwashed models by measuring a divergence over subpopulation-wise fidelity measures of the interpretable model. We empirically demonstrate that this divergence is significantly larger in purposefully fairwashed interpretable models than in honest ones. Furthermore, we show that our detector is robust to an informed adversary trying to bypass our detector. The code implementing FRAUD-Detect is available at https://github.com/cleverhans-lab/FRAUD-Detect.
count=13
* Revisiting Deep Learning Models for Tabular Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/9d86d83f925f2149e9edb0ac3b49229c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/9d86d83f925f2149e9edb0ac3b49229c-Paper.pdf)]
    * Title: Revisiting Deep Learning Models for Tabular Data
    * Year: `2021`
    * Authors: Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, Artem Babenko
    * Abstract: The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets. However, the proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols. As a result, it is unclear for both researchers and practitioners what models perform best. Additionally, the field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems.In this work, we perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures. The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works. The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks. Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols. We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution. The source code is available at https://github.com/yandex-research/rtdl.
count=13
* SnapBoost: A Heterogeneous Boosting Machine
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/7fd3b80fb1884e2927df46a7139bb8bf-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/7fd3b80fb1884e2927df46a7139bb8bf-Paper.pdf)]
    * Title: SnapBoost: A Heterogeneous Boosting Machine
    * Year: `2020`
    * Authors: Thomas Parnell, Andreea Anghel, Małgorzata Łazuka, Nikolas Ioannou, Sebastian Kurella, Peshal Agarwal, Nikolaos Papandreou, Haralampos Pozidis
    * Abstract: Modern gradient boosting software frameworks, such as XGBoost and LightGBM, implement Newton descent in a functional space. At each boosting iteration, their goal is to find the base hypothesis, selected from some base hypothesis class, that is closest to the Newton descent direction in a Euclidean sense. Typically, the base hypothesis class is fixed to be all binary decision trees up to a given depth. In this work, we study a Heterogeneous Newton Boosting Machine (HNBM) in which the base hypothesis class may vary across boosting iterations. Specifically, at each boosting iteration, the base hypothesis class is chosen, from a fixed set of subclasses, by sampling from a probability distribution. We derive a global linear convergence rate for the HNBM under certain assumptions, and show that it agrees with existing rates for Newton's method when the Newton direction can be perfectly fitted by the base hypothesis at each boosting iteration. We then describe a particular realization of a HNBM, SnapBoost, that, at each boosting iteration, randomly selects between either a decision tree of variable depth or a linear regressor with random Fourier features. We describe how SnapBoost is implemented, with a focus on the training complexity. Finally, we present experimental results, using OpenML and Kaggle datasets, that show that SnapBoost is able to achieve better generalization loss than competing boosting frameworks, without taking significantly longer to tune.
count=13
* Logarithmic Time Online Multiclass prediction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/e369853df766fa44e1ed0ff613f563bd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/e369853df766fa44e1ed0ff613f563bd-Paper.pdf)]
    * Title: Logarithmic Time Online Multiclass prediction
    * Year: `2015`
    * Authors: Anna E. Choromanska, John Langford
    * Abstract: We study the problem of multiclass classification with an extremely large number of classes (k), with the goal of obtaining train and test time complexity logarithmic in the number of classes. We develop top-down tree construction approaches for constructing logarithmic depth trees. On the theoretical front, we formulate a new objective function, which is optimized at each node of the tree and creates dynamic partitions of the data which are both pure (in terms of class labels) and balanced. We demonstrate that under favorable conditions, we can construct logarithmic depth trees that have leaves with low label entropy. However, the objective function at the nodes is challenging to optimize computationally. We address the empirical problem with a new online decision tree construction procedure. Experiments demonstrate that this online algorithm quickly achieves improvement in test error compared to more common logarithmic training time approaches, which makes it a plausible method in computationally constrained large-k applications.
count=12
* Towards Better Decision Forests: Forest Alternating Optimization
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Carreira-Perpinan_Towards_Better_Decision_Forests_Forest_Alternating_Optimization_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Carreira-Perpinan_Towards_Better_Decision_Forests_Forest_Alternating_Optimization_CVPR_2023_paper.pdf)]
    * Title: Towards Better Decision Forests: Forest Alternating Optimization
    * Year: `2023`
    * Authors: Miguel Á. Carreira-Perpiñán, Magzhan Gabidolla, Arman Zharmagambetov
    * Abstract: Decision forests are among the most accurate models in machine learning. This is remarkable given that the way they are trained is highly heuristic: neither the individual trees nor the overall forest optimize any well-defined loss. While diversity mechanisms such as bagging or boosting have been until now critical in the success of forests, we think that a better optimization should lead to better forests---ideally eliminating any need for an ensembling heuristic. However, unlike for most other models, such as neural networks, optimizing forests or trees is not easy, because they define a non-differentiable function. We show, for the first time, that it is possible to learn a forest by optimizing a desirable loss and regularization jointly over all its trees and parameters. Our algorithm, Forest Alternating Optimization, is based on defining a forest as a parametric model with a fixed number of trees and structure (rather than adding trees indefinitely as in bagging or boosting). It then iteratively updates each tree in alternation so that the objective function decreases monotonically. The algorithm is so effective at optimizing that it easily overfits, but this can be corrected by averaging. The result is a forest that consistently exceeds the accuracy of the state-of-the-art while using fewer, smaller trees.
count=12
* Filtered Feature Channels for Pedestrian Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Zhang_Filtered_Feature_Channels_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Zhang_Filtered_Feature_Channels_2015_CVPR_paper.pdf)]
    * Title: Filtered Feature Channels for Pedestrian Detection
    * Year: `2015`
    * Authors: Shanshan Zhang, Rodrigo Benenson, Bernt Schiele
    * Abstract: This paper starts from the observation that multiple top performing pedestrian detectors can be modelled by using an intermediate layer filtering low-level features in combination with a boosted decision forest. Based on this observation we propose a unifying framework and experimentally explore different filter families. We report extensive results enabling a systematic analysis. Using filtered channel features we obtain top performance on the challenging Caltech and KITTI datasets, while using only HOG+LUV as low-level features. When adding optical flow features we further improve detection quality and report the best known result on the Caltech dataset, reaching 93% recall at 1 FPPI.
count=12
* Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Aodha_Revisiting_Example_Dependent_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Aodha_Revisiting_Example_Dependent_2013_ICCV_paper.pdf)]
    * Title: Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees
    * Year: `2013`
    * Authors: Oisin Mac Aodha, Gabriel J. Brostow
    * Abstract: Typical approaches to classification treat class labels as disjoint. For each training example, it is assumed that there is only one class label that correctly describes it, and that all other labels are equally bad. We know however, that good and bad labels are too simplistic in many scenarios, hurting accuracy. In the realm of example dependent costsensitive learning, each label is instead a vector representing a data point's affinity for each of the classes. At test time, our goal is not to minimize the misclassification rate, but to maximize that affinity. We propose a novel example dependent cost-sensitive impurity measure for decision trees. Our experiments show that this new impurity measure improves test performance while still retaining the fast test times of standard classification trees. We compare our approach to classification trees and other cost-sensitive methods on three computer vision problems, tracking, descriptor matching, and optical flow, and show improvements in all three domains.
count=12
* What Can Transformers Learn In-Context? A Case Study of Simple Function Classes
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/c529dba08a146ea8d6cf715ae8930cbe-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/c529dba08a146ea8d6cf715ae8930cbe-Paper-Conference.pdf)]
    * Title: What Can Transformers Learn In-Context? A Case Study of Simple Function Classes
    * Year: `2022`
    * Authors: Shivam Garg, Dimitris Tsipras, Percy S. Liang, Gregory Valiant
    * Abstract: In-context learning is the ability of a model to condition on a prompt sequence consisting of in-context examples (input-output pairs corresponding to some task) along with a new query input, and generate the corresponding output. Crucially, in-context learning happens only at inference time without any parameter updates to the model. While large language models such as GPT-3 exhibit some ability to perform in-context learning, it is unclear what the relationship is between tasks on which this succeeds and what is present in the training data. To investigate this, we consider the problem of training a model to in-context learn a function class (e.g., linear functions): given data derived from some functions in the class, can we train a model (e.g., a Transformer) to in-context learn most functions from that class? We show empirically that standard Transformers can be trained from scratch to perform in-context learning of linear functions---that is, the trained model is able to learn unseen linear functions from in-context examples with performance comparable to the optimal least squares estimator. In fact, in-context learning is possible even under two forms of distribution shift: (i) between the training data of the Transformer and inference-time prompts, and (ii) between the in-context examples and the query input during inference. We also show that we can train Transformers to in-context learn more complex function classes: sparse linear functions where the model outperforms least squares and nearly matches the performance of Lasso, and two-layer neural networks where the model performs comparably to neural networks trained on in-context examples using gradient descent.
count=11
* Online Learning With Bayesian Classification Trees
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Bulo_Online_Learning_With_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Bulo_Online_Learning_With_CVPR_2016_paper.pdf)]
    * Title: Online Learning With Bayesian Classification Trees
    * Year: `2016`
    * Authors: Samuel Rota Bulo, Peter Kontschieder
    * Abstract: Randomized classification trees are among the most popular machine learning tools and found successful applications in many areas. Although this classifier was originally designed as offline learning algorithm, there has been an increased interest in the last years to provide an online variant. In this paper, we propose an online learning algorithm for classification trees that adheres to Bayesian principles. In contrast to state-of-the-art approaches that produce large forests with complex trees, we aim at constructing small ensembles consisting of shallow trees with high generalization capabilities. Experiments on benchmark machine learning and body part recognition datasets show superior performance over state-of-the-art approaches.
count=11
* Transformation-Invariant Convolutional Jungles
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Laptev_Transformation-Invariant_Convolutional_Jungles_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Laptev_Transformation-Invariant_Convolutional_Jungles_2015_CVPR_paper.pdf)]
    * Title: Transformation-Invariant Convolutional Jungles
    * Year: `2015`
    * Authors: Dmitry Laptev, Joachim M. Buhmann
    * Abstract: Many Computer Vision problems arise from information processing of data sources with nuisance variances like scale, orientation, contrast, perspective foreshortening or - in medical imaging - staining and local warping. In most cases these variances can be stated a priori and can be used to improve the generalization of recognition algorithms. We propose a novel supervised feature learning approach, which efficiently extracts information from these constraints to produce interpretable, transformation-invariant features. The proposed method can incorporate a large class of transformations, e.g., shifts, rotations, change of scale, morphological operations, non-linear distortions, photometric transformations, etc. These features boost the discrimination power of a novel image classification and segmentation method, which we call Transformation-Invariant Convolutional Jungles (TICJ). We test the algorithm on two benchmarks in face recognition and medical imaging, where it achieves state of the art results, while being computationally significantly more efficient than Deep Neural Networks.
count=11
* Neural Decision Forests for Semantic Image Labelling
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Bulo_Neural_Decision_Forests_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Bulo_Neural_Decision_Forests_2014_CVPR_paper.pdf)]
    * Title: Neural Decision Forests for Semantic Image Labelling
    * Year: `2014`
    * Authors: Samuel Rota Bulo, Peter Kontschieder
    * Abstract: In this work we present Neural Decision Forests, a novel approach to jointly tackle data representation- and discriminative learning within randomized decision trees. Recent advances of deep learning architectures demonstrate the power of embedding representation learning within the classifier – An idea that is intuitively supported by the hierarchical nature of the decision forest model where the input space is typically left unchanged during training and testing. We bridge this gap by introducing randomized Multi- Layer Perceptrons (rMLP) as new split nodes which are capable of learning non-linear, data-specific representations and taking advantage of them by finding optimal predictions for the emerging child nodes. To prevent overfitting, we i) randomly select the image data fed to the input layer, ii) automatically adapt the rMLP topology to meet the complexity of the data arriving at the node and iii) introduce an l1-norm based regularization that additionally sparsifies the network. The key findings in our experiments on three different semantic image labelling datasets are consistently improved results and significantly compressed trees compared to conventional classification trees.
count=11
* Semi-supervised Node Splitting for Random Forest Construction
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Liu_Semi-supervised_Node_Splitting_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Liu_Semi-supervised_Node_Splitting_2013_CVPR_paper.pdf)]
    * Title: Semi-supervised Node Splitting for Random Forest Construction
    * Year: `2013`
    * Authors: Xiao Liu, Mingli Song, Dacheng Tao, Zicheng Liu, Luming Zhang, Chun Chen, Jiajun Bu
    * Abstract: Node splitting is an important issue in Random Forest but robust splitting requires a large number of training samples. Existing solutions fail to properly partition the feature space if there are insufficient training data. In this paper, we present semi-supervised splitting to overcome this limitation by splitting nodes with the guidance of both labeled and unlabeled data. In particular, we derive a nonparametric algorithm to obtain an accurate quality measure of splitting by incorporating abundant unlabeled data. To avoid the curse of dimensionality, we project the data points from the original high-dimensional feature space onto a low-dimensional subspace before estimation. A unified optimization framework is proposed to select a coupled pair of subspace and separating hyperplane such that the smoothness of the subspace and the quality of the splitting are guaranteed simultaneously. The proposed algorithm is compared with state-of-the-art supervised and semi-supervised algorithms for typical computer vision applications such as object categorization and image segmentation. Experimental results on publicly available datasets demonstrate the superiority of our method.
count=11
* Structured Forests for Fast Edge Detection
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Dollar_Structured_Forests_for_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Dollar_Structured_Forests_for_2013_ICCV_paper.pdf)]
    * Title: Structured Forests for Fast Edge Detection
    * Year: `2013`
    * Authors: Piotr Dollar, C. L. Zitnick
    * Abstract: Edge detection is a critical component of many vision systems, including object detectors and image segmentation algorithms. Patches of edges exhibit well-known forms of local structure, such as straight lines or T-junctions. In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. The result is an approach that obtains realtime performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets.
count=11
* The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/1403ab1a427050538ec59c7f570aec8b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/1403ab1a427050538ec59c7f570aec8b-Paper-Conference.pdf)]
    * Title: The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance
    * Year: `2023`
    * Authors: Jon Donnelly, Srikar Katta, Cynthia Rudin, Edward Browne
    * Abstract: Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We demonstrate through experiments that our framework recovers variable importance rankings for complex simulation setups where other methods fail. Further, we show that our framework accurately estimates the true importance of a variable for the underlying data distribution. We provide theoretical guarantees on the consistency and finite sample error rates for our estimator. Finally, we demonstrate its utility with a real-world case study exploring which genes are important for predicting HIV load in persons with HIV, highlighting an important gene that has not previously been studied in connection with HIV.
count=11
* High dimensional, tabular deep learning with an auxiliary knowledge graph
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/53dd219b6b11abc8ce523921c18c7a3e-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/53dd219b6b11abc8ce523921c18c7a3e-Paper-Conference.pdf)]
    * Title: High dimensional, tabular deep learning with an auxiliary knowledge graph
    * Year: `2023`
    * Authors: Camilo Ruiz, Hongyu Ren, Kexin Huang, Jure Leskovec
    * Abstract: Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high $d$-dimensional features but limited $n$ samples (i.e. $d \gg n$), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose PLATO, a method that achieves strong performance on tabular data with $d \gg n$ by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In PLATO, each input feature corresponds to a node in the auxiliary KG. In the MLP’s first layer, each input feature also corresponds to a weight vector. PLATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP's first layer. PLATO captures this inductive bias by inferring the weight vector for each input feature from its corresponding node in the KG via a trainable message-passing function. Across 6 $d \gg n$ datasets, PLATO outperforms 13 state-of-the-art baselines by up to 10.19%.
count=11
* On Embeddings for Numerical Features in Tabular Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/9e9f0ffc3d836836ca96cbf8fe14b105-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/9e9f0ffc3d836836ca96cbf8fe14b105-Paper-Conference.pdf)]
    * Title: On Embeddings for Numerical Features in Tabular Deep Learning
    * Year: `2022`
    * Authors: Yury Gorishniy, Ivan Rubachev, Artem Babenko
    * Abstract: Recently, Transformer-like deep architectures have shown strong performance on tabular data problems. Unlike traditional models, e.g., MLP, these architectures map scalar values of numerical features to high-dimensional embeddings before mixing them in the main backbone. In this work, we argue that embeddings for numerical features are an underexplored degree of freedom in tabular DL, which allows constructing more powerful DL models and competing with gradient boosted decision trees (GBDT) on some GBDT-friendly benchmarks (that is, where GBDT outperforms conventional DL models). We start by describing two conceptually different approaches to building embedding modules: the first one is based on a piecewise linear encoding of scalar values, and the second one utilizes periodic activations. Then, we empirically demonstrate that these two approaches can lead to significant performance boosts compared to the embeddings based on conventional blocks such as linear layers and ReLU activations. Importantly, we also show that embedding numerical features is beneficial for many backbones, not only for Transformers. Specifically, after proper embeddings, simple MLP-like models can perform on par with the attention-based architectures. Overall, we highlight embeddings for numerical features as an important design aspect with good potential for further improvements in tabular DL. The source code is available at https://github.com/Yura52/tabular-dl-num-embeddings
count=11
* Human-in-the-Loop Interpretability Prior
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/0a7d83f084ec258aefd128569dda03d7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/0a7d83f084ec258aefd128569dda03d7-Paper.pdf)]
    * Title: Human-in-the-Loop Interpretability Prior
    * Year: `2018`
    * Authors: Isaac Lage, Andrew Ross, Samuel J. Gershman, Been Kim, Finale Doshi-Velez
    * Abstract: We often desire our models to be interpretable as well as accurate. Prior work on optimizing models for interpretability has relied on easy-to-quantify proxies for interpretability, such as sparsity or the number of operations required. In this work, we optimize for interpretability by directly including humans in the optimization loop. We develop an algorithm that minimizes the number of user studies to find models that are both predictive and interpretable and demonstrate our approach on several data sets. Our human subjects results show trends towards different proxy notions of interpretability on different datasets, which suggests that different proxies are preferred on different tasks.
count=11
* Multi-Layered Gradient Boosting Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/39027dfad5138c9ca0c474d71db915c3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/39027dfad5138c9ca0c474d71db915c3-Paper.pdf)]
    * Title: Multi-Layered Gradient Boosting Decision Trees
    * Year: `2018`
    * Authors: Ji Feng, Yang Yu, Zhi-Hua Zhou
    * Abstract: Multi-layered distributed representation is believed to be the key ingredient of deep neural networks especially in cognitive tasks like computer vision. While non-differentiable models such as gradient boosting decision trees (GBDTs) are still the dominant methods for modeling discrete or tabular data, they are hard to incorporate with such representation learning ability. In this work, we propose the multi-layered GBDT forest (mGBDTs), with an explicit emphasis on exploring the ability to learn hierarchical distributed representations by stacking several layers of regression GBDTs as its building block. The model can be jointly trained by a variant of target propagation across layers, without the need to derive backpropagation nor differentiability. Experiments confirmed the effectiveness of the model in terms of performance and representation learning ability.
count=11
* Multi-Class Deep Boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/7bb060764a818184ebb1cc0d43d382aa-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/7bb060764a818184ebb1cc0d43d382aa-Paper.pdf)]
    * Title: Multi-Class Deep Boosting
    * Year: `2014`
    * Authors: Vitaly Kuznetsov, Mehryar Mohri, Umar Syed
    * Abstract: We present new ensemble learning algorithms for multi-class classification. Our algorithms can use as a base classifier set a family of deep decision trees or other rich or complex families and yet benefit from strong generalization guarantees. We give new data-dependent learning bounds for convex ensembles in the multi-class classification setting expressed in terms of the Rademacher complexities of the sub-families composing the base classifier set, and the mixture weight assigned to each sub-family. These bounds are finer than existing ones both thanks to an improved dependency on the number of classes and, more crucially, by virtue of a more favorable complexity term expressed as an average of the Rademacher complexities based on the ensemble’s mixture weights. We introduce and discuss several new multi-class ensemble algorithms benefiting from these guarantees, prove positive results for the H-consistency of several of them, and report the results of experiments showing that their performance compares favorably with that of multi-class versions of AdaBoost and Logistic Regression and their L1-regularized counterparts.
count=11
* Local Supervised Learning through Space Partitioning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/a684eceee76fc522773286a895bc8436-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/a684eceee76fc522773286a895bc8436-Paper.pdf)]
    * Title: Local Supervised Learning through Space Partitioning
    * Year: `2012`
    * Authors: Joseph Wang, Venkatesh Saligrama
    * Abstract: We develop a novel approach for supervised learning based on adaptively partitioning the feature space into different regions and learning local region-specific classifiers. We formulate an empirical risk minimization problem that incorporates both partitioning and classification in to a single global objective. We show that space partitioning can be equivalently reformulated as a supervised learning problem and consequently any discriminative learning method can be utilized in conjunction with our approach. Nevertheless, we consider locally linear schemes by learning linear partitions and linear region classifiers. Locally linear schemes can not only approximate complex decision boundaries and ensure low training error but also provide tight control on over-fitting and generalization error. We train locally linear classifiers by using LDA, logistic regression and perceptrons, and so our scheme is scalable to large data sizes and high-dimensions. We present experimental results demonstrating improved performance over state of the art classification techniques on benchmark datasets. We also show improved robustness to label noise.
count=10
* FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Shao_FineGym_A_Hierarchical_Video_Dataset_for_Fine-Grained_Action_Understanding_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Shao_FineGym_A_Hierarchical_Video_Dataset_for_Fine-Grained_Action_Understanding_CVPR_2020_paper.pdf)]
    * Title: FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding
    * Year: `2020`
    * Authors: Dian Shao,  Yue Zhao,  Bo Dai,  Dahua Lin
    * Abstract: On public benchmarks, current action recognition techniques have achieved great success. However, when used in real-world applications, e.g. sport analysis, which requires the capability of parsing an activity into phases and differentiating between subtly different actions, their performances remain far from being satisfactory. To take action recognition to a new level, we develop FineGym, a new dataset built on top of gymnasium videos. Compared to existing action recognition datasets, FineGym is distinguished in richness, quality, and diversity. In particular, it provides temporal annotations at both action and sub-action levels with a three-level semantic hierarchy. For example, a "balance beam" activity will be annotated as a sequence of elementary sub-actions derived from five sets: "leap-jump-hop", "beam-turns", "flight-salto", "flight-handspring", and "dismount", where the sub-action in each set will be further annotated with finely defined class labels. This new level of granularity presents significant challenges for action recognition, e.g. how to parse the temporal structures from a coherent action, and how to distinguish between subtly different action classes. We systematically investigates different methods on this dataset and obtains a number of interesting findings. We hope this dataset could advance research towards action understanding.
count=10
* The Global Patch Collider
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Wang_The_Global_Patch_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Wang_The_Global_Patch_CVPR_2016_paper.pdf)]
    * Title: The Global Patch Collider
    * Year: `2016`
    * Authors: Shenlong Wang, Sean Ryan Fanello, Christoph Rhemann, Shahram Izadi, Pushmeet Kohli
    * Abstract: This paper proposes a novel extremely efficient, fully-parallelizable, task-specific algorithm for the computation of global point-wise correspondences in images and videos. Our algorithm, the Global Patch Collider, is based on detecting unique collisions between image points using a collection of learned tree structures that act as conditional hash functions. In contrast to conventional approaches that rely on pairwise distance computation, our algorithm isolates distinctive pixel pairs that hit the same leaf during traversal through multiple learned tree structures. The split functions stored at the intermediate nodes of the trees are trained to ensure that only visually similar patches or their geometric or photometric transformed versions fall into the same leaf node. The matching process involves passing all pixel positions in the images under analysis through the tree structures. We then compute matches by isolating points that uniquely collide with each other ie. fell in the same empty leaf in multiple trees. Our algorithm is linear in the number of pixels but can be made constant time on a parallel computation architecture as the tree traversal for individual image points is decoupled. We demonstrate the efficacy of our method by using it to perform optical flow matching and stereo matching on some challenging benchmarks. Experimental results show that not only is our method extremely computationally efficient, but it is also able to match or outperform state of the art methods that are much more complex.
count=10
* Efficient 3D Scene Labeling Using Fields of Trees
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Kahler_Efficient_3D_Scene_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Kahler_Efficient_3D_Scene_2013_ICCV_paper.pdf)]
    * Title: Efficient 3D Scene Labeling Using Fields of Trees
    * Year: `2013`
    * Authors: Olaf Kahler, Ian Reid
    * Abstract: We address the problem of 3D scene labeling in a structured learning framework. Unlike previous work which uses structured Support Vector Machines, we employ the recently described Decision Tree Field and Regression Tree Field frameworks, which learn the unary and binary terms of a Conditional Random Field from training data. We show this has significant advantages in terms of inference speed, while maintaining similar accuracy. We also demonstrate empirically the importance for overall labeling accuracy of features that make use of prior knowledge about the coarse scene layout such as the location of the ground plane. We show how this coarse layout can be estimated by our framework automatically, and that this information can be used to bootstrap improved accuracy in the detailed labeling.
count=10
* A Deep Sum-Product Architecture for Robust Facial Attributes Analysis
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Luo_A_Deep_Sum-Product_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Luo_A_Deep_Sum-Product_2013_ICCV_paper.pdf)]
    * Title: A Deep Sum-Product Architecture for Robust Facial Attributes Analysis
    * Year: `2013`
    * Authors: Ping Luo, Xiaogang Wang, Xiaoou Tang
    * Abstract: Recent works have shown that facial attributes are useful in a number of applications such as face recognition and retrieval. However, estimating attributes in images with large variations remains a big challenge. This challenge is addressed in this paper. Unlike existing methods that assume the independence of attributes during their estimation, our approach captures the interdependencies of local regions for each attribute, as well as the high-order correlations between different attributes, which makes it more robust to occlusions and misdetection of face regions. First, we have modeled region interdependencies with a discriminative decision tree, where each node consists of a detector and a classifier trained on a local region. The detector allows us to locate the region, while the classifier determines the presence or absence of an attribute. Second, correlations of attributes and attribute predictors are modeled by organizing all of the decision trees into a large sum-product network (SPN), which is learned by the EM algorithm and yields the most probable explanation (MPE) of the facial attributes in terms of the region's localization and classification. Experimental results on a large data set with 22, 400 images show the effectiveness of the proposed approach.
count=10
* Scalable Rule-Based Representation Learning for Interpretable Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/ffbd6cbb019a1413183c8d08f2929307-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/ffbd6cbb019a1413183c8d08f2929307-Paper.pdf)]
    * Title: Scalable Rule-Based Representation Learning for Interpretable Classification
    * Year: `2021`
    * Authors: Zhuo Wang, Wei Zhang, Ning Liu, Jianyong Wang
    * Abstract: Rule-based models, e.g., decision trees, are widely used in scenarios demanding high model interpretability for their transparent inner structures and good model expressivity. However, rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are commonly used to improve performance, but they sacrifice the model interpretability. To obtain both good scalability and interpretability, we propose a new classifier, named Rule-based Representation Learner (RRL), that automatically learns interpretable non-fuzzy rules for data representation and classification. To train the non-differentiable RRL effectively, we project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end-to-end. Exhaustive experiments on nine small and four large data sets show that RRL outperforms the competitive interpretable approaches and can be easily adjusted to obtain a trade-off between classification accuracy and model complexity for different scenarios. Our code is available at: https://github.com/12wang3/rrl.
count=10
* CatBoost: unbiased boosting with categorical features
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/14491b756b3a51daac41c24863285549-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf)]
    * Title: CatBoost: unbiased boosting with categorical features
    * Year: `2018`
    * Authors: Liudmila Prokhorenkova, Gleb Gusev, Aleksandr Vorobev, Anna Veronika Dorogush, Andrey Gulin
    * Abstract: This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.
count=9
* Transition Forests: Learning Discriminative Temporal Transitions for Action Recognition and Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Garcia-Hernando_Transition_Forests_Learning_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Garcia-Hernando_Transition_Forests_Learning_CVPR_2017_paper.pdf)]
    * Title: Transition Forests: Learning Discriminative Temporal Transitions for Action Recognition and Detection
    * Year: `2017`
    * Authors: Guillermo Garcia-Hernando, Tae-Kyun Kim
    * Abstract: A human action can be seen as transitions between one's body poses over time, where the transition depicts a temporal relation between two poses. Recognizing actions thus involves learning a classifier sensitive to these pose transitions as well as to static poses. In this paper, we introduce a novel method called transitions forests, an ensemble of decision trees that both learn to discriminate static poses and transitions between pairs of two independent frames. During training, node splitting is driven by alternating two criteria: the standard classification objective that maximizes the discrimination power in individual frames, and the proposed one in pairwise frame transitions. Growing the trees tends to group frames that have similar associated transitions and share same action label incorporating temporal information that was not available otherwise. Unlike conventional decision trees where the best split in a node is determined independently of other nodes, the transition forests try to find the best split of nodes jointly (within a layer) for incorporating distant node transitions. When inferring the class label of a new frame, it is passed down the trees and the prediction is made based on previous frame predictions and the current one in an efficient and online manner. We apply our method on varied skeleton action recognition and online detection datasets showing its suitability over several baselines and state-of-the-art approaches.
count=9
* A benchmark of categorical encoders for binary classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/ac01e21bb14609416760f790dd8966ae-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/ac01e21bb14609416760f790dd8966ae-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: A benchmark of categorical encoders for binary classification
    * Year: `2023`
    * Authors: Federico Matteucci, Vadim Arzamasov, Klemens Böhm
    * Abstract: Categorical encoders transform categorical features into numerical representations that are indispensable for a wide range of machine learning models.Existing encoder benchmark studies lack generalizability because of their limited choice of (1) encoders, (2) experimental factors, and (3) datasets. Additionally, inconsistencies arise from the adoption of varying aggregation strategies.This paper is the most comprehensive benchmark of categorical encoders to date, including an extensive evaluation of 32 configurations of encoders from diverse families, with 36 combinations of experimental factors, and on 50 datasets.The study shows the profound influence of dataset selection, experimental factors, and aggregation strategies on the benchmark's conclusions~---~aspects disregarded in previous encoder benchmarks.Our code is available at \url{https://github.com/DrCohomology/EncoderBenchmarking}.
count=9
* Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Selection with Theoretical Guarantees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/b153f11554e8f7926189e3f21185f00f-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/b153f11554e8f7926189e3f21185f00f-Paper-Conference.pdf)]
    * Title: Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Selection with Theoretical Guarantees
    * Year: `2022`
    * Authors: Wenying Deng, Beau Coker, Rajarshi Mukherjee, Jeremiah Liu, Brent Coull
    * Abstract: We develop a simple and unified framework for nonlinear variable importance estimation that incorporates uncertainty in the prediction function and is compatible with a wide range of machine learning models (e.g., tree ensembles, kernel methods, neural networks, etc). In particular, for a learned nonlinear model $f(\mathbf{x})$, we consider quantifying the importance of an input variable $\mathbf{x}^j$ using the integrated partial derivative $\Psi_j = \Vert \frac{\partial}{\partial \mathbf{x}^j} f(\mathbf{x})\Vert^2_{P_\mathcal{X}}$. We then (1) provide a principled approach for quantifying uncertainty in variable importance by deriving its posterior distribution, and (2) show that the approach is generalizable even to non-differentiable models such as tree ensembles. Rigorous Bayesian nonparametric theorems are derived to guarantee the posterior consistency and asymptotic uncertainty of the proposed approach. Extensive simulations and experiments on healthcare benchmark datasets confirm that the proposed algorithm outperforms existing classical and recent variable selection methods.
count=9
* Learning to Synthesize Programs as Interpretable and Generalizable Policies
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/d37124c4c79f357cb02c655671a432fa-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/d37124c4c79f357cb02c655671a432fa-Paper.pdf)]
    * Title: Learning to Synthesize Programs as Interpretable and Generalizable Policies
    * Year: `2021`
    * Authors: Dweep Trivedi, Jesse Zhang, Shao-Hua Sun, Joseph J. Lim
    * Abstract: Recently, deep reinforcement learning (DRL) methods have achieved impressive performance on tasks in a variety of domains. However, neural network policies produced with DRL methods are not human-interpretable and often have difficulty generalizing to novel scenarios. To address these issues, prior works explore learning programmatic policies that are more interpretable and structured for generalization. Yet, these works either employ limited policy representations (e.g. decision trees, state machines, or predefined program templates) or require stronger supervision (e.g. input/output state pairs or expert demonstrations). We present a framework that instead learns to synthesize a program, which details the procedure to solve a task in a flexible and expressive manner, solely from reward signals. To alleviate the difficulty of learning to compose programs to induce the desired agent behavior from scratch, we propose to first learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner and then search over the learned program embedding space to yield a program that maximizes the return for a given task. Experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms DRL and program synthesis baselines while producing interpretable and more generalizable policies. We also justify the necessity of the proposed two-stage learning scheme as well as analyze various methods for learning the program embedding. Website at https://clvrai.com/leaps.
count=9
* Calibrated Structured Prediction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/52d2752b150f9c35ccb6869cbf074e48-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/52d2752b150f9c35ccb6869cbf074e48-Paper.pdf)]
    * Title: Calibrated Structured Prediction
    * Year: `2015`
    * Authors: Volodymyr Kuleshov, Percy S. Liang
    * Abstract: In user-facing applications, displaying calibrated confidence measures---probabilities that correspond to true frequency---can be as important as obtaining high accuracy. We are interested in calibration for structured prediction problems such as speech recognition, optical character recognition, and medical diagnosis. Structured prediction presents new challenges for calibration: the output space is large, and users may issue many types of probability queries (e.g., marginals) on the structured output. We extend the notion of calibration so as to handle various subtleties pertaining to the structured setting, and then provide a simple recalibration method that trains a binary classifier to predict probabilities of interest. We explore a range of features appropriate for structured recalibration, and demonstrate their efficacy on three real-world datasets.
count=8
* Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.pdf)]
    * Title: Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization
    * Year: `2020`
    * Authors: Ruyi Ji,  Longyin Wen,  Libo Zhang,  Dawei Du,  Yanjun Wu,  Chen Zhao,  Xianglong Liu,  Feiyue Huang
    * Abstract: Fine-grained visual categorization (FGVC) is an important but challenging task due to high intra-class variances and low inter-class variances caused by deformation, occlusion, illumination, etc. An attention convolutional binary neural tree architecture is presented to address those problems for weakly supervised FGVC. Specifically, we incorporate convolutional operations along edges of the tree structure, and use the routing functions in each node to determine the root-to-leaf computational paths within the tree. The final decision is computed as the summation of the predictions from leaf nodes. The deep convolutional operations learn to capture the representations of objects, and the tree structure characterizes the coarse-to-fine hierarchical feature learning process. In addition, we use the attention transformer module to enforce the network to capture discriminative features. The negative log-likelihood loss is used to train the entire network in an end-to-end fashion by SGD with back-propagation. Several experiments on the CUB-200-2011, Stanford Cars and Aircraft datasets demonstrate that the proposed method performs favorably against the state-of-the-arts.
count=8
* Deep Regression Forests for Age Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Shen_Deep_Regression_Forests_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Shen_Deep_Regression_Forests_CVPR_2018_paper.pdf)]
    * Title: Deep Regression Forests for Age Estimation
    * Year: `2018`
    * Authors: Wei Shen, Yilu Guo, Yan Wang, Kai Zhao, Bo Wang, Alan L. Yuille
    * Abstract: Age estimation from facial images is typically cast as a nonlinear regression problem. The main challenge of this problem is the facial feature space w.r.t. ages is inhomogeneous, due to the large variation in facial appearance across different persons of the same age and the non-stationary property of aging patterns. In this paper, we propose Deep Regression Forests (DRFs), an end-to-end model, for age estimation. DRFs connect the split nodes to a fully connected layer of a convolutional neural network (CNN) and deal with inhomogeneous data by jointly learning input-dependant data partitions at the split nodes and data abstractions at the leaf nodes. This joint learning follows an alternating strategy: First, by fixing the leaf nodes, the split nodes as well as the CNN parameters are optimized by Back-propagation; Then, by fixing the split nodes, the leaf nodes are optimized by iterating a step-size free update rule derived from Variational Bounding. We verify the proposed DRFs on three standard age estimation benchmarks and achieve state-of-the-art results on all of them.
count=8
* A Maximum Entropy Feature Descriptor for Age Invariant Face Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Gong_A_Maximum_Entropy_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Gong_A_Maximum_Entropy_2015_CVPR_paper.pdf)]
    * Title: A Maximum Entropy Feature Descriptor for Age Invariant Face Recognition
    * Year: `2015`
    * Authors: Dihong Gong, Zhifeng Li, Dacheng Tao, Jianzhuang Liu, Xuelong Li
    * Abstract: In this paper, we propose a new approach to overcome the representation and matching problems in age invariant face recognition. First, a new maximum entropy feature descriptor (MEFD) is developed that encodes the microstructure of facial images into a set of discrete codes in terms of maximum entropy. By densely sampling the encoded face image, sufficient discriminatory and expressive information can be extracted for further analysis. A new matching method is also developed, called identity factor analysis (IFA), to estimate the probability that two faces have the same underlying identity. The effectiveness of the framework is confirmed by extensive experimentation on two face aging datasets, MORPH (the largest public-domain face aging dataset) and FGNET. We also conduct experiments on the famous LFW dataset to demonstrate the excellent generalizability of our new approach.
count=8
* Convolutional Channel Features
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Yang_Convolutional_Channel_Features_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Yang_Convolutional_Channel_Features_ICCV_2015_paper.pdf)]
    * Title: Convolutional Channel Features
    * Year: `2015`
    * Authors: Bin Yang, Junjie Yan, Zhen Lei, Stan Z. Li
    * Abstract: Deep learning methods are powerful tools but often suffer from expensive computation and limited flexibility. An alternative is to combine light-weight models with deep representations. As successful cases exist in several visual problems, a unified framework is absent. In this paper, we revisit two widely used approaches in computer vision, namely filtered channel features and Convolutional Neural Networks (CNN), and absorb merits from both by proposing an integrated method called Convolutional Channel Features (CCF). CCF transfers low-level features from pre-trained CNN models to feed the boosting forest model. With the combination of CNN features and boosting forest, CCF benefits from the richer capacity in feature representation compared with channel features, as well as lower cost in computation and storage compared with end-to-end CNN methods. We show that CCF serves as a good way of tailoring pre-trained CNN models to diverse tasks without fine-tuning the whole network to each task by achieving state-of-the-art performances in pedestrian detection, face detection, edge detection and object proposal generation.
count=8
* Metis: Understanding and Enhancing In-Network Regular Expressions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/f54bd48aba0dff7acdac86123188f1b6-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/f54bd48aba0dff7acdac86123188f1b6-Paper-Conference.pdf)]
    * Title: Metis: Understanding and Enhancing In-Network Regular Expressions
    * Year: `2023`
    * Authors: Zhengxin Zhang, Yucheng Huang, Guanglin Duan, Qing Li, Dan Zhao, Yong Jiang, Lianbo Ma, Xi Xiao, Hengyang Xu
    * Abstract: Regular expressions (REs) offer one-shot solutions for many networking tasks, e.g., network intrusion detection. However, REs purely rely on expert knowledge and cannot utilize labeled data for better accuracy. Today, neural networks (NNs) have shown superior accuracy and flexibility, thanks to their ability to learn from rich labeled data. Nevertheless, NNs are often incompetent in cold-start scenarios and too complex for deployment on network devices. In this paper, we propose Metis, a general framework that converts REs to network device affordable models for superior accuracy and throughput by taking advantage of REs' expert knowledge and NNs' learning ability. In Metis, we convert REs to byte-level recurrent neural networks (BRNNs) without training. The BRNNs preserve expert knowledge from REs and offer adequate accuracy in cold-start scenarios. When rich labeled data is available, the performance of BRNNs can be improved by training. Furthermore, we design a semi-supervised knowledge distillation to transform the BRNNs into pooling soft random forests (PSRFs) that can be deployed on network devices. To the best of our knowledge, this is the first method to employ model inference as an alternative to RE matching in network scenarios. We collect network traffic data on our campus for three weeks and evaluate Metis on them. Experimental results show that Metis is more accurate than original REs and other baselines, achieving superior throughput when deployed on network devices.
count=8
* (De-)Randomized Smoothing for Decision Stump Ensembles
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/146b4bab3f8536a07905f25d367b4924-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/146b4bab3f8536a07905f25d367b4924-Paper-Conference.pdf)]
    * Title: (De-)Randomized Smoothing for Decision Stump Ensembles
    * Year: `2022`
    * Authors: Miklós Horváth, Mark Müller, Marc Fischer, Martin Vechev
    * Abstract: Tree-based models are used in many high-stakes application domains such as ﬁnance and medicine, where robustness and interpretability are of utmost importance. Yet, methods for improving and certifying their robustness are severely under-explored, in contrast to those focusing on neural networks. Targeting this important challenge, we propose deterministic smoothing for decision stump ensembles. Whereas most prior work on randomized smoothing focuses on evaluating arbitrary base models approximately under input randomization, the key insight of our work is that decision stump ensembles enable exact yet efﬁcient evaluation via dynamic programming. Importantly, we obtain deterministic robustness certiﬁcates, even jointly over numerical and categorical features, a setting ubiquitous in the real world. Further, we derive an MLE-optimal training method for smoothed decision stumps under randomization and propose two boosting approaches to improve their provable robustness. An extensive experimental evaluation on computer vision and tabular data tasks shows that our approach yields signiﬁcantly higher certiﬁed accuracies than the state-of-the-art for tree-based models. We release all code and trained models at https://github.com/eth-sri/drs.
count=8
* Neural Additive Models: Interpretable Machine Learning with Neural Nets
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/251bd0442dfcc53b5a761e050f8022b8-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/251bd0442dfcc53b5a761e050f8022b8-Paper.pdf)]
    * Title: Neural Additive Models: Interpretable Machine Learning with Neural Nets
    * Year: `2021`
    * Authors: Rishabh Agarwal, Levi Melnick, Nicholas Frosst, Xuezhou Zhang, Ben Lengerich, Rich Caruana, Geoffrey E. Hinton
    * Abstract: Deep neural networks (DNNs) are powerful black-box predictors that have achieved impressive performance on a wide variety of tasks. However, their accuracy comes at the cost of intelligibility: it is usually unclear how they make their decisions. This hinders their applicability to high stakes decision-making domains such as healthcare. We propose Neural Additive Models (NAMs) which combine some of the expressivity of DNNs with the inherent intelligibility of generalized additive models. NAMs learn a linear combination of neural networks that each attend to a single input feature. These networks are trained jointly and can learn arbitrarily complex relationships between their input feature and the output. Our experiments on regression and classification datasets show that NAMs are more accurate than widely used intelligible models such as logistic regression and shallow decision trees. They perform similarly to existing state-of-the-art generalized additive models in accuracy, but are more flexible because they are based on neural nets instead of boosted trees. To demonstrate this, we show how NAMs can be used for multitask learning on synthetic data and on the COMPAS recidivism data due to their composability, and demonstrate that the differentiability of NAMs allows them to train more complex interpretable models for COVID-19.
count=8
* Learning Tree Interpretation from Object Representation for Deep Reinforcement Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/a35fe7f7fe8217b4369a0af4244d1fca-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/a35fe7f7fe8217b4369a0af4244d1fca-Paper.pdf)]
    * Title: Learning Tree Interpretation from Object Representation for Deep Reinforcement Learning
    * Year: `2021`
    * Authors: Guiliang Liu, Xiangyu Sun, Oliver Schulte, Pascal Poupart
    * Abstract: Interpreting Deep Reinforcement Learning (DRL) models is important to enhance trust and comply with transparency regulations. Existing methods typically explain a DRL model by visualizing the importance of low-level input features with super-pixels, attentions, or saliency maps. Our approach provides an interpretation based on high-level latent object features derived from a disentangled representation. We propose a Represent And Mimic (RAMi) framework for training 1) an identifiable latent representation to capture the independent factors of variation for the objects and 2) a mimic tree that extracts the causal impact of the latent features on DRL action values. To jointly optimize both the fidelity and the simplicity of a mimic tree, we derive a novel Minimum Description Length (MDL) objective based on the Information Bottleneck (IB) principle. Based on this objective, we describe a Monte Carlo Regression Tree Search (MCRTS) algorithm that explores different splits to find the IB-optimal mimic tree. Experiments show that our mimic tree achieves strong approximation performance with significantly fewer nodes than baseline models. We demonstrate the interpretability of our mimic tree by showing latent traversals, decision rules, causal impacts, and human evaluation results.
count=8
* Efficient Contextual Bandits with Continuous Actions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/033cc385728c51d97360020ed57776f0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/033cc385728c51d97360020ed57776f0-Paper.pdf)]
    * Title: Efficient Contextual Bandits with Continuous Actions
    * Year: `2020`
    * Authors: Maryam Majzoubi, Chicheng Zhang, Rajan Chari, Akshay Krishnamurthy, John Langford, Aleksandrs Slivkins
    * Abstract: We create a computationally tractable learning algorithm for contextual bandits with continuous actions having unknown structure. The new reduction-style algorithm composes with most supervised learning representations. We prove that this algorithm works in a general sense and verify the new functionality with large-scale experiments.
count=8
* Universal consistency and minimax rates for online Mondrian Forests
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/f80ff32e08a25270b5f252ce39522f72-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/f80ff32e08a25270b5f252ce39522f72-Paper.pdf)]
    * Title: Universal consistency and minimax rates for online Mondrian Forests
    * Year: `2017`
    * Authors: Jaouad Mourtada, Stéphane Gaïffas, Erwan Scornet
    * Abstract: We establish the consistency of an algorithm of Mondrian Forests~\cite{lakshminarayanan2014mondrianforests,lakshminarayanan2016mondrianuncertainty}, a randomized classification algorithm that can be implemented online. First, we amend the original Mondrian Forest algorithm proposed in~\cite{lakshminarayanan2014mondrianforests}, that considers a \emph{fixed} lifetime parameter. Indeed, the fact that this parameter is fixed actually hinders statistical consistency of the original procedure. Our modified Mondrian Forest algorithm grows trees with increasing lifetime parameters $\lambda_n$, and uses an alternative updating rule, allowing to work also in an online fashion. Second, we provide a theoretical analysis establishing simple conditions for consistency. Our theoretical analysis also exhibits a surprising fact: our algorithm achieves the minimax rate (optimal rate) for the estimation of a Lipschitz regression function, which is a strong extension of previous results~\cite{arlot2014purf_bias} to an \emph{arbitrary dimension}.
count=7
* Neural Contours: Learning to Draw Lines From 3D Shapes
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Neural_Contours_Learning_to_Draw_Lines_From_3D_Shapes_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Neural_Contours_Learning_to_Draw_Lines_From_3D_Shapes_CVPR_2020_paper.pdf)]
    * Title: Neural Contours: Learning to Draw Lines From 3D Shapes
    * Year: `2020`
    * Authors: Difan Liu,  Mohamed Nabail,  Aaron Hertzmann,  Evangelos Kalogerakis
    * Abstract: This paper introduces a method for learning to generate line drawings from 3D models. Our architecture incorporates a differentiable module operating on geometric features of the 3D model, and an image-based module operating on view-based shape representations. At test time, geometric and view-based reasoning are combined with the help of a neural module to create a line drawing. The model is trained on a large number of crowdsourced comparisons of line drawings. Experiments demonstrate that our method achieves significant improvements in line drawing over the state-of-the-art when evaluated on standard benchmarks, resulting in drawings that are comparable to those produced by experienced human artists.
count=7
* Pedestrian Detection Inspired by Appearance Constancy and Shape Symmetry
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Cao_Pedestrian_Detection_Inspired_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Cao_Pedestrian_Detection_Inspired_CVPR_2016_paper.pdf)]
    * Title: Pedestrian Detection Inspired by Appearance Constancy and Shape Symmetry
    * Year: `2016`
    * Authors: Jiale Cao, Yanwei Pang, Xuelong Li
    * Abstract: The discrimination and simplicity of features are very important for effective and efficient pedestrian detection. However, most state-of-the-art methods are unable to achieve good tradeoff between accuracy and efficiency. Inspired by some simple inherent attributes of pedestrians (i.e., appearance constancy and shape symmetry), we propose two new types of non-neighboring features (NNF): side-inner difference features (SIDF) and symmetrical similarity features (SSF). SIDF can characterize the difference between the background and pedestrian and the difference between the pedestrian contour and its inner part. SSF can capture the symmetrical similarity of pedestrian shape. However, it's difficult for neighboring features to have such above characterization abilities. Finally, we propose to combine both non-neighboring and neighboring features for pedestrian detection. It's found that nonneighboring features can further decrease the average miss rate by 4.44%. Experimental results on INRIA and Caltech pedestrian datasets demonstrate the effectiveness and efficiency of the proposed method. Compared to the state-ofthe- art methods without using CNN, our method achieves the best detection performance on Caltech, outperforming the second best method (i.e., Checkboards) by 1.63%.
count=7
* Taking a Deeper Look at Pedestrians
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Hosang_Taking_a_Deeper_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Hosang_Taking_a_Deeper_2015_CVPR_paper.pdf)]
    * Title: Taking a Deeper Look at Pedestrians
    * Year: `2015`
    * Authors: Jan Hosang, Mohamed Omran, Rodrigo Benenson, Bernt Schiele
    * Abstract: The only goal of the abstract is to the answer the question: why should I read this paper? In this paper we study the use of convolutional neural networks (convnets) for the task of pedestrian detection. Despite their recent diverse successes, convnets historically underperform compared to other pedestrian detectors. We deliberately omit explicitly modelling the problem into the network (e.g. parts or occlusion modelling) and show that we can reach competitive performance without bells and whistles. In a wide range of experiments we analyse small and big convnets, their architectural choices, parameters, and the influence of different training data, including pre-training on surrogate tasks. We present the best convnet detectors on the Caltech and KITTI dataset. On Caltech our convnets reach top performance both for the Caltech1x and Caltech10x training setup. Using additional data at training time our strongest convnet model is competitive to detectors that use instead additional data at test time.
count=7
* Filter Forests for Learning Data-Dependent Convolutional Kernels
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Fanello_Filter_Forests_for_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Fanello_Filter_Forests_for_2014_CVPR_paper.pdf)]
    * Title: Filter Forests for Learning Data-Dependent Convolutional Kernels
    * Year: `2014`
    * Authors: Sean Ryan Fanello, Cem Keskin, Pushmeet Kohli, Shahram Izadi, Jamie Shotton, Antonio Criminisi, Ugo Pattacini, Tim Paek
    * Abstract: We propose 'filter forests' (FF), an efficient new discriminative approach for predicting continuous variables given a signal and its context. FF can be used for general signal restoration tasks that can be tackled via convolutional filtering, where it attempts to learn the optimal filtering kernels to be applied to each data point. The model can learn both the size of the kernel and its values, conditioned on the observation and its spatial or temporal context. We show that FF compares favorably to both Markov random field based and recently proposed regression forest based approaches for labeling problems in terms of efficiency and accuracy. In particular, we demonstrate how FF can be used to learn optimal denoising filters for natural images as well as for other tasks such as depth image refinement, and 1D signal magnitude estimation. Numerous experiments and quantitative comparisons show that FFs achieve accuracy at par or superior to recent state of the art techniques, while being several orders of magnitude faster.
count=7
* A Learning-to-Rank Approach for Image Color Enhancement
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Yan_A_Learning-to-Rank_Approach_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Yan_A_Learning-to-Rank_Approach_2014_CVPR_paper.pdf)]
    * Title: A Learning-to-Rank Approach for Image Color Enhancement
    * Year: `2014`
    * Authors: Jianzhou Yan, Stephen Lin, Sing Bing Kang, Xiaoou Tang
    * Abstract: We present a machine-learned ranking approach for automatically enhancing the color of a photograph. Unlike previous techniques that train on pairs of images before and after adjustment by a human user, our method takes into account the intermediate steps taken in the enhancement process, which provide detailed information on the person's color preferences. To make use of this data, we formulate the color enhancement task as a learning-to-rank problem in which ordered pairs of images are used for training, and then various color enhancements of a novel input image can be evaluated from their corresponding rank values. From the parallels between the decision tree structures we use for ranking and the decisions made by a human during the editing process, we posit that breaking a full enhancement sequence into individual steps can facilitate training. Our experiments show that this approach compares well to existing methods for automatic color enhancement.
count=7
* Constructing Robust Affinity Graphs for Spectral Clustering
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Zhu_Constructing_Robust_Affinity_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Zhu_Constructing_Robust_Affinity_2014_CVPR_paper.pdf)]
    * Title: Constructing Robust Affinity Graphs for Spectral Clustering
    * Year: `2014`
    * Authors: Xiatian Zhu, Chen Change Loy, Shaogang Gong
    * Abstract: Spectral clustering requires robust and meaningful affinity graphs as input in order to form clusters with desired structures that can well support human intuition. To construct such affinity graphs is non-trivial due to the ambiguity and uncertainty inherent in the raw data. In contrast to most existing clustering methods that typically employ all available features to construct affinity matrices with the Euclidean distance, which is often not an accurate representation of the underlying data structures, we propose a novel unsupervised approach to generating more robust affinity graphs via identifying and exploiting discriminative features for improving spectral clustering. Specifically, our model is capable of capturing and combining subtle similarity information distributed over discriminative feature subspaces for more accurately revealing the latent data distribution and thereby leading to improved data clustering, especially with heterogeneous data sources. We demonstrate the efficacy of the proposed approach on challenging image and video datasets.
count=7
* A Performance-Driven Benchmark for Feature Selection in Tabular Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/82f39c7409155b74d15d73b048f06771-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/82f39c7409155b74d15d73b048f06771-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: A Performance-Driven Benchmark for Feature Selection in Tabular Deep Learning
    * Year: `2023`
    * Authors: Valeriia Cherepanova, Roman Levin, Gowthami Somepalli, Jonas Geiping, C. Bayan Bruss, Andrew G. Wilson, Tom Goldstein, Micah Goldblum
    * Abstract: Academic tabular benchmarks often contain small sets of curated features. In contrast, data scientists typically collect as many features as possible into their datasets, and even engineer new features from existing ones. To prevent over-fitting in subsequent downstream modeling, practitioners commonly use automated feature selection methods that identify a reduced subset of informative features. Existing benchmarks for tabular feature selection consider classical downstream models, toy synthetic datasets, or do not evaluate feature selectors on the basis of downstream performance. We construct a challenging feature selection benchmark evaluated on downstream neural networks including transformers, using real datasets and multiple methods for generating extraneous features. We also propose an input-gradient-based analogue of LASSO for neural networks that outperforms classical feature selection methods on challenging problems such as selecting from corrupted or second-order features.
count=7
* On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/a134eaebd55b7406ff29cd75d5f1a622-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/a134eaebd55b7406ff29cd75d5f1a622-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets
    * Year: `2023`
    * Authors: Jiashuo Liu, Tianyu Wang, Peng Cui, Hongseok Namkoong
    * Abstract: Different distribution shifts require different algorithmic and operational interventions. Methodological research must be grounded by the specific shifts they address. Although nascent benchmarks provide a promising empirical foundation, they \emph{implicitly} focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes. We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent. To encourage researchers to develop a refined language for distribution shifts, we build ``WhyShift``, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over. Since $Y|X$-shifts are prevalent in tabular settings, we \emph{identify covariate regions} that suffer the biggest $Y|X$-shifts and discuss implications for algorithmic and data-based interventions. Our testbed highlights the importance of future research that builds an understanding of why distributions differ.
count=7
* Why do tree-based models still outperform deep learning on typical tabular data?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/0378c7692da36807bdec87ab043cdadc-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Why do tree-based models still outperform deep learning on typical tabular data?
    * Year: `2022`
    * Authors: Leo Grinsztajn, Edouard Oyallon, Gael Varoquaux
    * Abstract: While deep learning has enabled tremendous progress on text and image datasets, its superiority on tabular data is not clear. We contribute extensive benchmarks of standard and novel deep learning methods as well as tree-based models such as XGBoost and Random Forests, across a large number of datasets and hyperparameter combinations. We define a standard set of 45 datasets from varied domains with clear characteristics of tabular data and a benchmarking methodology accounting for both fitting models and finding good hyperparameters. Results show that tree-based models remain state-of-the-art on medium-sized data ($\sim$10K samples) even without accounting for their superior speed. To understand this gap, we conduct an empirical investigation into the differing inductive biases of tree-based models and neural networks. This leads to a series of challenges which should guide researchers aiming to build tabular-specific neural network: 1) be robust to uninformative features, 2) preserve the orientation of the data, and 3) be able to easily learn irregular functions. To stimulate research on tabular architectures, we contribute a standard benchmark and raw data for baselines: every point of a 20\,000 compute hours hyperparameter search for each learner.
count=7
* A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/6e01383fd96a17ae51cc3e15447e7533-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/6e01383fd96a17ae51cc3e15447e7533-Paper.pdf)]
    * Title: A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference
    * Year: `2021`
    * Authors: Antonio Vergari, YooJung Choi, Anji Liu, Stefano Teso, Guy Van den Broeck
    * Abstract: Circuit representations are becoming the lingua franca to express and reason about tractable generative and discriminative models. In this paper, we show how complex inference scenarios for these models that commonly arise in machine learning---from computing the expectations of decision tree ensembles to information-theoretic divergences of sum-product networks---can be represented in terms of tractable modular operations over circuits. Specifically, we characterize the tractability of simple transformations---sums, products, quotients, powers, logarithms, and exponentials---in terms of sufficient structural constraints of the circuits they operate on, and present novel hardness results for the cases in which these properties are not satisfied. Building on these operations, we derive a unified framework for reasoning about tractable models that generalizes several results in the literature and opens up novel tractable inference scenarios.
count=7
* Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/eaa32c96f620053cf442ad32258076b9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/eaa32c96f620053cf442ad32258076b9-Paper.pdf)]
    * Title: Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach
    * Year: `2021`
    * Authors: Fan Yang, Kai He, Linxiao Yang, Hongxia Du, Jingbang Yang, Bo Yang, Liang Sun
    * Abstract: Rule sets are highly interpretable logical models in which the predicates for decision are expressed in disjunctive normal form (DNF, OR-of-ANDs), or, equivalently, the overall model comprises an unordered collection of if-then decision rules. In this paper, we consider a submodular optimization based approach for learning rule sets. The learning problem is framed as a subset selection task in which a subset of all possible rules needs to be selected to form an accurate and interpretable rule set. We employ an objective function that exhibits submodularity and thus is amenable to submodular optimization techniques. To overcome the difficulty arose from dealing with the exponential-sized ground set of rules, the subproblem of searching a rule is casted as another subset selection task that asks for a subset of features. We show it is possible to write the induced objective function for the subproblem as a difference of two submodular (DS) functions to make it approximately solvable by DS optimization algorithms. Overall, the proposed approach is simple, scalable, and likely to be benefited from further research on submodular optimization. Experiments on real datasets demonstrate the effectiveness of our method.
count=7
* Learning Global Transparent Models consistent with Local Contrastive Explanations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/24aef8cb3281a2422a59b51659f1ad2e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/24aef8cb3281a2422a59b51659f1ad2e-Paper.pdf)]
    * Title: Learning Global Transparent Models consistent with Local Contrastive Explanations
    * Year: `2020`
    * Authors: Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam, Amit Dhurandhar
    * Abstract: There is a rich and growing literature on producing local contrastive/counterfactual explanations for black-box models (e.g. neural networks). In these methods, for an input, an explanation is in the form of a contrast point differing in very few features from the original input and lying in a different class. Other works try to build globally interpretable models like decision trees and rule lists based on the data using actual labels or based on the black-box models predictions. Although these interpretable global models can be useful, they may not be consistent with local explanations from a specific black-box of choice. In this work, we explore the question: Can we produce a transparent global model that is simultaneously accurate and consistent with the local (contrastive) explanations of the black-box model? We introduce a local consistency metric that quantifies if the local explanations for the black-box model are also applicable to the proxy/surrogate globally transparent model. Based on a key insight we propose a novel method where we create custom boolean features from local contrastive explanations of the black-box model and then train a globally transparent model that has higher local consistency compared with other known strategies in addition to being accurate.
count=7
* Model Interpretability through the lens of Computational Complexity
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/b1adda14824f50ef24ff1c05bb66faf3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/b1adda14824f50ef24ff1c05bb66faf3-Paper.pdf)]
    * Title: Model Interpretability through the lens of Computational Complexity
    * Year: `2020`
    * Authors: Pablo Barceló, Mikaël Monet, Jorge Pérez, Bernardo Subercaseaux
    * Abstract: In spite of several claims stating that some models are more interpretable than others --e.g., "linear models are more interpretable than deep neural networks"-- we still lack a principled notion of interpretability that allows us to formally compare among different classes of models. We make a step towards such a theory by studying whether folklore interpretability claims have a correlate in terms of computational complexity theory. We focus on post-hoc explainability queries that, intuitively, attempt to answer why individual inputs are classified in a certain way by a given model. In a nutshell, we say that a class C1 of models is more interpretable than another class C2, if the computational complexity of answering post-hoc queries for models in C2 is higher than for C1. We prove that this notion provides a good theoretical counterpart to current beliefs on the interpretability of models; in particular, we show that under our definition and assuming standard complexity-theoretical assumptions (such as P!=NP), both linear and tree-based models are strictly more interpretable than neural networks. Our complexity analysis, however, does not provide a clear-cut difference between linear and tree-based models, as we obtain different results depending on the particular {post-hoc explanations} considered. Finally, by applying a finer complexity analysis based on parameterized complexity, we are able to prove a theoretical result suggesting that shallow neural networks are more interpretable than deeper ones.
count=7
* The Diversified Ensemble Neural Network
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/b86e8d03fe992d1b0e19656875ee557c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/b86e8d03fe992d1b0e19656875ee557c-Paper.pdf)]
    * Title: The Diversified Ensemble Neural Network
    * Year: `2020`
    * Authors: Shaofeng Zhang, Meng Liu, Junchi Yan
    * Abstract: Ensemble is a general way of improving the accuracy and stability of learning models, especially for the generalization ability on small datasets. Compared with tree-based methods, relatively less works have been devoted to an in-depth study on effective ensemble design for neural networks. In this paper, we propose a principled ensemble technique by constructing the so-called diversified ensemble layer to combine multiple networks as individual modules. We theoretically show that each individual model in our ensemble layer corresponds to weights in the ensemble layer optimized in different directions. Meanwhile, the devised ensemble layer can be readily integrated into popular neural architectures, including CNNs, RNNs, and GCNs. Extensive experiments are conducted on public tabular datasets, images, and texts. By adopting weight sharing approach, the results show our method can notably improve the accuracy and stability of the original neural networks with ignorable extra time and space overhead.
count=7
* Efficiently Learning Fourier Sparse Set Functions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/c77331e51c5555f8f935d3344c964bd5-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/c77331e51c5555f8f935d3344c964bd5-Paper.pdf)]
    * Title: Efficiently Learning Fourier Sparse Set Functions
    * Year: `2019`
    * Authors: Andisheh Amrollahi, Amir Zandieh, Michael Kapralov, Andreas Krause
    * Abstract: Learning set functions is a key challenge arising in many domains, ranging from sketching graphs to black-box optimization with discrete parameters. In this paper we consider the problem of efficiently learning set functions that are defined over a ground set of size $n$ and that are sparse (say $k$-sparse) in the Fourier domain. This is a wide class, that includes graph and hypergraph cut functions, decision trees and more. Our central contribution is the first algorithm that allows learning functions whose Fourier support only contains low degree (say degree $d=o(n)$) polynomials using $O(k d \log n)$ sample complexity and runtime $O( kn \log^2 k \log n \log d)$. This implies that sparse graphs with $k$ edges can, for the first time, be learned from $O(k \log n)$ observations of cut values and in linear time in the number of vertices. Our algorithm can also efficiently learn (sums of) decision trees of small depth. The algorithm exploits techniques from the sparse Fourier transform literature and is easily implementable. Lastly, we also develop an efficient robust version of our algorithm and prove $\ell_2/\ell_2$ approximation guarantees without any statistical assumptions on the noise.
count=7
* Adaptive Influence Maximization with Myopic Feedback
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/f6b5f8c32c65fee991049a55dc97d1ce-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/f6b5f8c32c65fee991049a55dc97d1ce-Paper.pdf)]
    * Title: Adaptive Influence Maximization with Myopic Feedback
    * Year: `2019`
    * Authors: Binghui Peng, Wei Chen
    * Abstract: We study the adaptive influence maximization problem with myopic feedback under the independent cascade model: one sequentially selects k nodes as seeds one by one from a social network, and each selected seed returns the immediate neighbors it activates as the feedback available for by later selections, and the goal is to maximize the expected number of total activated nodes, referred as the influence spread. We show that the adaptivity gap, the ratio between the optimal adaptive influence spread and the optimal non-adaptive influence spread, is at most 4 and at least e/(e-1), and the approximation ratios with respect to the optimal adaptive influence spread of both the non-adaptive greedy and adaptive greedy algorithms are at least \frac{1}{4}(1 - \frac{1}{e}) and at most \frac{e^2 + 1}{(e + 1)^2} < 1 - \frac{1}{e}. Moreover, the approximation ratio of the non-adaptive greedy algorithm is no worse than that of the adaptive greedy algorithm, when considering all graphs. Our result confirms a long-standing open conjecture of Golovin and Krause (2011) on the constant approximation ratio of adaptive greedy with myopic feedback, and it also suggests that adaptive greedy may not bring much benefit under myopic feedback.
count=7
* Maximum Margin Interval Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/2288f691b58edecadcc9a8691762b4fd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/2288f691b58edecadcc9a8691762b4fd-Paper.pdf)]
    * Title: Maximum Margin Interval Trees
    * Year: `2017`
    * Authors: Alexandre Drouin, Toby Hocking, Francois Laviolette
    * Abstract: Learning a regression function using censored or interval-valued output data is an important problem in fields such as genomics and medicine. The goal is to learn a real-valued prediction function, and the training output labels indicate an interval of possible values. Whereas most existing algorithms for this task are linear models, in this paper we investigate learning nonlinear tree models. We propose to learn a tree by minimizing a margin-based discriminative objective function, and we provide a dynamic programming algorithm for computing the optimal solution in log-linear time. We show empirically that this algorithm achieves state-of-the-art speed and prediction accuracy in a benchmark of several data sets.
count=7
* An ensemble diversity approach to supervised binary hashing
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/67f7fb873eaf29526a11a9b7ac33bfac-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/67f7fb873eaf29526a11a9b7ac33bfac-Paper.pdf)]
    * Title: An ensemble diversity approach to supervised binary hashing
    * Year: `2016`
    * Authors: Miguel A. Carreira-Perpinan, Ramin Raziperchikolaei
    * Abstract: Binary hashing is a well-known approach for fast approximate nearest-neighbor search in information retrieval. Much work has focused on affinity-based objective functions involving the hash functions or binary codes. These objective functions encode neighborhood information between data points and are often inspired by manifold learning algorithms. They ensure that the hash functions differ from each other through constraints or penalty terms that encourage codes to be orthogonal or dissimilar across bits, but this couples the binary variables and complicates the already difficult optimization. We propose a much simpler approach: we train each hash function (or bit) independently from each other, but introduce diversity among them using techniques from classifier ensembles. Surprisingly, we find that not only is this faster and trivially parallelizable, but it also improves over the more complex, coupled objective function, and achieves state-of-the-art precision and recall in experiments with image retrieval.
count=7
* Zero-shot recognition with unreliable attributes
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/1f1baa5b8edac74eb4eaa329f14a0361-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/1f1baa5b8edac74eb4eaa329f14a0361-Paper.pdf)]
    * Title: Zero-shot recognition with unreliable attributes
    * Year: `2014`
    * Authors: Dinesh Jayaraman, Kristen Grauman
    * Abstract: In principle, zero-shot learning makes it possible to train an object recognition model simply by specifying the category's attributes. For example, with classifiers for generic attributes like striped and four-legged, one can construct a classifier for the zebra category by enumerating which properties it possesses --- even without providing zebra training images. In practice, however, the standard zero-shot paradigm suffers because attribute predictions in novel images are hard to get right. We propose a novel random forest approach to train zero-shot models that explicitly accounts for the unreliability of attribute predictions. By leveraging statistics about each attribute’s error tendencies, our method obtains more robust discriminative models for the unseen classes. We further devise extensions to handle the few-shot scenario and unreliable attribute descriptions. On three datasets, we demonstrate the benefit for visual category learning with zero or few training examples, a critical domain for rare categories or categories defined on the fly.
count=6
* Semantic Channels for Fast Pedestrian Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Costea_Semantic_Channels_for_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Costea_Semantic_Channels_for_CVPR_2016_paper.pdf)]
    * Title: Semantic Channels for Fast Pedestrian Detection
    * Year: `2016`
    * Authors: Arthur Daniel Costea, Sergiu Nedevschi
    * Abstract: Pedestrian detection and semantic segmentation are high potential tasks for many real-time applications. However most of the top performing approaches provide state of art results at high computational costs. In this work we propose a fast solution for achieving state of art results for both pedestrian detection and semantic segmentation. As baseline for pedestrian detection we use sliding windows over cost efficient multiresolution filtered LUV+HOG channels. We use the same channels for classifying pixels into eight semantic classes. Using short range and long range multiresolution channel features we achieve more robust segmentation results compared to traditional codebook based approaches at much lower computational costs. The resulting segmentations are used as additional semantic channels in order to achieve a more powerful pedestrian detector. To also achieve fast pedestrian detection we employ a multiscale detection scheme based on a single flexible pedestrian model and a single image scale. The proposed solution provides competitive results on both pedestrian detection and semantic segmentation benchmarks at 8 FPS on CPU and at 15 FPS on GPU, being the fastest top performing approach.
count=6
* Efficient Nonlinear Markov Models for Human Motion
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Lehrmann_Efficient_Nonlinear_Markov_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Lehrmann_Efficient_Nonlinear_Markov_2014_CVPR_paper.pdf)]
    * Title: Efficient Nonlinear Markov Models for Human Motion
    * Year: `2014`
    * Authors: Andreas M. Lehrmann, Peter V. Gehler, Sebastian Nowozin
    * Abstract: Dynamic Bayesian networks such as Hidden Markov Models (HMMs) are successfully used as probabilistic models for human motion. The use of hidden variables makes them expressive models, but inference is only approximate and requires procedures such as particle filters or Markov chain Monte Carlo methods. In this work we propose to instead use simple Markov models that only model observed quantities. We retain a highly expressive dynamic model by using interactions that are nonlinear and non-parametric. A presentation of our approach in terms of latent variables shows logarithmic growth for the computation of exact log-likelihoods in the number of latent states. We validate our model on human motion capture data and demonstrate state-of-the-art performance on action recognition and motion completion tasks.
count=6
* Expressive Visual Text-to-Speech Using Active Appearance Models
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Anderson_Expressive_Visual_Text-to-Speech_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Anderson_Expressive_Visual_Text-to-Speech_2013_CVPR_paper.pdf)]
    * Title: Expressive Visual Text-to-Speech Using Active Appearance Models
    * Year: `2013`
    * Authors: Robert Anderson, Bjorn Stenger, Vincent Wan, Roberto Cipolla
    * Abstract: This paper presents a complete system for expressive visual text-to-speech (VTTS), which is capable of producing expressive output, in the form of a 'talking head', given an input text and a set of continuous expression weights. The face is modeled using an active appearance model (AAM), and several extensions are proposed which make it more applicable to the task of VTTS. The model allows for normalization with respect to both pose and blink state which significantly reduces artifacts in the resulting synthesized sequences. We demonstrate quantitative improvements in terms of reconstruction error over a million frames, as well as in large-scale user studies, comparing the output of different systems.
count=6
* Seeking the Strongest Rigid Detector
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Benenson_Seeking_the_Strongest_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Benenson_Seeking_the_Strongest_2013_CVPR_paper.pdf)]
    * Title: Seeking the Strongest Rigid Detector
    * Year: `2013`
    * Authors: Rodrigo Benenson, Markus Mathias, Tinne Tuytelaars, Luc Van Gool
    * Abstract: The current state of the art solutions for object detection describe each class by a set of models trained on discovered sub-classes (so called "components"), with each model itself composed of collections of interrelated parts (deformable models). These detectors build upon the now classic Histogram of Oriented Gradients+linear SVM combo. In this paper we revisit some of the core assumptions in HOG+SVM and show that by properly designing the feature pooling, feature selection, preprocessing, and training methods, it is possible to reach top quality, at least for pedestrian detections, using a single rigid component. We provide experiments for a large design space, that give insights into the design of classifiers, as well as relevant information for practitioners. Our best detector is fully feed-forward, has a single unified architecture, uses only histograms of oriented gradients and colour information in monocular static images, and improves over 23 other methods on the INRIA, ETH and Caltech-USA datasets, reducing the average miss-rate over HOG+SVM by more than 30%.
count=6
* Learning Compact Binary Codes for Visual Tracking
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Li_Learning_Compact_Binary_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Li_Learning_Compact_Binary_2013_CVPR_paper.pdf)]
    * Title: Learning Compact Binary Codes for Visual Tracking
    * Year: `2013`
    * Authors: Xi Li, Chunhua Shen, Anthony Dick, Anton van den Hengel
    * Abstract: A key problem in visual tracking is to represent the appearance of an object in a way that is robust to visual changes. To attain this robustness, increasingly complex models are used to capture appearance variations. However, such models can be difficult to maintain accurately and efficiently. In this paper, we propose a visual tracker in which objects are represented by compact and discriminative binary codes. This representation can be processed very efficiently, and is capable of effectively fusing information from multiple cues. An incremental discriminative learner is then used to construct an appearance model that optimally separates the object from its surrounds. Furthermore, we design a hypergraph propagation method to capture the contextual information on samples, which further improves the tracking accuracy. Experimental results on challenging videos demonstrate the effectiveness and robustness of the proposed tracker.
count=6
* Adaptive RNN Tree for Large-Scale Human Action Recognition
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Li_Adaptive_RNN_Tree_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Adaptive_RNN_Tree_ICCV_2017_paper.pdf)]
    * Title: Adaptive RNN Tree for Large-Scale Human Action Recognition
    * Year: `2017`
    * Authors: Wenbo Li, Longyin Wen, Ming-Ching Chang, Ser Nam Lim, Siwei Lyu
    * Abstract: In this work, we present the RNN Tree (RNN-T), an adaptive learning framework for skeleton based human action recognition. Our method categorizes action classes and uses multiple Recurrent Neural Networks (RNNs) in a tree-like hierarchy. The RNNs in RNN-T are co-trained with the action category hierarchy, which determines the structure of RNN-T. Actions in skeletal representations are recognized via a hierarchical inference process, during which individual RNNs differentiate finer-grained action classes with increasing confidence. Inference in RNN-T ends when any RNN in the tree recognizes the action with high confidence, or a leaf node is reached. RNN-T effectively addresses two main challenges of large-scale action recognition: (i) able to distinguish fine-grained action classes that are intractable using a single network, and (ii) adaptive to new action classes by augmenting an existing model. We demonstrate the effectiveness of RNN-T/ACH method and compare it with the state-of-the-art methods on a large-scale dataset and several existing benchmarks.
count=6
* Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Tang_Real-Time_Articulated_Hand_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Tang_Real-Time_Articulated_Hand_2013_ICCV_paper.pdf)]
    * Title: Real-Time Articulated Hand Pose Estimation Using Semi-supervised Transductive Regression Forests
    * Year: `2013`
    * Authors: Danhang Tang, Tsz-Ho Yu, Tae-Kyun Kim
    * Abstract: This paper presents the first semi-supervised transductive algorithm for real-time articulated hand pose estimation. Noisy data and occlusions are the major challenges of articulated hand pose estimation. In addition, the discrepancies among realistic and synthetic pose data undermine the performances of existing approaches that use synthetic data extensively in training. We therefore propose the Semi-supervised Transductive Regression (STR) forest which learns the relationship between a small, sparsely labelled realistic dataset and a large synthetic dataset. We also design a novel data-driven, pseudo-kinematic technique to refine noisy or occluded joints. Our contributions include: (i) capturing the benefits of both realistic and synthetic data via transductive learning; (ii) showing accuracies can be improved by considering unlabelled data; and (iii) introducing a pseudo-kinematic technique to refine articulations efficiently. Experimental results show not only the promising performance of our method with respect to noise and occlusions, but also its superiority over state-ofthe-arts in accuracy, robustness and speed.
count=6
* A Competitive Algorithm for Agnostic Active Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/b7385cb3fa76a0aeedb23d4163640db0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/b7385cb3fa76a0aeedb23d4163640db0-Paper-Conference.pdf)]
    * Title: A Competitive Algorithm for Agnostic Active Learning
    * Year: `2023`
    * Authors: Yihan Zhou, Eric Price
    * Abstract: For some hypothesis classes and input distributions, \emph{active} agnostic learning needs exponentially fewer samples than passive learning; for other classes and distributions, it offers little to no improvement. The most popular algorithms for agnostic active learning express their performance in terms of a parameter called the disagreement coefficient, but it is known that these algorithms are inefficient on some inputs. We take a different approach to agnostic active learning, getting an algorithm that is \emph{competitive} with the optimal algorithm for any binary hypothesis class $H$ and distribution $\mathcal{D}_X$ over $X$. In particular, if any algorithm can use $m^*$ queries to get $O(\eta)$ error, then our algorithm uses $O(m^* \log H)$ queries to get $O(\eta)$ error. Our algorithm lies in the vein of the splitting-based approach of Dasgupta [2004], which gets a similar result for the realizable ($\eta = 0$) setting. We also show that it is NP-hard to do better than our algorithm's $O(\log H)$ overhead in general.
count=6
* ProtoX: Explaining a Reinforcement Learning Agent via Prototyping
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/ae5bf4f35236240c9460e761c60fa53d-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/ae5bf4f35236240c9460e761c60fa53d-Paper-Conference.pdf)]
    * Title: ProtoX: Explaining a Reinforcement Learning Agent via Prototyping
    * Year: `2022`
    * Authors: Ronilo Ragodos, Tong Wang, Qihang Lin, Xun Zhou
    * Abstract: While deep reinforcement learning has proven to be successful in solving control tasks, the ``black-box'' nature of an agent has received increasing concerns. We propose a prototype-based post-hoc \emph{policy explainer}, ProtoX, that explains a black-box agent by prototyping the agent's behaviors into scenarios, each represented by a prototypical state. When learning prototypes, ProtoX considers both visual similarity and scenario similarity. The latter is unique to the reinforcement learning context since it explains why the same action is taken in visually different states. To teach ProtoX about visual similarity, we pre-train an encoder using contrastive learning via self-supervised learning to recognize states as similar if they occur close together in time and receive the same action from the black-box agent. We then add an isometry layer to allow ProtoX to adapt scenario similarity to the downstream task. ProtoX is trained via imitation learning using behavior cloning, and thus requires no access to the environment or agent. In addition to explanation fidelity, we design different prototype shaping terms in the objective function to encourage better interpretability. We conduct various experiments to test ProtoX. Results show that ProtoX achieved high fidelity to the original black-box agent while providing meaningful and understandable explanations.
count=6
* Tree ensemble kernels for Bayesian optimization with known constraints over  mixed-feature spaces
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/f3398b76d17792893ce6d4f660546353-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/f3398b76d17792893ce6d4f660546353-Paper-Conference.pdf)]
    * Title: Tree ensemble kernels for Bayesian optimization with known constraints over  mixed-feature spaces
    * Year: `2022`
    * Authors: Alexander Thebelt, Calvin Tsay, Robert Lee, Nathan Sudermann-Merx, David Walz, Behrang Shafei, Ruth Misener
    * Abstract: Tree ensembles can be well-suited for black-box optimization tasks such as algorithm tuning and neural architecture search, as they achieve good predictive performance with little or no manual tuning, naturally handle discrete feature spaces, and are relatively insensitive to outliers in the training data. Two well-known challenges in using tree ensembles for black-box optimization are (i) effectively quantifying model uncertainty for exploration and (ii) optimizing over the piece-wise constant acquisition function. To address both points simultaneously, we propose using the kernel interpretation of tree ensembles as a Gaussian Process prior to obtain model variance estimates, and we develop a compatible optimization formulation for the acquisition function. The latter further allows us to seamlessly integrate known constraints to improve sampling efficiency by considering domain-knowledge in engineering settings and modeling search space symmetries, e.g., hierarchical relationships in neural architecture search. Our framework performs as well as state-of-the-art methods for unconstrained black-box optimization over continuous/discrete features and outperforms competing methods for problems combining mixed-variable feature spaces and known input constraints.
count=6
* A PAC-Bayes Analysis of Adversarial Robustness
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/78e8dffe65a2898eef68a33b8db35b78-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/78e8dffe65a2898eef68a33b8db35b78-Paper.pdf)]
    * Title: A PAC-Bayes Analysis of Adversarial Robustness
    * Year: `2021`
    * Authors: Paul Viallard, Eric Guillaume VIDOT, Amaury Habrard, Emilie Morvant
    * Abstract: We propose the first general PAC-Bayesian generalization bounds for adversarial robustness, that estimate, at test time, how much a model will be invariant to imperceptible perturbations in the input. Instead of deriving a worst-case analysis of the risk of a hypothesis over all the possible perturbations, we leverage the PAC-Bayesian framework to bound the averaged risk on the perturbations for majority votes (over the whole class of hypotheses). Our theoretically founded analysis has the advantage to provide general bounds (i) that are valid for any kind of attacks (i.e., the adversarial attacks), (ii) that are tight thanks to the PAC-Bayesian framework, (iii) that can be directly minimized during the learning phase to obtain a robust model on different attacks at test time.
count=6
* Characterizing the risk of fairwashing
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/7caf5e22ea3eb8175ab518429c8589a4-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/7caf5e22ea3eb8175ab518429c8589a4-Paper.pdf)]
    * Title: Characterizing the risk of fairwashing
    * Year: `2021`
    * Authors: Ulrich Aïvodji, Hiromi Arai, Sébastien Gambs, Satoshi Hara
    * Abstract: Fairwashing refers to the risk that an unfair black-box model can be explained by a fairer model through post-hoc explanation manipulation. In this paper, we investigate the capability of fairwashing attacks by analyzing their fidelity-unfairness trade-offs. In particular, we show that fairwashed explanation models can generalize beyond the suing group (i.e., data points that are being explained), meaning that a fairwashed explainer can be used to rationalize subsequent unfair decisions of a black-box model. We also demonstrate that fairwashing attacks can transfer across black-box models, meaning that other black-box models can perform fairwashing without explicitly using their predictions. This generalization and transferability of fairwashing attacks imply that their detection will be difficult in practice. Finally, we propose an approach to quantify the risk of fairwashing, which is based on the computation of the range of the unfairness of high-fidelity explainers.
count=6
* Auditing Black-Box Prediction Models for Data Minimization Compliance
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/ac6b3cce8c74b2e23688c3e45532e2a7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/ac6b3cce8c74b2e23688c3e45532e2a7-Paper.pdf)]
    * Title: Auditing Black-Box Prediction Models for Data Minimization Compliance
    * Year: `2021`
    * Authors: Bashir Rastegarpanah, Krishna Gummadi, Mark Crovella
    * Abstract: In this paper, we focus on auditing black-box prediction models for compliance with the GDPR’s data minimization principle. This principle restricts prediction models to use the minimal information that is necessary for performing the task at hand. Given the challenge of the black-box setting, our key idea is to check if each of the prediction model’s input features is individually necessary by assigning it some constant value (i.e., applying a simple imputation) across all prediction instances, and measuring the extent to which the model outcomes would change. We introduce a metric for data minimization that is based on model instability under simple imputations. We extend the applicability of this metric from a finite sample model to a distributional setting by introducing a probabilistic data minimization guarantee, which we derive using a Bayesian approach. Furthermore, we address the auditing problem under a constraint on the number of queries to the prediction system. We formulate the problem of allocating a budget of system queries to feasible simple imputations (for investigating model instability) as a multi-armed bandit framework with probabilistic success metrics. We define two bandit problems for providing a probabilistic data minimization guarantee at a given confidence level: a decision problem given a data minimization level, and a measurement problem given a fixed query budget. We design efficient algorithms for these auditing problems using novel exploration strategies that expand classical bandit strategies. Our experiments with real-world prediction systems show that our auditing algorithms significantly outperform simpler benchmarks in both measurement and decision problems.
count=6
* The staircase property: How hierarchical structure can guide deep learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/e2db7186375992e729165726762cb4c1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/e2db7186375992e729165726762cb4c1-Paper.pdf)]
    * Title: The staircase property: How hierarchical structure can guide deep learning
    * Year: `2021`
    * Authors: Emmanuel Abbe, Enric Boix-Adsera, Matthew S Brennan, Guy Bresler, Dheeraj Nagaraj
    * Abstract: This paper identifies a structural property of data distributions that enables deep neural networks to learn hierarchically. We define the ``staircase'' property for functions over the Boolean hypercube, which posits that high-order Fourier coefficients are reachable from lower-order Fourier coefficients along increasing chains. We prove that functions satisfying this property can be learned in polynomial time using layerwise stochastic coordinate descent on regular neural networks -- a class of network architectures and initializations that have homogeneity properties. Our analysis shows that for such staircase functions and neural networks, the gradient-based algorithm learns high-level features by greedily combining lower-level features along the depth of the network. We further back our theoretical results with experiments showing that staircase functions are learnable by more standard ResNet architectures with stochastic gradient descent. Both the theoretical and experimental results support the fact that the staircase property has a role to play in understanding the capabilities of gradient-based learning on regular networks, in contrast to general polynomial-size networks that can emulate any Statistical Query or PAC algorithm, as recently shown.
count=6
* An Efficient Adversarial Attack for Tree Ensembles
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/ba3e9b6a519cfddc560b5d53210df1bd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/ba3e9b6a519cfddc560b5d53210df1bd-Paper.pdf)]
    * Title: An Efficient Adversarial Attack for Tree Ensembles
    * Year: `2020`
    * Authors: Chong Zhang, Huan Zhang, Cho-Jui Hsieh
    * Abstract: We study the problem of efficient adversarial attacks on tree based ensembles such as gradient boosting decision trees (GBDTs) and random forests (RFs). Since these models are non-continuous step functions and gradient does not exist, most existing efficient adversarial attacks are not applicable. Although decision-based black-box attacks can be applied, they cannot utilize the special structure of trees. In our work, we transform the attack problem into a discrete search problem specially designed for tree ensembles, where the goal is to find a valid ``leaf tuple'' that leads to mis-classification while having the shortest distance to the original input. With this formulation, we show that a simple yet effective greedy algorithm can be applied to iteratively optimize the adversarial example by moving the leaf tuple to its neighborhood within hamming distance 1. Experimental results on several large GBDT and RF models with up to hundreds of trees demonstrate that our method can be thousands of times faster than the previous mixed-integer linear programming (MILP) based approach, while also providing smaller (better) adversarial examples than decision-based black-box attacks on general $\ell_p$ ($p=1, 2, \infty$) norm perturbations.
count=6
* Handling Missing Data with Graph Representation Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/dc36f18a9a0a776671d4879cae69b551-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/dc36f18a9a0a776671d4879cae69b551-Paper.pdf)]
    * Title: Handling Missing Data with Graph Representation Learning
    * Year: `2020`
    * Authors: Jiaxuan You, Xiaobai Ma, Yi Ding, Mykel J. Kochenderfer, Jure Leskovec
    * Abstract: Machine learning with missing data has been approached in many different ways, including feature imputation where missing feature values are estimated based on observed values and label prediction where downstream labels are learned directly from incomplete data. However, existing imputation models tend to have strong prior assumptions and cannot learn from downstream tasks, while models targeting label predictions often involve heuristics and can encounter scalability issues. Here we propose GRAPE, a framework for feature imputation as well as label prediction. GRAPE tackles the missing data problem using graph representation, where the observations and features are viewed as two types of nodes in a bipartite graph, and the observed feature values as edges. Under the GRAPE framework, the feature imputation is formulated as an edge-level prediction task and the label prediction as a node-level prediction task. These tasks are then solved with Graph Neural Networks. Experimental results on nine benchmark datasets show that GRAPE yields 20% lower mean absolute error for imputation tasks and 10% lower for label prediction tasks, compared with existing state-of-the-art methods.
count=6
* Faster Boosting with Smaller Memory
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/3ffebb08d23c609875d7177ee769a3e9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/3ffebb08d23c609875d7177ee769a3e9-Paper.pdf)]
    * Title: Faster Boosting with Smaller Memory
    * Year: `2019`
    * Authors: Julaiti Alafate, Yoav S. Freund
    * Abstract: State-of-the-art implementations of boosting, such as XGBoost and LightGBM, can process large training sets extremely fast. However, this performance requires that the memory size is sufficient to hold a 2-3 multiple of the training set size. This paper presents an alternative approach to implementing the boosted trees, which achieves a significant speedup over XGBoost and LightGBM, especially when the memory size is small. This is achieved using a combination of three techniques: early stopping, effective sample size, and stratified sampling. Our experiments demonstrate a 10-100 speedup over XGBoost when the training data is too large to fit in memory.
count=6
* Regularized Gradient Boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/465636eb4a7ff4b267f3b765d07a02da-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/465636eb4a7ff4b267f3b765d07a02da-Paper.pdf)]
    * Title: Regularized Gradient Boosting
    * Year: `2019`
    * Authors: Corinna Cortes, Mehryar Mohri, Dmitry Storcheus
    * Abstract: Gradient Boosting (\GB) is a popular and very successful ensemble method for binary trees. While various types of regularization of the base predictors are used with this algorithm, the theory that connects such regularizations with generalization guarantees is poorly understood. We fill this gap by deriving data-dependent learning guarantees for \GB\ used with \emph{regularization}, expressed in terms of the Rademacher complexities of the constrained families of base predictors. We introduce a new algorithm, called \rgb\, that directly benefits from these generalization bounds and that, at every boosting round, applies the \emph{Structural Risk Minimization} principle to search for a base predictor with the best empirical fit versus complexity trade-off. Inspired by \emph{Randomized Coordinate Descent} we provide a scalable implementation of our algorithm, able to search over large families of base predictors. Finally, we provide experimental results, demonstrating that our algorithm achieves significantly better out-of-sample performance on multiple datasets than the standard \GB\ algorithm used with its regularization.
count=6
* Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/0829424ffa0d3a2547b6c9622c77de03-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/0829424ffa0d3a2547b6c9622c77de03-Paper.pdf)]
    * Title: Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog
    * Year: `2018`
    * Authors: Sang-Woo Lee, Yu-Jung Heo, Byoung-Tak Zhang
    * Abstract: Goal-oriented dialog has been given attention due to its numerous applications in artificial intelligence. Goal-oriented dialogue tasks occur when a questioner asks an action-oriented question and an answerer responds with the intent of letting the questioner know a correct action to take. To ask the adequate question, deep learning and reinforcement learning have been recently applied. However, these approaches struggle to find a competent recurrent neural questioner, owing to the complexity of learning a series of sentences. Motivated by theory of mind, we propose "Answerer in Questioner's Mind" (AQM), a novel information theoretic algorithm for goal-oriented dialog. With AQM, a questioner asks and infers based on an approximated probabilistic model of the answerer. The questioner figures out the answerer’s intention via selecting a plausible question by explicitly calculating the information gain of the candidate intentions and possible answers to each question. We test our framework on two goal-oriented visual dialog tasks: "MNIST Counting Dialog" and "GuessWhat?!". In our experiments, AQM outperforms comparative algorithms by a large margin.
count=6
* Learning Loop Invariants for Program Verification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/65b1e92c585fd4c2159d5f33b5030ff2-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/65b1e92c585fd4c2159d5f33b5030ff2-Paper.pdf)]
    * Title: Learning Loop Invariants for Program Verification
    * Year: `2018`
    * Authors: Xujie Si, Hanjun Dai, Mukund Raghothaman, Mayur Naik, Le Song
    * Abstract: A fundamental problem in program verification concerns inferring loop invariants. The problem is undecidable and even practical instances are challenging. Inspired by how human experts construct loop invariants, we propose a reasoning framework Code2Inv that constructs the solution by multi-step decision making and querying an external program graph memory block. By training with reinforcement learning, Code2Inv captures rich program features and avoids the need for ground truth solutions as supervision. Compared to previous learning tasks in domains with graph-structured data, it addresses unique challenges, such as a binary objective function and an extremely sparse reward that is given by an automated theorem prover only after the complete loop invariant is proposed. We evaluate Code2Inv on a suite of 133 benchmark problems and compare it to three state-of-the-art systems. It solves 106 problems compared to 73 by a stochastic search-based system, 77 by a heuristic search-based system, and 100 by a decision tree learning-based system. Moreover, the strategy learned can be generalized to new programs: compared to solving new instances from scratch, the pre-trained agent is more sample efficient in finding solutions.
count=6
* A no-regret generalization of hierarchical softmax to extreme multi-label classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/8b8388180314a337c9aa3c5aa8e2f37a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/8b8388180314a337c9aa3c5aa8e2f37a-Paper.pdf)]
    * Title: A no-regret generalization of hierarchical softmax to extreme multi-label classification
    * Year: `2018`
    * Authors: Marek Wydmuch, Kalina Jasinska, Mikhail Kuznetsov, Róbert Busa-Fekete, Krzysztof Dembczynski
    * Abstract: Extreme multi-label classification (XMLC) is a problem of tagging an instance with a small subset of relevant labels chosen from an extremely large pool of possible labels. Large label spaces can be efficiently handled by organizing labels as a tree, like in the hierarchical softmax (HSM) approach commonly used for multi-class problems. In this paper, we investigate probabilistic label trees (PLTs) that have been recently devised for tackling XMLC problems. We show that PLTs are a no-regret multi-label generalization of HSM when precision@$k$ is used as a model evaluation metric. Critically, we prove that pick-one-label heuristic---a reduction technique from multi-label to multi-class that is routinely used along with HSM---is not consistent in general. We also show that our implementation of PLTs, referred to as extremeText (XT), obtains significantly better results than HSM with the pick-one-label heuristic and XML-CNN, a deep network specifically designed for XMLC problems. Moreover, XT is competitive to many state-of-the-art approaches in terms of statistical performance, model size and prediction time which makes it amenable to deploy in an online system.
count=6
* Improving Simple Models with Confidence Profiles
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/972cda1e62b72640cb7ac702714a115f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/972cda1e62b72640cb7ac702714a115f-Paper.pdf)]
    * Title: Improving Simple Models with Confidence Profiles
    * Year: `2018`
    * Authors: Amit Dhurandhar, Karthikeyan Shanmugam, Ronny Luss, Peder A. Olsen
    * Abstract: In this paper, we propose a new method called ProfWeight for transferring information from a pre-trained deep neural network that has a high test accuracy to a simpler interpretable model or a very shallow network of low complexity and a priori low test accuracy. We are motivated by applications in interpretability and model deployment in severely memory constrained environments (like sensors). Our method uses linear probes to generate confidence scores through flattened intermediate representations. Our transfer method involves a theoretically justified weighting of samples during the training of the simple model using confidence scores of these intermediate layers. The value of our method is first demonstrated on CIFAR-10, where our weighting method significantly improves (3-4\%) networks with only a fraction of the number of Resnet blocks of a complex Resnet model. We further demonstrate operationally significant results on a real manufacturing problem, where we dramatically increase the test accuracy of a CART model (the domain standard) by roughly $13\%$.
count=6
* Understanding variable importances in forests of randomized trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/e3796ae838835da0b6f6ea37bcf8bcb7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/e3796ae838835da0b6f6ea37bcf8bcb7-Paper.pdf)]
    * Title: Understanding variable importances in forests of randomized trees
    * Year: `2013`
    * Authors: Gilles Louppe, Louis Wehenkel, Antonio Sutera, Pierre Geurts
    * Abstract: Despite growing interest and practical use in various scientific areas, variable importances derived from tree-based ensemble methods are not well understood from a theoretical point of view. In this work we characterize the Mean Decrease Impurity (MDI) variable importances as measured by an ensemble of totally randomized trees in asymptotic sample and ensemble size conditions. We derive a three-level decomposition of the information jointly provided by all input variables about the output in terms of i) the MDI importance of each input variable, ii) the degree of interaction of a given input variable with the other input variables, iii) the different interaction terms of a given degree. We then show that this MDI importance of a variable is equal to zero if and only if the variable is irrelevant and that the MDI importance of a relevant variable is invariant with respect to the removal or the addition of irrelevant variables. We illustrate these properties on a simple example and discuss how they may change in the case of non-totally randomized trees such as Random Forests and Extra-Trees.
count=5
* Speed Invariant Time Surface for Learning to Detect Corner Points With Event-Based Cameras
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Manderscheid_Speed_Invariant_Time_Surface_for_Learning_to_Detect_Corner_Points_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Manderscheid_Speed_Invariant_Time_Surface_for_Learning_to_Detect_Corner_Points_CVPR_2019_paper.pdf)]
    * Title: Speed Invariant Time Surface for Learning to Detect Corner Points With Event-Based Cameras
    * Year: `2019`
    * Authors: Jacques Manderscheid,  Amos Sironi,  Nicolas Bourdis,  Davide Migliore,  Vincent Lepetit
    * Abstract: We propose a learning approach to corner detection for event-based cameras that is stable even under fast and abrupt motions. Event-based cameras offer high temporal resolution, power efficiency, and high dynamic range. However, the properties of event-based data are very different compared to standard intensity images, and simple extensions of corner detection methods designed for these images do not perform well on event-based data. We first introduce an efficient way to compute a time surface that is invariant to the speed of the objects. We then show that we can train a Random Forest to recognize events generated by a moving corner from our time surface. Random Forests are also extremely efficient, and therefore a good choice to deal with the high capture frequency of event-based cameras ---our implementation processes up to 1.6Mev/s on a single CPU. Thanks to our time surface formulation and this learning approach, our method is significantly more robust to abrupt changes of direction of the corners compared to previous ones. Our method also naturally assigns a confidence score for the corners, which can be useful for postprocessing. Moreover, we introduce a high-resolution dataset suitable for quantitative evaluation and comparison of corner detection methods for event-based cameras. We call our approach SILC, for Speed Invariant Learned Corners, and compare it to the state-of-the-art with extensive experiments, showing better performance.
count=5
* Deep Decision Network for Multi-Class Image Classification
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Murthy_Deep_Decision_Network_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Murthy_Deep_Decision_Network_CVPR_2016_paper.pdf)]
    * Title: Deep Decision Network for Multi-Class Image Classification
    * Year: `2016`
    * Authors: Venkatesh N. Murthy, Vivek Singh, Terrence Chen, R. Manmatha, Dorin Comaniciu
    * Abstract: In this paper, we present a novel Deep Decision Network (DDN) that provides an alternative approach towards building an efficient deep learning network. During the learning phase, starting from the root network node, DDN automatically builds a network that splits the data into disjoint clusters of classes which would be handled by the subsequent expert networks. This results in a tree-like structured network driven by the data. The proposed method provides an insight into the data by identifying the group of classes that are hard to classify and require more attention when compared to others. DDN also has the ability to make early decisions thus making it suitable for time-sensitive applications. We validate DDN on two publicly available benchmark datasets: CIFAR-10 and CIFAR-100 and it yields state-of-the-art classification performance on both the datasets. The proposed algorithm has no limitations to be applied to any generic classification problems.
count=5
* Monocular Depth Estimation Using Neural Regression Forest
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Roy_Monocular_Depth_Estimation_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Roy_Monocular_Depth_Estimation_CVPR_2016_paper.pdf)]
    * Title: Monocular Depth Estimation Using Neural Regression Forest
    * Year: `2016`
    * Authors: Anirban Roy, Sinisa Todorovic
    * Abstract: This paper presents a novel deep architecture, called neural regression forest (NRF), for depth estimation from a single image. NRF combines random forests and convolutional neural networks (CNNs). Scanning windows extracted from the image represent samples which are passed down the trees of NRF for predicting their depth. At every tree node, the sample is filtered with a CNN associated with that node. Results of the convolutional filtering are passed to left and right children nodes, i.e., corresponding CNNs, with a Bernoulli probability, until the leaves, where depth estimations are made. CNNs at every node are designed to have fewer parameters than seen in recent work, but their stacked processing along a path in the tree effectively amounts to a deeper CNN. NRF allows for parallelizable training of all "shallow" CNNs, and efficient enforcing of smoothness in depth estimation results. Our evaluation on the benchmark Make3D and NYUv2 datasets demonstrates that NRF outperforms the state of the art, and gracefully handles gradually decreasing training datasets.
count=5
* Fast Training of Triplet-Based Deep Binary Embedding Networks
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Zhuang_Fast_Training_of_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Zhuang_Fast_Training_of_CVPR_2016_paper.pdf)]
    * Title: Fast Training of Triplet-Based Deep Binary Embedding Networks
    * Year: `2016`
    * Authors: Bohan Zhuang, Guosheng Lin, Chunhua Shen, Ian Reid
    * Abstract: In this paper, we aim to learn a mapping (or embedding) from images to a compact binary space in which Hamming distances correspond to a ranking measure for the image retrieval task. We make use of a triplet loss because this has been shown to be most effective for ranking problems. How- ever, training in previous works can be prohibitively expensive due to the fact that optimization is directly performed on the triplet space, where the number of possible triplets for training is cubic in the number of training examples. To address this issue, we propose to formulate high-order binary codes learning as a multi-label classification problem by explicitly separating learning into two interleaved stages. To solve the first stage, we design a large-scale high-order binary codes inference algorithm to reduce the high-order objective to a standard binary quadratic problem such that graph cuts can be used to efficiently infer the binary codes which serve as the labels of each training datum. In the second stage we propose to map the original image to compact binary codes via carefully designed deep convolutional neural networks (CNNs) and the hash- ing function fitting can be solved by training binary CNN classifiers. An incremental/interleaved optimization strategy is proffered to ensure that these two steps are interactive with each other during training for better accuracy. We conduct experiments on several benchmark datasets, which demonstrate both improved training time (by as much as two orders of magnitude) as well as producing state-of-the- art hashing for various retrieval tasks.
count=5
* Random Tree Walk Toward Instantaneous 3D Human Pose Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Jung_Random_Tree_Walk_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Jung_Random_Tree_Walk_2015_CVPR_paper.pdf)]
    * Title: Random Tree Walk Toward Instantaneous 3D Human Pose Estimation
    * Year: `2015`
    * Authors: Ho Yub Jung, Soochahn Lee, Yong Seok Heo, Il Dong Yun
    * Abstract: The availability of accurate depth cameras have made real-time human pose estimation possible; however, there are still demands for faster algorithms on low power processors. This paper introduces 1000 frames per second pose estimation method on a single core CPU. A large computation gain is achieved by random walk sub-sampling. Instead of training trees for pixel-wise classification, a regression tree is trained to estimate the probability distribution to the direction toward the particular joint, relative to the current position. At test time, the direction for the random walk is randomly chosen from a set of representative directions. The new position is found by a constant step toward the direction, and the distribution for next direction is found at the new position. The continual random walk through 3D space will eventually produce an expectation of step positions, which we estimate as the joint position. A regression tree is built separately for each joint. The number of random walk steps can be assigned for each joint so that the computation time is consistent regardless of the size of body segmentation. The experiments show that even with large computation gain, the accuracy is higher or comparable to the state-of-the-art pose estimation methods.
count=5
* Learning To Look Up: Realtime Monocular Gaze Correction Using Machine Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Kononenko_Learning_To_Look_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Kononenko_Learning_To_Look_2015_CVPR_paper.pdf)]
    * Title: Learning To Look Up: Realtime Monocular Gaze Correction Using Machine Learning
    * Year: `2015`
    * Authors: Daniil Kononenko, Victor Lempitsky
    * Abstract: We revisit the well-known problem of gaze correction and present a solution based on supervised machine learning. At training time, our system observes pairs of images, where each pair contains the face of the same person with a fixed angular difference in gaze direction. It then learns to synthesize the second image of a pair from the first one. After learning, the system becomes able to redirect the gaze of a previously unseen person by the same angular difference. Unlike many previous solutions to gaze problem in videoconferencing, ours is purely monocular, i.e. it does not require any hardware apart from an in-built web-camera of a laptop. We base our machine learning implementation on a special kind of decision forests that predict a displacement (flow) vector for each pixel in the input image. As a result, our system is highly efficient (runs in real-time on a single core of a modern laptop). In the paper, we demonstrate results on a variety of videoconferencing frames and evaluate the method quantitatively on the hold-out set of registered images. The supplementary video shows example sessions of our system at work.
count=5
* RIGOR: Reusing Inference in Graph Cuts for Generating Object Regions
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Humayun_RIGOR_Reusing_Inference_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Humayun_RIGOR_Reusing_Inference_2014_CVPR_paper.pdf)]
    * Title: RIGOR: Reusing Inference in Graph Cuts for Generating Object Regions
    * Year: `2014`
    * Authors: Ahmad Humayun, Fuxin Li, James M. Rehg
    * Abstract: Popular figure-ground segmentation algorithms generate a pool of boundary-aligned segment proposals that can be used in subsequent object recognition engines. These algorithms can recover most image objects with high accuracy, but are usually computationally intensive since many graph cuts are computed with different enumerations of segment seeds. In this paper we propose an algorithm, RIGOR, for efficiently generating a pool of overlapping segment proposals in images. By precomputing a graph which can be used for parametric min-cuts over different seeds, we speed up the generation of the segment pool. In addition, we have made design choices that avoid extensive computations without losing performance. In particular, we demonstrate that the segmentation performance of our algorithm is slightly better than the state-of-the-art on the PASCAL VOC dataset, while being an order of magnitude faster.
count=5
* Fully-Connected CRFs with Non-Parametric Pairwise Potential
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Campbell_Fully-Connected_CRFs_with_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Campbell_Fully-Connected_CRFs_with_2013_CVPR_paper.pdf)]
    * Title: Fully-Connected CRFs with Non-Parametric Pairwise Potential
    * Year: `2013`
    * Authors: Neill D.F. Campbell, Kartic Subr, Jan Kautz
    * Abstract: Conditional Random Fields (CRFs) are used for diverse tasks, ranging from image denoising to object recognition. For images, they are commonly defined as a graph with nodes corresponding to individual pixels and pairwise links that connect nodes to their immediate neighbors. Recent work has shown that fully-connected CRFs, where each node is connected to every other node, can be solved efficiently under the restriction that the pairwise term is a Gaussian kernel over a Euclidean feature space. In this paper, we generalize the pairwise terms to a non-linear dissimilarity measure that is not required to be a distance metric. To this end, we propose a density estimation technique to derive conditional pairwise potentials in a nonparametric manner. We then use an efficient embedding technique to estimate an approximate Euclidean feature space for these potentials, in which the pairwise term can still be expressed as a Gaussian kernel. We demonstrate that the use of non-parametric models for the pairwise interactions, conditioned on the input data, greatly increases expressive power whilst maintaining efficient inference.
count=5
* Finding Representative Interpretations on Convolutional Neural Networks
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Lam_Finding_Representative_Interpretations_on_Convolutional_Neural_Networks_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Lam_Finding_Representative_Interpretations_on_Convolutional_Neural_Networks_ICCV_2021_paper.pdf)]
    * Title: Finding Representative Interpretations on Convolutional Neural Networks
    * Year: `2021`
    * Authors: Peter Cho-Ho Lam, Lingyang Chu, Maxim Torgonskiy, Jian Pei, Yong Zhang, Lanjun Wang
    * Abstract: Interpreting the decision logic behind effective deep convolutional neural networks (CNN) on images complements the success of deep learning models. However, the existing methods can only interpret some specific decision logic on individual or a small number of images. To facilitate human understandability and generalization ability, it is important to develop representative interpretations that interpret common decision logics of a CNN on a large group of similar images, which reveal the common semantics data contributes to many closely related predictions. In this paper, we develop a novel unsupervised approach to produce a highly representative interpretation for a large number of similar images. We formulate the problem of finding representative interpretations as a co-clustering problem, and convert it into a submodular cost submodular cover problem based on a sample of the linear decision boundaries of a CNN. We also present a visualization and similarity ranking method. Our extensive experiments demonstrate the excellent performance of our method.
count=5
* Real-Time Pose Estimation Piggybacked on Object Detection
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Juranek_Real-Time_Pose_Estimation_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Juranek_Real-Time_Pose_Estimation_ICCV_2015_paper.pdf)]
    * Title: Real-Time Pose Estimation Piggybacked on Object Detection
    * Year: `2015`
    * Authors: Roman Juranek, Adam Herout, Marketa Dubska, Pavel Zemcik
    * Abstract: We present an object detector coupled with pose estimation directly in a single compact and simple model, where the detector shares extracted image features with the pose estimator. The output of the classification of each candidate window consists of both object score and likelihood map of poses. This extension introduces negligible overhead during detection so that the detector is still capable of real time operation. We evaluated the proposed approach on the problem of vehicle detection. We used existing datasets with viewpoint/pose annotation (WCVP, 3D objects, KITTI). Besides that, we collected a new traffic surveillance dataset COD20k which fills certain gaps of the existing datasets and we make it public. The experimental results show that the proposed approach is comparable with state-of-the-art approaches in terms of accuracy, but it is considerably faster - easily operating in real time (Matlab with C++ code). The source codes and the collected COD20k dataset are made public along with the paper.
count=5
* Multi-scale Topological Features for Hand Posture Representation and Analysis
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Hu_Multi-scale_Topological_Features_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Hu_Multi-scale_Topological_Features_2013_ICCV_paper.pdf)]
    * Title: Multi-scale Topological Features for Hand Posture Representation and Analysis
    * Year: `2013`
    * Authors: Kaoning Hu, Lijun Yin
    * Abstract: In this paper, we propose a multi-scale topological feature representation for automatic analysis of hand posture. Such topological features have the advantage of being posture-dependent while being preserved under certain variations of illumination, rotation, personal dependency, etc. Our method studies the topology of the holes between the hand region and its convex hull. Inspired by the principle of Persistent Homology, which is the theory of computational topology for topological feature analysis over multiple scales, we construct the multi-scale Betti Numbers matrix (MSBNM) for the topological feature representation. In our experiments, we used 12 different hand postures and compared our features with three popular features (HOG, MCT, and Shape Context) on different data sets. In addition to hand postures, we also extend the feature representations to arm postures. The results demonstrate the feasibility and reliability of the proposed method.
count=5
* GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/5eaafd67434a4cfb1cf829722c65f184-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/5eaafd67434a4cfb1cf829722c65f184-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection
    * Year: `2023`
    * Authors: Jianheng Tang, Fengrui Hua, Ziqi Gao, Peilin Zhao, Jia Li
    * Abstract: With a long history of traditional Graph Anomaly Detection (GAD) algorithms and recently popular Graph Neural Networks (GNNs), it is still not clear (1) how they perform under a standard comprehensive setting, (2) whether GNNs can outperform traditional algorithms such as tree ensembles, and (3) how about their efficiency on large-scale graphs. In response, we introduce GADBench---a benchmark tool dedicated to supervised anomalous node detection in static graphs. GADBench facilitates a detailed comparison across 29 distinct models on ten real-world GAD datasets, encompassing thousands to millions (~6M) nodes. Our main finding is that tree ensembles with simple neighborhood aggregation can outperform the latest GNNs tailored for the GAD task. We shed light on the current progress of GAD, setting a robust groundwork for subsequent investigations in this domain. GADBench is open-sourced at https://github.com/squareRoot3/GADBench.
count=5
* Neural Basis Models for Interpretability
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/37da88965c016dca016514df0e420c72-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/37da88965c016dca016514df0e420c72-Paper-Conference.pdf)]
    * Title: Neural Basis Models for Interpretability
    * Year: `2022`
    * Authors: Filip Radenovic, Abhimanyu Dubey, Dhruv Mahajan
    * Abstract: Due to the widespread use of complex machine learning models in real-world applications, it is becoming critical to explain model predictions. However, these models are typically black-box deep neural networks, explained post-hoc via methods with known faithfulness limitations. Generalized Additive Models (GAMs) are an inherently interpretable class of models that address this limitation by learning a non-linear shape function for each feature separately, followed by a linear model on top. However, these models are typically difficult to train, require numerous parameters, and are difficult to scale. We propose an entirely new subfamily of GAMs that utilizes basis decomposition of shape functions. A small number of basis functions are shared among all features, and are learned jointly for a given task, thus making our model scale much better to large-scale data with high-dimensional features, especially when features are sparse. We propose an architecture denoted as the Neural Basis Model (NBM) which uses a single neural network to learn these bases. On a variety of tabular and image datasets, we demonstrate that for interpretable machine learning, NBMs are the state-of-the-art in accuracy, model size, and, throughput and can easily model all higher-order feature interactions. Source code is available at \href{https://github.com/facebookresearch/nbm-spam}{\ttfamily github.com/facebookresearch/nbm-spam}.
count=5
* Symbolic Distillation for Learned TCP Congestion Control
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/4574ac9854d4defe3bf119d07b817084-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/4574ac9854d4defe3bf119d07b817084-Paper-Conference.pdf)]
    * Title: Symbolic Distillation for Learned TCP Congestion Control
    * Year: `2022`
    * Authors: S P Sharan, Wenqing Zheng, Kuo-Feng Hsu, Jiarong Xing, Ang Chen, Zhangyang Wang
    * Abstract: Recent advances in TCP congestion control (CC) have achieved tremendous success with deep reinforcement learning (RL) approaches, which use feedforward neural networks (NN) to learn complex environment conditions and make better decisions. However, such ``black-box'' policies lack interpretability and reliability, and often, they need to operate outside the traditional TCP datapath due to the use of complex NNs. This paper proposes a novel two-stage solution to achieve the best of both worlds: first to train a deep RL agent, then distill its (over-)parameterized NN policy into white-box, light-weight rules in the form of symbolic expressions that are much easier to understand and to implement in constrained environments. At the core of our proposal is a novel symbolic branching algorithm that enables the rule to be aware of the context in terms of various network conditions, eventually converting the NN policy into a symbolic tree. The distilled symbolic rules preserve and often improve performance over state-of-the-art NN policies while being faster and simpler than a standard neural network. We validate the performance of our distilled symbolic rules on both simulation and emulation environments. Our code is available at https://github.com/VITA-Group/SymbolicPCC.
count=5
* Linear Label Ranking with Bounded Noise
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/64792f7bd5d400c9ac310c6fef97ef2d-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/64792f7bd5d400c9ac310c6fef97ef2d-Paper-Conference.pdf)]
    * Title: Linear Label Ranking with Bounded Noise
    * Year: `2022`
    * Authors: Dimitris Fotakis, Alkis Kalavasis, Vasilis Kontonis, Christos Tzamos
    * Abstract: Label Ranking (LR) is the supervised task of learning a sorting function that maps feature vectors $x \in \mathbb{R}^d$ to rankings $\sigma(x) \in \mathbb S_k$ over a finite set of $k$ labels. We focus on the fundamental case of learning linear sorting functions (LSFs) under Gaussian marginals: $x$ is sampled from the $d$-dimensional standard normal and the ground truth ranking $\sigma^\star(x)$ is the ordering induced by sorting the coordinates of the vector $W^\star x$, where $W^\star \in \mathbb{R}^{k \times d}$ is unknown. We consider learning LSFs in the presence of bounded noise: assuming that a noiseless example is of the form $(x, \sigma^\star(x))$, we observe $(x, \pi)$, where for any pair of elements $i \neq j$, the probability that the order of $i, j$ is different in $\pi$ than in $\sigma^\star(x)$ is at most $\eta < 1/2$. We design efficient non-proper and proper learning algorithms that learn hypotheses within normalized Kendall's Tau distance $\epsilon$ from the ground truth with $N= \widetilde{O}(d\log(k)/\epsilon)$ labeled examples and runtime $\mathrm{poly}(N, k)$. For the more challenging top-$r$ disagreement loss, we give an efficient proper learning algorithm that achieves $\epsilon$ top-$r$ disagreement with the ground truth with $N = \widetilde{O}(d k r /\epsilon)$ samples and $\mathrm{poly}(N)$ runtime.
count=5
* From global to local MDI variable importances for random forests and when they are Shapley values
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/1cfa81af29c6f2d8cacb44921722e753-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/1cfa81af29c6f2d8cacb44921722e753-Paper.pdf)]
    * Title: From global to local MDI variable importances for random forests and when they are Shapley values
    * Year: `2021`
    * Authors: Antonio Sutera, Gilles Louppe, Van Anh Huynh-Thu, Louis Wehenkel, Pierre Geurts
    * Abstract: Random forests have been widely used for their ability to provide so-called importance measures, which give insight at a global (per dataset) level on the relevance of input variables to predict a certain output. On the other hand, methods based on Shapley values have been introduced to refine the analysis of feature relevance in tree-based models to a local (per instance) level. In this context, we first show that the global Mean Decrease of Impurity (MDI) variable importance scores correspond to Shapley values under some conditions. Then, we derive a local MDI importance measure of variable relevance, which has a very natural connection with the global MDI measure and can be related to a new notion of local feature relevance. We further link local MDI importances with Shapley values and discuss them in the light of related measures from the literature. The measures are illustrated through experiments on several classification and regression problems.
count=5
* Retiring Adult: New Datasets for Fair Machine Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/32e54441e6382a7fbacbbbaf3c450059-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/32e54441e6382a7fbacbbbaf3c450059-Paper.pdf)]
    * Title: Retiring Adult: New Datasets for Fair Machine Learning
    * Year: `2021`
    * Authors: Frances Ding, Moritz Hardt, John Miller, Ludwig Schmidt
    * Abstract: Although the fairness community has recognized the importance of data, researchers in the area primarily rely on UCI Adult when it comes to tabular data. Derived from a 1994 US Census survey, this dataset has appeared in hundreds of research papers where it served as the basis for the development and comparison of many algorithmic fairness interventions. We reconstruct a superset of the UCI Adult data from available US Census sources and reveal idiosyncrasies of the UCI Adult dataset that limit its external validity. Our primary contribution is a suite of new datasets derived from US Census surveys that extend the existing data ecosystem for research on fair machine learning. We create prediction tasks relating to income, employment, health, transportation, and housing. The data span multiple years and all states of the United States, allowing researchers to study temporal shift and geographic variation. We highlight a broad initial sweep of new empirical insights relating to trade-offs between fairness criteria, performance of algorithmic interventions, and the role of distribution shift based on our new datasets. Our findings inform ongoing debates, challenge some existing narratives, and point to future research directions.
count=5
* Discerning Decision-Making Process of Deep Neural Networks with Hierarchical Voting Transformation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/8f1fa0193ca2b5d2fa0695827d8270e9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/8f1fa0193ca2b5d2fa0695827d8270e9-Paper.pdf)]
    * Title: Discerning Decision-Making Process of Deep Neural Networks with Hierarchical Voting Transformation
    * Year: `2021`
    * Authors: Ying Sun, Hengshu Zhu, Chuan Qin, Fuzhen Zhuang, Qing He, Hui Xiong
    * Abstract: Neural network based deep learning techniques have shown great success for numerous applications. While it is expected to understand their intrinsic decision-making processes, these deep neural networks often work in a black-box way. To this end, in this paper, we aim to discern the decision-making processes of neural networks through a hierarchical voting strategy by developing an explainable deep learning model, namely Voting Transformation-based Explainable Neural Network (VOTEN). Specifically, instead of relying on massive feature combinations, VOTEN creatively models expressive single-valued voting functions between explicitly modeled latent concepts to achieve high fitting ability. Along this line, we first theoretically analyze the major components of VOTEN and prove the relationship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), the basic structure of deep neural networks. Moreover, we design efficient algorithms to improve the model usability by explicitly showing the decision processes of VOTEN. Finally, extensive experiments on multiple real-world datasets clearly validate the performances and explainability of VOTEN.
count=5
* Well-tuned Simple Nets Excel on Tabular Datasets
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/c902b497eb972281fb5b4e206db38ee6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/c902b497eb972281fb5b4e206db38ee6-Paper.pdf)]
    * Title: Well-tuned Simple Nets Excel on Tabular Datasets
    * Year: `2021`
    * Authors: Arlind Kadra, Marius Lindauer, Frank Hutter, Josif Grabocka
    * Abstract: Tabular datasets are the last "unconquered castle" for deep learning, with traditional ML methods like Gradient-Boosted Decision Trees still performing strongly even against recent specialized neural architectures. In this paper, we hypothesize that the key to boosting the performance of neural networks lies in rethinking the joint and simultaneous application of a large set of modern regularization techniques. As a result, we propose regularizing plain Multilayer Perceptron (MLP) networks by searching for the optimal combination/cocktail of 13 regularization techniques for each dataset using a joint optimization over the decision on which regularizers to apply and their subsidiary hyperparameters. We empirically assess the impact of these regularization cocktails for MLPs in a large-scale empirical study comprising 40 tabular datasets and demonstrate that (i) well-regularized plain MLPs significantly outperform recent state-of-the-art specialized neural network architectures, and (ii) they even outperform strong traditional ML methods, such as XGBoost.
count=5
* MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/a64bd53139f71961c5c31a9af03d775e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/a64bd53139f71961c5c31a9af03d775e-Paper.pdf)]
    * Title: MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler
    * Year: `2020`
    * Authors: Zhining Liu, Pengfei Wei, Jing Jiang, Wei Cao, Jiang Bian, Yi Chang
    * Abstract: Imbalanced learning (IL), i.e., learning unbiased models from class-imbalanced data, is a challenging problem. Typical IL methods including resampling and reweighting were designed based on some heuristic assumptions. They often suffer from unstable performance, poor applicability, and high computational cost in complex tasks where their assumptions do not hold. In this paper, we introduce a novel ensemble IL framework named MESA. It adaptively resamples the training set in iterations to get multiple classifiers and forms a cascade ensemble model. MESA directly learns the sampling strategy from data to optimize the final metric beyond following random heuristics. Moreover, unlike prevailing meta-learning-based IL solutions, we decouple the model-training and meta-training in MESA by independently train the meta-sampler over task-agnostic meta-data. This makes MESA generally applicable to most of the existing learning models and the meta-sampler can be efficiently applied to new tasks. Extensive experiments on both synthetic and real-world tasks demonstrate the effectiveness, robustness, and transferability of MESA. Our code is available at https://github.com/ZhiningLiu1998/mesa.
count=5
* A Bayesian model for identifying hierarchically organised states in neural population activity
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/1bc0249a6412ef49b07fe6f62e6dc8de-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/1bc0249a6412ef49b07fe6f62e6dc8de-Paper.pdf)]
    * Title: A Bayesian model for identifying hierarchically organised states in neural population activity
    * Year: `2014`
    * Authors: Patrick Putzky, Florian Franzen, Giacomo Bassetto, Jakob H. Macke
    * Abstract: Neural population activity in cortical circuits is not solely driven by external inputs, but is also modulated by endogenous states which vary on multiple time-scales. To understand information processing in cortical circuits, we need to understand the statistical structure of internal states and their interaction with sensory inputs. Here, we present a statistical model for extracting hierarchically organised neural population states from multi-channel recordings of neural spiking activity. Population states are modelled using a hidden Markov decision tree with state-dependent tuning parameters and a generalised linear observation model. We present a variational Bayesian inference algorithm for estimating the posterior distribution over parameters from neural population recordings. On simulated data, we show that we can identify the underlying sequence of population states and reconstruct the ground truth parameters. Using population recordings from visual cortex, we find that a model with two levels of population states outperforms both a one-state and a two-state generalised linear model. Finally, we find that modelling of state-dependence also improves the accuracy with which sensory stimuli can be decoded from the population response.
count=5
* Direct 0-1 Loss Minimization and Margin Maximization with Boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/9461cce28ebe3e76fb4b931c35a169b0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/9461cce28ebe3e76fb4b931c35a169b0-Paper.pdf)]
    * Title: Direct 0-1 Loss Minimization and Margin Maximization with Boosting
    * Year: `2013`
    * Authors: Shaodan Zhai, Tian Xia, Ming Tan, Shaojun Wang
    * Abstract: We propose a boosting method, DirectBoost, a greedy coordinate descent algorithm that builds an ensemble classifier of weak classifiers through directly minimizing empirical classification error over labeled training examples; once the training classification error is reduced to a local coordinatewise minimum, DirectBoost runs a greedy coordinate ascent algorithm that continuously adds weak classifiers to maximize any targeted arbitrarily defined margins until reaching a local coordinatewise maximum of the margins in a certain sense. Experimental results on a collection of machine-learning benchmark datasets show that DirectBoost gives consistently better results than AdaBoost, LogitBoost, LPBoost with column generation and BrownBoost, and is noise tolerant when it maximizes an n'th order bottom sample margin.
count=5
* Structured Learning via Logistic Regression
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/d9fc5b73a8d78fad3d6dffe419384e70-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/d9fc5b73a8d78fad3d6dffe419384e70-Paper.pdf)]
    * Title: Structured Learning via Logistic Regression
    * Year: `2013`
    * Authors: Justin Domke
    * Abstract: A successful approach to structured learning is to write the learning objective as a joint function of linear parameters and inference messages, and iterate between updates to each. This paper observes that if the inference problem is “smoothed” through the addition of entropy terms, for fixed messages, the learning objective reduces to a traditional (non-structured) logistic regression problem with respect to parameters. In these logistic regression problems, each training example has a bias term determined by the current set of messages. Based on this insight, the structured energy function can be extended from linear factors to any function class where an “oracle” exists to minimize a logistic loss.
count=4
* Generative Adversarial Image Synthesis With Decision Tree Latent Controller
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Kaneko_Generative_Adversarial_Image_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kaneko_Generative_Adversarial_Image_CVPR_2018_paper.pdf)]
    * Title: Generative Adversarial Image Synthesis With Decision Tree Latent Controller
    * Year: `2018`
    * Authors: Takuhiro Kaneko, Kaoru Hiramatsu, Kunio Kashino
    * Abstract: This paper proposes the decision tree latent controller generative adversarial network (DTLC-GAN), an extension of a GAN that can learn hierarchically interpretable representations without relying on detailed supervision. To impose a hierarchical inclusion structure on latent variables, we incorporate a new architecture called the DTLC into the generator input. The DTLC has a multiple-layer tree structure in which the ON or OFF of the child node codes is controlled by the parent node codes. By using this architecture hierarchically, we can obtain the latent space in which the lower layer codes are selectively used depending on the higher layer ones. To make the latent codes capture salient semantic features of images in a hierarchically disentangled manner in the DTLC, we also propose a hierarchical conditional mutual information regularization and optimize it with a newly defined curriculum learning method that we propose as well. This makes it possible to discover hierarchically interpretable representations in a layer-by-layer manner on the basis of information gain by only using a single DTLC-GAN model. We evaluated the DTLC-GAN on various datasets, i.e., MNIST, CIFAR-10, Tiny ImageNet, 3D Faces, and CelebA, and confirmed that the DTLC-GAN can learn hierarchically interpretable representations with either unsupervised or weakly supervised settings. Furthermore, we applied the DTLC-GAN to image-retrieval tasks and showed its effectiveness in representation learning.
count=4
* Superpixel-Based Tracking-By-Segmentation Using Markov Chains
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Yeo_Superpixel-Based_Tracking-By-Segmentation_Using_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Yeo_Superpixel-Based_Tracking-By-Segmentation_Using_CVPR_2017_paper.pdf)]
    * Title: Superpixel-Based Tracking-By-Segmentation Using Markov Chains
    * Year: `2017`
    * Authors: Donghun Yeo, Jeany Son, Bohyung Han, Joon Hee Han
    * Abstract: We propose a simple but effective tracking-by-segmentation algorithm using Absorbing Markov Chain (AMC) on superpixel segmentation, where target state is estimated by a combination of bottom-up and top-down approaches, and target segmentation is propagated to subsequent frames in a recursive manner. Our algorithm constructs a graph for AMC using the superpixels identified in two consecutive frames, where background superpixels in the previous frame correspond to absorbing vertices while all other superpixels create transient ones. The weight of each edge depends on the similarity of scores in the end superpixels, which are learned by support vector regression. Once graph construction is completed, target segmentation is estimated using the absorption time of each superpixel. The proposed tracking algorithm achieves substantially improved performance compared to the state-of-the-art segmentation-based tracking techniques in multiple challenging datasets.
count=4
* Fast 2D Border Ownership Assignment
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Teo_Fast_2D_Border_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Teo_Fast_2D_Border_2015_CVPR_paper.pdf)]
    * Title: Fast 2D Border Ownership Assignment
    * Year: `2015`
    * Authors: Ching Teo, Cornelia Fermuller, Yiannis Aloimonos
    * Abstract: A method for efficient border ownership assignment in 2D images is proposed. Leveraging on recent advances using Structured Random Forests (SRF) for boundary detection, we impose a novel border ownership structure that detects both boundaries and border ownership at the same time. Key to this work are features that predict ownership cues from 2D images. To this end, we use several different local cues: shape, spectral properties of boundary patches, and semi-global grouping cues that are indicative of perceived depth. For shape, we use HoG-like descriptors that encode local curvature (convexity and concavity). For spectral properties, such as extremal edges, we first learn an orthonormal basis spanned by the top K eigenvectors via PCA over common types of contour tokens. For grouping, we introduce a novel mid-level descriptor that captures patterns near edges and indicates ownership information of the boundary. Experimental results over a subset of the Berkeley Segmentation Dataset (BSDS) and the NYU Depth V2 dataset show that our method's performance exceeds current state-of-the-art multi-stage approaches that use more complex features.
count=4
* Learning to Detect Motion Boundaries
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Weinzaepfel_Learning_to_Detect_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Weinzaepfel_Learning_to_Detect_2015_CVPR_paper.pdf)]
    * Title: Learning to Detect Motion Boundaries
    * Year: `2015`
    * Authors: Philippe Weinzaepfel, Jerome Revaud, Zaid Harchaoui, Cordelia Schmid
    * Abstract: We propose a learning-based approach for motion boundary detection. Precise localization of motion boundaries is essential for the success of optical flow estimation, as motion boundaries correspond to discontinuities of the optical flow field. The proposed approach allows to predict motion boundaries, using a structured random forest trained on the ground-truth of the MPI-Sintel dataset. The random forest leverages several cues at the patch level, namely appearance (RGB color) and motion cues (optical flow estimated by state-of-the-art algorithms). Experimental results show that the proposed approach is both robust and computationally efficient. It significantly outperforms state-of-the-art motion-difference approaches on the MPI-Sintel and Middlebury datasets. We compare the results obtained with several state-of-the-art optical flow approaches and study the impact of the different cues used in the random forest.Furthermore, we introduce a new dataset, the YouTube Motion Boundaries dataset (YMB), that comprises 60 sequences taken from real-world videos with manually annotated motion boundaries. On this dataset, our approach, although trained on MPI-Sintel, also outperforms by a large margin state-of-the-art optical flow algorithms.
count=4
* Discriminative Feature-to-Point Matching in Image-Based Localization
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Donoser_Discriminative_Feature-to-Point_Matching_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Donoser_Discriminative_Feature-to-Point_Matching_2014_CVPR_paper.pdf)]
    * Title: Discriminative Feature-to-Point Matching in Image-Based Localization
    * Year: `2014`
    * Authors: Michael Donoser, Dieter Schmalstieg
    * Abstract: The prevalent approach to image-based localization is matching interest points detected in the query image to a sparse 3D point cloud representing the known world. The obtained correspondences are then used to recover a precise camera pose. The state-of-the-art in this field often ignores the availability of a set of 2D descriptors per 3D point, for example by representing each 3D point by only its centroid. In this paper we demonstrate that these sets contain useful information that can be exploited by formulating matching as a discriminative classification problem. Since memory demands and computational complexity are crucial in such a setup, we base our algorithm on the efficient and effective random fern principle. We propose an extension which projects features to fern-specific embedding spaces, which yields improved matching rates in short runtime. Experiments first show that our novel formulation provides improved matching performance in comparison to the standard nearest neighbor approach and that we outperform related randomization methods in our localization scenario.
count=4
* Multilabel Ranking with Inconsistent Rankers
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Geng_Multilabel_Ranking_with_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Geng_Multilabel_Ranking_with_2014_CVPR_paper.pdf)]
    * Title: Multilabel Ranking with Inconsistent Rankers
    * Year: `2014`
    * Authors: Xin Geng, Longrun Luo
    * Abstract: While most existing multilabel ranking methods assume the availability of a single objective label ranking for each instance in the training set, this paper deals with a more common case where subjective inconsistent rankings from multiple rankers are associated with each instance. The key idea is to learn a latent preference distribution for each instance. The proposed method mainly includes two steps. The first step is to generate a common preference distribution that is most compatible to all the personal rankings. The second step is to learn a mapping from the instances to the preference distributions. The proposed preference distribution learning (PDL) method is applied to the problem of multilabel ranking for natural scene images. Experimental results show that PDL can effectively incorporate the information given by the inconsistent rankers, and perform remarkably better than the compared state-of-the-art multilabel ranking algorithms.
count=4
* Accurate Object Detection with Joint Classification-Regression Random Forests
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Schulter_Accurate_Object_Detection_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Schulter_Accurate_Object_Detection_2014_CVPR_paper.pdf)]
    * Title: Accurate Object Detection with Joint Classification-Regression Random Forests
    * Year: `2014`
    * Authors: Samuel Schulter, Christian Leistner, Paul Wohlhart, Peter M. Roth, Horst Bischof
    * Abstract: In this paper, we present a novel object detection approach that is capable of regressing the aspect ratio of objects. This results in accurately predicted bounding boxes having high overlap with the ground truth. In contrast to most recent works, we employ a Random Forest for learning a template-based model but exploit the nature of this learning algorithm to predict arbitrary output spaces. In this way, we can simultaneously predict the object probability of a window in a sliding window approach as well as regress its aspect ratio with a single model. Furthermore, we also exploit the additional information of the aspect ratio during the training of the Joint Classification-Regression Random Forest, resulting in better detection models. Our experiments demonstrate several benefits: (i) Our approach gives competitive results on standard detection benchmarks. (ii) The additional aspect ratio regression delivers more accurate bounding boxes than standard object detection approaches in terms of overlap with ground truth, especially when tightening the evaluation criterion. (iii) The detector itself becomes better by only including the aspect ratio information during training.
count=4
* Joint 3D Scene Reconstruction and Class Segmentation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Hane_Joint_3D_Scene_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Hane_Joint_3D_Scene_2013_CVPR_paper.pdf)]
    * Title: Joint 3D Scene Reconstruction and Class Segmentation
    * Year: `2013`
    * Authors: Christian Hane, Christopher Zach, Andrea Cohen, Roland Angst, Marc Pollefeys
    * Abstract: Both image segmentation and dense 3D modeling from images represent an intrinsically ill-posed problem. Strong regularizers are therefore required to constrain the solutions from being 'too noisy'. Unfortunately, these priors generally yield overly smooth reconstructions and/or segmentations in certain regions whereas they fail in other areas to constrain the solution sufficiently. In this paper we argue that image segmentation and dense 3D reconstruction contribute valuable information to each other's task. As a consequence, we propose a rigorous mathematical framework to formulate and solve a joint segmentation and dense reconstruction problem. Image segmentations provide geometric cues about which surface orientations are more likely to appear at a certain location in space whereas a dense 3D reconstruction yields a suitable regularization for the segmentation problem by lifting the labeling from 2D images to 3D space. We show how appearance-based cues and 3D surface orientation priors can be learned from training data and subsequently used for class-specific regularization. Experimental results on several real data sets highlight the advantages of our joint formulation.
count=4
* GeoF: Geodesic Forests for Learning Coupled Predictors
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Kontschieder_GeoF_Geodesic_Forests_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Kontschieder_GeoF_Geodesic_Forests_2013_CVPR_paper.pdf)]
    * Title: GeoF: Geodesic Forests for Learning Coupled Predictors
    * Year: `2013`
    * Authors: Peter Kontschieder, Pushmeet Kohli, Jamie Shotton, Antonio Criminisi
    * Abstract: Conventional decision forest based methods for image labelling tasks like object segmentation make predictions for each variable (pixel) independently [3, 5, 8]. This prevents them from enforcing dependencies between variables and translates into locally inconsistent pixel labellings. Random field models, instead, encourage spatial consistency of labels at increased computational expense. This paper presents a new and efficient forest based model that achieves spatially consistent semantic image segmentation by encoding variable dependencies directly in the feature space the forests operate on. Such correlations are captured via new long-range, soft connectivity features, computed via generalized geodesic distance transforms. Our model can be thought of as a generalization of the successful Semantic Texton Forest, Auto-Context, and Entangled Forest models. A second contribution is to show the connection between the typical Conditional Random Field (CRF) energy and the forest training objective. This analysis yields a new objective for training decision forests that encourages more accurate structured prediction. Our GeoF model is validated quantitatively on the task of semantic image segmentation, on four challenging and very diverse image datasets. GeoF outperforms both stateof-the-art forest models and the conventional pairwise CRF.
count=4
* 3D Hand Pose Estimation Using Randomized Decision Forest With Segmentation Index Points
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Li_3D_Hand_Pose_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Li_3D_Hand_Pose_ICCV_2015_paper.pdf)]
    * Title: 3D Hand Pose Estimation Using Randomized Decision Forest With Segmentation Index Points
    * Year: `2015`
    * Authors: Peiyi Li, Haibin Ling, Xi Li, Chunyuan Liao
    * Abstract: In this paper, we propose a real-time 3D hand pose estimation algorithm using the randomized decision forest framework. Our algorithm takes a depth image as input and generates a set of skeletal joints as output. Previous decision forest-based methods often give labels to all points in a point cloud at a very early stage and vote for the joint locations. By contrast, our algorithm only tracks a set of more flexible virtual landmark points, named segmentation index points (SIPs), before reaching the final decision at a leaf node. Roughly speaking, a SIP represents the centroid of a subset of skeletal joints, which are to be located at the leaves of the branch expanded from the SIP. Inspired by recent latent regression forest-based hand pose estimation framework (Tang et al. 2014), we integrate SIP into the framework with several important improvements: First, we devise a new forest growing strategy, whose decision is made using a randomized feature guided by SIPs. Second, we speed-up the training procedure since only SIPs, not the skeletal joints, are estimated at non-leaf nodes. Third, the experimental results on public benchmark datasets show clearly the advantage of the proposed algorithm over previous state-of-the-art methods, and our algorithm runs at 55.5 fps on a normal CPU without parallelism.
count=4
* Alternating Regression Forests for Object Detection and Pose Estimation
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Schulter_Alternating_Regression_Forests_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Schulter_Alternating_Regression_Forests_2013_ICCV_paper.pdf)]
    * Title: Alternating Regression Forests for Object Detection and Pose Estimation
    * Year: `2013`
    * Authors: Samuel Schulter, Christian Leistner, Paul Wohlhart, Peter M. Roth, Horst Bischof
    * Abstract: We present Alternating Regression Forests (ARFs), a novel regression algorithm that learns a Random Forest by optimizing a global loss function over all trees. This interrelates the information of single trees during the training phase and results in more accurate predictions. ARFs can minimize any differentiable regression loss without sacrificing the appealing properties of Random Forests, like low computational complexity during both, training and testing. Inspired by recent developments for classification [19], we derive a new algorithm capable of dealing with different regression loss functions, discuss its properties and investigate the relations to other methods like Boosted Trees. We evaluate ARFs on standard machine learning benchmarks, where we observe better generalization power compared to both standard Random Forests and Boosted Trees. Moreover, we apply the proposed regressor to two computer vision applications: object detection and head pose estimation from depth images. ARFs outperform the Random Forest baselines in both tasks, illustrating the importance of optimizing a common loss function for all trees.
count=4
* On the Exploration of Local Significant Differences For Two-Sample Test
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/10fc83943b4540a9524af6fc67a23fef-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/10fc83943b4540a9524af6fc67a23fef-Paper-Conference.pdf)]
    * Title: On the Exploration of Local Significant Differences For Two-Sample Test
    * Year: `2023`
    * Authors: Zhijian Zhou, Jie Ni, Jia-He Yao, Wei Gao
    * Abstract: Recent years have witnessed increasing attentions on two-sample test with diverse real applications, while this work takes one more step on the exploration of local significant differences for two-sample test. We propose the ME$_\text{MaBiD}$, an effective test for two-sample testing, and the basic idea is to exploit local information by multiple Mahalanobis kernels and introduce bi-directional hypothesis for testing. On the exploration of local significant differences, we first partition the embedding space into several rectangle regions via a new splitting criterion, which is relevant to test power and data correlation. We then explore local significant differences based on our bi-directional masked $p$-value together with the ME$_\text{MaBiD}$ test. Theoretically, we present the asymptotic distribution and lower bounds of test power for our ME$_\text{MaBiD}$ test, and control the familywise error rate on the exploration of local significant differences. We finally conduct extensive experiments to validate the effectiveness of our proposed methods on two-sample test and the exploration of local significant differences.
count=4
* Trade-off Between Efficiency and Consistency for Removal-based Explanations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/51484744337f4bf5fea0e4dd92ddab0b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/51484744337f4bf5fea0e4dd92ddab0b-Paper-Conference.pdf)]
    * Title: Trade-off Between Efficiency and Consistency for Removal-based Explanations
    * Year: `2023`
    * Authors: Yifan Zhang, Haowei He, Zhiquan Tan, Yang Yuan
    * Abstract: In the current landscape of explanation methodologies, most predominant approaches, such as SHAP and LIME, employ removal-based techniques to evaluate the impact of individual features by simulating various scenarios with specific features omitted. Nonetheless, these methods primarily emphasize efficiency in the original context, often resulting in general inconsistencies. In this paper, we demonstrate that such inconsistency is an inherent aspect of these approaches by establishing the Impossible Trinity Theorem, which posits that interpretability, efficiency, and consistency cannot hold simultaneously. Recognizing that the attainment of an ideal explanation remains elusive, we propose the utilization of interpretation error as a metric to gauge inefficiencies and inconsistencies. To this end, we present two novel algorithms founded on the standard polynomial basis, aimed at minimizing interpretation error. Our empirical findings indicate that the proposed methods achieve a substantial reduction in interpretation error, up to 31.8 times lower when compared to alternative techniques.
count=4
* Exploring and Interacting with the Set of Good Sparse Generalized Additive Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/b1719f44953c2e0754a016ab267fe4e7-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/b1719f44953c2e0754a016ab267fe4e7-Paper-Conference.pdf)]
    * Title: Exploring and Interacting with the Set of Good Sparse Generalized Additive Models
    * Year: `2023`
    * Authors: Chudi Zhong, Zhi Chen, Jiachang Liu, Margo Seltzer, Cynthia Rudin
    * Abstract: In real applications, interaction between machine learning models and domain experts is critical; however, the classical machine learning paradigm that usually produces only a single model does not facilitate such interaction. Approximating and exploring the Rashomon set, i.e., the set of all near-optimal models, addresses this practical challenge by providing the user with a searchable space containing a diverse set of models from which domain experts can choose. We present algorithms to efficiently and accurately approximate the Rashomon set of sparse, generalized additive models with ellipsoids for fixed support sets and use these ellipsoids to approximate Rashomon sets for many different support sets. The approximated Rashomon set serves as a cornerstone to solve practical challenges such as (1) studying the variable importance for the model class; (2) finding models under user-specified constraints (monotonicity, direct editing); and (3) investigating sudden changes in the shape functions. Experiments demonstrate the fidelity of the approximated Rashomon set and its effectiveness in solving practical challenges.
count=4
* When Does Optimizing a Proper Loss Yield Calibration?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/e4165c96702bac5f4962b70f3cf2f136-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/e4165c96702bac5f4962b70f3cf2f136-Paper-Conference.pdf)]
    * Title: When Does Optimizing a Proper Loss Yield Calibration?
    * Year: `2023`
    * Authors: Jaroslaw Blasiok, Parikshit Gopalan, Lunjia Hu, Preetum Nakkiran
    * Abstract: Optimizing proper loss functions is popularly believed to yield predictors with good calibration properties; the intuition being that for such losses, the global optimum is to predict the ground-truth probabilities, which is indeed calibrated. However, typical machine learning models are trained to approximately minimize loss over restricted families of predictors, that are unlikely to contain the ground truth. Under what circumstances does optimizing proper loss over a restricted family yield calibrated models? What precise calibration guarantees does it give? In this work, we provide a rigorous answer to these questions. We replace the global optimality with a local optimality condition stipulating that the (proper) loss of the predictor cannot be reduced much by post-processing its predictions with a certain family of Lipschitz functions. We show that any predictor with this local optimality satisfies smooth calibration as defined in [Kakade and Foster, 2008, Błasiok et al., 2023]. Local optimality is plausibly satisfied by well-trained DNNs, which suggests an explanation for why they are calibrated from proper loss minimization alone. Finally, we show that the connection between local optimality and calibration error goes both ways: nearly calibrated predictors are also nearly locally optimal.
count=4
* GLOBEM Dataset: Multi-Year Datasets for Longitudinal Human Behavior Modeling Generalization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/9c7e8a0821dfcb58a9a83cbd37cc8131-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/9c7e8a0821dfcb58a9a83cbd37cc8131-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: GLOBEM Dataset: Multi-Year Datasets for Longitudinal Human Behavior Modeling Generalization
    * Year: `2022`
    * Authors: Xuhai Xu, Han Zhang, Yasaman Sefidgar, Yiyi Ren, Xin Liu, Woosuk Seo, Jennifer Brown, Kevin Kuehn, Mike Merrill, Paula Nurius, Shwetak Patel, Tim Althoff, Margaret Morris, Eve Riskin, Jennifer Mankoff, Anind Dey
    * Abstract: Recent research has demonstrated the capability of behavior signals captured by smartphones and wearables for longitudinal behavior modeling. However, there is a lack of a comprehensive public dataset that serves as an open testbed for fair comparison among algorithms. Moreover, prior studies mainly evaluate algorithms using data from a single population within a short period, without measuring the cross-dataset generalizability of these algorithms. We present the first multi-year passive sensing datasets, containing over 700 user-years and 497 unique users’ data collected from mobile and wearable sensors, together with a wide range of well-being metrics. Our datasets can support multiple cross-dataset evaluations of behavior modeling algorithms’ generalizability across different users and years. As a starting point, we provide the benchmark results of 18 algorithms on the task of depression detection. Our results indicate that both prior depression detection algorithms and domain generalization techniques show potential but need further research to achieve adequate cross-dataset generalizability. We envision our multi-year datasets can support the ML community in developing generalizable longitudinal behavior modeling algorithms.
count=4
* Tsetlin Machine for Solving Contextual Bandit Problems
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/c2d550cf3b2e177deb2d1720fb1e2710-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/c2d550cf3b2e177deb2d1720fb1e2710-Paper-Conference.pdf)]
    * Title: Tsetlin Machine for Solving Contextual Bandit Problems
    * Year: `2022`
    * Authors: Raihan Seraj, Jivitesh Sharma, Ole-Christoffer Granmo
    * Abstract: This paper introduces an interpretable contextual bandit algorithm using Tsetlin Machines, which solves complex pattern recognition tasks using propositional (Boolean) logic. The proposed bandit learning algorithm relies on straightforward bit manipulation, thus simplifying computation and interpretation. We then present a mechanism for performing Thompson sampling with Tsetlin Machine, given its non-parametric nature. Our empirical analysis shows that Tsetlin Machine as a base contextual bandit learner outperforms other popular base learners on eight out of nine datasets. We further analyze the interpretability of our learner, investigating how arms are selected based on propositional expressions that model the context.
count=4
* ADBench: Anomaly Detection Benchmark
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/cf93972b116ca5268827d575f2cc226b-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/cf93972b116ca5268827d575f2cc226b-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: ADBench: Anomaly Detection Benchmark
    * Year: `2022`
    * Authors: Songqiao Han, Xiyang Hu, Hailiang Huang, Minqi Jiang, Yue Zhao
    * Abstract: Given a long list of anomaly detection algorithms developed in the last few decades, how do they perform with regard to (i) varying levels of supervision, (ii) different types of anomalies, and (iii) noisy and corrupted data? In this work, we answer these key questions by conducting (to our best knowledge) the most comprehensive anomaly detection benchmark with 30 algorithms on 57 benchmark datasets, named ADBench. Our extensive experiments (98,436 in total) identify meaningful insights into the role of supervision and anomaly types, and unlock future directions for researchers in algorithm selection and design. With ADBench, researchers can easily conduct comprehensive and fair evaluations for newly proposed methods on the datasets (including our contributed ones from natural language and computer vision domains) against the existing baselines. To foster accessibility and reproducibility, we fully open-source ADBench and the corresponding results.
count=4
* Finding Regions of Heterogeneity in Decision-Making via Expected Conditional Covariance
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/81930c54e08b6d26d9638dd2e4656dc1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/81930c54e08b6d26d9638dd2e4656dc1-Paper.pdf)]
    * Title: Finding Regions of Heterogeneity in Decision-Making via Expected Conditional Covariance
    * Year: `2021`
    * Authors: Justin Lim, Christina X Ji, Michael Oberst, Saul Blecker, Leora Horwitz, David Sontag
    * Abstract: Individuals often make different decisions when faced with the same context, due to personal preferences and background. For instance, judges may vary in their leniency towards certain drug-related offenses, and doctors may vary in their preference for how to start treatment for certain types of patients. With these examples in mind, we present an algorithm for identifying types of contexts (e.g., types of cases or patients) with high inter-decision-maker disagreement. We formalize this as a causal inference problem, seeking a region where the assignment of decision-maker has a large causal effect on the decision. Our algorithm finds such a region by maximizing an empirical objective, and we give a generalization bound for its performance. In a semi-synthetic experiment, we show that our algorithm recovers the correct region of heterogeneity accurately compared to baselines. Finally, we apply our algorithm to real-world healthcare datasets, recovering variation that aligns with existing clinical knowledge.
count=4
* Post-Contextual-Bandit Inference
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/eff3058117fd4cf4d4c3af12e273a40f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/eff3058117fd4cf4d4c3af12e273a40f-Paper.pdf)]
    * Title: Post-Contextual-Bandit Inference
    * Year: `2021`
    * Authors: Aurelien Bibaut, Maria Dimakopoulou, Nathan Kallus, Antoine Chambaz, Mark van der Laan
    * Abstract: Contextual bandit algorithms are increasingly replacing non-adaptive A/B tests in e-commerce, healthcare, and policymaking because they can both improve outcomes for study participants and increase the chance of identifying good or even best policies. To support credible inference on novel interventions at the end of the study, nonetheless, we still want to construct valid confidence intervals on average treatment effects, subgroup effects, or value of new policies. The adaptive nature of the data collected by contextual bandit algorithms, however, makes this difficult: standard estimators are no longer asymptotically normally distributed and classic confidence intervals fail to provide correct coverage. While this has been addressed in non-contextual settings by using stabilized estimators, variance stabilized estimators in the contextual setting pose unique challenges that we tackle for the first time in this paper. We propose the Contextual Adaptive Doubly Robust (CADR) estimator, a novel estimator for policy value that is asymptotically normal under contextual adaptive data collection. The main technical challenge in constructing CADR is designing adaptive and consistent conditional standard deviation estimators for stabilization. Extensive numerical experiments using 57 OpenML datasets demonstrate that confidence intervals based on CADR uniquely provide correct coverage.
count=4
* Finding the Homology of Decision Boundaries with Active Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/5f14615696649541a025d3d0f8e0447f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/5f14615696649541a025d3d0f8e0447f-Paper.pdf)]
    * Title: Finding the Homology of Decision Boundaries with Active Learning
    * Year: `2020`
    * Authors: Weizhi Li, Gautam Dasarathy, Karthikeyan Natesan Ramamurthy, Visar Berisha
    * Abstract: Accurately and efficiently characterizing the decision boundary of classifiers is important for problems related to model selection and meta-learning. Inspired by topological data analysis, the characterization of decision boundaries using their homology has recently emerged as a general and powerful tool. In this paper, we propose an active learning algorithm to recover the homology of decision boundaries. Our algorithm sequentially and adaptively selects which samples it requires the labels of. We theoretically analyze the proposed framework and show that the query complexity of our active learning algorithm depends naturally on the intrinsic complexity of the underlying manifold. We demonstrate the effectiveness of our framework in selecting best-performing machine learning models for datasets just using their respective homological summaries. Experiments on several standard datasets show the sample complexity improvement in recovering the homology and demonstrate the practical utility of the framework for model selection.
count=4
* Deep active inference agents using Monte-Carlo methods
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/865dfbde8a344b44095495f3591f7407-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/865dfbde8a344b44095495f3591f7407-Paper.pdf)]
    * Title: Deep active inference agents using Monte-Carlo methods
    * Year: `2020`
    * Authors: Zafeirios Fountas, Noor Sajid, Pedro Mediano, Karl Friston
    * Abstract: Active inference is a Bayesian framework for understanding biological intelligence. The underlying theory brings together perception and action under one single imperative: minimizing free energy. However, despite its theoretical utility in explaining intelligence, computational implementations have been restricted to low-dimensional and idealized situations. In this paper, we present a neural architecture for building deep active inference agents operating in complex, continuous state-spaces using multiple forms of Monte-Carlo (MC) sampling. For this, we introduce a number of techniques, novel to active inference. These include: i) selecting free-energy-optimal policies via MC tree search, ii) approximating this optimal policy distribution via a feed-forward `habitual' network, iii) predicting future parameter belief updates using MC dropouts and, finally, iv) optimizing state transition precision (a high-end form of attention). Our approach enables agents to learn environmental dynamics efficiently, while maintaining task performance, in relation to reward-based counterparts. We illustrate this in a new toy environment, based on the dSprites data-set, and demonstrate that active inference agents automatically create disentangled representations that are apt for modeling state transitions. In a more complex Animal-AI environment, our agents (using the same neural architecture) are able to simulate future state transitions and actions (i.e., plan), to evince reward-directed navigation - despite temporary suspension of visual input. These results show that deep active inference - equipped with MC methods - provides a flexible framework to develop biologically-inspired intelligent agents, with applications in both machine learning and cognitive science.
count=4
* Random Tessellation Forests
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/043c2ec6c6390dd0ac5519190a57c88c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/043c2ec6c6390dd0ac5519190a57c88c-Paper.pdf)]
    * Title: Random Tessellation Forests
    * Year: `2019`
    * Authors: Shufei Ge, Shijia Wang, Yee Whye Teh, Liangliang Wang, Lloyd Elliott
    * Abstract: Space partitioning methods such as random forests and the Mondrian process are powerful machine learning methods for multi-dimensional and relational data, and are based on recursively cutting a domain. The flexibility of these methods is often limited by the requirement that the cuts be axis aligned. The Ostomachion process and the self-consistent binary space partitioning-tree process were recently introduced as generalizations of the Mondrian process for space partitioning with non-axis aligned cuts in the plane. Motivated by the need for a multi-dimensional partitioning tree with non-axis aligned cuts, we propose the Random Tessellation Process, a framework that includes the Mondrian process as a special case. We derive a sequential Monte Carlo algorithm for inference, and provide random forest methods. Our methods are self-consistent and can relax axis-aligned constraints, allowing complex inter-dimensional dependence to be captured. We present a simulation study and analyze gene expression data of brain tissue, showing improved accuracies over other methods.
count=4
* SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/044a23cadb567653eb51d4eb40acaa88-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/044a23cadb567653eb51d4eb40acaa88-Paper.pdf)]
    * Title: SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers
    * Year: `2019`
    * Authors: Igor Fedorov, Ryan P. Adams, Matthew Mattina, Paul Whatmough
    * Abstract: The vast majority of processors in the world are actually microcontroller units (MCUs), which find widespread use performing simple control tasks in applications ranging from automobiles to medical devices and office equipment. The Internet of Things (IoT) promises to inject machine learning into many of these every-day objects via tiny, cheap MCUs. However, these resource-impoverished hardware platforms severely limit the complexity of machine learning models that can be deployed. For example, although convolutional neural networks (CNNs) achieve state-of-the-art results on many visual recognition tasks, CNN inference on MCUs is challenging due to severe memory limitations. To circumvent the memory challenge associated with CNNs, various alternatives have been proposed that do fit within the memory budget of an MCU, albeit at the cost of prediction accuracy. This paper challenges the idea that CNNs are not suitable for deployment on MCUs. We demonstrate that it is possible to automatically design CNNs which generalize well, while also being small enough to fit onto memory-limited MCUs. Our Sparse Architecture Search method combines neural architecture search with pruning in a single, unified approach, which learns superior models on four popular IoT datasets. The CNNs we find are more accurate and up to 7.4× smaller than previous approaches, while meeting the strict MCU working memory constraint.
count=4
* Privacy-Preserving Classification of Personal Text Messages with Secure Multi-Party Computation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/a501bebf79d570651ff601788ea9d16d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/a501bebf79d570651ff601788ea9d16d-Paper.pdf)]
    * Title: Privacy-Preserving Classification of Personal Text Messages with Secure Multi-Party Computation
    * Year: `2019`
    * Authors: Devin Reich, Ariel Todoki, Rafael Dowsley, Martine De Cock, anderson nascimento
    * Abstract: Classification of personal text messages has many useful applications in surveillance, e-commerce, and mental health care, to name a few. Giving applications access to personal texts can easily lead to (un)intentional privacy violations. We propose the first privacy-preserving solution for text classification that is provably secure. Our method, which is based on Secure Multiparty Computation (SMC), encompasses both feature extraction from texts, and subsequent classification with logistic regression and tree ensembles. We prove that when using our secure text classification method, the application does not learn anything about the text, and the author of the text does not learn anything about the text classification model used by the application beyond what is given by the classification result itself. We perform end-to-end experiments with an application for detecting hate speech against women and immigrants, demonstrating excellent runtime results without loss of accuracy.
count=4
* Making AI Forget You: Data Deletion in Machine Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/cb79f8fa58b91d3af6c9c991f63962d3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/cb79f8fa58b91d3af6c9c991f63962d3-Paper.pdf)]
    * Title: Making AI Forget You: Data Deletion in Machine Learning
    * Year: `2019`
    * Authors: Antonio Ginart, Melody Guan, Gregory Valiant, James Y. Zou
    * Abstract: Intense recent discussions have focused on how to provide individuals with control over when their data can and cannot be used --- the EU’s Right To Be Forgotten regulation is an example of this effort. In this paper we initiate a framework studying what to do when it is no longer permissible to deploy models derivative from specific user data. In particular, we formulate the problem of efficiently deleting individual data points from trained machine learning models. For many standard ML models, the only way to completely remove an individual's data is to retrain the whole model from scratch on the remaining data, which is often not computationally practical. We investigate algorithmic principles that enable efficient data deletion in ML. For the specific setting of $k$-means clustering, we propose two provably deletion efficient algorithms which achieve an average of over $100\times$ improvement in deletion efficiency across 6 datasets, while producing clusters of comparable statistical quality to a canonical $k$-means++ baseline.
count=4
* PAC-Bayes Tree: weighted subtrees with guarantees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/1819020b02e926785cf3be594d957696-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/1819020b02e926785cf3be594d957696-Paper.pdf)]
    * Title: PAC-Bayes Tree: weighted subtrees with guarantees
    * Year: `2018`
    * Authors: Tin D. Nguyen, Samory Kpotufe
    * Abstract: We present a weighted-majority classification approach over subtrees of a fixed tree, which provably achieves excess-risk of the same order as the best tree-pruning. Furthermore, the computational efficiency of pruning is maintained at both training and testing time despite having to aggregate over an exponential number of subtrees. We believe this is the first subtree aggregation approach with such guarantees.
count=4
* Learning to Solve SMT Formulas
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/68331ff0427b551b68e911eebe35233b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/68331ff0427b551b68e911eebe35233b-Paper.pdf)]
    * Title: Learning to Solve SMT Formulas
    * Year: `2018`
    * Authors: Mislav Balunovic, Pavol Bielik, Martin Vechev
    * Abstract: We present a new approach for learning to solve SMT formulas. We phrase the challenge of solving SMT formulas as a tree search problem where at each step a transformation is applied to the input formula until the formula is solved. Our approach works in two phases: first, given a dataset of unsolved formulas we learn a policy that for each formula selects a suitable transformation to apply at each step in order to solve the formula, and second, we synthesize a strategy in the form of a loop-free program with branches. This strategy is an interpretable representation of the policy decisions and is used to guide the SMT solver to decide formulas more efficiently, without requiring any modification to the solver itself and without needing to evaluate the learned policy at inference time. We show that our approach is effective in practice - it solves 17% more formulas over a range of benchmarks and achieves up to 100x runtime improvement over a state-of-the-art SMT solver.
count=4
* SplineNets: Continuous Neural Decision Graphs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/9246444d94f081e3549803b928260f56-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/9246444d94f081e3549803b928260f56-Paper.pdf)]
    * Title: SplineNets: Continuous Neural Decision Graphs
    * Year: `2018`
    * Authors: Cem Keskin, Shahram Izadi
    * Abstract: We present SplineNets, a practical and novel approach for using conditioning in convolutional neural networks (CNNs). SplineNets are continuous generalizations of neural decision graphs, and they can dramatically reduce runtime complexity and computation costs of CNNs, while maintaining or even increasing accuracy. Functions of SplineNets are both dynamic (i.e., conditioned on the input) and hierarchical (i.e.,conditioned on the computational path). SplineNets employ a unified loss function with a desired level of smoothness over both the network and decision parameters, while allowing for sparse activation of a subset of nodes for individual samples. In particular, we embed infinitely many function weights (e.g. filters) on smooth, low dimensional manifolds parameterized by compact B-splines, which are indexed by a position parameter. Instead of sampling from a categorical distribution to pick a branch, samples choose a continuous position to pick a function weight. We further show that by maximizing the mutual information between spline positions and class labels, the network can be optimally utilized and specialized for classification tasks. Experiments show that our approach can significantly increase the accuracy of ResNets with negligible cost in speed, matching the precision of a 110 level ResNet with a 32 level SplineNet.
count=4
* Model Agnostic Supervised Local Explanations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/b495ce63ede0f4efc9eec62cb947c162-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/b495ce63ede0f4efc9eec62cb947c162-Paper.pdf)]
    * Title: Model Agnostic Supervised Local Explanations
    * Year: `2018`
    * Authors: Gregory Plumb, Denali Molitor, Ameet S. Talwalkar
    * Abstract: Model interpretability is an increasingly important component of practical machine learning. Some of the most common forms of interpretability systems are example-based, local, and global explanations. One of the main challenges in interpretability is designing explanation systems that can capture aspects of each of these explanation types, in order to develop a more thorough understanding of the model. We address this challenge in a novel model called MAPLE that uses local linear modeling techniques along with a dual interpretation of random forests (both as a supervised neighborhood approach and as a feature selection method). MAPLE has two fundamental advantages over existing interpretability systems. First, while it is effective as a black-box explanation system, MAPLE itself is a highly accurate predictive model that provides faithful self explanations, and thus sidesteps the typical accuracy-interpretability trade-off. Specifically, we demonstrate, on several UCI datasets, that MAPLE is at least as accurate as random forests and that it produces more faithful local explanations than LIME, a popular interpretability system. Second, MAPLE provides both example-based and local explanations and can detect global patterns, which allows it to diagnose limitations in its local explanations.
count=4
* Variable Importance Using Decision Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/5737c6ec2e0716f3d8a7a5c4e0de0d9a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/5737c6ec2e0716f3d8a7a5c4e0de0d9a-Paper.pdf)]
    * Title: Variable Importance Using Decision Trees
    * Year: `2017`
    * Authors: Jalil Kazemitabar, Arash Amini, Adam Bloniarz, Ameet S. Talwalkar
    * Abstract: Decision trees and random forests are well established models that not only offer good predictive performance, but also provide rich feature importance information. While practitioners often employ variable importance methods that rely on this impurity-based information, these methods remain poorly characterized from a theoretical perspective. We provide novel insights into the performance of these methods by deriving finite sample performance guarantees in a high-dimensional setting under various modeling assumptions. We further demonstrate the effectiveness of these impurity-based methods via an extensive set of simulations.
count=4
* Ranking Data with Continuous Labels through Oriented Recursive Partitions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/97416ac0f58056947e2eb5d5d253d4f2-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/97416ac0f58056947e2eb5d5d253d4f2-Paper.pdf)]
    * Title: Ranking Data with Continuous Labels through Oriented Recursive Partitions
    * Year: `2017`
    * Authors: Stéphan Clémençon, Mastane Achab
    * Abstract: We formulate a supervised learning problem, referred to as continuous ranking, where a continuous real-valued label Y is assigned to an observable r.v. X taking its values in a feature space X and the goal is to order all possible observations x in X by means of a scoring function s : X → R so that s(X) and Y tend to increase or decrease together with highest probability. This problem generalizes bi/multi-partite ranking to a certain extent and the task of finding optimal scoring functions s(x) can be naturally cast as optimization of a dedicated functional cri- terion, called the IROC curve here, or as maximization of the Kendall τ related to the pair (s(X), Y ). From the theoretical side, we describe the optimal elements of this problem and provide statistical guarantees for empirical Kendall τ maximiza- tion under appropriate conditions for the class of scoring function candidates. We also propose a recursive statistical learning algorithm tailored to empirical IROC curve optimization and producing a piecewise constant scoring function that is fully described by an oriented binary tree. Preliminary numerical experiments highlight the difference in nature between regression and continuous ranking and provide strong empirical evidence of the performance of empirical optimizers of the criteria proposed.
count=4
* Efficient and Robust Automated Machine Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/11d0e6287202fced83f79975ec59a3a6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf)]
    * Title: Efficient and Robust Automated Machine Learning
    * Year: `2015`
    * Authors: Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum, Frank Hutter
    * Abstract: The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods. In this work we introduce a robust new AutoML system based on scikit-learn (using 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub auto-sklearn, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the first phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of auto-sklearn.
count=4
* An Active Learning Framework using Sparse-Graph Codes for Sparse Polynomials and Graph Sketching
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/84438b7aae55a0638073ef798e50b4ef-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/84438b7aae55a0638073ef798e50b4ef-Paper.pdf)]
    * Title: An Active Learning Framework using Sparse-Graph Codes for Sparse Polynomials and Graph Sketching
    * Year: `2015`
    * Authors: Xiao Li, Kannan Ramchandran
    * Abstract: Let $f: \{-1,1\}^n \rightarrow \mathbb{R}$ be an $n$-variate polynomial consisting of $2^n$ monomials, in which only $s\ll 2^n$ coefficients are non-zero. The goal is to learn the polynomial by querying the values of $f$. We introduce an active learning framework that is associated with a low query cost and computational runtime. The significant savings are enabled by leveraging sampling strategies based on modern coding theory, specifically, the design and analysis of {\it sparse-graph codes}, such as Low-Density-Parity-Check (LDPC) codes, which represent the state-of-the-art of modern packet communications. More significantly, we show how this design perspective leads to exciting, and to the best of our knowledge, largely unexplored intellectual connections between learning and coding. The key is to relax the worst-case assumption with an ensemble-average setting, where the polynomial is assumed to be drawn uniformly at random from the ensemble of all polynomials (of a given size $n$ and sparsity $s$). Our framework succeeds with high probability with respect to the polynomial ensemble with sparsity up to $s={O}(2^{\delta n})$ for any $\delta\in(0,1)$, where $f$ is exactly learned using ${O}(ns)$ queries in time ${O}(n s \log s)$, even if the queries are perturbed by Gaussian noise. We further apply the proposed framework to graph sketching, which is the problem of inferring sparse graphs by querying graph cuts. By writing the cut function as a polynomial and exploiting the graph structure, we propose a sketching algorithm to learn the an arbitrary $n$-node unknown graph using only few cut queries, which scales {\it almost linearly} in the number of edges and {\it sub-linearly} in the graph size $n$. Experiments on real datasets show significant reductions in the runtime and query complexity compared with competitive schemes.
count=3
* HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Guan_HallusionBench_An_Advanced_Diagnostic_Suite_for_Entangled_Language_Hallucination_and_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Guan_HallusionBench_An_Advanced_Diagnostic_Suite_for_Entangled_Language_Hallucination_and_CVPR_2024_paper.pdf)]
    * Title: HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models
    * Year: `2024`
    * Authors: Tianrui Guan, Fuxiao Liu, Xiyang Wu, Ruiqi Xian, Zongxia Li, Xiaoyu Liu, Xijun Wang, Lichang Chen, Furong Huang, Yaser Yacoob, Dinesh Manocha, Tianyi Zhou
    * Abstract: We introduce "HallusionBench" a comprehensive benchmark designed for the evaluation of image-context reasoning. This benchmark presents significant challenges to advanced large visual-language models (LVLMs) such as GPT-4V(ision) Gemini Pro Vision Claude 3 and LLaVA-1.5 by emphasizing nuanced understanding and interpretation of visual data. The benchmark comprises 346 images paired with 1129 questions all meticulously crafted by human experts. We introduce a novel structure for these visual questions designed to establish control groups. This structure enables us to conduct a quantitative analysis of the models' response tendencies logical consistency and various failure modes. In our evaluation on HallusionBench we benchmarked 15 different models highlighting a 31.42% question-pair accuracy achieved by the state-of-the-art GPT-4V. Notably all other evaluated models achieve accuracy below 16%. Moreover our analysis not only highlights the observed failure modes including language hallucination and visual illusion but also deepens an under standing of these pitfalls. Our comprehensive case studies within HallusionBench shed light on the challenges of hallucination and illusion in LVLMs. Based on these insights we suggest potential pathways for their future improvement. The benchmark and codebase can be accessed at https://github.com/tianyilab/HallusionBench.
count=3
* MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Wang_MCPNet_An_Interpretable_Classifier_via_Multi-Level_Concept_Prototypes_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_MCPNet_An_Interpretable_Classifier_via_Multi-Level_Concept_Prototypes_CVPR_2024_paper.pdf)]
    * Title: MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes
    * Year: `2024`
    * Authors: Bor-Shiun Wang, Chien-Yi Wang, Wei-Chen Chiu
    * Abstract: Recent advancements in post-hoc and inherently interpretable methods have markedly enhanced the explanations of black box classifier models. These methods operate either through post-analysis or by integrating concept learning during model training. Although being effective in bridging the semantic gap between a model's latent space and human interpretation these explanation methods only partially reveal the model's decision-making process. The outcome is typically limited to high-level semantics derived from the last feature map. We argue that the explanations lacking insights into the decision processes at low and mid-level features are neither fully faithful nor useful. Addressing this gap we introduce the Multi-Level Concept Prototypes Classifier (MCPNet) an inherently interpretable model. MCPNet autonomously learns meaningful concept prototypes across multiple feature map levels using Centered Kernel Alignment (CKA) loss and an energy-based weighted PCA mechanism and it does so without reliance on predefined concept labels. Further we propose a novel classifier paradigm that learns and aligns multi-level concept prototype distributions for classification purposes via Class-aware Concept Distribution (CCD) loss. Our experiments reveal that our proposed MCPNet while being adaptable to various model architectures offers comprehensive multi-level explanations while maintaining classification accuracy. Additionally its concept distribution-based classification approach shows improved generalization capabilities in few-shot classification scenarios.
count=3
* Interactive Disentanglement: Learning Concepts by Interacting With Their Prototype Representations
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Stammer_Interactive_Disentanglement_Learning_Concepts_by_Interacting_With_Their_Prototype_Representations_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Stammer_Interactive_Disentanglement_Learning_Concepts_by_Interacting_With_Their_Prototype_Representations_CVPR_2022_paper.pdf)]
    * Title: Interactive Disentanglement: Learning Concepts by Interacting With Their Prototype Representations
    * Year: `2022`
    * Authors: Wolfgang Stammer, Marius Memmel, Patrick Schramowski, Kristian Kersting
    * Abstract: Learning visual concepts from raw images without strong supervision is a challenging task. In this work, we show the advantages of prototype representations for understanding and revising the latent space of neural concept learners. For this purpose, we introduce interactive Concept Swapping Networks (iCSNs), a novel framework for learning concept-grounded representations via weak supervision and implicit prototype representations. iCSNs learn to bind conceptual information to specific prototype slots by swapping the latent representations of paired images. This semantically grounded and discrete latent space facilitates human understanding and human-machine interaction. We support this claim by conducting experiments on our novel data set "Elementary Concept Reasoning" (ECR), focusing on visual concepts shared by geometric objects.
count=3
* Assessing Personally Perceived Image Quality via Image Features and Collaborative Filtering
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Korhonen_Assessing_Personally_Perceived_Image_Quality_via_Image_Features_and_Collaborative_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Korhonen_Assessing_Personally_Perceived_Image_Quality_via_Image_Features_and_Collaborative_CVPR_2019_paper.pdf)]
    * Title: Assessing Personally Perceived Image Quality via Image Features and Collaborative Filtering
    * Year: `2019`
    * Authors: Jari Korhonen
    * Abstract: During the past few years, different methods for optimizing the camera settings and post-processing techniques to improve the subjective quality of consumer photos have been studied extensively. However, most of the research in the prior art has focused on finding the optimal method for an average user. Since there is large deviation in personal opinions and aesthetic standards, the next challenge is to find the settings and post-processing techniques that fit to the individual users' personal taste. In this study, we aim to predict the personally perceived image quality by combining classical image feature analysis and collaboration filtering approach known from the recommendation systems. The experimental results for the proposed method show promising results. As a practical application, our work can be used for personalizing the camera settings or post-processing parameters for different users and images.
count=3
* BridgeNet: A Continuity-Aware Probabilistic Network for Age Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Li_BridgeNet_A_Continuity-Aware_Probabilistic_Network_for_Age_Estimation_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_BridgeNet_A_Continuity-Aware_Probabilistic_Network_for_Age_Estimation_CVPR_2019_paper.pdf)]
    * Title: BridgeNet: A Continuity-Aware Probabilistic Network for Age Estimation
    * Year: `2019`
    * Authors: Wanhua Li,  Jiwen Lu,  Jianjiang Feng,  Chunjing Xu,  Jie Zhou,  Qi Tian
    * Abstract: Age estimation is an important yet very challenging problem in computer vision. Existing methods for age estimation usually apply a divide-and-conquer strategy to deal with heterogeneous data caused by the non-stationary aging process. However, the facial aging process is also a continuous process, and the continuity relationship between different components has not been effectively exploited. In this paper, we propose BridgeNet for age estimation, which aims to mine the continuous relation between age labels effectively. The proposed BridgeNet consists of local regressors and gating networks. Local regressors partition the data space into multiple overlapping subspaces to tackle heterogeneous data and gating networks learn continuity aware weights for the results of local regressors by employing the proposed bridge-tree structure, which introduces bridge connections into tree models to enforce the similarity between neighbor nodes. Moreover, these two components of BridgeNet can be jointly learned in an end-to-end way. We show experimental results on the MORPH II, FG-NET and Chalearn LAP 2015 datasets and find that BridgeNet outperforms the state-of-the-art methods.
count=3
* Hashing as Tie-Aware Learning to Rank
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/He_Hashing_as_Tie-Aware_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/He_Hashing_as_Tie-Aware_CVPR_2018_paper.pdf)]
    * Title: Hashing as Tie-Aware Learning to Rank
    * Year: `2018`
    * Authors: Kun He, Fatih Cakir, Sarah Adel Bargal, Stan Sclaroff
    * Abstract: Hashing, or learning binary embeddings of data, is frequently used in nearest neighbor retrieval. In this paper, we develop learning to rank formulations for hashing, aimed at directly optimizing ranking-based evaluation metrics such as Average Precision (AP) and Normalized Discounted Cumulative Gain (NDCG). We first observe that the integer-valued Hamming distance often leads to tied rankings, and propose to use tie-aware versions of AP and NDCG to evaluate hashing for retrieval. Then, to optimize tie-aware ranking metrics, we derive their continuous relaxations, and perform gradient-based optimization with deep neural networks. Our results establish the new state-of-the-art for image retrieval by Hamming ranking in common benchmarks.
count=3
* Material Classification Using Raw Time-Of-Flight Measurements
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Su_Material_Classification_Using_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Su_Material_Classification_Using_CVPR_2016_paper.pdf)]
    * Title: Material Classification Using Raw Time-Of-Flight Measurements
    * Year: `2016`
    * Authors: Shuochen Su, Felix Heide, Robin Swanson, Jonathan Klein, Clara Callenberg, Matthias Hullin, Wolfgang Heidrich
    * Abstract: We propose a material classification method using raw time-of-flight (ToF) measurements. ToF cameras capture the correlation between a reference signal and the temporal response of material to incident illumination. Such measurements encode unique signatures of the material, i.e. the degree of subsurface scattering inside a volume. Subsequently, it offers an orthogonal domain of feature representation compared to conventional spatial and angular reflectance-based approaches. We demonstrate the effectiveness, robustness, and efficiency of our method through experiments and comparisons of real-world materials.
count=3
* SemiContour: A Semi-Supervised Learning Approach for Contour Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Zhang_SemiContour_A_Semi-Supervised_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Zhang_SemiContour_A_Semi-Supervised_CVPR_2016_paper.pdf)]
    * Title: SemiContour: A Semi-Supervised Learning Approach for Contour Detection
    * Year: `2016`
    * Authors: Zizhao Zhang, Fuyong Xing, Xiaoshuang Shi, Lin Yang
    * Abstract: Supervised contour detection methods usually require many labeled training images to obtain satisfactory performance. However, a large set of annotated data might be unavailable or extremely labor intensive. In this paper, we investigate the usage of semi-supervised learning (SSL) to obtain competitive detection accuracy with very limited training data (three labeled images). Specifically, we propose a semi-supervised structured ensemble learning approach for contour detection built on structured random forests (SRF). To allow SRF to be applicable to unlabeled data, we present an effective sparse representation approach to capture inherent structure in image patches by finding a compact and discriminative low-dimensional subspace representation in an unsupervised manner, enabling the incorporation of abundant unlabeled patches with their estimated structured labels to help SRF perform better node splitting. We re-examine the role of sparsity and propose a novel and fast sparse coding algorithm to boost the overall learning efficiency. To the best of our knowledge, this is the first attempt to apply SSL for contour detection. Extensive experiments on the BSDS500 segmentation dataset and the NYU Depth dataset demonstrate the superiority of the proposed method.
count=3
* Oriented Edge Forests for Boundary Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Hallman_Oriented_Edge_Forests_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Hallman_Oriented_Edge_Forests_2015_CVPR_paper.pdf)]
    * Title: Oriented Edge Forests for Boundary Detection
    * Year: `2015`
    * Authors: Sam Hallman, Charless C. Fowlkes
    * Abstract: We present a simple, efficient model for learning boundary detection based on a random forest classifier. Our approach combines (1) efficient clustering of training examples based on a simple partitioning of the space of local edge orientations and (2) scale-dependent calibration of individual tree output probabilities prior to multiscale combination. The resulting model outperforms published results on the challenging BSDS500 boundary detection benchmark. Further, on large datasets our model requires substantially less memory for training and speeds up training time by a factor of 10 over the structured forest model.
count=3
* Graph-Based Simplex Method for Pairwise Energy Minimization With Binary Variables
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Prusa_Graph-Based_Simplex_Method_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Prusa_Graph-Based_Simplex_Method_2015_CVPR_paper.pdf)]
    * Title: Graph-Based Simplex Method for Pairwise Energy Minimization With Binary Variables
    * Year: `2015`
    * Authors: Daniel Prusa
    * Abstract: We show how the simplex algorithm can be tailored to the linear programming relaxation of pairwise energy minimization with binary variables. A special structure formed by basic and nonbasic variables in each stage of the algorithm is identified and utilized to perform the whole iterative process combinatorially over the input energy minimization graph rather than algebraically over the simplex tableau. This leads to a new efficient solver. We demonstrate that for some computer vision instances it performs even better than methods reducing binary energy minimization to finding maximum flow in a network.
count=3
* Global Refinement of Random Forest
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Ren_Global_Refinement_of_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Ren_Global_Refinement_of_2015_CVPR_paper.pdf)]
    * Title: Global Refinement of Random Forest
    * Year: `2015`
    * Authors: Shaoqing Ren, Xudong Cao, Yichen Wei, Jian Sun
    * Abstract: Random forest is well known as one of the best learning methods. In spite of its great success, it also has certain drawbacks: the heuristic learning rule does not effectively minimize the global training loss; the model size is usually too large for many real applications. To address the issues, we propose two techniques, global refinement and global pruning, to improve a pre-trained random forest. The proposed global refinement jointly relearns the leaf nodes of all trees under a global objective function so that the complementary information between multiple trees is well exploited. In this way, the fitting power of the forest is significantly enhanced. The global pruning is developed to reduce the model size as well as the over-fitting risk. The refined model has better performance and smaller storage cost, as verified in extensive experiments.
count=3
* Iterated Second-Order Label Sensitive Pooling for 3D Human Pose Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Ionescu_Iterated_Second-Order_Label_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Ionescu_Iterated_Second-Order_Label_2014_CVPR_paper.pdf)]
    * Title: Iterated Second-Order Label Sensitive Pooling for 3D Human Pose Estimation
    * Year: `2014`
    * Authors: Catalin Ionescu, Joao Carreira, Cristian Sminchisescu
    * Abstract: Recently, the emergence of Kinect systems has demonstrated the benefits of predicting an intermediate body part labeling for 3D human pose estimation, in conjunction with RGB-D imagery. The availability of depth information plays a critical role, so an important question is whether a similar representation can be developed with sufficient robustness in order to estimate 3D pose from RGB images. This paper provides evidence for a positive answer, by leveraging (a) 2D human body part labeling in images, (b) second-order label-sensitive pooling over dynamically computed regions resulting from a hierarchical decomposition of the body, and (c) iterative structured-output modeling to contextualize the process based on 3D pose estimates. For robustness and generalization, we take advantage of a recent large-scale 3D human motion capture dataset, Human3.6M [18] that also has human body part labeling annotations available with images. We provide extensive experimental studies where alternative intermediate representations are compared and report a substantial 33% error reduction over competitive discriminative baselines that regress 3D human pose against global HOG features.
count=3
* Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Bergamo_Leveraging_Structure_from_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Bergamo_Leveraging_Structure_from_2013_CVPR_paper.pdf)]
    * Title: Leveraging Structure from Motion to Learn Discriminative Codebooks for Scalable Landmark Classification
    * Year: `2013`
    * Authors: Alessandro Bergamo, Sudipta N. Sinha, Lorenzo Torresani
    * Abstract: In this paper we propose a new technique for learning a discriminative codebook for local feature descriptors, specifically designed for scalable landmark classification. The key contribution lies in exploiting the knowledge of correspondences within sets of feature descriptors during codebook learning. Feature correspondences are obtained using structure from motion (SfM) computation on Internet photo collections which serve as the training data. Our codebook is defined by a random forest that is trained to map corresponding feature descriptors into identical codes. Unlike prior forest-based codebook learning methods, we utilize fine-grained descriptor labels and address the challenge of training a forest with an extremely large number of labels. Our codebook is used with various existing feature encoding schemes and also a variant we propose for importanceweighted aggregation of local features. We evaluate our approach on a public dataset of 25 landmarks and our new dataset of 620 landmarks (614K images). Our approach significantly outperforms the state of the art in landmark classification. Furthermore, our method is memory efficient and scalable.
count=3
* Ensemble Learning for Confidence Measures in Stereo Vision
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Haeusler_Ensemble_Learning_for_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Haeusler_Ensemble_Learning_for_2013_CVPR_paper.pdf)]
    * Title: Ensemble Learning for Confidence Measures in Stereo Vision
    * Year: `2013`
    * Authors: Ralf Haeusler, Rahul Nair, Daniel Kondermann
    * Abstract: With the aim to improve accuracy of stereo confidence measures, we apply the random decision forest framework to a large set of diverse stereo confidence measures. Learning and testing sets were drawn from the recently introduced KITTI dataset, which currently poses higher challenges to stereo solvers than other benchmarks with ground truth for stereo evaluation. We experiment with semi global matching stereo (SGM) and a census dataterm, which is the best performing realtime capable stereo method known to date. On KITTI images, SGM still produces a significant amount of error. We obtain consistently improved area under curve values of sparsification measures in comparison to best performing single stereo confidence measures where numbers of stereo errors are large. More specifically, our method performs best in all but one out of 194 frames of the KITTI dataset.
count=3
* Five Shades of Grey for Fast and Reliable Camera Pose Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Herout_Five_Shades_of_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Herout_Five_Shades_of_2013_CVPR_paper.pdf)]
    * Title: Five Shades of Grey for Fast and Reliable Camera Pose Estimation
    * Year: `2013`
    * Authors: Adam Herout, Istvan Szentandrasi, Michal Zacharias, Marketa Dubska, Rudolf Kajan
    * Abstract: We introduce here an improved design of the Uniform Marker Fields and an algorithm for their fast and reliable detection. Our concept of the marker field is designed so that it can be detected and recognized for camera pose estimation: in various lighting conditions, under a severe perspective, while heavily occluded, and under a strong motion blur. Our marker field detection harnesses the fact that the edges within the marker field meet at two vanishing points and that the projected planar grid of squares can be defined by a detectable mathematical formalism. The modules of the grid are greyscale and the locations within the marker field are defined by the edges between the modules. The assumption that the marker field is planar allows for a very cheap and reliable camera pose estimation in the captured scene. The detection rates and accuracy are slightly better compared to state-of-the-art marker-based solutions. At the same time, and more importantly, our detector of the marker field is several times faster and the reliable real-time detection can be thus achieved on mobile and low-power devices. We show three targeted applications where the planarity is assured and where the presented marker field design and detection algorithm provide a reliable and extremely fast solution.
count=3
* Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Kappes_Towards_Efficient_and_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Kappes_Towards_Efficient_and_2013_CVPR_paper.pdf)]
    * Title: Towards Efficient and Exact MAP-Inference for Large Scale Discrete Computer Vision Problems via Combinatorial Optimization
    * Year: `2013`
    * Authors: Jorg Hendrik Kappes, Markus Speth, Gerhard Reinelt, Christoph Schnorr
    * Abstract: Discrete graphical models (also known as discrete Markov random fields) are a major conceptual tool to model the structure of optimization problems in computer vision. While in the last decade research has focused on fast approximative methods, algorithms that provide globally optimal solutions have come more into the research focus in the last years. However, large scale computer vision problems seemed to be out of reach for such methods. In this paper we introduce a promising way to bridge this gap based on partial optimality and structural properties of the underlying problem factorization. Combining these preprocessing steps, we are able to solve grids of size 2048 x 2048 in less than 90 seconds. On the hitherto unsolvable Chinese character dataset of Nowozin et al. we obtain provably optimal results in 56% of the instances and achieve competitive runtimes on other recent benchmark problems. While in the present work only generalized Potts models are considered, an extension to general graphical models seems to be feasible.
count=3
* Finding Things: Image Parsing with Regions and Per-Exemplar Detectors
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Tighe_Finding_Things_Image_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Tighe_Finding_Things_Image_2013_CVPR_paper.pdf)]
    * Title: Finding Things: Image Parsing with Regions and Per-Exemplar Detectors
    * Year: `2013`
    * Authors: Joseph Tighe, Svetlana Lazebnik
    * Abstract: This paper presents a system for image parsing, or labeling each pixel in an image with its semantic category, aimed at achieving broad coverage across hundreds of object categories, many of them sparsely sampled. The system combines region-level features with per-exemplar sliding window detectors. Per-exemplar detectors are better suited for our parsing task than traditional bounding box detectors: they perform well on classes with little training data and high intra-class variation, and they allow object masks to be transferred into the test image for pixel-level segmentation. The proposed system achieves state-of-theart accuracy on three challenging datasets, the largest of which contains 45,676 images and 232 labels.
count=3
* Evaluation and Improvement of Interpretability for Self-Explainable Part-Prototype Networks
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.pdf)]
    * Title: Evaluation and Improvement of Interpretability for Self-Explainable Part-Prototype Networks
    * Year: `2023`
    * Authors: Qihan Huang, Mengqi Xue, Wenqi Huang, Haofei Zhang, Jie Song, Yongcheng Jing, Mingli Song
    * Abstract: Part-prototype networks (e.g., ProtoPNet, ProtoTree, and ProtoPool) have attracted broad research interest for their intrinsic interpretability and comparable accuracy to non-interpretable counterparts. However, recent works find that the interpretability from prototypes is fragile, due to the semantic gap between the similarities in the feature space and that in the input space. In this work, we strive to address this challenge by making the first attempt to quantitatively and objectively evaluate the interpretability of the part-prototype networks. Specifically, we propose two evaluation metrics, termed as "consistency score" and "stability score", to evaluate the explanation consistency across images and the explanation robustness against perturbations, respectively, both of which are essential for explanations taken into practice. Furthermore, we propose an elaborated part-prototype network with a shallow-deep feature alignment (SDFA) module and a score aggregation (SA) module to improve the interpretability of prototypes. We conduct systematical evaluation experiments and provide substantial discussions to uncover the interpretability of existing part-prototype networks. Experiments on three benchmarks across nine architectures demonstrate that our model achieves significantly superior performance to the state of the art, in both the accuracy and interpretability. Our code is available at https://github.com/hqhQAQ/EvalProtoPNet.
count=3
* Explainable Person Re-Identification With Attribute-Guided Metric Distillation
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Explainable_Person_Re-Identification_With_Attribute-Guided_Metric_Distillation_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Explainable_Person_Re-Identification_With_Attribute-Guided_Metric_Distillation_ICCV_2021_paper.pdf)]
    * Title: Explainable Person Re-Identification With Attribute-Guided Metric Distillation
    * Year: `2021`
    * Authors: Xiaodong Chen, Xinchen Liu, Wu Liu, Xiao-Ping Zhang, Yongdong Zhang, Tao Mei
    * Abstract: Despite the great progress of person re-identification (ReID) with the adoption of Convolutional Neural Networks, current ReID models are opaque and only outputs a scalar distance between two persons. There are few methods providing users semantically understandable explanations for why two persons are the same one or not. In this paper, we propose a post-hoc method, named Attribute-guided Metric Distillation (AMD), to explain existing ReID models. This is the first method to explore attributes to answer: 1) what and where the attributes make two persons different, and 2) how much each attribute contributes to the difference. In AMD, we design a pluggable interpreter network for target models to generate quantitative contributions of attributes and visualize accurate attention maps of the most discriminative attributes. To achieve this goal, we propose a metric distillation loss by which the interpreter learns to decompose the distance of two persons into components of attributes with knowledge distilled from the target model. Moreover, we propose an attribute prior loss to make the interpreter generate attribute-guided attention maps and to eliminate biases caused by the imbalanced distribution of attributes. This loss can guide the interpreter to focus on the exclusive and discriminative attributes rather than the large-area but common attributes of two persons. Comprehensive experiments show that the interpreter can generate effective and intuitive explanations for varied models and generalize well under cross-domain settings. As a by-product, the accuracy of target models can be further improved with our interpreter.
count=3
* Interpretable Image Recognition by Constructing Transparent Embedding Space
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Interpretable_Image_Recognition_by_Constructing_Transparent_Embedding_Space_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Interpretable_Image_Recognition_by_Constructing_Transparent_Embedding_Space_ICCV_2021_paper.pdf)]
    * Title: Interpretable Image Recognition by Constructing Transparent Embedding Space
    * Year: `2021`
    * Authors: Jiaqi Wang, Huafeng Liu, Xinyue Wang, Liping Jing
    * Abstract: Humans usually explain their reasoning (e.g. classification) by dissecting the image and pointing out the evidence from these parts to the concepts in their minds. Inspired by this cognitive process, several part-level interpretable neural network architectures have been proposed to explain the predictions. However, they suffer from the complex data structure and confusing the effect of the individual part to output category. In this work, an interpretable image recognition deep network is designed by introducing a plug-in transparent embedding space (TesNet) to bridge the high-level input patches (e.g. CNN feature maps) and the output categories. This plug-in embedding space is spanned by transparent basis concepts which are constructed on the Grassmann manifold. These basis concepts are enforced to be category-aware and within-category concepts are orthogonal to each other, which makes sure the embedding space is disentangled. Meanwhile, each basis concept can be traced back to the particular image patches, thus they are transparent and friendly to explain the reasoning process. By comparing with state-of-the-art interpretable methods, TesNet is much more beneficial to classification tasks, esp. providing better interpretability on predictions and improve the final accuracy.
count=3
* Visual Distant Supervision for Scene Graph Generation
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Yao_Visual_Distant_Supervision_for_Scene_Graph_Generation_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Yao_Visual_Distant_Supervision_for_Scene_Graph_Generation_ICCV_2021_paper.pdf)]
    * Title: Visual Distant Supervision for Scene Graph Generation
    * Year: `2021`
    * Authors: Yuan Yao, Ao Zhang, Xu Han, Mengdi Li, Cornelius Weber, Zhiyuan Liu, Stefan Wermter, Maosong Sun
    * Abstract: Scene graph generation aims to identify objects and their relations in images, providing structured image representations that can facilitate numerous applications in computer vision. However, scene graph models usually require supervised learning on large quantities of labeled data with intensive human annotation. In this work, we propose visual distant supervision, a novel paradigm of visual relation learning, which can train scene graph models without any human-labeled data. The intuition is that by aligning commonsense knowledge bases and images, we can automatically create large-scale labeled data to provide distant supervision for visual relation learning. To alleviate the noise in distantly labeled data, we further propose a framework that iteratively estimates the probabilistic relation labels and eliminates the noisy ones. Comprehensive experimental results show that our distantly supervised model outperforms strong weakly supervised and semi-supervised baselines. By further incorporating human-labeled data in a semi-supervised fashion, our model outperforms state-of-the-art fully supervised models by a large margin (e.g., 8.3 micro- and 7.8 macro-recall@50 improvements for predicate classification in Visual Genome evaluation). We make the data and code for this paper publicly available at https://github.com/thunlp/VisualDS.
count=3
* Saliency Pattern Detection by Ranking Structured Trees
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Saliency_Pattern_Detection_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Saliency_Pattern_Detection_ICCV_2017_paper.pdf)]
    * Title: Saliency Pattern Detection by Ranking Structured Trees
    * Year: `2017`
    * Authors: Lei Zhu, Haibin Ling, Jin Wu, Huiping Deng, Jin Liu
    * Abstract: In this paper we propose a new salient object detection method via structured label prediction. By learning appearance features in rectangular regions, our structural region representation encodes the local saliency distribution with a matrix of binary labels. We show that the linear combination of structured labels can well model the saliency distribution in local regions. Representing region saliency with structured labels has two advantages: 1) it connects the label assignment of all enclosed pixels, which produces a smooth saliency prediction; and 2) regular-shaped nature of structured labels enables well definition of traditional cues such as regional properties and center surround contrast, and these cues help to build meaningful and informative saliency measures. To measure the consistency between a structured label and the corresponding saliency distribution, we further propose an adaptive label ranking algorithm using proposals that are generated by a CNN model. Finally, we introduce a K-NN enhanced graph representation for saliency propagation, which is more favorable for our task than the widely-used adjacent-graph-based ones. Experimental results demonstrate the effectiveness of our proposed method on six popular benchmarks compared with state-of-the-art approaches.
count=3
* Contour Detection and Characterization for Asynchronous Event Sensors
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Barranco_Contour_Detection_and_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Barranco_Contour_Detection_and_ICCV_2015_paper.pdf)]
    * Title: Contour Detection and Characterization for Asynchronous Event Sensors
    * Year: `2015`
    * Authors: Francisco Barranco, Ching L. Teo, Cornelia Fermuller, Yiannis Aloimonos
    * Abstract: The bio-inspired, asynchronous event-based dynamic vision sensor records temporal changes in the luminance of the scene at high temporal resolution. Since events are only triggered at significant luminance changes, most events occur at the boundary of objects and their parts. The detection of these contours is an essential step for further interpretation of the scene. This paper presents an approach to learn the location of contours and their border ownership using Structured Random Forests on event-based features that encode motion, timing, texture, and spatial orientations. The classifier integrates elegantly information over time by utilizing the classification results previously computed. Finally, the contour detection and boundary assignment are demonstrated in a layer-segmentation of the scene. Experimental results demonstrate good performance in boundary detection and segmentation.
count=3
* Learning Complexity-Aware Cascades for Deep Pedestrian Detection
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Cai_Learning_Complexity-Aware_Cascades_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Cai_Learning_Complexity-Aware_Cascades_ICCV_2015_paper.pdf)]
    * Title: Learning Complexity-Aware Cascades for Deep Pedestrian Detection
    * Year: `2015`
    * Authors: Zhaowei Cai, Mohammad Saberian, Nuno Vasconcelos
    * Abstract: The design of complexity-aware cascaded detectors, combining features of very different complexities, is considered. A new cascade design procedure is introduced, by formulating cascade learning as the Lagrangian optimization of a risk that accounts for both accuracy and complexity. A boosting algorithm, denoted as complexity aware cascade training (CompACT), is then derived to solve this optimization. CompACT cascades are shown to seek an optimal trade-off between accuracy and complexity by pushing features of higher complexity to the later cascade stages, where only a few difficult candidate patches remain to be classified. This enables the use of features of vastly different complexities in a single detector. In result, the feature pool can be expanded to features previously impractical for cascade design, such as the responses of a deep convolutional neural network (CNN). This is demonstrated through the design of a pedestrian detector with a pool of features whose complexities span orders of magnitude. The resulting cascade generalizes the combination of a CNN with an object proposal mechanism: rather than a pre-processing stage, CompACT cascades seamlessly integrate CNNs in their stages. This enables state of the art performance on the Caltech and KITTI datasets, at fairly fast speeds.
count=3
* COUNT Forest: CO-Voting Uncertain Number of Targets Using Random Forest for Crowd Density Estimation
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Pham_COUNT_Forest_CO-Voting_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Pham_COUNT_Forest_CO-Voting_ICCV_2015_paper.pdf)]
    * Title: COUNT Forest: CO-Voting Uncertain Number of Targets Using Random Forest for Crowd Density Estimation
    * Year: `2015`
    * Authors: Viet-Quoc Pham, Tatsuo Kozakaya, Osamu Yamaguchi, Ryuzo Okada
    * Abstract: This paper presents a patch-based approach for crowd density estimation in public scenes. We formulate the problem of estimating density in a structured learning framework applied to random decision forests. Our approach learns the mapping between patch features and relative locations of all objects inside each patch, which contribute to generate the patch density map through Gaussian kernel density estimation. We build the forest in a coarse-to-fine manner with two split node layers, and further propose a crowdedness prior and an effective forest reduction method to improve the estimation accuracy and speed. Moreover, we introduce a semi-automatic training method to learn the estimator for a specific scene. We achieved state-of-the-art results on the public Mall dataset and UCSD dataset, and also proposed two potential applications in traffic counts and scene understanding with promising results.
count=3
* Hierarchical Higher-Order Regression Forest Fields: An Application to 3D Indoor Scene Labelling
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Pham_Hierarchical_Higher-Order_Regression_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Pham_Hierarchical_Higher-Order_Regression_ICCV_2015_paper.pdf)]
    * Title: Hierarchical Higher-Order Regression Forest Fields: An Application to 3D Indoor Scene Labelling
    * Year: `2015`
    * Authors: Trung T. Pham, Ian Reid, Yasir Latif, Stephen Gould
    * Abstract: This paper addresses the problem of semantic segmentation of 3D indoor scenes reconstructed from RGB-D images.Traditionally label prediction for 3D points is tackled by employing graphical models that capture scene features and complex relations between different class labels. However, the existing work is restricted to pairwise conditional random fields, which are insufficient when encoding rich scene context. In this work we propose models with higher-order potentials to describe complex relational information from the 3D scenes. Specifically, we relax the labelling problem to a regression, and generalize the higher-order associative P n Potts model to a new family of arbitrary higher-order models based on regression forests. We show that these models, like the robust P n models, can still be decomposed into the sum of pairwise terms by introducing auxiliary variables. Moreover, our proposed higher-order models also permit extension to hierarchical random fields, which allows for the integration of scene context and features computed at different scales. Our potential functions are constructed based on regression forests encoding Gaussian densities that admit efficient inference. The parameters of our model are learned from training data using a structured learning approach. Results on two datasets show clear improvements over current state-of-the-art methods.
count=3
* Detection and Segmentation of 2D Curved Reflection Symmetric Structures
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Teo_Detection_and_Segmentation_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Teo_Detection_and_Segmentation_ICCV_2015_paper.pdf)]
    * Title: Detection and Segmentation of 2D Curved Reflection Symmetric Structures
    * Year: `2015`
    * Authors: Ching L. Teo, Cornelia Fermuller, Yiannis Aloimonos
    * Abstract: Symmetry, as one of the key components of Gestalt theory, provides an important mid-level cue that serves as input to higher visual processes such as segmentation. In this work, we propose a complete approach that links the detection of curved reflection symmetries to produce symmetry-constrained segments of structures/regions in real images with clutter. For curved reflection symmetry detection, we leverage on patch-based symmetric features to train a Structured Random Forest classifier that detects multiscaled curved symmetries in 2D images. Next, using these curved symmetries, we modulate a novel symmetry-constrained foreground-background segmentation by their symmetry scores so that we enforce global symmetrical consistency in the final segmentation. This is achieved by imposing a pairwise symmetry prior that encourages symmetric pixels to have the same labels over a MRF-based representation of the input image edges, and the final segmentation is obtained via graph-cuts. Experimental results over four publicly available datasets containing annotated symmetric structures: 1) SYMMAX-300, 2) BSD-Parts, 3) Weizmann Horse and 4) NY-roads demonstrate the approach's applicability to different environments with state-of-the-art performance.
count=3
* Random Forests of Local Experts for Pedestrian Detection
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Marin_Random_Forests_of_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Marin_Random_Forests_of_2013_ICCV_paper.pdf)]
    * Title: Random Forests of Local Experts for Pedestrian Detection
    * Year: `2013`
    * Authors: Javier Marin, David Vazquez, Antonio M. Lopez, Jaume Amores, Bastian Leibe
    * Abstract: Pedestrian detection is one of the most challenging tasks in computer vision, and has received a lot of attention in the last years. Recently, some authors have shown the advantages of using combinations of part/patch-based detectors in order to cope with the large variability of poses and the existence of partial occlusions. In this paper, we propose a pedestrian detection method that efficiently combines multiple local experts by means of a Random Forest ensemble. The proposed method works with rich block-based representations such as HOG and LBP, in such a way that the same features are reused by the multiple local experts, so that no extra computational cost is needed with respect to a holistic method. Furthermore, we demonstrate how to integrate the proposed approach with a cascaded architecture in order to achieve not only high accuracy but also an acceptable efficiency. In particular, the resulting detector operates at five frames per second using a laptop machine. We tested the proposed method with well-known challenging datasets such as Caltech, ETH, Daimler, and INRIA. The method proposed in this work consistently ranks among the top performers in all the datasets, being either the best method or having a small difference with the best one.
count=3
* Video Synopsis by Heterogeneous Multi-source Correlation
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Zhu_Video_Synopsis_by_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Zhu_Video_Synopsis_by_2013_ICCV_paper.pdf)]
    * Title: Video Synopsis by Heterogeneous Multi-source Correlation
    * Year: `2013`
    * Authors: Xiatian Zhu, Chen Change Loy, Shaogang Gong
    * Abstract: Generating coherent synopsis for surveillance video stream remains a formidable challenge due to the ambiguity and uncertainty inherent to visual observations. In contrast to existing video synopsis approaches that rely on visual cues alone, we propose a novel multi-source synopsis framework capable of correlating visual data and independent non-visual auxiliary information to better describe and summarise subtle physical events in complex scenes. Specifically, our unsupervised framework is capable of seamlessly uncovering latent correlations among heterogeneous types of data sources, despite the non-trivial heteroscedasticity and dimensionality discrepancy problems. Additionally, the proposed model is robust to partial or missing non-visual information. We demonstrate the effectiveness of our framework on two crowded public surveillance datasets.
count=3
* SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/18ef499ee57c4822e1e3ea9b9948af18-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/18ef499ee57c4822e1e3ea9b9948af18-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking
    * Year: `2023`
    * Authors: Soukayna Mouatadid, Paulo Orenstein, Genevieve Flaspohler, Miruna Oprescu, Judah Cohen, Franklyn Wang, Sean Knight, Maria Geogdzhayeva, Sam Levang, Ernest Fraenkel, Lester Mackey
    * Abstract: Subseasonal forecasting of the weather two to six weeks in advance is critical for resource allocation and climate adaptation but poses many challenges for the forecasting community. At this forecast horizon, physics-based dynamical models have limited skill, and the targets for prediction depend in a complex manner on both local weather variables and global climate variables. Recently, machine learning methods have shown promise in advancing the state of the art but only at the cost of complex data curation, integrating expert knowledge with aggregation across multiple relevant data sources, file formats, and temporal and spatial resolutions.To streamline this process and accelerate future development, we introduce SubseasonalClimateUSA, a curated dataset for training and benchmarking subseasonal forecasting models in the United States. We use this dataset to benchmark a diverse suite of models, including operational dynamical models, classical meteorological baselines, and ten state-of-the-art machine learning and deep learning-based methods from the literature. Overall, our benchmarks suggest simple and effective ways to extend the accuracy of current operational models. SubseasonalClimateUSA is regularly updated and accessible via the https://github.com/microsoft/subseasonal_data/ Python package.
count=3
* Boosting Verification of Deep Reinforcement Learning via Piece-Wise Linear Decision Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/1f96b24df4b06f5d68389845a9a13ed9-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/1f96b24df4b06f5d68389845a9a13ed9-Paper-Conference.pdf)]
    * Title: Boosting Verification of Deep Reinforcement Learning via Piece-Wise Linear Decision Neural Networks
    * Year: `2023`
    * Authors: Jiaxu Tian, Dapeng Zhi, Si Liu, Peixin Wang, Cheng Chen, Min Zhang
    * Abstract: Formally verifying deep reinforcement learning (DRL) systems suffers from both inaccurate verification results and limited scalability. The major obstacle lies in the large overestimation introduced inherently during training and then transforming the inexplicable decision-making models, i.e., deep neural networks (DNNs), into easy-to-verify models. In this paper, we propose an inverse transform-then-train approach, which first encodes a DNN into an equivalent set of efficiently and tightly verifiable linear control policies and then optimizes them via reinforcement learning. We accompany our inverse approach with a novel neural network model called piece-wise linear decision neural networks (PLDNNs), which are compatible with most existing DRL training algorithms with comparable performance against conventional DNNs. Our extensive experiments show that, compared to DNN-based DRL systems, PLDNN-based systems can be more efficiently and tightly verified with up to $438$ times speedup and a significant reduction in overestimation. In particular, even a complex $12$-dimensional DRL system is efficiently verified with up to 7 times deeper computation steps.
count=3
* RD-Suite: A Benchmark for Ranking Distillation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/701eba0f98c6f28ffee0de5969d8d034-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/701eba0f98c6f28ffee0de5969d8d034-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: RD-Suite: A Benchmark for Ranking Distillation
    * Year: `2023`
    * Authors: Zhen Qin, Rolf Jagerman, Rama Kumar Pasumarthi, Honglei Zhuang, He Zhang, Aijun Bai, Kai Hui, Le Yan, Xuanhui Wang
    * Abstract: The distillation of ranking models has become an important topic in both academia and industry. In recent years, several advanced methods have been proposed to tackle this problem, often leveraging ranking information from teacher rankers that is absent in traditional classification settings. To date, there is no well-established consensus on how to evaluate this class of models. Moreover, inconsistent benchmarking on a wide range of tasks and datasets make it difficult to assess or invigorate advances in this field. This paper first examines representative prior arts on ranking distillation, and raises three questions to be answered around methodology and reproducibility. To that end, we propose a systematic and unified benchmark, Ranking Distillation Suite (RD-Suite), which is a suite of tasks with 4 large real-world datasets, encompassing two major modalities (textual and numeric) and two applications (standard distillation and distillation transfer). RD-Suite consists of benchmark results that challenge some of the common wisdom in the field, and the release of datasets with teacher scores and evaluation scripts for future research. RD-Suite paves the way towards better understanding of ranking distillation, facilities more research in this direction, and presents new challenges.
count=3
* Pareto Frontiers in Deep Feature Learning: Data, Compute, Width, and Luck
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/960573a3b797441aec39caa9f74bc793-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/960573a3b797441aec39caa9f74bc793-Paper-Conference.pdf)]
    * Title: Pareto Frontiers in Deep Feature Learning: Data, Compute, Width, and Luck
    * Year: `2023`
    * Authors: Benjamin Edelman, Surbhi Goel, Sham Kakade, Eran Malach, Cyril Zhang
    * Abstract: In modern deep learning, algorithmic choices (such as width, depth, and learning rate) are known to modulate nuanced resource tradeoffs. This work investigates how these complexities necessarily arise for feature learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding "lottery ticket" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning. We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests.
count=3
* Adapting Fairness Interventions to Missing Values
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/ba0ad9d1e0c737800b2340b9cd68c208-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/ba0ad9d1e0c737800b2340b9cd68c208-Paper-Conference.pdf)]
    * Title: Adapting Fairness Interventions to Missing Values
    * Year: `2023`
    * Authors: Raymond Feng, Flavio Calmon, Hao Wang
    * Abstract: Missing values in real-world data pose a significant and unique challenge to algorithmic fairness. Different demographic groups may be unequally affected by missing data, and the standard procedure for handling missing values where first data is imputed, then the imputed data is used for classification—a procedure referred to as "impute-then-classify"—can exacerbate discrimination. In this paper, we analyze how missing values affect algorithmic fairness. We first prove that training a classifier from imputed data can significantly worsen the achievable values of group fairness and average accuracy. This is because imputing data results in the loss of the missing pattern of the data, which often conveys information about the predictive label. We present scalable and adaptive algorithms for fair classification with missing values. These algorithms can be combined with any preexisting fairness-intervention algorithm to handle all possible missing patterns while preserving information encoded within the missing patterns. Numerical experiments with state-of-the-art fairness interventions demonstrate that our adaptive algorithms consistently achieve higher fairness and accuracy than impute-then-classify across different datasets.
count=3
* SSL4EO-L: Datasets and Foundation Models for Landsat Imagery
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/bbf7ee04e2aefec136ecf60e346c2e61-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/bbf7ee04e2aefec136ecf60e346c2e61-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: SSL4EO-L: Datasets and Foundation Models for Landsat Imagery
    * Year: `2023`
    * Authors: Adam Stewart, Nils Lehmann, Isaac Corley, Yi Wang, Yi-Chia Chang, Nassim Ait Ait Ali Braham, Shradha Sehgal, Caleb Robinson, Arindam Banerjee
    * Abstract: The Landsat program is the longest-running Earth observation program in history, with 50+ years of data acquisition by 8 satellites. The multispectral imagery captured by sensors onboard these satellites is critical for a wide range of scientific fields. Despite the increasing popularity of deep learning and remote sensing, the majority of researchers still use decision trees and random forests for Landsat image analysis due to the prevalence of small labeled datasets and lack of foundation models. In this paper, we introduce SSL4EO-L, the first ever dataset designed for Self-Supervised Learning for Earth Observation for the Landsat family of satellites (including 3 sensors and 2 product levels) and the largest Landsat dataset in history (5M image patches). Additionally, we modernize and re-release the L7 Irish and L8 Biome cloud detection datasets, and introduce the first ML benchmark datasets for Landsats 4–5 TM and Landsat 7 ETM+ SR. Finally, we pre-train the first foundation models for Landsat imagery using SSL4EO-L and evaluate their performance on multiple semantic segmentation tasks. All datasets and model weights are available via the TorchGeo library, making reproducibility and experimentation easy, and enabling scientific advancements in the burgeoning field of remote sensing for a multitude of downstream applications.
count=3
* Online Label Shift: Optimal Dynamic Regret meets Practical Algorithms
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/cf42f133f355e0e07a8957b508b26a1b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/cf42f133f355e0e07a8957b508b26a1b-Paper-Conference.pdf)]
    * Title: Online Label Shift: Optimal Dynamic Regret meets Practical Algorithms
    * Year: `2023`
    * Authors: Dheeraj Baby, Saurabh Garg, Tzu-Ching Yen, Sivaraman Balakrishnan, Zachary Lipton, Yu-Xiang Wang
    * Abstract: This paper focuses on supervised and unsupervised online label shift,where the class marginals $Q(y)$ variesbut the class-conditionals $Q(x|y)$ remain invariant. In the unsupervised setting, our goal is to adapt a learner, trained on some offline labeled data, to changing label distributions given unlabeled online data. In the supervised setting, we must both learn a classifier and adapt to the dynamically evolving class marginals given only labeled online data. We develop novel algorithms that reduce the adaptation problem to online regression and guarantee optimal dynamic regret without any prior knowledge of the extent of drift in the label distribution. Our solution is based on bootstrapping the estimates of *online regression oracles* that track the drifting proportions. Experiments across numerous simulated and real-world online label shift scenarios demonstrate the superior performance of our proposed approaches, often achieving 1-3% improvement in accuracy while being sample and computationally efficient. Code is publicly available at https://github.com/Anon-djiwh/OnlineLabelShift
count=3
* Benchmarking Foundation Models with Language-Model-as-an-Examiner
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/f64e55d03e2fe61aa4114e49cb654acb-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/f64e55d03e2fe61aa4114e49cb654acb-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Benchmarking Foundation Models with Language-Model-as-an-Examiner
    * Year: `2023`
    * Authors: Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv, Yuze He, Xiaozhi Wang, Jifan Yu, Kaisheng Zeng, Yijia Xiao, Haozhe Lyu, Jiayin Zhang, Juanzi Li, Lei Hou
    * Abstract: Numerous benchmarks have been established to assess the performance of foundation models on open-ended question answering, which serves as a comprehensive test of a model's ability to understand and generate language in a manner similar to humans.Most of these works focus on proposing new datasets, however, we see two main issues within previous benchmarking pipelines, namely testing leakage and evaluation automation. In this paper, we propose a novel benchmarking framework, Language-Model-as-an-Examiner, where the LM serves as a knowledgeable examiner that formulates questions based on its knowledge and evaluates responses in a reference-free manner. Our framework allows for effortless extensibility as various LMs can be adopted as the examiner, and the questions can be constantly updated given more diverse trigger topics. For a more comprehensive and equitable evaluation, we devise three strategies: (1) We instruct the LM examiner to generate questions across a multitude of domains to probe for a broad acquisition, and raise follow-up questions to engage in a more in-depth assessment. (2) Upon evaluation, the examiner combines both scoring and ranking measurements, providing a reliable result as it aligns closely with human annotations. (3) We additionally propose a decentralized Peer-examination method to address the biases in a single examiner. Our data and benchmarking results are available at: http://lmexam.xlore.cn.
count=3
* Self-Supervised Learning Through Efference Copies
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/1d1cea122b9ec9f78acc21510659e500-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/1d1cea122b9ec9f78acc21510659e500-Paper-Conference.pdf)]
    * Title: Self-Supervised Learning Through Efference Copies
    * Year: `2022`
    * Authors: Franz Scherr, Qinghai Guo, Timoleon Moraitis
    * Abstract: Self-supervised learning (SSL) methods aim to exploit the abundance of unlabelled data for machine learning (ML), however the underlying principles are often method-specific. An SSL framework derived from biological first principles of embodied learning could unify the various SSL methods, help elucidate learning in the brain, and possibly improve ML. SSL commonly transforms each training datapoint into a pair of views, uses the knowledge of this pairing as a positive (i.e. non-contrastive) self-supervisory sign, and potentially opposes it to unrelated, (i.e. contrastive) negative examples. Here, we show that this type of self-supervision is an incomplete implementation of a concept from neuroscience, the Efference Copy (EC). Specifically, the brain also transforms the environment through efference, i.e. motor commands, however it sends to itself an EC of the full commands, i.e. more than a mere SSL sign. In addition, its action representations are likely egocentric. From such a principled foundation we formally recover and extend SSL methods such as SimCLR, BYOL, and ReLIC under a common theoretical framework, i.e. Self-supervision Through Efference Copies (S-TEC). Empirically, S-TEC restructures meaningfully the within- and between-class representations. This manifests as improvement in recent strong SSL baselines in image classification, segmentation, object detection, and in audio. These results hypothesize a testable positive influence from the brain's motor outputs onto its sensory representations.
count=3
* FACT: Learning Governing Abstractions Behind Integer Sequences
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/72372ec86dd49238900fc0b68bad63f8-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/72372ec86dd49238900fc0b68bad63f8-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: FACT: Learning Governing Abstractions Behind Integer Sequences
    * Year: `2022`
    * Authors: Peter Belcak, Ard Kastrati, Flavio Schenker, Roger Wattenhofer
    * Abstract: Integer sequences are of central importance to the modeling of concepts admitting complete finitary descriptions. We introduce a novel view on the learning of such concepts and lay down a set of benchmarking tasks aimed at conceptual understanding by machine learning models. These tasks indirectly assess model ability to abstract, and challenge them to reason both interpolatively and extrapolatively from the knowledge gained by observing representative examples. To further aid research in knowledge representation and reasoning, we present FACT, the Finitary Abstraction Comprehension Toolkit. The toolkit surrounds a large dataset of integer sequences comprising both organic and synthetic entries, a library for data pre-processing and generation, a set of model performance evaluation tools, and a collection of baseline model implementations, enabling the making of the future advancements with ease.
count=3
* Ontologue: Declarative Benchmark Construction for Ontological Multi-Label Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/8cf04c64d1734e5f7e63418a2a4d49de-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/8cf04c64d1734e5f7e63418a2a4d49de-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Ontologue: Declarative Benchmark Construction for Ontological Multi-Label Classification
    * Year: `2022`
    * Authors: Sean Yang, Bernease Herman, Bill Howe
    * Abstract: We describe a customizable benchmark for hierarchical and ontological multi-label classification, a task where labels are equipped with a graph structure and data items can be assigned multiple labels. We find that current benchmarks do not adequately represent the problem space, casting doubt on the generalizability of current results. We consider three dimensions of the problem space: context (availability of rich features on the data and labels), distribution of labels over data, and graph structure. For context, the lack of complex features on the labels (and in some cases, the data) artificially prevent the use of modern representation learning techniques as an appropriate baseline. For distribution, we find the long tail of labels over data constitute a few-shot learning problem that artificially confounds the results: for most common benchmarks, over 40% of the labels have fewer than 5 data points in the training set. For structure, we find that the correlation between performance and the height of the tree can explain some of the variation in performance, informing practical utility. In this paper, we demonstrate how the lack of diversity in benchmarks can confound performance analysis, then present a declarative query system called Ontologue for generating custom benchmarks with specific properties, then use this system to design 4 new benchmarks extracted from DBPedia that better represent the problem space. We evaluate state-of-the-art algorithms on both existing and new benchmarks and show that the performance conclusions can vary significantly depending on the dimensions we consider. We intend the system and derived benchmarks to improve the analysis of generalizability for these problems.
count=3
* Depth is More Powerful than Width with Prediction Concatenation in Deep Forest
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/c017e92288b5056c578bb6b0b69d9e76-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/c017e92288b5056c578bb6b0b69d9e76-Paper-Conference.pdf)]
    * Title: Depth is More Powerful than Width with Prediction Concatenation in Deep Forest
    * Year: `2022`
    * Authors: Shen-Huan Lyu, Yi-Xiao He, Zhi-Hua Zhou
    * Abstract: Random Forest (RF) is an ensemble learning algorithm proposed by \citet{breiman2001random} that constructs a large number of randomized decision trees individually and aggregates their predictions by naive averaging. \citet{zhou2019deep} further propose Deep Forest (DF) algorithm with multi-layer feature transformation, which significantly outperforms random forest in various application fields. The prediction concatenation (PreConc) operation is crucial for the multi-layer feature transformation in deep forest, though little has been known about its theoretical property. In this paper, we analyze the influence of Preconc on the consistency of deep forest. Especially when the individual tree is inconsistent (as in practice, the individual tree is often set to be fully grown, i.e., there is only one sample at each leaf node), we find that the convergence rate of two-layer DF \textit{w.r.t.} the number of trees $M$ can reach $\mathcal{O}(1/M^2)$ under some mild conditions, while the convergence rate of RF is $\mathcal{O}(1/M)$. Therefore, with the help of PreConc, DF with deeper layer will be more powerful than the shallower layer. Experiments confirm theoretical advantages.
count=3
* Turning the Tables: Biased, Imbalanced, Dynamic Tabular Datasets for ML Evaluation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/d9696563856bd350e4e7ac5e5812f23c-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/d9696563856bd350e4e7ac5e5812f23c-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Turning the Tables: Biased, Imbalanced, Dynamic Tabular Datasets for ML Evaluation
    * Year: `2022`
    * Authors: Sérgio Jesus, José Pombal, Duarte Alves, André Cruz, Pedro Saleiro, Rita Ribeiro, João Gama, Pedro Bizarro
    * Abstract: Evaluating new techniques on realistic datasets plays a crucial role in the development of ML research and its broader adoption by practitioners. In recent years, there has been a significant increase of publicly available unstructured data resources for computer vision and NLP tasks. However, tabular data — which is prevalent in many high-stakes domains — has been lagging behind. To bridge this gap, we present Bank Account Fraud (BAF), the first publicly available 1 privacy-preserving, large-scale, realistic suite of tabular datasets. The suite was generated by applying state-of-the-art tabular data generation techniques on an anonymized,real-world bank account opening fraud detection dataset. This setting carries a set of challenges that are commonplace in real-world applications, including temporal dynamics and significant class imbalance. Additionally, to allow practitioners to stress test both performance and fairness of ML methods, each dataset variant of BAF contains specific types of data bias. With this resource, we aim to provide the research community with a more realistic, complete, and robust test bed to evaluate novel and existing methods.
count=3
* BAST: Bayesian Additive Regression Spanning Trees for Complex Constrained Domain
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/00b76fddeaaa7d8c2c43d504b2babd8a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/00b76fddeaaa7d8c2c43d504b2babd8a-Paper.pdf)]
    * Title: BAST: Bayesian Additive Regression Spanning Trees for Complex Constrained Domain
    * Year: `2021`
    * Authors: Zhao Tang Luo, Huiyan Sang, Bani Mallick
    * Abstract: Nonparametric regression on complex domains has been a challenging task as most existing methods, such as ensemble models based on binary decision trees, are not designed to account for intrinsic geometries and domain boundaries. This article proposes a Bayesian additive regression spanning trees (BAST) model for nonparametric regression on manifolds, with an emphasis on complex constrained domains or irregularly shaped spaces embedded in Euclidean spaces. Our model is built upon a random spanning tree manifold partition model as each weak learner, which is capable of capturing any irregularly shaped spatially contiguous partitions while respecting intrinsic geometries and domain boundary constraints. Utilizing many nice properties of spanning tree structures, we design an efficient Bayesian inference algorithm. Equipped with a soft prediction scheme, BAST is demonstrated to significantly outperform other competing methods in simulation experiments and in an application to the chlorophyll data in Aral Sea, due to its strong local adaptivity to different levels of smoothness.
count=3
* Probabilistic Forecasting: A Level-Set Approach
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/32b127307a606effdcc8e51f60a45922-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/32b127307a606effdcc8e51f60a45922-Paper.pdf)]
    * Title: Probabilistic Forecasting: A Level-Set Approach
    * Year: `2021`
    * Authors: Hilaf Hasson, Bernie Wang, Tim Januschowski, Jan Gasthaus
    * Abstract: Large-scale time series panels have become ubiquitous over the last years in areas such as retail, operational metrics, IoT, and medical domain (to name only a few). This has resulted in a need for forecasting techniques that effectively leverage all available data by learning across all time series in each panel. Among the desirable properties of forecasting techniques, being able to generate probabilistic predictions ranks among the top. In this paper, we therefore present Level Set Forecaster (LSF), a simple yet effective general approach to transform a point estimator into a probabilistic one. By recognizing the connection of our algorithm to random forests (RFs) and quantile regression forests (QRFs), we are able to prove consistency guarantees of our approach under mild assumptions on the underlying point estimator. As a byproduct, we prove the first consistency results for QRFs under the CART-splitting criterion. Empirical experiments show that our approach, equipped with tree-based models as the point estimator, rivals state-of-the-art deep learning models in terms of forecasting accuracy.
count=3
* Online Adaptation to Label Distribution Shift
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/5e6bd7a6970cd4325e587f02667f7f73-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/5e6bd7a6970cd4325e587f02667f7f73-Paper.pdf)]
    * Title: Online Adaptation to Label Distribution Shift
    * Year: `2021`
    * Authors: Ruihan Wu, Chuan Guo, Yi Su, Kilian Q. Weinberger
    * Abstract: Machine learning models often encounter distribution shifts when deployed in the real world. In this paper, we focus on adaptation to label distribution shift in the online setting, where the test-time label distribution is continually changing and the model must dynamically adapt to it without observing the true label. This setting is common in many real world scenarios such as medical diagnosis, where disease prevalences can vary substantially at different times of the year. Leveraging a novel analysis, we show that the lack of true label does not hinder estimation of the expected test loss, which enables the reduction of online label shift adaptation to conventional online learning. Informed by this observation, we propose adaptation algorithms inspired by classical online learning techniques such as Follow The Leader (FTL) and Online Gradient Descent (OGD) and derive their regret bounds. We empirically verify our findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to a variety of challenging label shift scenarios.
count=3
* BCORLE($\lambda$): An Offline Reinforcement Learning and Evaluation Framework for Coupons Allocation in E-commerce Market
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/ab452534c5ce28c4fbb0e102d4a4fb2e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/ab452534c5ce28c4fbb0e102d4a4fb2e-Paper.pdf)]
    * Title: BCORLE($\lambda$): An Offline Reinforcement Learning and Evaluation Framework for Coupons Allocation in E-commerce Market
    * Year: `2021`
    * Authors: Yang Zhang, Bo Tang, Qingyu Yang, Dou An, Hongyin Tang, Chenyang Xi, Xueying LI, Feiyu Xiong
    * Abstract: Coupons allocation is an important tool for enterprises to increase the activity and loyalty of users on the e-commerce market. One fundamental problem related is how to allocate coupons within a fixed budget while maximizing users' retention on the e-commerce platform. The online e-commerce environment is complicated and ever changing, so it requires the coupons allocation policy learning can quickly adapt to the changes of the company's business strategy. Unfortunately, existing studies with a huge computation overhead can hardly satisfy the requirements of real-time and fast-response in the real world. Specifically, the problem of coupons allocation within a fixed budget is usually formulated as a Lagrangian problem. Existing solutions need to re-learn the policy once the value of Lagrangian multiplier variable $\lambda$ is updated, causing a great computation overhead. Besides, a mature e-commerce market often faces tens of millions of users and dozens of types of coupons which construct the huge policy space, further increasing the difficulty of solving the problem. To tackle with above problems, we propose a budget constrained offline reinforcement learning and evaluation with $\lambda$-generalization (BCORLE($\lambda$)) framework. The proposed method can help enterprises develop a coupons allocation policy which greatly improves users' retention rate on the platform while ensuring the cost does not exceed the budget. Specifically, $\lambda$-generalization method is proposed to lead the policy learning process can be executed according to different $\lambda$ values adaptively, avoiding re-learning new polices from scratch. Thus the computation overhead is greatly reduced. Further, a novel offline reinforcement learning method and an off-policy evaluation algorithm are proposed for policy learning and policy evaluation, respectively. Finally, experiments on the simulation platform and real-world e-commerce market validate the effectiveness of our approach.
count=3
* Lattice partition recovery with dyadic CART
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/dba4c1a117472f6aca95211285d0587e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/dba4c1a117472f6aca95211285d0587e-Paper.pdf)]
    * Title: Lattice partition recovery with dyadic CART
    * Year: `2021`
    * Authors: OSCAR HERNAN MADRID PADILLA, Yi Yu, Alessandro Rinaldo
    * Abstract: We study piece-wise constant signals corrupted by additive Gaussian noise over a $d$-dimensional lattice. Data of this form naturally arise in a host of applications, and the tasks of signal detection or testing, de-noising and estimation have been studied extensively in the statistical and signal processing literature. In this paper we consider instead the problem of partition recovery, i.e.~of estimating the partition of the lattice induced by the constancy regions of the unknown signal, using the computationally-efficient dyadic classification and regression tree (DCART) methodology proposed by \citep{donoho1997cart}. We prove that, under appropriate regularity conditions on the shape of the partition elements, a DCART-based procedure consistently estimates the underlying partition at a rate of order $\sigma^2 k^* \log (N)/\kappa^2$, where $k^*$ is the minimal number of rectangular sub-graphs obtained using recursive dyadic partitions supporting the signal partition, $\sigma^2$ is the noise variance, $\kappa$ is the minimal magnitude of the signal difference among contiguous elements of the partition and $N$ is the size of the lattice. Furthermore, under stronger assumptions, our method attains a sharper estimation error of order $\sigma^2\log(N)/\kappa^2$, independent of $k^*$, which we show to be minimax rate optimal. Our theoretical guarantees further extend to the partition estimator based on the optimal regression tree estimator (ORT) of \cite{chatterjee2019adaptive} and to the one obtained through an NP-hard exhaustive search method. We corroborate our theoretical findings and the effectiveness of DCART for partition recovery in simulations.
count=3
* Shapley Residuals: Quantifying the limits of the Shapley value for explanations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/dfc6aa246e88ab3e32caeaaecf433550-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/dfc6aa246e88ab3e32caeaaecf433550-Paper.pdf)]
    * Title: Shapley Residuals: Quantifying the limits of the Shapley value for explanations
    * Year: `2021`
    * Authors: Indra Kumar, Carlos  Scheidegger, Suresh Venkatasubramanian, Sorelle Friedler
    * Abstract: Popular feature importance techniques compute additive approximations to nonlinear models by first defining a cooperative game describing the value of different subsets of the model's features, then calculating the resulting game's Shapley values to attribute credit additively between the features. However, the specific modeling settings in which the Shapley values are a poor approximation for the true game have not been well-described. In this paper we utilize an interpretation of Shapley values as the result of an orthogonal projection between vector spaces to calculate a residual representing the kernel component of that projection. We provide an algorithm for computing these residuals, characterize different modeling settings based on the value of the residuals, and demonstrate that they capture information about model predictions that Shapley values cannot. Shapley residuals can thus act as a warning to practitioners against overestimating the degree to which Shapley-value-based explanations give them insight into a model.
count=3
* Nearly-Tight and Oblivious Algorithms for Explainable Clustering
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/f24ad6f72d6cc4cb51464f2b29ab69d3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/f24ad6f72d6cc4cb51464f2b29ab69d3-Paper.pdf)]
    * Title: Nearly-Tight and Oblivious Algorithms for Explainable Clustering
    * Year: `2021`
    * Authors: Buddhima Gamlath, Xinrui Jia, Adam Polak, Ola Svensson
    * Abstract: We study the problem of explainable clustering in the setting first formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian (ICML 2020). A $k$-clustering is said to be explainable if it is given by a decision tree where each internal node splits data points with a threshold cut in a single dimension (feature), and each of the $k$ leaves corresponds to a cluster. We give an algorithm that outputs an explainable clustering that loses at most a factor of $O(\log^2 k)$ compared to an optimal (not necessarily explainable) clustering for the $k$-medians objective, and a factor of $O(k \log^2 k)$ for the $k$-means objective. This improves over the previous best upper bounds of $O(k)$ and $O(k^2)$, respectively, and nearly matches the previous $\Omega(\log k)$ lower bound for $k$-medians and our new $\Omega(k)$ lower bound for $k$-means. The algorithm is remarkably simple. In particular, given an initial not necessarily explainable clustering in $\mathbb{R}^d$, it is oblivious to the data points and runs in time $O(dk \log^2 k)$, independent of the number of data points $n$. Our upper and lower bounds also generalize to objectives given by higher $\ell_p$-norms.
count=3
* Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/62d75fb2e3075506e8837d8f55021ab1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/62d75fb2e3075506e8837d8f55021ab1-Paper.pdf)]
    * Title: Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation
    * Year: `2020`
    * Authors: Rasool Fakoor, Jonas W. Mueller, Nick Erickson, Pratik Chaudhari, Alexander J. Smola
    * Abstract: Automated machine learning (AutoML) can produce complex model ensembles by stacking, bagging, and boosting many individual models like trees, deep networks, and nearest neighbor estimators. While highly accurate, the resulting predictors are large, slow, and opaque as compared to their constituents. To improve the deployment of AutoML on tabular data, we propose FAST-DAD to distill arbitrarily-complex ensemble predictors into individual models like boosted trees, random forests, and deep networks. At the heart of our approach is a data augmentation strategy based on Gibbs sampling from a self-attention pseudolikelihood estimator. Across 30 datasets spanning regression and binary/multiclass classification tasks, FAST-DAD distillation produces significantly better individual models than one obtains through standard training on the original data. Our individual distilled models are over 10x faster and more accurate than ensemble predictors produced by AutoML tools like H2O/AutoSklearn.
count=3
* Towards Convergence Rate Analysis of Random Forests for Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/6925f2a16026e36e4fc112f82dd79406-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/6925f2a16026e36e4fc112f82dd79406-Paper.pdf)]
    * Title: Towards Convergence Rate Analysis of Random Forests for Classification
    * Year: `2020`
    * Authors: Wei Gao, Zhi-Hua Zhou
    * Abstract: Random forests have been one of the successful ensemble algorithms in machine learning. The basic idea is to construct a large number of random trees individually and make prediction based on an average of their predictions. The great successes have attracted much attention on the consistency of random forests, mostly focusing on regression. This work takes one step towards convergence rates of random forests for classification. We present the first finite-sample rate O(n^{-1/(8d+2)}) on the convergence of pure random forests for classification, which can be improved to be of O(n^{-1/(3.87d+2)}) by considering the midpoint splitting mechanism. We introduce another variant of random forests, which follow Breiman's original random forests but with different mechanisms on splitting dimensions and positions. We get a convergence rate O(n^{-{1}/(d+2)}(\ln n)^{{1}/(d+2)}) for the variant of random forests, which reaches the minimax rate, except for a factor (\ln n)^{{1}/(d+2)}, of the optimal plug-in classifier under the L-Lipschitz assumption. We achieve tighter convergence rate O(\sqrt{\ln n/n}) under proper assumptions over structural data.
count=3
* Federated Bayesian Optimization via Thompson Sampling
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/6dfe08eda761bd321f8a9b239f6f4ec3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/6dfe08eda761bd321f8a9b239f6f4ec3-Paper.pdf)]
    * Title: Federated Bayesian Optimization via Thompson Sampling
    * Year: `2020`
    * Authors: Zhongxiang Dai, Bryan Kian Hsiang Low, Patrick Jaillet
    * Abstract: Bayesian optimization (BO) is a prominent approach to optimizing expensive-to-evaluate black-box functions. The massive computational capability of edge devices such as mobile phones, coupled with privacy concerns, has led to a surging interest in federated learning (FL) which focuses on collaborative training of deep neural networks (DNNs) via first-order optimization techniques. However, some common machine learning tasks such as hyperparameter tuning of DNNs lack access to gradients and thus require zeroth-order/black-box optimization. This hints at the possibility of extending BO to the FL setting (FBO) for agents to collaborate in these black-box optimization tasks. This paper presents federated Thompson sampling (FTS) which overcomes a number of key challenges of FBO and FL in a principled way: We (a) use random Fourier features to approximate the Gaussian process surrogate model used in BO, which naturally produces the parameters to be exchanged between agents, (b) design FTS based on Thompson sampling, which significantly reduces the number of parameters to be exchanged, and (c) provide a theoretical convergence guarantee that is robust against heterogeneous agents, which is a major challenge in FL and FBO. We empirically demonstrate the effectiveness of FTS in terms of communication efficiency, computational efficiency, and practical performance.
count=3
* Regularizing Black-box Models for Improved Interpretability
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/770f8e448d07586afbf77bb59f698587-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/770f8e448d07586afbf77bb59f698587-Paper.pdf)]
    * Title: Regularizing Black-box Models for Improved Interpretability
    * Year: `2020`
    * Authors: Gregory Plumb, Maruan Al-Shedivat, Ángel Alexander Cabrera, Adam Perer, Eric Xing, Ameet Talwalkar
    * Abstract: Most of the work on interpretable machine learning has focused on designing either inherently interpretable models, which typically trade-off accuracy for interpretability, or post-hoc explanation systems, whose explanation quality can be unpredictable. Our method, ExpO, is a hybridization of these approaches that regularizes a model for explanation quality at training time. Importantly, these regularizers are differentiable, model agnostic, and require no domain knowledge to define. We demonstrate that post-hoc explanations for ExpO-regularized models have better explanation quality, as measured by the common fidelity and stability metrics. We verify that improving these metrics leads to significantly more useful explanations with a user study on a realistic task.
count=3
* Deep Multi-State Dynamic Recurrent Neural Networks Operating on Wavelet Based Neural Features for Robust Brain Machine Interfaces
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/1e0feeaff84a19bf3936e693311fa66d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/1e0feeaff84a19bf3936e693311fa66d-Paper.pdf)]
    * Title: Deep Multi-State Dynamic Recurrent Neural Networks Operating on Wavelet Based Neural Features for Robust Brain Machine Interfaces
    * Year: `2019`
    * Authors: Benyamin Allahgholizadeh Haghi, Spencer Kellis, Sahil Shah, Maitreyi Ashok, Luke Bashford, Daniel Kramer, Brian Lee, Charles Liu, Richard Andersen, Azita Emami
    * Abstract: We present a new deep multi-state Dynamic Recurrent Neural Network (DRNN) architecture for Brain Machine Interface (BMI) applications. Our DRNN is used to predict Cartesian representation of a computer cursor movement kinematics from open-loop neural data recorded from the posterior parietal cortex (PPC) of a human subject in a BMI system. We design the algorithm to achieve a reasonable trade-off between performance and robustness, and we constrain memory usage in favor of future hardware implementation. We feed the predictions of the network back to the input to improve prediction performance and robustness. We apply a scheduled sampling approach to the model in order to solve a statistical distribution mismatch between the ground truth and predictions. Additionally, we configure a small DRNN to operate with a short history of input, reducing the required buffering of input data and number of memory accesses. This configuration lowers the expected power consumption in a neural network accelerator. Operating on wavelet-based neural features, we show that the average performance of DRNN surpasses other state-of-the-art methods in the literature on both single- and multi-day data recorded over 43 days. Results show that multi-state DRNN has the potential to model the nonlinear relationships between the neural data and kinematics for robust BMIs.
count=3
* A Debiased MDI Feature Importance Measure for Random Forests
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/702cafa3bb4c9c86e4a3b6834b45aedd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/702cafa3bb4c9c86e4a3b6834b45aedd-Paper.pdf)]
    * Title: A Debiased MDI Feature Importance Measure for Random Forests
    * Year: `2019`
    * Authors: Xiao Li, Yu Wang, Sumanta Basu, Karl Kumbier, Bin Yu
    * Abstract: Tree ensembles such as Random Forests have achieved impressive empirical success across a wide variety of applications. To understand how these models make predictions, people routinely turn to feature importance measures calculated from tree ensembles. It has long been known that Mean Decrease Impurity (MDI), one of the most widely used measures of feature importance, incorrectly assigns high importance to noisy features, leading to systematic bias in feature selection. In this paper, we address the feature selection bias of MDI from both theoretical and methodological perspectives. Based on the original definition of MDI by Breiman et al. \cite{Breiman1984} for a single tree, we derive a tight non-asymptotic bound on the expected bias of MDI importance of noisy features, showing that deep trees have higher (expected) feature selection bias than shallow ones. However, it is not clear how to reduce the bias of MDI using its existing analytical expression. We derive a new analytical expression for MDI, and based on this new expression, we are able to propose a debiased MDI feature importance measure using out-of-bag samples, called MDI-oob. For both the simulated data and a genomic ChIP dataset, MDI-oob achieves state-of-the-art performance in feature selection from Random Forests for both deep and shallow trees.
count=3
* On Relating Explanations and Adversarial Examples
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/7392ea4ca76ad2fb4c9c3b6a5c6e31e3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/7392ea4ca76ad2fb4c9c3b6a5c6e31e3-Paper.pdf)]
    * Title: On Relating Explanations and Adversarial Examples
    * Year: `2019`
    * Authors: Alexey Ignatiev, Nina Narodytska, Joao Marques-Silva
    * Abstract: The importance of explanations (XP's) of machine learning (ML) model predictions and of adversarial examples (AE's) cannot be overstated, with both arguably being essential for the practical success of ML in different settings. There has been recent work on understanding and assessing the relationship between XP's and AE's. However, such work has been mostly experimental and a sound theoretical relationship has been elusive. This paper demonstrates that explanations and adversarial examples are related by a generalized form of hitting set duality, which extends earlier work on hitting set duality observed in model-based diagnosis and knowledge compilation. Furthermore, the paper proposes algorithms, which enable computing adversarial examples from explanations and vice-versa.
count=3
* Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/8ca01ea920679a0fe3728441494041b9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/8ca01ea920679a0fe3728441494041b9-Paper.pdf)]
    * Title: Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration
    * Year: `2019`
    * Authors: Meelis Kull, Miquel Perello Nieto, Markus Kängsepp, Telmo Silva Filho, Hao Song, Peter Flach
    * Abstract: Class probabilities predicted by most multiclass classifiers are uncalibrated, often tending towards over-confidence. With neural networks, calibration can be improved by temperature scaling, a method to learn a single corrective multiplicative factor for inputs to the last softmax layer. On non-neural models the existing methods apply binary calibration in a pairwise or one-vs-rest fashion. We propose a natively multiclass calibration method applicable to classifiers from any model class, derived from Dirichlet distributions and generalising the beta calibration method from binary classification. It is easily implemented with neural nets since it is equivalent to log-transforming the uncalibrated probabilities, followed by one linear layer and softmax. Experiments demonstrate improved probabilistic predictions according to multiple measures (confidence-ECE, classwise-ECE, log-loss, Brier score) across a wide range of datasets and classifiers. Parameters of the learned Dirichlet calibration map provide insights to the biases in the uncalibrated model.
count=3
* Identifying Causal Effects via Context-specific Independence Relations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/d88518acbcc3d08d1f18da62f9bb26ec-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/d88518acbcc3d08d1f18da62f9bb26ec-Paper.pdf)]
    * Title: Identifying Causal Effects via Context-specific Independence Relations
    * Year: `2019`
    * Authors: Santtu Tikka, Antti Hyttinen, Juha Karvanen
    * Abstract: Causal effect identification considers whether an interventional probability distribution can be uniquely determined from a passively observed distribution in a given causal structure. If the generating system induces context-specific independence (CSI) relations, the existing identification procedures and criteria based on do-calculus are inherently incomplete. We show that deciding causal effect non-identifiability is NP-hard in the presence of CSIs. Motivated by this, we design a calculus and an automated search procedure for identifying causal effects in the presence of CSIs. The approach is provably sound and it includes standard do-calculus as a special case. With the approach we can obtain identifying formulas that were unobtainable previously, and demonstrate that a small number of CSI-relations may be sufficient to turn a previously non-identifiable instance to identifiable.
count=3
* A Refined Margin Distribution Analysis for Forest Representation Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/db5cea26ca37aa09e5365f3e7f5dd9eb-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/db5cea26ca37aa09e5365f3e7f5dd9eb-Paper.pdf)]
    * Title: A Refined Margin Distribution Analysis for Forest Representation Learning
    * Year: `2019`
    * Authors: Shen-Huan Lyu, Liang Yang, Zhi-Hua Zhou
    * Abstract: In this paper, we formulate the forest representation learning approach called \textsc{CasDF} as an additive model which boosts the augmented feature instead of the prediction. We substantially improve the upper bound of the generalization gap from $\mathcal{O}(\sqrt{\ln m/m})$ to $\mathcal{O}(\ln m/m)$, while the margin ratio of the margin standard deviation to the margin mean is sufficiently small. This tighter upper bound inspires us to optimize the ratio. Therefore, we design a margin distribution reweighting approach for deep forest to achieve a small margin ratio by boosting the augmented feature. Experiments confirm the correlation between the margin distribution and generalization performance. We remark that this study offers a novel understanding of \textsc{CasDF} from the perspective of the margin theory and further guides the layer-by-layer forest representation learning.
count=3
* Why Is My Classifier Discriminatory?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/1f1baa5b8edac74eb4eaa329f14a0361-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/1f1baa5b8edac74eb4eaa329f14a0361-Paper.pdf)]
    * Title: Why Is My Classifier Discriminatory?
    * Year: `2018`
    * Authors: Irene Chen, Fredrik D. Johansson, David Sontag
    * Abstract: Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.
count=3
* Learning from discriminative feature feedback
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/36ac8e558ac7690b6f44e2cb5ef93322-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/36ac8e558ac7690b6f44e2cb5ef93322-Paper.pdf)]
    * Title: Learning from discriminative feature feedback
    * Year: `2018`
    * Authors: Sanjoy Dasgupta, Akansha Dey, Nicholas Roberts, Sivan Sabato
    * Abstract: We consider the problem of learning a multi-class classifier from labels as well as simple explanations that we call "discriminative features". We show that such explanations can be provided whenever the target concept is a decision tree, or more generally belongs to a particular subclass of DNF formulas. We present an efficient online algorithm for learning from such feedback and we give tight bounds on the number of mistakes made during the learning process. These bounds depend only on the size of the target concept and not on the overall number of available features, which could be infinite. We also demonstrate the learning procedure experimentally.
count=3
* Multivariate Time Series Imputation with Generative Adversarial Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/96b9bff013acedfb1d140579e2fbeb63-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/96b9bff013acedfb1d140579e2fbeb63-Paper.pdf)]
    * Title: Multivariate Time Series Imputation with Generative Adversarial Networks
    * Year: `2018`
    * Authors: Yonghong Luo, Xiangrui Cai, Ying ZHANG, Jun Xu, Yuan xiaojie
    * Abstract: Multivariate time series usually contain a large number of missing values, which hinders the application of advanced analysis methods on multivariate time series data. Conventional approaches to addressing the challenge of missing values, including mean/zero imputation, case deletion, and matrix factorization-based imputation, are all incapable of modeling the temporal dependencies and the nature of complex distribution in multivariate time series. In this paper, we treat the problem of missing value imputation as data generation. Inspired by the success of Generative Adversarial Networks (GAN) in image generation, we propose to learn the overall distribution of a multivariate time series dataset with GAN, which is further used to generate the missing values for each sample. Different from the image data, the time series data are usually incomplete due to the nature of data recording process. A modified Gate Recurrent Unit is employed in GAN to model the temporal irregularity of the incomplete time series. Experiments on two multivariate time series datasets show that the proposed model outperformed the baselines in terms of accuracy of imputation. Experimental results also showed that a simple model on the imputed data can achieve state-of-the-art results on the prediction tasks, demonstrating the benefits of our model in downstream applications.
count=3
* Active Learning for Non-Parametric Regression Using Purely Random Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/dc4c44f624d600aa568390f1f1104aa0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/dc4c44f624d600aa568390f1f1104aa0-Paper.pdf)]
    * Title: Active Learning for Non-Parametric Regression Using Purely Random Trees
    * Year: `2018`
    * Authors: Jack Goetz, Ambuj Tewari, Paul Zimmerman
    * Abstract: Active learning is the task of using labelled data to select additional points to label, with the goal of fitting the most accurate model with a fixed budget of labelled points. In binary classification active learning is known to produce faster rates than passive learning for a broad range of settings. However in regression restrictive structure and tailored methods were previously needed to obtain theoretically superior performance. In this paper we propose an intuitive tree based active learning algorithm for non-parametric regression with provable improvement over random sampling. When implemented with Mondrian Trees our algorithm is tuning parameter free, consistent and minimax optimal for Lipschitz functions.
count=3
* Online multiclass boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/08b255a5d42b89b0585260b6f2360bdd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/08b255a5d42b89b0585260b6f2360bdd-Paper.pdf)]
    * Title: Online multiclass boosting
    * Year: `2017`
    * Authors: Young Hun Jung, Jack Goetz, Ambuj Tewari
    * Abstract: Recent work has extended the theoretical analysis of boosting algorithms to multiclass problems and to online settings. However, the multiclass extension is in the batch setting and the online extensions only consider binary classification. We fill this gap in the literature by defining, and justifying, a weak learning condition for online multiclass boosting. This condition leads to an optimal boosting algorithm that requires the minimal number of weak learners to achieve a certain accuracy. Additionally, we propose an adaptive algorithm which is near optimal and enjoys an excellent performance on real data due to its adaptive property.
count=3
* Discriminative State Space Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/6fe131632103526e3a6e8114c78eb1e1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/6fe131632103526e3a6e8114c78eb1e1-Paper.pdf)]
    * Title: Discriminative State Space Models
    * Year: `2017`
    * Authors: Vitaly Kuznetsov, Mehryar Mohri
    * Abstract: In this paper, we introduce and analyze Discriminative State-Space Models for forecasting non-stationary time series. We provide data-dependent generalization guarantees for learning these models based on the recently introduced notion of discrepancy. We provide an in-depth analysis of the complexity of such models. Finally, we also study the generalization guarantees for several structural risk minimization approaches to this problem and provide an efficient implementation for one of them which is based on a convex objective.
count=3
* Learning with Feature Evolvable Streams
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/7634ea65a4e6d9041cfd3f7de18e334a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/7634ea65a4e6d9041cfd3f7de18e334a-Paper.pdf)]
    * Title: Learning with Feature Evolvable Streams
    * Year: `2017`
    * Authors: Bo-Jian Hou, Lijun Zhang, Zhi-Hua Zhou
    * Abstract: Learning with streaming data has attracted much attention during the past few years.Though most studies consider data stream with fixed features, in real practice the features may be evolvable. For example, features of data gathered by limited lifespan sensors will change when these sensors are substituted by new ones. In this paper, we propose a novel learning paradigm: Feature Evolvable Streaming Learning where old features would vanish and new features would occur. Rather than relying on only the current features, we attempt to recover the vanished features and exploit it to improve performance. Specifically, we learn two models from the recovered features and the current features, respectively. To benefit from the recovered features, we develop two ensemble methods. In the first method, we combine the predictions from two models and theoretically show that with the assistance of old features, the performance on new features can be improved. In the second approach, we dynamically select the best single prediction and establish a better performance guarantee when the best model switches. Experiments on both synthetic and real data validate the effectiveness of our proposal.
count=3
* A Unified Approach to Interpreting Model Predictions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf)]
    * Title: A Unified Approach to Interpreting Model Predictions
    * Year: `2017`
    * Authors: Scott M. Lundberg, Su-In Lee
    * Abstract: Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.
count=3
* Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf)]
    * Title: Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles
    * Year: `2017`
    * Authors: Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell
    * Abstract: Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.
count=3
* Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/d5e2fbef30a4eb668a203060ec8e5eef-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/d5e2fbef30a4eb668a203060ec8e5eef-Paper.pdf)]
    * Title: Efficient High-Order Interaction-Aware Feature Selection Based on Conditional Mutual Information
    * Year: `2016`
    * Authors: Alexander Shishkin, Anastasia Bezzubtseva, Alexey Drutsa, Ilia Shishkov, Ekaterina Gladkikh, Gleb Gusev, Pavel Serdyukov
    * Abstract: This study introduces a novel feature selection approach CMICOT, which is a further evolution of filter methods with sequential forward selection (SFS) whose scoring functions are based on conditional mutual information (MI). We state and study a novel saddle point (max-min) optimization problem to build a scoring function that is able to identify joint interactions between several features. This method fills the gap of MI-based SFS techniques with high-order dependencies. In this high-dimensional case, the estimation of MI has prohibitively high sample complexity. We mitigate this cost using a greedy approximation and binary representatives what makes our technique able to be effectively used. The superiority of our approach is demonstrated by comparison with recently proposed interaction-aware filters and several interaction-agnostic state-of-the-art ones on ten publicly available benchmark datasets.
count=3
* Large-scale probabilistic predictors with and without guarantees of validity
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/a9a1d5317a33ae8cef33961c34144f84-Paper.pdf)]
    * Title: Large-scale probabilistic predictors with and without guarantees of validity
    * Year: `2015`
    * Authors: Vladimir Vovk, Ivan Petej, Valentina Fedorova
    * Abstract: This paper studies theoretically and empirically a method of turning machine-learning algorithms into probabilistic predictors that automatically enjoys a property of validity (perfect calibration) and is computationally efficient. The price to pay for perfect calibration is that these probabilistic predictors produce imprecise (in practice, almost precise for large data sets) probabilities. When these imprecise probabilities are merged into precise probabilities, the resulting predictors, while losing the theoretical property of perfect calibration, are consistently more accurate than the existing methods in empirical studies.
count=3
* Algorithm selection by rational metareasoning as a model of human strategy selection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/7fb8ceb3bd59c7956b1df66729296a4c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/7fb8ceb3bd59c7956b1df66729296a4c-Paper.pdf)]
    * Title: Algorithm selection by rational metareasoning as a model of human strategy selection
    * Year: `2014`
    * Authors: Falk Lieder, Dillon Plunkett, Jessica B. Hamrick, Stuart J. Russell, Nicholas Hay, Tom Griffiths
    * Abstract: Selecting the right algorithm is an important problem in computer science, because the algorithm often has to exploit the structure of the input to be efficient. The human mind faces the same challenge. Therefore, solutions to the algorithm selection problem can inspire models of human strategy selection and vice versa. Here, we view the algorithm selection problem as a special case of metareasoning and derive a solution that outperforms existing methods in sorting algorithm selection. We apply our theory to model how people choose between cognitive strategies and test its prediction in a behavioral experiment. We find that people quickly learn to adaptively choose between cognitive strategies. People's choices in our experiment are consistent with our model but inconsistent with previous theories of human strategy selection. Rational metareasoning appears to be a promising framework for reverse-engineering how people choose among cognitive strategies and translating the results into better solutions to the algorithm selection problem.
count=3
* A Representation Theory for Ranking Functions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/d96409bf894217686ba124d7356686c9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/d96409bf894217686ba124d7356686c9-Paper.pdf)]
    * Title: A Representation Theory for Ranking Functions
    * Year: `2014`
    * Authors: Harsh H. Pareek, Pradeep K. Ravikumar
    * Abstract: This paper presents a representation theory for permutation-valued functions, which in their general form can also be called listwise ranking functions. Pointwise ranking functions assign a score to each object independently, without taking into account the other objects under consideration; whereas listwise loss functions evaluate the set of scores assigned to all objects as a whole. In many supervised learning to rank tasks, it might be of interest to use listwise ranking functions instead; in particular, the Bayes Optimal ranking functions might themselves be listwise, especially if the loss function is listwise. A key caveat to using listwise ranking functions has been the lack of an appropriate representation theory for such functions. We show that a natural symmetricity assumption that we call exchangeability allows us to explicitly characterize the set of such exchangeable listwise ranking functions. Our analysis draws from the theories of tensor analysis, functional analysis and De Finetti theorems. We also present experiments using a novel reranking method motivated by our representation theory.
count=3
* A Latent Source Model for Nonparametric Time Series Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/a8849b052492b5106526b2331e526138-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/a8849b052492b5106526b2331e526138-Paper.pdf)]
    * Title: A Latent Source Model for Nonparametric Time Series Classification
    * Year: `2013`
    * Authors: George H. Chen, Stanislav Nikolov, Devavrat Shah
    * Abstract: For classifying time series, a nearest-neighbor approach is widely used in practice with performance often competitive with or better than more elaborate methods such as neural networks, decision trees, and support vector machines. We develop theoretical justification for the effectiveness of nearest-neighbor-like classification of time series. Our guiding hypothesis is that in many applications, such as forecasting which topics will become trends on Twitter, there aren't actually that many prototypical time series to begin with, relative to the number of time series we have access to, e.g., topics become trends on Twitter only in a few distinct manners whereas we can collect massive amounts of Twitter data. To operationalize this hypothesis, we propose a latent source model for time series, which naturally leads to a weighted majority voting" classification rule that can be approximated by a nearest-neighbor classifier. We establish nonasymptotic performance guarantees of both weighted majority voting and nearest-neighbor classification under our model accounting for how much of the time series we observe and the model complexity. Experimental results on synthetic data show weighted majority voting achieving the same misclassification rate as nearest-neighbor classification while observing less of the time series. We then use weighted majority to forecast which news topics on Twitter become trends, where we are able to detect such "trending topics" in advance of Twitter 79% of the time, with a mean early advantage of 1 hour and 26 minutes, a true positive rate of 95%, and a false positive rate of 4%.
count=3
* Feature-aware Label Space Dimension Reduction for Multi-label Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/d4c2e4a3297fe25a71d030b67eb83bfc-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/d4c2e4a3297fe25a71d030b67eb83bfc-Paper.pdf)]
    * Title: Feature-aware Label Space Dimension Reduction for Multi-label Classification
    * Year: `2012`
    * Authors: Yao-nan Chen, Hsuan-tien Lin
    * Abstract: Label space dimension reduction (LSDR) is an efficient and effective paradigm for multi-label classification with many classes. Existing approaches to LSDR, such as compressive sensing and principal label space transformation, exploit only the label part of the dataset, but not the feature part. In this paper, we propose a novel approach to LSDR that considers both the label and the feature parts. The approach, called conditional principal label space transformation, is based on minimizing an upper bound of the popular Hamming loss. The minimization step of the approach can be carried out efficiently by a simple use of singular value decomposition. In addition, the approach can be extended to a kernelized version that allows the use of sophisticated feature combinations to assist LSDR. The experimental results verify that the proposed approach is more effective than existing ones to LSDR across many real-world datasets.
count=3
* Projection Retrieval for Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/ea8fcd92d59581717e06eb187f10666d-Paper.pdf)]
    * Title: Projection Retrieval for Classification
    * Year: `2012`
    * Authors: Madalina Fiterau, Artur Dubrawski
    * Abstract: In many applications classification systems often require in the loop human intervention. In such cases the decision process must be transparent and comprehensible simultaneously requiring minimal assumptions on the underlying data distribution. To tackle this problem, we formulate it as an axis-alligned subspacefinding task under the assumption that query specific information dictates the complementary use of the subspaces. We develop a regression-based approach called RECIP that efficiently solves this problem by finding projections that minimize a nonparametric conditional entropy estimator. Experiments show that the method is accurate in identifying the informative projections of the dataset, picking the correct ones to classify query points and facilitates visual evaluation by users.
count=2
* Learning without Exact Guidance: Updating Large-scale High-resolution Land Cover Maps from Low-resolution Historical Labels
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Li_Learning_without_Exact_Guidance_Updating_Large-scale_High-resolution_Land_Cover_Maps_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Learning_without_Exact_Guidance_Updating_Large-scale_High-resolution_Land_Cover_Maps_CVPR_2024_paper.pdf)]
    * Title: Learning without Exact Guidance: Updating Large-scale High-resolution Land Cover Maps from Low-resolution Historical Labels
    * Year: `2024`
    * Authors: Zhuohong Li, Wei He, Jiepan Li, Fangxiao Lu, Hongyan Zhang
    * Abstract: Large-scale high-resolution (HR) land-cover mapping is a vital task to survey the Earth's surface and resolve many challenges facing humanity. However it is still a non-trivial task hindered by complex ground details various landforms and the scarcity of accurate training labels over a wide-span geographic area. In this paper we propose an efficient weakly supervised framework (Paraformer) to guide large-scale HR land-cover mapping with easy-access historical land-cover data of low resolution (LR). Specifically existing land-cover mapping approaches reveal the dominance of CNNs in preserving local ground details but still suffer from insufficient global modeling in various landforms. Therefore we design a parallel CNN-Transformer feature extractor in Paraformer consisting of a downsampling-free CNN branch and a Transformer branch to jointly capture local and global contextual information. Besides facing the spatial mismatch of training data a pseudo-label-assisted training (PLAT) module is adopted to reasonably refine LR labels for weakly supervised semantic segmentation of HR images. Experiments on two large-scale datasets demonstrate the superiority of Paraformer over other state-of-the-art methods for automatically updating HR land-cover maps from LR historical labels.
count=2
* SketchXAI: A First Look at Explainability for Human Sketches
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Qu_SketchXAI_A_First_Look_at_Explainability_for_Human_Sketches_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Qu_SketchXAI_A_First_Look_at_Explainability_for_Human_Sketches_CVPR_2023_paper.pdf)]
    * Title: SketchXAI: A First Look at Explainability for Human Sketches
    * Year: `2023`
    * Authors: Zhiyu Qu, Yulia Gryaditskaya, Ke Li, Kaiyue Pang, Tao Xiang, Yi-Zhe Song
    * Abstract: This paper, for the very first time, introduces human sketches to the landscape of XAI (Explainable Artificial Intelligence). We argue that sketch as a "human-centred" data form, represents a natural interface to study explainability. We focus on cultivating sketch-specific explainability designs. This starts by identifying strokes as a unique building block that offers a degree of flexibility in object construction and manipulation impossible in photos. Following this, we design a simple explainability-friendly sketch encoder that accommodates the intrinsic properties of strokes: shape, location, and order. We then move on to define the first ever XAI task for sketch, that of stroke location inversion SLI. Just as we have heat maps for photos, and correlation matrices for text, SLI offers an explainability angle to sketch in terms of asking a network how well it can recover stroke locations of an unseen sketch. We offer qualitative results for readers to interpret as snapshots of the SLI process in the paper, and as GIFs on the project page. A minor but interesting note is that thanks to its sketch-specific design, our sketch encoder also yields the best sketch recognition accuracy to date while having the smallest number of parameters. The code is available at https://sketchxai.github.io.
count=2
* Make-a-Story: Visual Memory Conditioned Consistent Story Generation
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Rahman_Make-a-Story_Visual_Memory_Conditioned_Consistent_Story_Generation_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Rahman_Make-a-Story_Visual_Memory_Conditioned_Consistent_Story_Generation_CVPR_2023_paper.pdf)]
    * Title: Make-a-Story: Visual Memory Conditioned Consistent Story Generation
    * Year: `2023`
    * Authors: Tanzila Rahman, Hsin-Ying Lee, Jian Ren, Sergey Tulyakov, Shweta Mahajan, Leonid Sigal
    * Abstract: There has been a recent explosion of impressive generative models that can produce high quality images (or videos) conditioned on text descriptions. However, all such approaches rely on conditional sentences that contain unambiguous descriptions of scenes and main actors in them. Therefore employing such models for more complex task of story visualization, where naturally references and co-references exist, and one requires to reason about when to maintain consistency of actors and backgrounds across frames/scenes, and when not to, based on story progression, remains a challenge. In this work, we address the aforementioned challenges and propose a novel autoregressive diffusion-based framework with a visual memory module that implicitly captures the actor and background context across the generated frames. Sentence-conditioned soft attention over the memories enables effective reference resolution and learns to maintain scene and actor consistency when needed. To validate the effectiveness of our approach, we extend the MUGEN dataset and introduce additional characters, backgrounds and referencing in multi-sentence storylines. Our experiments for story generation on the MUGEN, the PororoSV and the FlintstonesSV dataset show that our method not only outperforms prior state-of-the-art in generating frames with high visual quality, which are consistent with the story, but also models appropriate correspondences between the characters and the background.
count=2
* Starting From Non-Parametric Networks for 3D Point Cloud Analysis
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Starting_From_Non-Parametric_Networks_for_3D_Point_Cloud_Analysis_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Starting_From_Non-Parametric_Networks_for_3D_Point_Cloud_Analysis_CVPR_2023_paper.pdf)]
    * Title: Starting From Non-Parametric Networks for 3D Point Cloud Analysis
    * Year: `2023`
    * Authors: Renrui Zhang, Liuhui Wang, Yali Wang, Peng Gao, Hongsheng Li, Jianbo Shi
    * Abstract: We present a Non-parametric Network for 3D point cloud analysis, Point-NN, which consists of purely non-learnable components: farthest point sampling (FPS), k-nearest neighbors (k-NN), and pooling operations, with trigonometric functions. Surprisingly, it performs well on various 3D tasks, requiring no parameters or training, and even surpasses existing fully trained models. Starting from this basic non-parametric model, we propose two extensions. First, Point-NN can serve as a base architectural framework to construct Parametric Networks by simply inserting linear layers on top. Given the superior non-parametric foundation, the derived Point-PN exhibits a high performance-efficiency trade-off with only a few learnable parameters. Second, Point-NN can be regarded as a plug-and-play module for the already trained 3D models during inference. Point-NN captures the complementary geometric knowledge and enhances existing methods for different 3D benchmarks without re-training. We hope our work may cast a light on the community for understanding 3D point clouds with non-parametric methods. Code is available at https://github.com/ZrrSkywalker/Point-NN.
count=2
* Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.pdf)]
    * Title: Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification
    * Year: `2022`
    * Authors: Jingzhou Chen, Peng Wang, Jian Liu, Yuntao Qian
    * Abstract: Hierarchical multi-granularity classification (HMC) assigns hierarchical multi-granularity labels to each object and focuses on encoding the label hierarchy, e.g., ["Albatross", "Laysan Albatross"] from coarse-to-fine levels. However, the definition of what is fine-grained is subjective, and the image quality may affect the identification. Thus, samples could be observed at any level of the hierarchy, e.g., ["Albatross"] or ["Albatross", "Laysan Albatross"], and examples discerned at coarse categories are often neglected in the conventional setting of HMC. In this paper, we study the HMC problem in which objects are labeled at any level of the hierarchy. The essential designs of the proposed method are derived from two motivations: (1) learning with objects labeled at various levels should transfer hierarchical knowledge between levels; (2) lower-level classes should inherit attributes related to upper-level superclasses. The proposed combinatorial loss maximizes the marginal probability of the observed ground truth label by aggregating information from related labels defined in the tree hierarchy. If the observed label is at the leaf level, the combinatorial loss further imposes the multi-class cross-entropy loss to increase the weight of fine-grained classification loss. Considering the hierarchical feature interaction, we propose a hierarchical residual network (HRN), in which granularity-specific features from parent levels acting as residual connections are added to features of children levels. Experiments on three commonly used datasets demonstrate the effectiveness of our approach compared to the state-of-the-art HMC approaches. The code will be available at https://github.com/MonsterZhZh/HRN.
count=2
* HINT: Hierarchical Neuron Concept Explainer
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.pdf)]
    * Title: HINT: Hierarchical Neuron Concept Explainer
    * Year: `2022`
    * Authors: Andong Wang, Wei-Ning Lee, Xiaojuan Qi
    * Abstract: To interpret deep networks, one main approach is to associate neurons with human-understandable concepts. However, existing methods often ignore the inherent connections of different concepts (e.g., dog and cat both belong to animals), and thus lose the chance to explain neurons responsible for higher-level concepts (e.g., animal). In this paper, we study hierarchical concepts inspired by the hierarchical cognition process of human beings. To this end, we propose HIerarchical Neuron concepT explainer (HINT) to effectively build bidirectional associations between neurons and hierarchical concepts in a low-cost and scalable manner. HINT enables us to systematically and quantitatively study whether and how the implicit hierarchical relationships of concepts are embedded into neurons. Specifically, HINT identifies collaborative neurons responsible for one concept and multimodal neurons pertinent to different concepts, at different semantic levels from concrete concepts (e.g., dog) to more abstract ones (e.g., animal). Finally, we verify the faithfulness of the associations using Weakly Supervised Object Localization, and demonstrate its applicability in various tasks, such as discovering saliency regions and explaining adversarial attacks. Code is available on https://github.com/AntonotnaWang/HINT.
count=2
* Attributable Visual Similarity Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Attributable_Visual_Similarity_Learning_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Attributable_Visual_Similarity_Learning_CVPR_2022_paper.pdf)]
    * Title: Attributable Visual Similarity Learning
    * Year: `2022`
    * Authors: Borui Zhang, Wenzhao Zheng, Jie Zhou, Jiwen Lu
    * Abstract: This paper proposes an attributable visual similarity learning (AVSL) framework for a more accurate and explainable similarity measure between images. Most existing similarity learning methods exacerbate the unexplainability by mapping each sample to a single point in the embedding space with a distance metric (e.g., Mahalanobis distance, Euclidean distance). Motivated by the human semantic similarity cognition, we propose a generalized similarity learning paradigm to represent the similarity between two images with a graph and then infer the overall similarity accordingly. Furthermore, we establish a bottom-up similarity construction and top-down similarity inference framework to infer the similarity based on semantic hierarchy consistency. We first identify unreliable higher-level similarity nodes and then correct them using the most coherent adjacent lower-level similarity nodes, which simultaneously preserve traces for similarity attribution. Extensive experiments on the CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate significant improvements over existing deep similarity learning methods and verify the interpretability of our framework.
count=2
* Dist-PU: Positive-Unlabeled Learning From a Label Distribution Perspective
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Dist-PU_Positive-Unlabeled_Learning_From_a_Label_Distribution_Perspective_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Dist-PU_Positive-Unlabeled_Learning_From_a_Label_Distribution_Perspective_CVPR_2022_paper.pdf)]
    * Title: Dist-PU: Positive-Unlabeled Learning From a Label Distribution Perspective
    * Year: `2022`
    * Authors: Yunrui Zhao, Qianqian Xu, Yangbangyan Jiang, Peisong Wen, Qingming Huang
    * Abstract: Positive-Unlabeled (PU) learning tries to learn binary classifiers from a few labeled positive examples with many unlabeled ones. Compared with ordinary semi-supervised learning, this task is much more challenging due to the absence of any known negative labels. While existing cost-sensitive-based methods have achieved state-of-the-art performances, they explicitly minimize the risk of classifying unlabeled data as negative samples, which might result in a negative-prediction preference of the classifier. To alleviate this issue, we resort to a label distribution perspective for PU learning in this paper. Noticing that the label distribution of unlabeled data is fixed when the class prior is known, it can be naturally used as supervision for the model. Motivated by this, we propose to pursue the label distribution consistency between predicted and ground-truth label distributions, which is formulated by aligning their expectations. Moreover, we further adopt the entropy minimization and Mixup regularization to avoid the trivial solution of the label distribution consistency on unlabeled data and mitigate the consequent confirmation bias. Experiments on three benchmark datasets validate the effectiveness of the proposed method.
count=2
* 3D Graph Anatomy Geometry-Integrated Network for Pancreatic Mass Segmentation, Diagnosis, and Quantitative Patient Management
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_3D_Graph_Anatomy_Geometry-Integrated_Network_for_Pancreatic_Mass_Segmentation_Diagnosis_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_3D_Graph_Anatomy_Geometry-Integrated_Network_for_Pancreatic_Mass_Segmentation_Diagnosis_CVPR_2021_paper.pdf)]
    * Title: 3D Graph Anatomy Geometry-Integrated Network for Pancreatic Mass Segmentation, Diagnosis, and Quantitative Patient Management
    * Year: `2021`
    * Authors: Tianyi Zhao, Kai Cao, Jiawen Yao, Isabella Nogues, Le Lu, Lingyun Huang, Jing Xiao, Zhaozheng Yin, Ling Zhang
    * Abstract: The pancreatic disease taxonomy includes ten types of masses (tumors or cysts) [20, 8]. Previous work focuses on developing segmentation or classification methods only for certain mass types. Differential diagnosis of all mass types is clinically highly desirable [20] but has not been investigated using an automated image understanding approach. We exploit the feasibility to distinguish pancreatic ductal adenocarcinoma (PDAC) from the nine other nonPDAC masses using multi-phase CT imaging. Both image appearance and the 3D organ-mass geometry relationship are critical. We propose a holistic segmentation-mesh-classification network (SMCN) to provide patient-level diagnosis, by fully utilizing the geometry and location information, which is accomplished by combining the anatomical structure and the semantic detection-by-segmentation network. SMCN learns the pancreas and mass segmentation task and builds an anatomical correspondence-aware organ mesh model by progressively deforming a pancreas prototype on the raw segmentation mask (i.e., mask-to-mesh). A new graph-based residual convolutional network (Graph-ResNet), whose nodes fuse the information of the mesh model and feature vectors extracted from the segmentation network, is developed to produce the patient-level differential classification results. Extensive experiments on 661 patients' CT scans (five phases per patient) show that SMCN can improve the mass segmentation and detection accuracy compared to the strong baseline method nnUNet (e.g., for nonPDAC, Dice: 0.611 vs. 0.478; detection rate: 89% vs. 70%), achieve similar sensitivity and specificity in differentiating PDAC and nonPDAC as expert radiologists (i.e., 94% and 90%), and obtain results comparable to a multimodality test [20] that combines clinical, imaging, and molecular testing for clinical management of patients.
count=2
* Explaining Knowledge Distillation by Quantifying the Knowledge
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Cheng_Explaining_Knowledge_Distillation_by_Quantifying_the_Knowledge_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Cheng_Explaining_Knowledge_Distillation_by_Quantifying_the_Knowledge_CVPR_2020_paper.pdf)]
    * Title: Explaining Knowledge Distillation by Quantifying the Knowledge
    * Year: `2020`
    * Authors: Xu Cheng,  Zhefan Rao,  Yilan Chen,  Quanshi Zhang
    * Abstract: This paper presents a method to interpret the success of knowledge distillation by quantifying and analyzing task-relevant and task-irrelevant visual concepts that are encoded in intermediate layers of a deep neural network (DNN). More specifically, three hypotheses are proposed as follows. 1. Knowledge distillation makes the DNN learn more visual concepts than learning from raw data. 2. Knowledge distillation ensures that the DNN is prone to learning various visual concepts simultaneously. Whereas, in the scenario of learning from raw data, the DNN learns visual concepts sequentially. 3. Knowledge distillation yields more stable optimization directions than learning from raw data. Accordingly, we design three types of mathematical metrics to evaluate feature representations of the DNN. In experiments, we diagnosed various DNNs, and above hypotheses were verified.
count=2
* Dreaming to Distill: Data-Free Knowledge Transfer via DeepInversion
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Yin_Dreaming_to_Distill_Data-Free_Knowledge_Transfer_via_DeepInversion_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yin_Dreaming_to_Distill_Data-Free_Knowledge_Transfer_via_DeepInversion_CVPR_2020_paper.pdf)]
    * Title: Dreaming to Distill: Data-Free Knowledge Transfer via DeepInversion
    * Year: `2020`
    * Authors: Hongxu Yin,  Pavlo Molchanov,  Jose M. Alvarez,  Zhizhong Li,  Arun Mallya,  Derek Hoiem,  Niraj K. Jha,  Jan Kautz
    * Abstract: We introduce DeepInversion, a new method for synthesizing images from the image distribution used to train a deep neural network. We "invert" a trained network (teacher) to synthesize class-conditional input images starting from random noise, without using any additional information about the training dataset. Keeping the teacher fixed, our method optimizes the input while regularizing the distribution of intermediate feature maps using information stored in the batch normalization layers of the teacher. Further, we improve the diversity of synthesized images using Adaptive DeepInversion, which maximizes the Jensen-Shannon divergence between the teacher and student network logits. The resulting synthesized images from networks trained on the CIFAR-10 and ImageNet datasets demonstrate high fidelity and degree of realism, and help enable a new breed of data-free applications - ones that do not require any real images or labeled data. We demonstrate the applicability of our proposed method to three tasks of immense practical importance - (i) data-free network pruning, (ii) data-free knowledge transfer, and (iii) data-free continual learning.
count=2
* ChamNet: Towards Efficient Network Design Through Platform-Aware Model Adaptation
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Dai_ChamNet_Towards_Efficient_Network_Design_Through_Platform-Aware_Model_Adaptation_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Dai_ChamNet_Towards_Efficient_Network_Design_Through_Platform-Aware_Model_Adaptation_CVPR_2019_paper.pdf)]
    * Title: ChamNet: Towards Efficient Network Design Through Platform-Aware Model Adaptation
    * Year: `2019`
    * Authors: Xiaoliang Dai,  Peizhao Zhang,  Bichen Wu,  Hongxu Yin,  Fei Sun,  Yanghan Wang,  Marat Dukhan,  Yunqing Hu,  Yiming Wu,  Yangqing Jia,  Peter Vajda,  Matt Uyttendaele,  Niraj K. Jha
    * Abstract: This paper proposes an efficient neural network (NN) architecture design methodology called Chameleon that honors given resource constraints. Instead of developing new building blocks or using computationally-intensive reinforcement learning algorithms, our approach leverages existing efficient network building blocks and focuses on exploiting hardware traits and adapting computation resources to fit target latency and/or energy constraints. We formulate platform-aware NN architecture search in an optimization framework and propose a novel algorithm to search for optimal architectures aided by efficient accuracy and resource (latency and/or energy) predictors. At the core of our algorithm lies an accuracy predictor built atop Gaussian Process with Bayesian optimization for iterative sampling. With a one-time building cost for the predictors, our algorithm produces state-of-the-art model architectures on different platforms under given constraints in just minutes. Our results show that adapting computation resources to building blocks is critical to model performance. Without the addition of any special features, our models achieve significant accuracy improvements relative to state-of-the-art handcrafted and automatically designed architectures. We achieve 73.8% and 75.3% top-1 accuracy on ImageNet at 20ms latency on a mobile CPU and DSP. At reduced latency, our models achieve up to 8.2% (4.8%) and 6.7% (9.3%) absolute top-1 accuracy improvements compared to MobileNetV2 and MnasNet, respectively, on a mobile CPU (DSP), and 2.7% (4.6%) and 5.6% (2.6%) accuracy gains over ResNet-101 and ResNet-152, respectively, on an Nvidia GPU (Intel CPU).
count=2
* Learning to Film From Professional Human Motion Videos
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Learning_to_Film_From_Professional_Human_Motion_Videos_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Huang_Learning_to_Film_From_Professional_Human_Motion_Videos_CVPR_2019_paper.pdf)]
    * Title: Learning to Film From Professional Human Motion Videos
    * Year: `2019`
    * Authors: Chong Huang,  Chuan-En Lin,  Zhenyu Yang,  Yan Kong,  Peng Chen,  Xin Yang,  Kwang-Ting Cheng
    * Abstract: We investigate the problem of 6 degrees of freedom (DOF) camera planning for filming professional human motion videos using a camera drone. Existing methods either plan motions for only a pan-tilt-zoom (PTZ) camera, or adopt ad-hoc solutions without carefully considering the impact of video contents and previous camera motions on the future camera motions. As a result, they can hardly achieve satisfactory results in our drone cinematography task. In this study, we propose a learning-based framework which incorporates the video contents and previous camera motions to predict the future camera motions that enable the capture of professional videos. Specifically, the inputs of our framework are video contents which are represented using subject-related feature based on 2D skeleton and scene-related features extracted from background RGB images, and camera motions which are represented using optical flows. The correlation between the inputs and output future camera motions are learned via a sequence-to-sequence convolutional long short-term memory (Seq2Seq ConvLSTM) network from a large set of video clips. We deploy our approach to a real drone cinematography system by first predicting the future camera motions, and then converting them to the drone's control commands via an odometer. Our experimental results on extensive datasets and showcases exhibit significant improvements in our approach over conventional baselines and our approach can successfully mimic the footage of a professional cameraman.
count=2
* Deep Tree Learning for Zero-Shot Face Anti-Spoofing
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Deep_Tree_Learning_for_Zero-Shot_Face_Anti-Spoofing_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Deep_Tree_Learning_for_Zero-Shot_Face_Anti-Spoofing_CVPR_2019_paper.pdf)]
    * Title: Deep Tree Learning for Zero-Shot Face Anti-Spoofing
    * Year: `2019`
    * Authors: Yaojie Liu,  Joel Stehouwer,  Amin Jourabloo,  Xiaoming Liu
    * Abstract: Face anti-spoofing is designed to keep face recognition systems from recognizing fake faces as the genuine users. While advanced face anti-spoofing methods are developed, new types of spoof attacks are also being created and becoming a threat to all existing systems. We define the detection of unknown spoof attacks as Zero-Shot Face Anti-spoofing (ZSFA). Previous works of ZSFA only study 1-2 types of spoof attacks, such as print/replay attacks, which limits the insight of this problem. In this work, we expand the ZSFA problem to a wide range of 13 types of spoof attacks, including print attack, replay attack, 3D mask attacks, and so on. A novel Deep Tree Network (DTN) is proposed to tackle the ZSFA. The tree is learned to partition the spoof samples into semantic sub-groups in an unsupervised fashion. When a data sample arrives, being know or unknown attacks, DTN routes it to the most similar spoof cluster, and make the binary decision. In addition, to enable the study of ZSFA, we introduce the first face anti-spoofing database that contains diverse types of spoof attacks. Experiments show that our proposed method achieves the state of the art on multiple testing protocols of ZSFA.
count=2
* Binary Ensemble Neural Network: More Bits per Network or More Networks per Bit?
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Binary_Ensemble_Neural_Network_More_Bits_per_Network_or_More_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Binary_Ensemble_Neural_Network_More_Bits_per_Network_or_More_CVPR_2019_paper.pdf)]
    * Title: Binary Ensemble Neural Network: More Bits per Network or More Networks per Bit?
    * Year: `2019`
    * Authors: Shilin Zhu,  Xin Dong,  Hao Su
    * Abstract: Binary neural networks (BNN) have been studied extensively since they run dramatically faster at lower memory and power consumption than floating-point networks, thanks to the efficiency of bit operations. However, contemporary BNNs whose weights and activations are both single bits suffer from severe accuracy degradation. To understand why, we investigate the representation ability, speed and bias/variance of BNNs through extensive experiments. We conclude that the error of BNNs is predominantly caused by intrinsic instability (training time) and non-robustness (train & test time). Inspired by this investigation, we propose the Binary Ensemble Neural Network (BENN) which leverages ensemble methods to improve the performance of BNNs with limited efficiency cost. While ensemble techniques have been broadly believed to be only marginally helpful for strong classifiers such as deep neural networks, our analysis and experiments show that they are naturally a perfect fit to boost BNNs. We find that our BENN, which is faster and more robust than state-of-the-art binary networks, can even surpass the accuracy of the full-precision floating number network with the same architecture.
count=2
* Planar Shape Detection at Structural Scales
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Fang_Planar_Shape_Detection_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Fang_Planar_Shape_Detection_CVPR_2018_paper.pdf)]
    * Title: Planar Shape Detection at Structural Scales
    * Year: `2018`
    * Authors: Hao Fang, Florent Lafarge, Mathieu Desbrun
    * Abstract: Interpreting 3D data such as point clouds or surface meshes depends heavily on the scale of observation. Yet, existing algorithms for shape detection rely on trial-and-error parameter tunings to output configurations representative of a structural scale. We present a framework to automatically extract a set of representations that capture the shape and structure of man-made objects at different key abstraction levels. A shape-collapsing process first generates a fine-to-coarse sequence of shape representations by exploiting local planarity. This sequence is then analyzed to identify significant geometric variations between successive representations through a supervised energy minimization. Our framework is flexible enough to learn how to detect both existing structural formalisms such as the CityGML Levels Of Details, and expert-specified levels of abstraction. Experiments on different input data and classes of man-made objects, as well as comparisons with existing shape detection methods, illustrate the strengths of our approach in terms of efficiency and flexibility.
count=2
* UltraStereo: Efficient Learning-Based Matching for Active Stereo Systems
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Fanello_UltraStereo_Efficient_Learning-Based_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Fanello_UltraStereo_Efficient_Learning-Based_CVPR_2017_paper.pdf)]
    * Title: UltraStereo: Efficient Learning-Based Matching for Active Stereo Systems
    * Year: `2017`
    * Authors: Sean Ryan Fanello, Julien Valentin, Christoph Rhemann, Adarsh Kowdle, Vladimir Tankovich, Philip Davidson, Shahram Izadi
    * Abstract: Efficient estimation of depth from pairs of stereo images is one of the core problems in computer vision. We efficiently solve the specialized problem of stereo matching under active illumination using a new learning-based algorithm. This type of 'active' stereo i.e. stereo matching where scene texture is augmented by an active light projector is proving compelling for designing depth cameras, largely due to improved robustness when compared to time of flight or traditional structured light techniques. Our algorithm uses an unsupervised greedy optimization scheme that learns features that are discriminative for estimating correspondences in infrared images. The proposed method optimizes a series of sparse hyperplanes that are used at test time to remap all the image patches into a compact binary representation in O(1). The proposed algorithm is cast in a PatchMatch Stereo-like framework, producing depth maps at 500Hz. In contrast to standard structured light methods, our approach generalizes to different scenes, does not require tedious per camera calibration procedures and is not adversely affected by interference from overlapping sensors. Extensive evaluations show we surpass the quality and overcome the limitations of current depth sensing technologies.
count=2
* Detecting Masked Faces in the Wild With LLE-CNNs
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Ge_Detecting_Masked_Faces_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Ge_Detecting_Masked_Faces_CVPR_2017_paper.pdf)]
    * Title: Detecting Masked Faces in the Wild With LLE-CNNs
    * Year: `2017`
    * Authors: Shiming Ge, Jia Li, Qiting Ye, Zhao Luo
    * Abstract: Detecting masked faces (i.e., faces with occlusions) is a challenging task due to two main reasons: 1)the absence of large datasets of masked faces, and 2)the absence of facial cues from the masked regions. To address these issues, this paper first introduces a dataset with 30,811 Internet images and 35,806 annotated MAsked FAces, which is denoted as MAFA. Different from many previous datasets, each annotated face in MAFA is partially occluded by mask. By analyzing the characteristics of masked faces, we propose LLE-CNNs that detect masked face via three major modules. The proposal module first combines two pre-trained CNNs to extract candidate facial regions from the input image and represent them with high dimensional descriptors. After that, the embedding module turns such descriptors into vectors of weights with respect to the components in pre-trained dictionaries of representative normal faces and non-faces by using locally linear embedding. In this manner, missing facial cues in the masked regions can be largely recovered, and the influences of noisy cues introduced by diversified masks can be greatly alleviated. Finally, the verification module takes the weight vectors as input and identifies real facial regions as well as their accurate positions by jointly performing the classification and regression tasks within unified CNNs. Experimental results on MAFA show that the proposed approach significantly outperforms 6 state-of-the-arts by at least 15.6% in detecting masked faces.
count=2
* Principled Parallel Mean-Field Inference for Discrete Random Fields
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Baque_Principled_Parallel_Mean-Field_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Baque_Principled_Parallel_Mean-Field_CVPR_2016_paper.pdf)]
    * Title: Principled Parallel Mean-Field Inference for Discrete Random Fields
    * Year: `2016`
    * Authors: Pierre Baque, Timur Bagautdinov, Francois Fleuret, Pascal Fua
    * Abstract: Mean-field variational inference is one of the most popular approaches to inference in discrete random fields. Standard mean-field optimization is based on coordinate descent and in many situations can be impractical. Thus, in practice, various parallel techniques are used, which either rely on ad hoc smoothing with heuristically set parameters, or put strong constraints on the type of models. In this paper, we propose a novel proximal gradient-based approach to optimizing the variational objective. It is naturally parallelizable and easy to implement. We prove its convergence, and then demonstrate that, in practice, it yields faster convergence and often finds better optima than more traditional mean-field optimization techniques. Moreover, our method is less sensitive to the choice of parameters.
count=2
* Structured Regression Gradient Boosting
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Diego_Structured_Regression_Gradient_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Diego_Structured_Regression_Gradient_CVPR_2016_paper.pdf)]
    * Title: Structured Regression Gradient Boosting
    * Year: `2016`
    * Authors: Ferran Diego, Fred A. Hamprecht
    * Abstract: We propose a new way to train a structured output prediction model. More specifically, we train nonlinear data terms in a Gaussian Conditional Random Field (GCRF) by a generalized version of gradient boosting. The approach is evaluated on three challenging regression benchmarks: vessel detection, single image depth estimation and image inpainting. These experiments suggest that the proposed boosting framework matches or exceeds the state-of-the-art.
count=2
* HyperDepth: Learning Depth From Structured Light Without Matching
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Fanello_HyperDepth_Learning_Depth_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Fanello_HyperDepth_Learning_Depth_CVPR_2016_paper.pdf)]
    * Title: HyperDepth: Learning Depth From Structured Light Without Matching
    * Year: `2016`
    * Authors: Sean Ryan Fanello, Christoph Rhemann, Vladimir Tankovich, Adarsh Kowdle, Sergio Orts Escolano, David Kim, Shahram Izadi
    * Abstract: Structured light sensors are popular due to their robustness to untextured scenes and multipath. These systems triangulate depth by solving a correspondence problem between each camera and projector pixel. This is often framed as a local stereo matching task, correlating patches of pixels in the observed and reference image. However, this is computationally intensive, leading to reduced depth accuracy and framerate. We contribute an algorithm for solving this correspondence problem efficiently, without compromising depth accuracy. For the first time, this problem is cast as a classification-regression task, which we solve extremely efficiently using an ensemble of cascaded random forests. Our algorithm scales in number of disparities, and each pixel can be processed independently, and in parallel. No matching or even access to the corresponding reference pattern is required at runtime, and regressed labels are directly mapped to depth. Our GPU-based algorithm runs at a 1KHz for 1.3MP input/output images, with disparity error of 0.1 subpixels. We show a prototype high framerate depth camera running at 375Hz, useful for solving tracking-related problems. We demonstrate our algorithmic performance, creating high resolution real-time depth maps that surpass the quality of current state of the art depth technologies, highlighting quantization-free results with reduced holes, edge fattening and other stereo-based depth artifacts.
count=2
* Unsupervised Learning of Edges
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Li_Unsupervised_Learning_of_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Li_Unsupervised_Learning_of_CVPR_2016_paper.pdf)]
    * Title: Unsupervised Learning of Edges
    * Year: `2016`
    * Authors: Yin Li, Manohar Paluri, James M. Rehg, Piotr Dollar
    * Abstract: Data-driven approaches for edge detection have proven effective and achieve top results on modern benchmarks. However, all current data-driven edge detectors require manual supervision for training in the form of hand-labeled region segments or object boundaries. Specifically, human annotators mark semantically meaningful edges which are subsequently used for training. Is this form of strong, high-level supervision actually necessary to learn to accurately detect edges? In this work we present a simple yet effective approach for training edge detectors without human supervision. To this end we utilize motion, and more specifically, the only input to our method is noisy semi-dense matches between frames. We begin with only a rudimentary knowledge of edges (in the form of image gradients), and alternate between improving motion estimation and edge detection in turn. Using a large corpus of video data, we show that edge detectors trained using our unsupervised scheme approach the performance of the same methods trained with full supervision (within 3-5%). Finally, we show that when using a deep network for the edge detector, our approach provides a novel pre-training scheme for object detection.
count=2
* Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Lin_Efficient_Piecewise_Training_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Lin_Efficient_Piecewise_Training_CVPR_2016_paper.pdf)]
    * Title: Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation
    * Year: `2016`
    * Authors: Guosheng Lin, Chunhua Shen, Anton van den Hengel, Ian Reid
    * Abstract: Recent advances in semantic image segmentation have mostly been achieved by training deep convolutional neural networks(CNNs). We show how to improve semantic segmentation through the use of contextual information; specifically, we explore 'patch-patch' context between image regions, and 'patch-background' context. For learning from the patch-patch context, we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the proposed deep structured model is then applied to avoid repeated expensive CRF inference for back propagation. For capturing the patch-background context, we show that a network design with traditional multi-scale image input and sliding pyramid pooling is effective for improving performance. Our experimental results set new state-of-the-art performance on a number of popular semantic segmentation datasets, including NYUDv2, PASCAL VOC 2012, PASCAL-Context, and SIFT-flow. In particular, we achieve an intersection-over-union score of 78.0 on the challenging PASCAL VOC 2012 dataset.
count=2
* Training Region-Based Object Detectors With Online Hard Example Mining
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf)]
    * Title: Training Region-Based Object Detectors With Online Hard Example Mining
    * Year: `2016`
    * Authors: Abhinav Shrivastava, Abhinav Gupta, Ross Girshick
    * Abstract: The field of object detection has made significant advances riding on the wave of region-based ConvNets, but their training procedure still includes many heuristics and hyperparameters that are costly to tune. We present a simple yet surprisingly effective online hard example mining (OHEM) algorithm for training region-based ConvNet detectors. Our motivation is the same as it has always been -- detection datasets contain an overwhelming number of easy examples and a small number of hard examples. Automatic selection of these hard examples can make training more effective and efficient. OHEM is a simple and intuitive algorithm that eliminates several heuristics and hyperparameters in common use. But more importantly, it yields consistent and significant boosts in detection performance on benchmarks like PASCAL VOC 2007 and 2012. Its effectiveness increases as datasets become larger and more difficult, as demonstrated by the results on the MS COCO dataset. Moreover, combined with complementary advances in the field, OHEM leads to state-of-the-art results of 78.9% and 76.3% mAP on PASCAL VOC 2007 and 2012 respectively.
count=2
* BOLD - Binary Online Learned Descriptor For Efficient Image Matching
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Balntas_BOLD_-_Binary_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Balntas_BOLD_-_Binary_2015_CVPR_paper.pdf)]
    * Title: BOLD - Binary Online Learned Descriptor For Efficient Image Matching
    * Year: `2015`
    * Authors: Vassileios Balntas, Lilian Tang, Krystian Mikolajczyk
    * Abstract: In this paper we propose a novel approach to generate a binary descriptor optimized for each image patch independently. The approach is inspired by the linear discriminant embedding that simultaneously increases inter and decreases intra class distances. A set of discriminative and uncorrelated binary tests is established from all possible tests in an offline training process. The patch adapted descriptors are then efficiently built online from a subset of tests which lead to lower intra class distances thus a more robust descriptor. A patch descriptor consists of two binary strings where one represents the results of the tests and the other indicates the subset of the patch-related robust tests that are used for calculating a masked Hamming distance. Our experiments on three different benchmarks demonstrate improvements in matching performance, and illustrate that per-patch optimization outperforms global optimization.
count=2
* Effective Learning-Based Illuminant Estimation Using Simple Features
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Cheng_Effective_Learning-Based_Illuminant_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Cheng_Effective_Learning-Based_Illuminant_2015_CVPR_paper.pdf)]
    * Title: Effective Learning-Based Illuminant Estimation Using Simple Features
    * Year: `2015`
    * Authors: Dongliang Cheng, Brian Price, Scott Cohen, Michael S. Brown
    * Abstract: Illumination estimation is the process of determining the chromaticity of the illumination in an imaged scene in order to remove undesirable color casts through white-balancing. While computational color constancy is a well-studied topic in computer vision, it remains challenging due to the ill-posed nature of the problem. One class of techniques relies on low-level statistical information in the image color distribution and works under various assumptions (e.g. Grey-World, White-Patch, etc). These methods have an advantage that they are simple and fast, but often do not perform well. More recent state-of-the-art methods employ learning-based techniques that produce better results, but often rely on complex features and have long evaluation and training times. In this paper, we present a learning-based method based on four simple color features and show how to use this with an ensemble of regression trees to estimate the illumination. We demonstrate that our approach is not only faster than existing learning-based methods in terms of both evaluation and training time, but also gives the best results reported to date on modern color constancy data sets.
count=2
* Computationally Bounded Retrieval
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Rastegari_Computationally_Bounded_Retrieval_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Rastegari_Computationally_Bounded_Retrieval_2015_CVPR_paper.pdf)]
    * Title: Computationally Bounded Retrieval
    * Year: `2015`
    * Authors: Mohammad Rastegari, Cem Keskin, Pushmeet Kohli, Shahram Izadi
    * Abstract: The increase in size of large image databases makes the problem of efficient retrieval extremely challenging. This is especially true in the case of high dimensional data where even operations like hashing become expensive because of costly projection operators. Unlike most hashing methods that sacrifice accuracy for speed, we propose a novel method that improves the speed of high dimensional image retrieval by several orders of magnitude without any significant drop in performance. To do this, we propose to learn computationally bounded sparse projections for the encoding step. To further increase the accuracy of the method, we add an orthogonality constraint on projections to reduce bit correlation. We then introduce an iterative scheme that jointly optimizes this objective, which helps us obtain fast and efficient projections. We demonstrate this technique on large retrieval databases, specifically ImageNET, GIST1M and SUN-attribute for the task of nearest neighbor retrieval, and show that our method achieves a speed-up of up to a factor of 100 over state-of-the-art methods, while having on-par and in some cases even better accuracy.
count=2
* Completing 3D Object Shape From One Depth Image
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Rock_Completing_3D_Object_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Rock_Completing_3D_Object_2015_CVPR_paper.pdf)]
    * Title: Completing 3D Object Shape From One Depth Image
    * Year: `2015`
    * Authors: Jason Rock, Tanmay Gupta, Justin Thorsen, JunYoung Gwak, Daeyun Shin, Derek Hoiem
    * Abstract: Our goal is to recover a complete 3D model from a depth image of an object. Existing approaches rely on user interaction or apply to a limited class of objects, such as chairs. We aim to fully automatically reconstruct a 3D model from any category. We take an exemplar-based approach: retrieve similar objects in a database of 3D models using view-based matching and transfer the symmetries and surfaces from retrieved models. We investigate completion of 3D models in three cases: novel view (model in database); novel model (models for other objects of the same category in database); and novel category (no models from the category in database).
count=2
* Situational Object Boundary Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Uijlings_Situational_Object_Boundary_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Uijlings_Situational_Object_Boundary_2015_CVPR_paper.pdf)]
    * Title: Situational Object Boundary Detection
    * Year: `2015`
    * Authors: Jasper R. R. Uijlings, Vittorio Ferrari
    * Abstract: Intuitively, the appearance of true object boundaries varies from image to image. Hence the usual monolithic approach of training a single boundary predictor and applying it to all images regardless of their content is bound to be suboptimal. In this paper we therefore propose Situational Object Boundary Detection: we first define a variety of situations and train a specialized object boundary detector for each of them using [Dollar13]. Then given a test image, we classify it into these situations using its context, which we model by global image appearance. We apply the corresponding situational object boundary detectors, and fuse them based on the classification probabilities. In experiments on ImageNet [Russakovsky14], Microsoft COCO [Lin], and Pascal VOC 2012 segmentation [Everingham14] we show that our situational object boundary detection gives significant improvements over a monolithic approach. Additionally, our method substantially outperforms [Hariharan11iccv] on semantic contour detection on their SBD dataset.
count=2
* Birdsnap: Large-scale Fine-grained Visual Categorization of Birds
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Berg_Birdsnap_Large-scale_Fine-grained_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Berg_Birdsnap_Large-scale_Fine-grained_2014_CVPR_paper.pdf)]
    * Title: Birdsnap: Large-scale Fine-grained Visual Categorization of Birds
    * Year: `2014`
    * Authors: Thomas Berg, Jiongxin Liu, Seung Woo Lee, Michelle L. Alexander, David W. Jacobs, Peter N. Belhumeur
    * Abstract: We address the problem of large-scale fine-grained visual categorization, describing new methods we have used to produce an online field guide to 500 North American bird species. We focus on the challenges raised when such a system is asked to distinguish between highly similar species of birds. First, we introduce "one-vs-most classifiers." By eliminating highly similar species during training, these classifiers achieve more accurate and intuitive results than common one-vs-all classifiers. Second, we show how to estimate spatio-temporal class priors from observations that are sampled at irregular and biased locations. We show how these priors can be used to significantly improve performance. We then show state-of-the-art recognition performance on a new, large dataset that we make publicly available. These recognition methods are integrated into the online field guide, which is also publicly available.
count=2
* Curvilinear Structure Tracking by Low Rank Tensor Approximation with Model Propagation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Cheng_Curvilinear_Structure_Tracking_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Cheng_Curvilinear_Structure_Tracking_2014_CVPR_paper.pdf)]
    * Title: Curvilinear Structure Tracking by Low Rank Tensor Approximation with Model Propagation
    * Year: `2014`
    * Authors: Erkang Cheng, Yu Pang, Ying Zhu, Jingyi Yu, Haibin Ling
    * Abstract: Robust tracking of deformable object like catheter or vascular structures in X-ray images is an important technique used in image guided medical interventions for effective motion compensation and dynamic multi-modality image fusion. Tracking of such anatomical structures and devices is very challenging due to large degrees of appearance changes, low visibility of X-ray images and the deformable nature of the underlying motion field as a result of complex 3D anatomical movements projected into 2D images. To address these issues, we propose a new deformable tracking method using the tensor-based algorithm with model propagation. Specifically, the deformable tracking is formulated as a multi-dimensional assignment problem which is solved by rank-1 l1 tensor approximation. The model prior is propagated in the course of deformable tracking. Both the higher order information and the model prior provide powerful discriminative cues for reducing ambiguity arising from the complex background, and consequently improve the tracking robustness. To validate the proposed approach, we applied it to catheter and vascular structures tracking and tested on X-ray fluoroscopic sequences obtained from 17 clinical cases. The results show, both quantitatively and qualitatively, that our approach achieves a mean tracking error of 1.4 pixels for vascular structure and 1.3 pixels for catheter tracking.
count=2
* From Categories to Individuals in Real Time -- A Unified Boosting Approach
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Hall_From_Categories_to_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Hall_From_Categories_to_2014_CVPR_paper.pdf)]
    * Title: From Categories to Individuals in Real Time -- A Unified Boosting Approach
    * Year: `2014`
    * Authors: David Hall, Pietro Perona
    * Abstract: A method for online, real-time learning of individual-object detectors is presented. Starting with a pre-trained boosted category detector, an individual-object detector is trained with near-zero computational cost. The individual detector is obtained by using the same feature cascade as the category detector along with elementary manipulations of the thresholds of the weak classifiers. This is ideal for online operation on a video stream or for interactive learning. Applications addressed by this technique are reidentification and individual tracking. Experiments on four challenging pedestrian and face datasets indicate that it is indeed possible to learn identity classifiers in real-time; besides being faster-trained, our classifier has better detection rates than previous methods on two of the datasets.
count=2
* Automatic Feature Learning for Robust Shadow Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Khan_Automatic_Feature_Learning_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Khan_Automatic_Feature_Learning_2014_CVPR_paper.pdf)]
    * Title: Automatic Feature Learning for Robust Shadow Detection
    * Year: `2014`
    * Authors: Salman Hameed Khan, Mohammed Bennamoun, Ferdous Sohel, Roberto Togneri
    * Abstract: We present a practical framework to automatically detect shadows in real world scenes from a single photograph. Previous works on shadow detection put a lot of effort in designing shadow variant and invariant hand-crafted features. In contrast, our framework automatically learns the most relevant features in a supervised manner using multiple convolutional deep neural networks (ConvNets). The 7-layer network architecture of each ConvNet consists of alternating convolution and sub-sampling layers. The proposed framework learns features at the super-pixel level and along the object boundaries. In both cases, features are extracted using a context aware window centered at interest points. The predicted posteriors based on the learned features are fed to a conditional random field model to generate smooth shadow contours. Our proposed framework consistently performed better than the state-of-the-art on all major shadow databases collected under a variety of conditions.
count=2
* Discriminative Ferns Ensemble for Hand Pose Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Krupka_Discriminative_Ferns_Ensemble_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Krupka_Discriminative_Ferns_Ensemble_2014_CVPR_paper.pdf)]
    * Title: Discriminative Ferns Ensemble for Hand Pose Recognition
    * Year: `2014`
    * Authors: Eyal Krupka, Alon Vinnikov, Ben Klein, Aharon Bar Hillel, Daniel Freedman, Simon Stachniak
    * Abstract: We present the Discriminative Ferns Ensemble (DFE) classifier for efficient visual object recognition. The classifier architecture is designed to optimize both classification speed and accuracy when a large training set is available. Speed is obtained using simple binary features and direct indexing into a set of tables, and accuracy by using a large capacity model and careful discriminative optimization. The proposed framework is applied to the problem of hand pose recognition in depth and infra-red images, using a very large training set. Both the accuracy and the classification time obtained are considerably superior to relevant competing methods, allowing one to reach accuracy targets with run times orders of magnitude faster than the competition. We show empirically that using DFE, we can significantly reduce classification time by increasing training sample size for a fixed target accuracy. Finally a DFE result is shown for the MNIST dataset, showing the method's merit extends beyond depth images.
count=2
* Optimal Decisions from Probabilistic Models: The Intersection-over-Union Case
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Nowozin_Optimal_Decisions_from_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Nowozin_Optimal_Decisions_from_2014_CVPR_paper.pdf)]
    * Title: Optimal Decisions from Probabilistic Models: The Intersection-over-Union Case
    * Year: `2014`
    * Authors: Sebastian Nowozin
    * Abstract: A probabilistic model allows us to reason about the world and make statistically optimal decisions using Bayesian decision theory. However, in practice the intractability of the decision problem forces us to adopt simplistic loss functions such as the 0/1 loss or Hamming loss and as result we make poor decisions through MAP estimates or through low-order marginal statistics. In this work we investigate optimal decision making for more realistic loss functions. Specifically we consider the popular intersection-over-union (IoU) score used in image segmentation benchmarks and show that it results in a hard combinatorial decision problem. To make this problem tractable we propose a statistical approximation to the objective function, as well as an approximate algorithm based on parametric linear programming. We apply the algorithm on three benchmark datasets and obtain improved intersection-over-union scores compared to maximum-posterior-marginal decisions. Our work points out the difficulties of using realistic loss functions with probabilistic computer vision models.
count=2
* Posebits for Monocular Human Pose Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Pons-Moll_Posebits_for_Monocular_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Pons-Moll_Posebits_for_Monocular_2014_CVPR_paper.pdf)]
    * Title: Posebits for Monocular Human Pose Estimation
    * Year: `2014`
    * Authors: Gerard Pons-Moll, David J. Fleet, Bodo Rosenhahn
    * Abstract: We advocate the inference of qualitative information about 3D human pose, called posebits, from images. Posebits represent boolean geometric relationships between body parts (e.g., left-leg in front of right-leg or hands close to each other). The advantages of posebits as a mid-level representation are 1) for many tasks of interest, such qualitative pose information may be sufficient (e.g., semantic image retrieval), 2) it is relatively easy to annotate large image corpora with posebits, as it simply requires answers to yes/no questions; and 3) they help resolve challenging pose ambiguities and therefore facilitate the difficult talk of image-based 3D pose estimation. We introduce posebits, a posebit database, a method for selecting useful posebits for pose estimation and a structural SVM model for posebit inference. Experiments show the use of posebits for semantic image retrieval and for improving 3D pose estimation.
count=2
* Empirical Minimum Bayes Risk Prediction: How to Extract an Extra Few % Performance from Vision Models with Just Three More Parameters
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Premachandran_Empirical_Minimum_Bayes_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Premachandran_Empirical_Minimum_Bayes_2014_CVPR_paper.pdf)]
    * Title: Empirical Minimum Bayes Risk Prediction: How to Extract an Extra Few % Performance from Vision Models with Just Three More Parameters
    * Year: `2014`
    * Authors: Vittal Premachandran, Daniel Tarlow, Dhruv Batra
    * Abstract: When building vision systems that predict structured objects such as image segmentations or human poses, a crucial concern is performance under task-specific evaluation measures (e.g. Jaccard Index or Average Precision). An ongoing research challenge is to optimize predictions so as to maximize performance on such complex measures. In this work, we present a simple meta-algorithm that is surprisingly effective – Empirical Min Bayes Risk. EMBR takes as input a pre-trained model that would normally be the final product and learns three additional parameters so as to optimize performance on the complex high-order task-specific measure. We demonstrate EMBR in several domains, taking existing state-of-the-art algorithms and improving performance up to ~7%, simply with three extra parameters.
count=2
* Dense Non-Rigid Shape Correspondence using Random Forests
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Rodola_Dense_Non-Rigid_Shape_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Rodola_Dense_Non-Rigid_Shape_2014_CVPR_paper.pdf)]
    * Title: Dense Non-Rigid Shape Correspondence using Random Forests
    * Year: `2014`
    * Authors: Emanuele Rodola, Samuel Rota Bulo, Thomas Windheuser, Matthias Vestner, Daniel Cremers
    * Abstract: We propose a shape matching method that produces dense correspondences tuned to a specific class of shapes and deformations. In a scenario where this class is represented by a small set of example shapes, the proposed method learns a shape descriptor capturing the variability of the deformations in the given class. The approach enables the wave kernel signature to extend the class of recognized deformations from near isometries to the deformations appearing in the example set by means of a random forest classifier. With the help of the introduced spatial regularization, the proposed method achieves significant improvements over the baseline approach and obtains state-of-the-art results while keeping short computation times.
count=2
* Latent Regression Forest: Structured Estimation of 3D Articulated Hand Posture
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Tang_Latent_Regression_Forest_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Tang_Latent_Regression_Forest_2014_CVPR_paper.pdf)]
    * Title: Latent Regression Forest: Structured Estimation of 3D Articulated Hand Posture
    * Year: `2014`
    * Authors: Danhang Tang, Hyung Jin Chang, Alykhan Tejani, Tae-Kyun Kim
    * Abstract: In this paper we present the Latent Regression Forest (LRF), a novel framework for real-time, 3D hand pose estimation from a single depth image. In contrast to prior forest-based methods, which take dense pixels as input, classify them independently and then estimate joint positions afterwards; our method can be considered as a structured coarse-to-fine search, starting from the centre of mass of a point cloud until locating all the skeletal joints. The searching process is guided by a learnt Latent Tree Model which reflects the hierarchical topology of the hand. Our main contributions can be summarised as follows: (i) Learning the topology of the hand in an unsupervised, data-driven manner. (ii) A new forest-based, discriminative framework for structured search in images, as well as an error regression step to avoid error accumulation. (iii) A new multi-view hand pose dataset containing 180K annotated images from 10 different subjects. Our experiments show that the LRF out-performs state-of-the-art methods in both accuracy and efficiency.
count=2
* Informed Haar-like Features Improve Pedestrian Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Zhang_Informed_Haar-like_Features_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Zhang_Informed_Haar-like_Features_2014_CVPR_paper.pdf)]
    * Title: Informed Haar-like Features Improve Pedestrian Detection
    * Year: `2014`
    * Authors: Shanshan Zhang, Christian Bauckhage, Armin B. Cremers
    * Abstract: We propose a simple yet effective detector for pedestrian detection. The basic idea is to incorporate common sense and everyday knowledge into the design of simple and computationally efficient features. As pedestrians usually appear up-right in image or video data, the problem of pedestrian detection is considerably simpler than general purpose people detection. We therefore employ a statistical model of the up-right human body where the head, the upper body, and the lower body are treated as three distinct components. Our main contribution is to systematically design a pool of rectangular templates that are tailored to this shape model. As we incorporate different kinds of low-level measurements, the resulting multi-modal & multi-channel Haar-like features represent characteristic differences between parts of the human body yet are robust against variations in clothing or environmental settings. Our approach avoids exhaustive searches over all possible configurations of rectangle features and neither relies on random sampling. It thus marks a middle ground among recently published techniques and yields efficient low-dimensional yet highly discriminative features. Experimental results on the INRIA and Caltech pedestrian datasets show that our detector reaches state-of-the-art performance at low computational costs and that our features are robust against occlusions.
count=2
* Unified Face Analysis by Iterative Multi-Output Random Forests
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Zhao_Unified_Face_Analysis_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Zhao_Unified_Face_Analysis_2014_CVPR_paper.pdf)]
    * Title: Unified Face Analysis by Iterative Multi-Output Random Forests
    * Year: `2014`
    * Authors: Xiaowei Zhao, Tae-Kyun Kim, Wenhan Luo
    * Abstract: In this paper, we present a unified method for joint face image analysis, i.e., simultaneously estimating head pose, facial expression and landmark positions in real-world face images. To achieve this goal, we propose a novel iterative Multi-Output Random Forests (iMORF) algorithm, which explicitly models the relations among multiple tasks and iteratively exploits such relations to boost the performance of all tasks. Specifically, a hierarchical face analysis forest is learned to perform classification of pose and expression at the top level, while performing landmark positions regression at the bottom level. On one hand, the estimated pose and expression provide strong shape prior to constrain the variation of landmark positions. On the other hand, more discriminative shape-related features could be extracted from the estimated landmark positions to further improve the predictions of pose and expression. This relatedness of face analysis tasks is iteratively exploited through several cascaded hierarchical face analysis forests until convergence. Experiments conducted on publicly available real-world face datasets demonstrate that the performance of all individual tasks are significantly improved by the proposed iMORF algorithm. In addition, our method outperforms state-of-the-arts for all three face analysis tasks.
count=2
* Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Gupta_Perceptual_Organization_and_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Gupta_Perceptual_Organization_and_2013_CVPR_paper.pdf)]
    * Title: Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images
    * Year: `2013`
    * Authors: Saurabh Gupta, Pablo Arbelaez, Jitendra Malik
    * Abstract: We address the problems of contour detection, bottomup grouping and semantic segmentation using RGB-D data. We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27]. We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gP b ucm approach of [2] by making effective use of depth information. We show that our system can label each contour with its type (depth, normal or albedo). We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping. We then turn to the problem of semantic segmentation and propose a simple approach that classifies superpixels into the 40 dominant object categories in NYUD2. We use both generic and class-specific features to encode the appearance and geometry of objects. We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition. In all of these tasks, we report significant improvements over the state-of-the-art.
count=2
* A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Kappes_A_Comparative_Study_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Kappes_A_Comparative_Study_2013_CVPR_paper.pdf)]
    * Title: A Comparative Study of Modern Inference Techniques for Discrete Energy Minimization Problems
    * Year: `2013`
    * Authors: J. Kappes, B. Andres, F. Hamprecht, C. Schnorr, S. Nowozin, D. Batra, S. Kim, B. Kausler, J. Lellmann, N. Komodakis, C. Rother
    * Abstract: Seven years ago, Szeliski et al. published an influential study on energy minimization methods for Markov random fields (MRF). This study provided valuable insights in choosing the best optimization technique for certain classes of problems. While these insights remain generally useful today, the phenominal success of random field models means that the kinds of inference problems we solve have changed significantly. Specifically, the models today often include higher order interactions, flexible connectivity structures, large label-spaces of different cardinalities, or learned energy tables. To reflect these changes, we provide a modernized and enlarged study. We present an empirical comparison of 24 state-of-art techniques on a corpus of 2,300 energy minimization instances from 20 diverse computer vision applications. To ensure reproducibility, we evaluate all methods in the OpenGM2 framework and report extensive results regarding runtime and solution quality. Key insights from our study agree with the results of Szeliski et al. for the types of models they studied. However, on new and challenging types of models our findings disagree and suggest that polyhedral methods and integer programming solvers are competitive in terms of runtime and solution quality over a large range of model types.
count=2
* Learning SURF Cascade for Fast and Accurate Object Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Li_Learning_SURF_Cascade_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Li_Learning_SURF_Cascade_2013_CVPR_paper.pdf)]
    * Title: Learning SURF Cascade for Fast and Accurate Object Detection
    * Year: `2013`
    * Authors: Jianguo Li, Yimin Zhang
    * Abstract: This paper presents a novel learning framework for training boosting cascade based object detector from large scale dataset. The framework is derived from the wellknown Viola-Jones (VJ) framework but distinguished by three key differences. First, the proposed framework adopts multi-dimensional SURF features instead of single dimensional Haar features to describe local patches. In this way, the number of used local patches can be reduced from hundreds of thousands to several hundreds. Second, it adopts logistic regression as weak classifier for each local patch instead of decision trees in the VJ framework. Third, we adopt AUC as a single criterion for the convergence test during cascade training rather than the two trade-off criteria (false-positive-rate and hit-rate) in the VJ framework. The benefit is that the false-positive-rate can be adaptive among different cascade stages, and thus yields much faster convergence speed of SURF cascade. Combining these points together, the proposed approach has three good properties. First, the boosting cascade can be trained very efficiently. Experiments show that the proposed approach can train object detectors from billions of negative samples within one hour even on personal computers. Second, the built detector is comparable to the stateof-the-art algorithm not only on the accuracy but also on the processing speed. Third, the built detector is small in model-size due to short cascade stages.
count=2
* Sketch Tokens: A Learned Mid-level Representation for Contour and Object Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Lim_Sketch_Tokens_A_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Lim_Sketch_Tokens_A_2013_CVPR_paper.pdf)]
    * Title: Sketch Tokens: A Learned Mid-level Representation for Contour and Object Detection
    * Year: `2013`
    * Authors: Joseph J. Lim, C. L. Zitnick, Piotr Dollar
    * Abstract: We propose a novel approach to both learning and detecting local contour-based representations for mid-level features. Our features, called sketch tokens, are learned using supervised mid-level information in the form of hand drawn contours in images. Patches of human generated contours are clustered to form sketch token classes and a random forest classifier is used for efficient detection in novel images. We demonstrate our approach on both topdown and bottom-up tasks. We show state-of-the-art results on the top-down task of contour detection while being over 200x faster than competing methods. We also achieve large improvements in detection accuracy for the bottom-up tasks of pedestrian and object detection as measured on INRIA [5] and PASCAL [10], respectively. These gains are due to the complementary information provided by sketch tokens to low-level features such as gradient histograms.
count=2
* A Statistical Model for Recreational Trails in Aerial Images
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Predoehl_A_Statistical_Model_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Predoehl_A_Statistical_Model_2013_CVPR_paper.pdf)]
    * Title: A Statistical Model for Recreational Trails in Aerial Images
    * Year: `2013`
    * Authors: Andrew Predoehl, Scott Morris, Kobus Barnard
    * Abstract: We present a statistical model of aerial images of recreational trails, and a method to infer trail routes in such images. We learn a set of textons describing the images, and use them to divide the image into super-pixels represented by their texton. We then learn, for each texton, the frequency of generating on-trail and off-trail pixels, and the direction of trail through on-trail pixels. From these, we derive an image likelihood function. We combine that with a prior model of trail length and smoothness, yielding a posterior distribution for trails, given an image. We search for good values of this posterior using a novel stochastic variation of Dijkstra's algorithm. Our experiments, on trail images and groundtruth collected in the western continental USA, show substantial improvement over those of the previous best trail-finding method.
count=2
* Geometric Context from Videos
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Raza_Geometric_Context_from_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Raza_Geometric_Context_from_2013_CVPR_paper.pdf)]
    * Title: Geometric Context from Videos
    * Year: `2013`
    * Authors: S. Hussain Raza, Matthias Grundmann, Irfan Essa
    * Abstract: We present a novel algorithm for estimating the broad 3D geometric structure of outdoor video scenes. Leveraging spatio-temporal video segmentation, we decompose a dynamic scene captured by a video into geometric classes, based on predictions made by region-classifiers that are trained on appearance and motion features. By examining the homogeneity of the prediction, we combine predictions across multiple segmentation hierarchy levels alleviating the need to determine the granularity a priori. We built a novel, extensive dataset on geometric context of video to evaluate our method, consisting of over 100 groundtruth annotated outdoor videos with over 20,000 frames. To further scale beyond this dataset, we propose a semisupervised learning framework to expand the pool of labeled data with high confidence predictions obtained from unlabeled data. Our system produces an accurate prediction of geometric context of video achieving 96% accuracy across main geometric classes.
count=2
* Decoding Children's Social Behavior
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Rehg_Decoding_Childrens_Social_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Rehg_Decoding_Childrens_Social_2013_CVPR_paper.pdf)]
    * Title: Decoding Children's Social Behavior
    * Year: `2013`
    * Authors: J. Rehg, G. Abowd, A. Rozga, M. Romero, M. Clements, S. Sclaroff, I. Essa, O. Ousley, Y. Li, C. Kim, H. Rao, J. Kim, L. Lo Presti, J. Zhang, D. Lantsman, J. Bidwell, Z. Ye
    * Abstract: We introduce a new problem domain for activity recognition: the analysis of children's social and communicative behaviors based on video and audio data. We specifically target interactions between children aged 1-2 years and an adult. Such interactions arise naturally in the diagnosis and treatment of developmental disorders such as autism. We introduce a new publicly-available dataset containing over 160 sessions of a 3-5 minute child-adult interaction. In each session, the adult examiner followed a semistructured play interaction protocol which was designed to elicit a broad range of social behaviors. We identify the key technical challenges in analyzing these behaviors, and describe methods for decoding the interactions. We present experimental results that demonstrate the potential of the dataset to drive interesting research questions, and show preliminary results for multi-modal activity recognition.
count=2
* Local Temperature Scaling for Probability Calibration
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Ding_Local_Temperature_Scaling_for_Probability_Calibration_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Ding_Local_Temperature_Scaling_for_Probability_Calibration_ICCV_2021_paper.pdf)]
    * Title: Local Temperature Scaling for Probability Calibration
    * Year: `2021`
    * Authors: Zhipeng Ding, Xu Han, Peirong Liu, Marc Niethammer
    * Abstract: For semantic segmentation, label probabilities are often uncalibrated as they are typically only the by-product of a segmentation task. Intersection over Union (IoU) and Dice score are often used as criteria for segmentation success, while metrics related to label probabilities are not often explored. However, probability calibration approaches have been studied, which match probability outputs with experimentally observed errors. These approaches mainly focus on classification tasks, but not on semantic segmentation. Thus, we propose a learning-based calibration method that focuses on multi-label semantic segmentation. Specifically, we adopt a convolutional neural network to predict local temperature values for probability calibration. One advantage of our approach is that it does not change prediction accuracy, hence allowing for calibration as a post-processing step. Experiments on the COCO, CamVid, and LPBA40 datasets demonstrate improved calibration performance for a range of different metrics. We also demonstrate the good performance of our method for multi-atlas brain segmentation from magnetic resonance images.
count=2
* Architecture Disentanglement for Deep Neural Networks
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Hu_Architecture_Disentanglement_for_Deep_Neural_Networks_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Hu_Architecture_Disentanglement_for_Deep_Neural_Networks_ICCV_2021_paper.pdf)]
    * Title: Architecture Disentanglement for Deep Neural Networks
    * Year: `2021`
    * Authors: Jie Hu, Liujuan Cao, Tong Tong, Qixiang Ye, Shengchuan Zhang, Ke Li, Feiyue Huang, Ling Shao, Rongrong Ji
    * Abstract: Understanding the inner workings of deep neural networks (DNNs) is essential to provide trustworthy artificial intelligence techniques for practical applications. Existing studies typically involve linking semantic concepts to units or layers of DNNs, but fail to explain the inference process. In this paper, we introduce neural architecture disentanglement (NAD) to fill the gap. Specifically, NAD learns to disentangle a pre-trained DNN into sub-architectures according to independent tasks, forming information flows that describe the inference processes. We investigate whether, where, and how the disentanglement occurs through experiments conducted with handcrafted and automatically-searched network architectures, on both object-based and scene-based datasets. Based on the experimental results, we present three new findings that provide fresh insights into the inner logic of DNNs. First, DNNs can be divided into sub-architectures for independent tasks. Second, deeper layers do not always correspond to higher semantics. Third, the connection type in a DNN affects how the information flows across layers, leading to different disentanglement behaviors. With NAD, we further explain why DNNs sometimes give wrong predictions. Experimental results show that misclassified images have a high probability of being assigned to task sub-architectures similar to the correct ones. Our code is available at https://github.com/hujiecpp/NAD.
count=2
* Keep CALM and Improve Visual Feature Attribution
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Kim_Keep_CALM_and_Improve_Visual_Feature_Attribution_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_Keep_CALM_and_Improve_Visual_Feature_Attribution_ICCV_2021_paper.pdf)]
    * Title: Keep CALM and Improve Visual Feature Attribution
    * Year: `2021`
    * Authors: Jae Myung Kim, Junsuk Choe, Zeynep Akata, Seong Joon Oh
    * Abstract: The class activation mapping, or CAM, has been the cornerstone of feature attribution methods for multiple vision tasks. Its simplicity and effectiveness have led to wide applications in the explanation of visual predictions and weakly-supervised localization tasks. However, CAM has its own shortcomings. The computation of attribution maps relies on ad-hoc calibration steps that are not part of the training computational graph, making it difficult for us to understand the real meaning of the attribution values. In this paper, we improve CAM by explicitly incorporating a latent variable encoding the location of the cue for recognition in the formulation, thereby subsuming the attribution map into the training computational graph. The resulting model, class activation latent mapping, or CALM, is trained with the expectation-maximization algorithm. Our experiments show that CALM identifies discriminative attributes for image classifiers more accurately than CAM and other visual attribution baselines. CALM also shows performance improvements over prior arts on the weakly-supervised object localization benchmarks. Our code is available at https://github.com/naver-ai/calm.
count=2
* Interpretable Visual Reasoning via Induced Symbolic Space
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Interpretable_Visual_Reasoning_via_Induced_Symbolic_Space_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Interpretable_Visual_Reasoning_via_Induced_Symbolic_Space_ICCV_2021_paper.pdf)]
    * Title: Interpretable Visual Reasoning via Induced Symbolic Space
    * Year: `2021`
    * Authors: Zhonghao Wang, Kai Wang, Mo Yu, Jinjun Xiong, Wen-mei Hwu, Mark Hasegawa-Johnson, Humphrey Shi
    * Abstract: We study the problem of concept induction in visual reasoning, i.e., identifying concepts and their hierarchical relationships from question-answer pairs associated with images; and achieve an interpretable model via working on the induced symbolic concept space. To this end, we first design a new framework named object-centric compositional attention model (OCCAM) to perform the visual reasoning task with object-level visual features. Then, we come up with a method to induce concepts of objects and relations using clues from the attention patterns between objects' visual features and question words. Finally, we achieve a higher level of interpretability by imposing OCCAM on the objects represented in the induced symbolic concept space. Experiments on the CLEVR and GQA datasets demonstrate: 1) our OCCAM achieves a new state of the art without human-annotated functional programs; 2) our induced concepts are both accurate and sufficient as OCCAM achieves an on-par performance on objects represented either in visual features or in the induced symbolic concept space.
count=2
* Towards Interpretable Deep Metric Learning With Structural Matching
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Towards_Interpretable_Deep_Metric_Learning_With_Structural_Matching_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Towards_Interpretable_Deep_Metric_Learning_With_Structural_Matching_ICCV_2021_paper.pdf)]
    * Title: Towards Interpretable Deep Metric Learning With Structural Matching
    * Year: `2021`
    * Authors: Wenliang Zhao, Yongming Rao, Ziyi Wang, Jiwen Lu, Jie Zhou
    * Abstract: How do the neural networks distinguish two images? It is of critical importance to understand the matching mechanism of deep models for developing reliable intelligent systems for many risky visual applications such as surveillance and access control. However, most existing deep metric learning methods match the images by comparing feature vectors, which ignores the spatial structure of images and thus lacks interpretability. In this paper, we present a deep interpretable metric learning (DIML) method for more transparent embedding learning. Unlike conventional metric learning methods based on feature vector comparison, we propose a structural matching strategy that explicitly aligns the spatial embeddings by computing an optimal matching flow between feature maps of the two images. Our method enables deep models to learn metrics in a more human-friendly way, where the similarity of two images can be decomposed to several part-wise similarities and their contributions to the overall similarity. Our method is model-agnostic, which can be applied to off-the-shelf backbone networks and metric learning methods. We evaluate our method on three major benchmarks of deep metric learning including CUB200- 2011, Cars196, and Stanford Online Products, and achieve substantial improvements over popular metric learning methods with better interpretability.
count=2
* Explaining Neural Networks Semantically and Quantitatively
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Chen_Explaining_Neural_Networks_Semantically_and_Quantitatively_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Explaining_Neural_Networks_Semantically_and_Quantitatively_ICCV_2019_paper.pdf)]
    * Title: Explaining Neural Networks Semantically and Quantitatively
    * Year: `2019`
    * Authors: Runjin Chen,  Hao Chen,  Jie Ren,  Ge Huang,  Quanshi Zhang
    * Abstract: This paper presents a method to pursue a semantic and quantitative explanation for the knowledge encoded in a convolutional neural network (CNN). The estimation of the specific rationale of each prediction made by the CNN presents a key issue of understanding neural networks, and it is of significant values in real applications. In this study, we propose to distill knowledge from the CNN into an explainable additive model, which explains the CNN prediction quantitatively. We discuss the problem of the biased interpretation of CNN predictions. To overcome the biased interpretation, we develop prior losses to guide the learning of the explainable additive model. Experimental results have demonstrated the effectiveness of our method.
count=2
* Gaussian Affinity for Max-Margin Class Imbalanced Learning
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Hayat_Gaussian_Affinity_for_Max-Margin_Class_Imbalanced_Learning_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Hayat_Gaussian_Affinity_for_Max-Margin_Class_Imbalanced_Learning_ICCV_2019_paper.pdf)]
    * Title: Gaussian Affinity for Max-Margin Class Imbalanced Learning
    * Year: `2019`
    * Authors: Munawar Hayat,  Salman Khan,  Syed Waqas Zamir,  Jianbing Shen,  Ling Shao
    * Abstract: Real-world object classes appear in imbalanced ratios. This poses a significant challenge for classifiers which get biased towards frequent classes. We hypothesize that improving the generalization capability of a classifier should improve learning on imbalanced datasets. Here, we introduce the first hybrid loss function that jointly performs classification and clustering in a single formulation. Our approach is based on an `affinity measure' in Euclidean space that leads to the following benefits: (1) direct enforcement of maximum margin constraints on classification boundaries, (2) a tractable way to ensure uniformly spaced and equidistant cluster centers, (3) flexibility to learn multiple class prototypes to support diversity and discriminability in feature space. Our extensive experiments demonstrate the significant performance improvements on visual classification and verification tasks on multiple imbalanced datasets. The proposed loss can easily be plugged in any deep architecture as a differentiable block and demonstrates robustness against different levels of data imbalance and corrupted labels.
count=2
* MIHash: Online Hashing With Mutual Information
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Cakir_MIHash_Online_Hashing_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Cakir_MIHash_Online_Hashing_ICCV_2017_paper.pdf)]
    * Title: MIHash: Online Hashing With Mutual Information
    * Year: `2017`
    * Authors: Fatih Cakir, Kun He, Sarah Adel Bargal, Stan Sclaroff
    * Abstract: Learning-based hashing methods are widely used for nearest neighbor retrieval, and recently, online hashing methods have demonstrated good performance-complexity trade-offs by learning hash functions from streaming data. In this paper, we first address a key challenge for online hashing: the binary codes for indexed data must be recomputed to keep pace with updates to the hash functions. We propose an efficient quality measure for hash functions, based on an information-theoretic quantity, mutual information, and use it successfully as a criterion to eliminate unnecessary hash table updates. Next, we also show how to optimize the mutual information objective using stochastic gradient descent. We thus develop a novel hashing method, MIHash, that can be used in both online and batch settings. Experiments on image retrieval benchmarks (including a 2.5M image dataset) confirm the effectiveness of our formulation, both in reducing hash table recomputations and in learning high-quality hash functions.
count=2
* Pairwise Conditional Random Forests for Facial Expression Recognition
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Dapogny_Pairwise_Conditional_Random_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Dapogny_Pairwise_Conditional_Random_ICCV_2015_paper.pdf)]
    * Title: Pairwise Conditional Random Forests for Facial Expression Recognition
    * Year: `2015`
    * Authors: Arnaud Dapogny, Kevin Bailly, Severine Dubuisson
    * Abstract: Facial expression can be seen as the dynamic variation of one's appearance over time. Successful recognition thus involves finding representations of high-dimensional spatiotemporal patterns that can be generalized to unseen facial morphologies and variations of the expression dynamics. In this paper, we propose to learn Random Forests from heterogeneous derivative features (e.g. facial fiducial point movements or texture variations) upon pairs of images. Those forests are conditioned on the expression label of the first frame to reduce the variability of the ongoing expression transitions. When testing on a specific frame of a video, pairs are created between this frame and the previous ones. Predictions for each previous frame are used to draw trees from Pairwise Conditional Random Forests (PCRF) whose pairwise outputs are averaged over time to produce robust estimates. As such, PCRF appears as a natural extension of Random Forests to learn spatio-temporal patterns, that leads to significant improvements over standard Random Forests as well as state-of-the-art approaches on several facial expression benchmarks.
count=2
* kNN Hashing With Factorized Neighborhood Representation
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Ding_kNN_Hashing_With_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Ding_kNN_Hashing_With_ICCV_2015_paper.pdf)]
    * Title: kNN Hashing With Factorized Neighborhood Representation
    * Year: `2015`
    * Authors: Kun Ding, Chunlei Huo, Bin Fan, Chunhong Pan
    * Abstract: Hashing is very effective for many tasks in reducing the processing time and in compressing massive databases. Although lots of approaches have been developed to learn data-dependent hash functions in recent years, how to learn hash functions to yield good performance with acceptable computational and memory cost is still a challenging problem. Based on the observation that retrieval precision is highly related to the kNN classification accuracy, this paper proposes a novel kNN-based supervised hashing method, which learns hash functions by directly maximizing the kNN accuracy of the Hamming-embedded training data. To make it scalable well to large problem, we propose a factorized neighborhood representation to parsimoniously model the neighborhood relationships inherent in training data. Considering that real-world data are often linearly inseparable, we further kernelize this basic model to improve its performance. As a result, the proposed method is able to learn accurate hashing functions with tolerable computation and storage cost. Experiments on four benchmarks demonstrate that our method outperforms the state-of-the-arts.
count=2
* Car That Knows Before You Do: Anticipating Maneuvers via Learning Temporal Driving Models
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Jain_Car_That_Knows_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Jain_Car_That_Knows_ICCV_2015_paper.pdf)]
    * Title: Car That Knows Before You Do: Anticipating Maneuvers via Learning Temporal Driving Models
    * Year: `2015`
    * Authors: Ashesh Jain, Hema S. Koppula, Bharad Raghavan, Shane Soh, Ashutosh Saxena
    * Abstract: Advanced Driver Assistance Systems (ADAS) have made driving safer over the last decade. They prepare vehicles for unsafe road conditions and alert drivers if they perform a dangerous maneuver. However, many accidents are unavoidable because by the time drivers are alerted, it is already too late. Anticipating maneuvers beforehand can alert drivers before they perform the maneuver and also give ADAS more time to avoid or prepare for the danger. In this work we anticipate driving maneuvers a few seconds before they occur. For this purpose we equip a car with cameras and a computing device to capture the driving context from both inside and outside of the car. We propose an Autoregressive Input-Output HMM to model the contextual information alongwith the maneuvers. We evaluate our approach on a diverse data set with 1180 miles of natural freeway and city driving and show that we can anticipate maneuvers 3.5 seconds before they occur with over 80% F1-score in real-time.
count=2
* Opening the Black Box: Hierarchical Sampling Optimization for Estimating Human Hand Pose
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Tang_Opening_the_Black_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Tang_Opening_the_Black_ICCV_2015_paper.pdf)]
    * Title: Opening the Black Box: Hierarchical Sampling Optimization for Estimating Human Hand Pose
    * Year: `2015`
    * Authors: Danhang Tang, Jonathan Taylor, Pushmeet Kohli, Cem Keskin, Tae-Kyun Kim, Jamie Shotton
    * Abstract: We address the problem of hand pose estimation, formulated as an inverse problem. Typical approaches optimize an energy function over pose parameters using a `black box' image generation procedure. This procedure knows little about either the relationships between the parameters or the form of the energy function. In this paper, we show that we can significantly improving upon black box optimization by exploiting high-level knowledge of the structure of the parameters and using a local surrogate energy function. Our new framework, hierarchical sampling optimization, consists of a sequence of predictors organized into a kinematic hierarchy. Each predictor is conditioned on its ancestors, and generates a set of samples over a subset of the pose parameters. The highly-efficient surrogate energy is used to select among samples. Having evaluated the full hierarchy, the partial pose samples are concatenated to generate a full-pose hypothesis. Several hypotheses are generated using the same procedure, and finally the original full energy function selects the best result. Experimental evaluation on three publically available datasets show that our method is particularly impressive in low-compute scenarios where it significantly outperforms all other state-of-the-art methods.
count=2
* Secrets of GrabCut and Kernel K-Means
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Tang_Secrets_of_GrabCut_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Tang_Secrets_of_GrabCut_ICCV_2015_paper.pdf)]
    * Title: Secrets of GrabCut and Kernel K-Means
    * Year: `2015`
    * Authors: Meng Tang, Ismail Ben Ayed, Dmitrii Marin, Yuri Boykov
    * Abstract: The log-likelihood energy term in popular model-fitting segmentation methods, e.g. Zhu&Yuille, Chan-Vese, GrabCut, is presented as a generalized "probabilistic K-means" energy for color space clustering. This interpretation reveals some limitations, e.g. over-fitting. We propose an alternative approach to color clustering using kernel K-means energy with well-known properties such as non-linear separation and scalability to higher-dimensional feature spaces. Our bound formulation for kernel K-means allows to combine general pair-wise feature clustering methods with image grid regularization using graph cuts, similarly to standard color model fitting techniques for segmentation. Unlike histogram or GMM fitting, our approach is closely related to average association and normalized cut. But, in contrast to previous pairwise clustering algorithms, our approach can incorporate any standard geometric regularization in the image domain. We analyze extreme cases for kernel bandwidth (e.g. Gini bias) and demonstrate effectiveness of KNN-based adaptive bandwidth strategies. Our kernel K-means approach to segmentation benefits from higher-dimensional features where standard model fitting fails.
count=2
* HARF: Hierarchy-Associated Rich Features for Salient Object Detection
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Zou_HARF_Hierarchy-Associated_Rich_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Zou_HARF_Hierarchy-Associated_Rich_ICCV_2015_paper.pdf)]
    * Title: HARF: Hierarchy-Associated Rich Features for Salient Object Detection
    * Year: `2015`
    * Authors: Wenbin Zou, Nikos Komodakis
    * Abstract: The state-of-the-art salient object detection models are able to perform well for relatively simple scenes, yet for more complex ones, they still have difficulties in highlighting salient objects completely from background, largely due to the lack of sufficiently robust features for saliency prediction. To address such an issue, this paper proposes a novel hierarchy-associated feature construction framework for salient object detection, which is based on integrating elementary features from multi-level regions in a hierarchy. Furthermore, multi-layered deep learning features are introduced and incorporated as elementary features into this framework through a compact integration scheme. This leads to a rich feature representation, which is able to represent the context of the whole object/background and is much more discriminative as well as robust for salient object detection. Extensive experiments on the most widely used and challenging benchmark datasets demonstrate that the proposed approach substantially outperforms the state-of-the-art on salient object detection.
count=2
* Learning to Predict Gaze in Egocentric Video
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Li_Learning_to_Predict_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Li_Learning_to_Predict_2013_ICCV_paper.pdf)]
    * Title: Learning to Predict Gaze in Egocentric Video
    * Year: `2013`
    * Authors: Yin Li, Alireza Fathi, James M. Rehg
    * Abstract: We present a model for gaze prediction in egocentric video by leveraging the implicit cues that exist in camera wearer's behaviors. Specifically, we compute the camera wearer's head motion and hand location from the video and combine them to estimate where the eyes look. We further model the dynamic behavior of the gaze, in particular fixations, as latent variables to improve the gaze prediction. Our gaze prediction results outperform the state-of-the-art algorithms by a large margin on publicly available egocentric vision datasets. In addition, we demonstrate that we get a significant performance boost in recognizing daily actions and segmenting foreground objects by plugging in our gaze predictions into state-of-the-art methods.
count=2
* Handling Occlusions with Franken-Classifiers
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Mathias_Handling_Occlusions_with_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Mathias_Handling_Occlusions_with_2013_ICCV_paper.pdf)]
    * Title: Handling Occlusions with Franken-Classifiers
    * Year: `2013`
    * Authors: Markus Mathias, Rodrigo Benenson, Radu Timofte, Luc Van Gool
    * Abstract: Detecting partially occluded pedestrians is challenging. A common practice to maximize detection quality is to train a set of occlusion-specific classifiers, each for a certain amount and type of occlusion. Since training classifiers is expensive, only a handful are typically trained. We show that by using many occlusion-specific classifiers, we outperform previous approaches on three pedestrian datasets; INRIA, ETH, and Caltech USA. We present a new approach to train such classifiers. By reusing computations among different training stages, 16 occlusion-specific classifiers can be trained at only one tenth the cost of one full training. We show that also test time cost grows sub-linearly.
count=2
* Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/0f6931a9e339a012a9909306d7c758b4-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/0f6931a9e339a012a9909306d7c758b4-Paper-Conference.pdf)]
    * Title: Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head
    * Year: `2023`
    * Authors: Alan Wang, Minh Nguyen, Mert Sabuncu
    * Abstract: Machine learning models will often fail when deployed in an environment with a data distribution that is different than the training distribution. When multiple environments are available during training, many methods exist that learn representations which are invariant across the different distributions, with the hope that these representations will be transportable to unseen domains. In this work, we present a nonparametric strategy for learning invariant representations based on the recently-proposed Nadaraya-Watson (NW) head. The NW head makes a prediction by comparing the learned representations of the query to the elements of a support set that consists of labeled data. We demonstrate that by manipulating the support set, one can encode different causal assumptions. In particular, restricting the support set to a single environment encourages the model to learn invariant features that do not depend on the environment. We present a causally-motivated setup for our modeling and training strategy and validate on three challenging real-world domain generalization tasks in computer vision.
count=2
* Explaining Predictive Uncertainty with Information Theoretic Shapley Values
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/16e4be78e61a3897665fa01504e9f452-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/16e4be78e61a3897665fa01504e9f452-Paper-Conference.pdf)]
    * Title: Explaining Predictive Uncertainty with Information Theoretic Shapley Values
    * Year: `2023`
    * Authors: David Watson, Joshua O'Hara, Niek Tax, Richard Mudd, Ido Guy
    * Abstract: Researchers in explainable artificial intelligence have developed numerous methods for helping users understand the predictions of complex supervised learning models. By contrast, explaining the $\textit{uncertainty}$ of model outputs has received relatively little attention. We adapt the popular Shapley value framework to explain various types of predictive uncertainty, quantifying each feature's contribution to the conditional entropy of individual model outputs. We consider games with modified characteristic functions and find deep connections between the resulting Shapley values and fundamental quantities from information theory and conditional independence testing. We outline inference procedures for finite sample error rate control with provable guarantees, and implement efficient algorithms that perform well in a range of experiments on real and simulated data. Our method has applications to covariate shift detection, active learning, feature selection, and active feature-value acquisition.
count=2
* SpatialRank: Urban Event Ranking with NDCG Optimization on Spatiotemporal Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/1f3cbee17170c3ffff3e413d2df54f6b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/1f3cbee17170c3ffff3e413d2df54f6b-Paper-Conference.pdf)]
    * Title: SpatialRank: Urban Event Ranking with NDCG Optimization on Spatiotemporal Data
    * Year: `2023`
    * Authors: BANG AN, Xun Zhou, YONGJIAN ZHONG, Tianbao Yang
    * Abstract: The problem of urban event ranking aims at predicting the top-$k$ most risky locations of future events such as traffic accidents and crimes. This problem is of fundamental importance to public safety and urban administration especially when limited resources are available. The problem is, however, challenging due to complex and dynamic spatio-temporal correlations between locations, uneven distribution of urban events in space, and the difficulty to correctly rank nearby locations with similar features. Prior works on event forecasting mostly aim at accurately predicting the actual risk score or counts of events for all the locations. Rankings obtained as such usually have low quality due to prediction errors. Learning-to-rank methods directly optimize measures such as Normalized Discounted Cumulative Gain (NDCG), but cannot handle the spatiotemporal autocorrelation existing among locations. Due to the common assumption that items are independent. In this paper, we bridge the gap by proposing a novel spatial event ranking approach named SpatialRank. SpatialRank features adaptive graph convolution layers that dynamically learn the spatiotemporal dependencies across locations from data. In addition, the model optimizes through surrogates a hybrid NDCG loss with a spatial component to better rank neighboring spatial locations. We design an importance-sampling with a spatial filtering algorithm to effectively evaluate the loss during training. Comprehensive experiments on three real-world datasets demonstrate that SpatialRank can effectively identify the top riskiest locations of crimes and traffic accidents and outperform state-of-art methods in terms of NDCG by up to 12.7%.
count=2
* Delegated Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/2aab664e0d1656e8b56c74f868e1ea69-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/2aab664e0d1656e8b56c74f868e1ea69-Paper-Conference.pdf)]
    * Title: Delegated Classification
    * Year: `2023`
    * Authors: Eden Saig, Inbal Talgam-Cohen, Nir Rosenfeld
    * Abstract: When machine learning is outsourced to a rational agent, conflicts of interest might arise and severely impact predictive performance. In this work, we propose a theoretical framework for incentive-aware delegation of machine learning tasks. We model delegation as a principal-agent game, in which accurate learning can be incentivized by the principal using performance-based contracts. Adapting the economic theory of contract design to this setting, we define budget-optimal contracts and prove they take a simple threshold form under reasonable assumptions. In the binary-action case, the optimality of such contracts is shown to be equivalent to the classic Neyman-Pearson lemma, establishing a formal connection between contract design and statistical hypothesis testing. Empirically, we demonstrate that budget-optimal contracts can be constructed using small-scale data, leveraging recent advances in the study of learning curves and scaling laws. Performance and economic outcomes are evaluated using synthetic and real-world classification tasks.
count=2
* Interpretable Graph Networks Formulate Universal Algebra Conjectures
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/2b2011a7d5396faf5899863d896a3c24-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/2b2011a7d5396faf5899863d896a3c24-Paper-Conference.pdf)]
    * Title: Interpretable Graph Networks Formulate Universal Algebra Conjectures
    * Year: `2023`
    * Authors: Francesco Giannini, Stefano Fioravanti, Oguzhan Keskin, Alisia Lupidi, Lucie Charlotte Magister, Pietro Lió, Pietro Barbiero
    * Abstract: The rise of Artificial Intelligence (AI) recently empowered researchers to investigate hard mathematical problems which eluded traditional approaches for decades. Yet, the use of AI in Universal Algebra (UA)---one of the fields laying the foundations of modern mathematics---is still completely unexplored. This work proposes the first use of AI to investigate UA's conjectures with an equivalent equational and topological characterization. While topological representations would enable the analysis of such properties using graph neural networks, the limited transparency and brittle explainability of these models hinder their straightforward use to empirically validate existing conjectures or to formulate new ones. To bridge these gaps, we propose a general algorithm generating AI-ready datasets based on UA's conjectures, and introduce a novel neural layer to build fully interpretable graph networks. The results of our experiments demonstrate that interpretable graph networks: (i) enhance interpretability without sacrificing task accuracy, (ii) strongly generalize when predicting universal algebra's properties, (iii) generate simple explanations that empirically validate existing conjectures, and (iv) identify subgraphs suggesting the formulation of novel conjectures.
count=2
* BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark for Short-Term Load Forecasting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3f17bf868966df01ca125e5bbc9ee24e-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3f17bf868966df01ca125e5bbc9ee24e-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark for Short-Term Load Forecasting
    * Year: `2023`
    * Authors: Patrick Emami, Abhijeet Sahu, Peter Graf
    * Abstract: Short-term forecasting of residential and commercial building energy consumption is widely used in power systems and continues to grow in importance. Data-driven short-term load forecasting (STLF), although promising, has suffered from a lack of open, large-scale datasets with high building diversity. This has hindered exploring the pretrain-then-fine-tune paradigm for STLF. To help address this, we present BuildingsBench, which consists of: 1) Buildings-900K, a large-scale dataset of 900K simulated buildings representing the U.S. building stock; and 2) an evaluation platform with over 1,900 real residential and commercial buildings from 7 open datasets. BuildingsBench benchmarks two under-explored tasks: zero-shot STLF, where a pretrained model is evaluated on unseen buildings without fine-tuning, and transfer learning, where a pretrained model is fine-tuned on a target building. The main finding of our benchmark analysis is that synthetically pretrained models generalize surprisingly well to real commercial buildings. An exploration of the effect of increasing dataset size and diversity on zero-shot commercial building performance reveals a power-law with diminishing returns. We also show that fine-tuning pretrained models on real commercial and residential buildings improves performance for a majority of target buildings. We hope that BuildingsBench encourages and facilitates future research on generalizable STLF. All datasets and code can be accessed from https://github.com/NREL/BuildingsBench.
count=2
* Nearest Neighbour with Bandit Feedback
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/4078c8b648dc107aedbdf561dd4edc2a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/4078c8b648dc107aedbdf561dd4edc2a-Paper-Conference.pdf)]
    * Title: Nearest Neighbour with Bandit Feedback
    * Year: `2023`
    * Authors: Stephen Pasteris, Chris Hicks, Vasilios Mavroudis
    * Abstract: In this paper we adapt the nearest neighbour rule to the contextual bandit problem. Our algorithm handles the fully adversarial setting in which no assumptions at all are made about the data-generation process. When combined with a sufficiently fast data-structure for (perhaps approximate) adaptive nearest neighbour search, such as a navigating net, our algorithm is extremely efficient - having a per trial running time polylogarithmic in both the number of trials and actions, and taking only quasi-linear space. We give generic regret bounds for our algorithm and further analyse them when applied to the stochastic bandit problem in euclidean space. A side result of this paper is that, when applied to the online classification problem with stochastic labels, our algorithm can, under certain conditions, have sublinear regret whilst only finding a single nearest neighbour per trial - in stark contrast to the k-nearest neighbours algorithm.
count=2
* BioMassters: A Benchmark Dataset for Forest Biomass Estimation using Multi-modal Satellite Time-series
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/40daf2a00278c4bea1b26cd4c8a654f8-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/40daf2a00278c4bea1b26cd4c8a654f8-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: BioMassters: A Benchmark Dataset for Forest Biomass Estimation using Multi-modal Satellite Time-series
    * Year: `2023`
    * Authors: Andrea Nascetti, Ritu Yadav, Kirill Brodt, Qixun Qu, Hongwei Fan, Yuri Shendryk, Isha Shah, Christine Chung
    * Abstract: Above Ground Biomass is an important variable as forests play a crucial role in mitigating climate change as they act as an efficient, natural and cost-effective carbon sink. Traditional field and airborne LiDAR measurements have been proven to provide reliable estimations of forest biomass. Nevertheless, the use of these techniques at a large scale can be challenging and expensive. Satellite data have been widely used as a valuable tool in estimating biomass on a global scale. However, the full potential of dense multi-modal satellite time series data, in combination with modern deep learning approaches, has yet to be fully explored. The aim of the "BioMassters" data challenge and benchmark dataset is to investigate the potential of multi-modal satellite data (Sentinel-1 SAR and Sentinel-2 MSI) to estimate forest biomass at a large scale using the Finnish Forest Centre's open forest and nature airborne LiDAR data as a reference. The performance of the top three baseline models shows the potential of deep learning to produce accurate and higher-resolution biomass maps. Our benchmark dataset is publically available at https://huggingface.co/datasets/nascetti-a/BioMassters (doi:10.57967/hf/1009) and the implementation of the top three winning models are available at https://github.com/drivendataorg/the-biomassters.
count=2
* VeriX: Towards Verified Explainability of Deep Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/46907c2ff9fafd618095161d76461842-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/46907c2ff9fafd618095161d76461842-Paper-Conference.pdf)]
    * Title: VeriX: Towards Verified Explainability of Deep Neural Networks
    * Year: `2023`
    * Authors: Min Wu, Haoze Wu, Clark Barrett
    * Abstract: We present VeriX (Verified eXplainability), a system for producing optimal robust explanations and generating counterfactuals along decision boundaries of machine learning models. We build such explanations and counterfactuals iteratively using constraint solving techniques and a heuristic based on feature-level sensitivity ranking. We evaluate our method on image recognition benchmarks and a real-world scenario of autonomous aircraft taxiing.
count=2
* Efficient Online Clustering with Moving Costs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/4ff08be7b0105049ff3e0ce3d70658c5-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/4ff08be7b0105049ff3e0ce3d70658c5-Paper-Conference.pdf)]
    * Title: Efficient Online Clustering with Moving Costs
    * Year: `2023`
    * Authors: Dimitrios Christou, Stratis Skoulakis, Volkan Cevher
    * Abstract: In this work we consider an online learning problem, called Online $k$-Clustering with Moving Costs, at which a learner maintains a set of $k$ facilities over $T$ rounds so as to minimize the connection cost of an adversarially selected sequence of clients. The learner is informed on the positions of the clients at each round $t$ only after its facility-selection and can use this information to update its decision in the next round. However, updating the facility positions comes with an additional moving cost based on the moving distance of the facilities. We present the first $\mathcal{O}(\log n)$-regret polynomial-time online learning algorithm guaranteeing that the overall cost (connection $+$ moving) is at most $\mathcal{O}(\log n)$ times the time-averaged connection cost of the best fixed solution. Our work improves on the recent result of (Fotakis et al., 2021) establishing $\mathcal{O}(k)$-regret guarantees only on the connection cost.
count=2
* OpenDataVal: a Unified Benchmark for Data Valuation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/5b047c7d862059a5df623c1ce2982fca-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/5b047c7d862059a5df623c1ce2982fca-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: OpenDataVal: a Unified Benchmark for Data Valuation
    * Year: `2023`
    * Authors: Kevin Jiang, Weixin Liang, James Y. Zou, Yongchan Kwon
    * Abstract: Assessing the quality and impact of individual data points is critical for improving model performance and mitigating undesirable biases within the training dataset. Several data valuation algorithms have been proposed to quantify data quality, however, there lacks a systemic and standardized benchmarking system for data valuation. In this paper, we introduce OpenDataVal, an easy-to-use and unified benchmark framework that empowers researchers and practitioners to apply and compare various data valuation algorithms. OpenDataVal provides an integrated environment that includes (i) a diverse collection of image, natural language, and tabular datasets, (ii) implementations of eleven different state-of-the-art data valuation algorithms, and (iii) a prediction model API that can import any models in scikit-learn. Furthermore, we propose four downstream machine learning tasks for evaluating the quality of data values. We perform benchmarking analysis using OpenDataVal, quantifying and comparing the efficacy of state-of-the-art data valuation approaches. We find that no single algorithm performs uniformly best across all tasks, and an appropriate algorithm should be employed for a user's downstream task. OpenDataVal is publicly available at https://opendataval.github.io with comprehensive documentation. Furthermore, we provide a leaderboard where researchers can evaluate the effectiveness of their own data valuation algorithms.
count=2
* Reimagining Synthetic Tabular Data Generation through Data-Centric AI: A Comprehensive Benchmark
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/6aa9a05b929fb08ff46a58cab6cf860d-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/6aa9a05b929fb08ff46a58cab6cf860d-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Reimagining Synthetic Tabular Data Generation through Data-Centric AI: A Comprehensive Benchmark
    * Year: `2023`
    * Authors: Lasse Hansen, Nabeel Seedat, Mihaela van der Schaar, Andrija Petrovic
    * Abstract: Synthetic data serves as an alternative in training machine learning models, particularly when real-world data is limited or inaccessible. However, ensuring that synthetic data mirrors the complex nuances of real-world data is a challenging task. This paper addresses this issue by exploring the potential of integrating data-centric AI techniques which profile the data to guide the synthetic data generation process. Moreover, we shed light on the often ignored consequences of neglecting these data profiles during synthetic data generation --- despite seemingly high statistical fidelity. Subsequently, we propose a novel framework to evaluate the integration of data profiles to guide the creation of more representative synthetic data. In an empirical study, we evaluate the performance of five state-of-the-art models for tabular data generation on eleven distinct tabular datasets. The findings offer critical insights into the successes and limitations of current synthetic data generation techniques. Finally, we provide practical recommendations for integrating data-centric insights into the synthetic data generation process, with a specific focus on classification performance, model selection, and feature selection. This study aims to reevaluate conventional approaches to synthetic data generation and promote the application of data-centric AI techniques in improving the quality and effectiveness of synthetic data.
count=2
* Simplifying Neural Network Training Under Class Imbalance
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/6ea69f8116b7c01e3c3e43b62e6868fc-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/6ea69f8116b7c01e3c3e43b62e6868fc-Paper-Conference.pdf)]
    * Title: Simplifying Neural Network Training Under Class Imbalance
    * Year: `2023`
    * Authors: Ravid Shwartz-Ziv, Micah Goldblum, Yucen Li, C. Bayan Bruss, Andrew G. Wilson
    * Abstract: Real-world datasets are often highly class-imbalanced, which can adversely impact the performance of deep learning models. The majority of research on training neural networks under class imbalance has focused on specialized loss functions and sampling techniques. Notably, we demonstrate that simply tuning existing components of standard deep learning pipelines, such as the batch size, data augmentation, architecture size, pre-training, optimizer, and label smoothing, can achieve state-of-the-art performance without any specialized loss functions or samplers. We also provide key prescriptions and considerations for training under class imbalance, and an understanding of why imbalance methods succeed or fail.
count=2
* Efficient Symbolic Policy Learning with Differentiable Symbolic Expression
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/7207ffb9888068c0ee13ae3be023cada-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/7207ffb9888068c0ee13ae3be023cada-Paper-Conference.pdf)]
    * Title: Efficient Symbolic Policy Learning with Differentiable Symbolic Expression
    * Year: `2023`
    * Authors: Jiaming Guo, Rui Zhang, Shaohui Peng, Qi Yi, Xing Hu, Ruizhi Chen, Zidong Du, xishan zhang, Ling Li, Qi Guo, Yunji Chen
    * Abstract: Deep reinforcement learning (DRL) has led to a wide range of advances in sequential decision-making tasks. However, the complexity of neural network policies makes it difficult to understand and deploy with limited computational resources. Currently, employing compact symbolic expressions as symbolic policies is a promising strategy to obtain simple and interpretable policies. Previous symbolic policy methods usually involve complex training processes and pre-trained neural network policies, which are inefficient and limit the application of symbolic policies. In this paper, we propose an efficient gradient-based learning method named Efficient Symbolic Policy Learning (ESPL) that learns the symbolic policy from scratch in an end-to-end way. We introduce a symbolic network as the search space and employ a path selector to find the compact symbolic policy. By doing so we represent the policy with a differentiable symbolic expression and train it in an off-policy manner which further improves the efficiency. In addition, in contrast with previous symbolic policies which only work in single-task RL because of complexity, we expand ESPL on meta-RL to generate symbolic policies for unseen tasks. Experimentally, we show that our approach generates symbolic policies with higher performance and greatly improves data efficiency for single-task RL. In meta-RL, we demonstrate that compared with neural network policies the proposed symbolic policy achieves higher performance and efficiency and shows the potential to be interpretable.
count=2
* Goal Driven Discovery of Distributional Differences via Language Descriptions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/7e810b2c75d69be186cadd2fe3febeab-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/7e810b2c75d69be186cadd2fe3febeab-Paper-Conference.pdf)]
    * Title: Goal Driven Discovery of Distributional Differences via Language Descriptions
    * Year: `2023`
    * Authors: Ruiqi Zhong, Peter Zhang, Steve Li, Jinwoo Ahn, Dan Klein, Jacob Steinhardt
    * Abstract: Exploring large corpora can generate useful discoveries but is time-consuming for humans. We formulate a new task, D5, that automatically discovers differences between two large corpora in a goal-driven way. The task input is a problem comprising a user-specified research goal (“comparing the side effects of drug A and drug”) and a corpus pair (two large collections of patients' self-reported reactions after taking each drug). The output is a goal-related description (discovery) of how these corpora differ (patients taking drug A “mention feelings of paranoia” more often). We build a D5 system, and to quantitatively evaluate its performance, we 1) build a diagnostic benchmark, SynD5, to test whether it can recover known differences between two synthetic corpora, and 2) contribute a meta-dataset, OpenD5, aggregating 675 open-ended problems ranging across business, social sciences, humanities, machine learning, and health. With both synthetic and real datasets, we confirm that language models can leverage the user-specified goals to propose more relevant candidate discoveries, and they sometimes produce discoveries previously unknown to the authors, including demographic differences in discussion topics, political stances in speech, insights in commercial reviews, and error patterns in NLP models. Finally, we discuss the limitations of the current D5 system, which discovers correlation rather than causation and has the potential to reinforce societal biases when misused; therefore, practitioners should treat the outputs of our system with caution.
count=2
* Towards robust and generalizable representations of extracellular data using contrastive learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/83c637c3bc0ca88eda6cf4f5f45bdced-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/83c637c3bc0ca88eda6cf4f5f45bdced-Paper-Conference.pdf)]
    * Title: Towards robust and generalizable representations of extracellular data using contrastive learning
    * Year: `2023`
    * Authors: Ankit Vishnubhotla, Charlotte Loh, Akash Srivastava, Liam Paninski, Cole Hurwitz
    * Abstract: Contrastive learning is quickly becoming an essential tool in neuroscience for extracting robust and meaningful representations of neural activity. Despite numerous applications to neuronal population data, there has been little exploration of how these methods can be adapted to key primary data analysis tasks such as spike sorting or cell-type classification. In this work, we propose a novel contrastive learning framework, CEED (Contrastive Embeddings for Extracellular Data), for high-density extracellular recordings. We demonstrate that through careful design of the network architecture and data augmentations, it is possible to generically extract representations that far outperform current specialized approaches. We validate our method across multiple high-density extracellular recordings. All code used to run CEED can be found at https://github.com/ankitvishnu23/CEED.
count=2
* Model Shapley: Equitable Model Valuation with Black-box Access
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/86bcae6da75c72e32f30a5553f094c06-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/86bcae6da75c72e32f30a5553f094c06-Paper-Conference.pdf)]
    * Title: Model Shapley: Equitable Model Valuation with Black-box Access
    * Year: `2023`
    * Authors: Xinyi Xu, Thanh Lam, Chuan Sheng Foo, Bryan Kian Hsiang Low
    * Abstract: Valuation methods of data and machine learning (ML) models are essential to the establishment of AI marketplaces. Importantly, certain practical considerations (e.g., operational constraints, legal restrictions) favor the use of model valuation over data valuation. Also, existing marketplaces that involve trading of pre-trained ML models call for an equitable model valuation method to price them. In particular, we investigate the black-box access setting which allows querying a model (to observe predictions) without disclosing model-specific information (e.g., architecture and parameters). By exploiting a Dirichlet abstraction of a model’s predictions, we propose a novel and equitable model valuation method called model Shapley. We also leverage a Lipschitz continuity of model Shapley to design a learning approach for predicting the model Shapley values (MSVs) of many vendors’ models (e.g., 150) in a large-scale marketplace. We perform extensive empirical validation on the effectiveness of model Shapley using various real-world datasets and heterogeneous model types.
count=2
* Reinforcement-Enhanced Autoregressive Feature Transformation: Gradient-steered Search in Continuous Space for Postfix Expressions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/8797d13e5998acfab387d4bf0a5b9b00-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/8797d13e5998acfab387d4bf0a5b9b00-Paper-Conference.pdf)]
    * Title: Reinforcement-Enhanced Autoregressive Feature Transformation: Gradient-steered Search in Continuous Space for Postfix Expressions
    * Year: `2023`
    * Authors: Dongjie Wang, Meng Xiao, Min Wu, pengfei wang, Yuanchun Zhou, Yanjie Fu
    * Abstract: Feature transformation aims to generate new pattern-discriminative feature space from original features to improve downstream machine learning (ML) task performances. However, the discrete search space for the optimal feature explosively grows on the basis of combinations of features and operations from low-order forms to high-order forms. Existing methods, such as exhaustive search, expansion reduction, evolutionary algorithms, reinforcement learning, and iterative greedy, suffer from large search space. Overly emphasizing efficiency in algorithm design usually sacrifice stability or robustness. To fundamentally fill this gap, we reformulate discrete feature transformation as a continuous space optimization task and develop an embedding-optimization-reconstruction framework. This framework includes four steps: 1) reinforcement-enhanced data preparation, aiming to prepare high-quality transformation-accuracy training data; 2) feature transformation operation sequence embedding, intending to encapsulate the knowledge of prepared training data within a continuous space; 3) gradient-steered optimal embedding search, dedicating to uncover potentially superior embeddings within the learned space; 4) transformation operation sequence reconstruction, striving to reproduce the feature transformation solution to pinpoint the optimal feature space. Finally, extensive experiments and case studies are performed to demonstrate the effectiveness and robustness of the proposed method. The code and data are publicly accessible https://www.dropbox.com/sh/imh8ckui7va3k5u/AACulQegVx0MuywYyoCqSdVPa?dl=0.
count=2
* The Utility of “Even if” Semifactual Explanation to Optimise Positive Outcomes
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/a5e146ca55a2b18be41942cfa677123d-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/a5e146ca55a2b18be41942cfa677123d-Paper-Conference.pdf)]
    * Title: The Utility of “Even if” Semifactual Explanation to Optimise Positive Outcomes
    * Year: `2023`
    * Authors: Eoin Kenny, Weipeng Huang
    * Abstract: When users receive either a positive or negative outcome from an automated system, Explainable AI (XAI) has almost exclusively focused on how to mutate negative outcomes into positive ones by crossing a decision boundary using counterfactuals (e.g., "If you earn 2k more, we will accept your loan application"). Here, we instead focus on positive outcomes, and take the novel step of using XAI to optimise them (e.g., "Even if you wish to half your down-payment, we will still accept your loan application"). Explanations such as these that employ "even if..." reasoning, and do not cross a decision boundary, are known as semifactuals. To instantiate semifactuals in this context, we introduce the concept of Gain (i.e., how much a user stands to benefit from the explanation), and consider the first causal formalisation of semifactuals. Tests on benchmark datasets show our algorithms are better at maximising gain compared to prior work, and that causality is important in the process. Most importantly however, a user study supports our main hypothesis by showing people find semifactual explanations more useful than counterfactuals when they receive the positive outcome of a loan acceptance.
count=2
* A Batch-to-Online Transformation under Random-Order Model
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/afe99e55be23b3523818da1fefa33494-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/afe99e55be23b3523818da1fefa33494-Paper-Conference.pdf)]
    * Title: A Batch-to-Online Transformation under Random-Order Model
    * Year: `2023`
    * Authors: Jing Dong, Yuichi Yoshida
    * Abstract: We introduce a transformation framework that can be utilized to develop online algorithms with low $\epsilon$-approximate regret in the random-order model from offline approximation algorithms. We first give a general reduction theorem that transforms an offline approximation algorithm with low average sensitivity to an online algorithm with low $\epsilon$-approximate regret. We then demonstrate that offline approximation algorithms can be transformed into a low-sensitivity version using a coreset construction method. To showcase the versatility of our approach, we apply it to various problems, including online $(k,z)$-clustering, online matrix approximation, and online regression, and successfully achieve polylogarithmic $\epsilon$-approximate regret for each problem. Moreover, we show that in all three cases, our algorithm also enjoys low inconsistency, which may be desired in some online applications.
count=2
* Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/b2e63e36c57e153b9015fece2352a9f9-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/b2e63e36c57e153b9015fece2352a9f9-Paper-Conference.pdf)]
    * Title: Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection
    * Year: `2023`
    * Authors: Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei
    * Abstract: Neural sequence models based on the transformer architecture have demonstrated remarkable \emph{in-context learning} (ICL) abilities, where they can perform new tasks when prompted with training and test examples, without any parameter update to the model. This work first provides a comprehensive statistical theory for transformers to perform ICL. Concretely, we show that transformers can implement a broad class of standard machine learning algorithms in context, such as least squares, ridge regression, Lasso, learning generalized linear models, and gradient descent on two-layer neural networks, with near-optimal predictive power on various in-context data distributions. Using an efficient implementation of in-context gradient descent as the underlying mechanism, our transformer constructions admit mild size bounds, and can be learned with polynomially many pretraining sequences. Building on these ``base'' ICL algorithms, intriguingly, we show that transformers can implement more complex ICL procedures involving \emph{in-context algorithm selection}, akin to what a statistician can do in real life---A \emph{single} transformer can adaptively select different base ICL algorithms---or even perform qualitatively different tasks---on different input sequences, without any explicit prompting of the right algorithm or task. We both establish this in theory by explicit constructions, and also observe this phenomenon experimentally. In theory, we construct two general mechanisms for algorithm selection with concrete examples: pre-ICL testing, and post-ICL validation. As an example, we use the post-ICL validation mechanism to construct a transformer that can perform nearly Bayes-optimal ICL on a challenging task---noisy linear models with mixed noise levels. Experimentally, we demonstrate the strong in-context algorithm selection capabilities of standard transformer architectures.
count=2
* Beyond probability partitions: Calibrating neural networks with semantic aware grouping
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/b693a240cf1009bff9fa4422141c9392-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/b693a240cf1009bff9fa4422141c9392-Paper-Conference.pdf)]
    * Title: Beyond probability partitions: Calibrating neural networks with semantic aware grouping
    * Year: `2023`
    * Authors: Jia-Qi Yang, De-Chuan Zhan, Le Gan
    * Abstract: Research has shown that deep networks tend to be overly optimistic about their predictions, leading to an underestimation of prediction errors. Due to the limited nature of data, existing studies have proposed various methods based on model prediction probabilities to bin the data and evaluate calibration error. We propose a more generalized definition of calibration error called Partitioned Calibration Error (PCE), revealing that the key difference among these calibration error metrics lies in how the data space is partitioned. We put forth an intuitive proposition that an accurate model should be calibrated across any partition, suggesting that the input space partitioning can extend beyond just the partitioning of prediction probabilities, and include partitions directly related to the input. Through semantic-related partitioning functions, we demonstrate that the relationship between model accuracy and calibration lies in the granularity of the partitioning function. This highlights the importance of partitioning criteria for training a calibrated and accurate model. To validate the aforementioned analysis, we propose a method that involves jointly learning a semantic aware grouping function based on deep model features and logits to partition the data space into subsets. Subsequently, a separate calibration function is learned for each subset. Experimental results demonstrate that our approach achieves significant performance improvements across multiple datasets and network architectures, thus highlighting the importance of the partitioning function for calibration.
count=2
* GRAND-SLAMIN’ Interpretable Additive Modeling with Structural Constraints
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/c057cb81b8d3c67093427bf1c16a4e9f-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/c057cb81b8d3c67093427bf1c16a4e9f-Paper-Conference.pdf)]
    * Title: GRAND-SLAMIN’ Interpretable Additive Modeling with Structural Constraints
    * Year: `2023`
    * Authors: Shibal Ibrahim, Gabriel Afriat, Kayhan Behdin, Rahul Mazumder
    * Abstract: Generalized Additive Models (GAMs) are a family of flexible and interpretable models with old roots in statistics. GAMs are often used with pairwise interactions to improve model accuracy while still retaining flexibility and interpretability but lead to computational challenges as we are dealing with order of $p^2$ terms. It is desirable to restrict the number of components (i.e., encourage sparsity) for easier interpretability, and better computational and statistical properties. Earlier approaches, considering sparse pairwise interactions, have limited scalability, especially when imposing additional structural interpretability constraints. We propose a flexible GRAND-SLAMIN framework that can learn GAMs with interactions under sparsity and additional structural constraints in a differentiable end-to-end fashion. We customize first-order gradient-based optimization to perform sparse backpropagation to exploit sparsity in additive effects for any differentiable loss function in a GPU-compatible manner. Additionally, we establish novel non-asymptotic prediction bounds for our estimators with tree-based shape functions. Numerical experiments on real-world datasets show that our toolkit performs favorably in terms of performance, variable selection and scalability when compared with popular toolkits to fit GAMs with interactions. Our work expands the landscape of interpretable modeling while maintaining prediction accuracy competitive with non-interpretable black-box models. Our code is available at https://github.com/mazumder-lab/grandslamin.
count=2
* Learning List-Level Domain-Invariant Representations for Ranking
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/cc473bb3ec4176a5e640c3a6b5fb5239-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/cc473bb3ec4176a5e640c3a6b5fb5239-Paper-Conference.pdf)]
    * Title: Learning List-Level Domain-Invariant Representations for Ranking
    * Year: `2023`
    * Authors: Ruicheng Xian, Honglei Zhuang, Zhen Qin, Hamed Zamani, Jing Lu, Ji Ma, Kai Hui, Han Zhao, Xuanhui Wang, Michael Bendersky
    * Abstract: Domain adaptation aims to transfer the knowledge learned on (data-rich) source domains to (low-resource) target domains, and a popular method is invariant representation learning, which matches and aligns the data distributions on the feature space. Although this method is studied extensively and applied on classification and regression problems, its adoption on ranking problems is sporadic, and the few existing implementations lack theoretical justifications. This paper revisits invariant representation learning for ranking. Upon reviewing prior work, we found that they implement what we call item-level alignment, which aligns the distributions of the items being ranked from all lists in aggregate but ignores their list structure. However, the list structure should be leveraged, because it is intrinsic to ranking problems where the data and the metrics are defined and computed on lists, not the items by themselves. To close this discrepancy, we propose list-level alignment—learning domain-invariant representations at the higher level of lists. The benefits are twofold: it leads to the first domain adaptation generalization bound for ranking, in turn providing theoretical support for the proposed method, and it achieves better empirical transfer performance for unsupervised domain adaptation on ranking tasks, including passage reranking.
count=2
* Understanding the Limitations of Deep Models for Molecular property prediction: Insights and Solutions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/cc83e97320000f4e08cb9e293b12cf7e-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/cc83e97320000f4e08cb9e293b12cf7e-Paper-Conference.pdf)]
    * Title: Understanding the Limitations of Deep Models for Molecular property prediction: Insights and Solutions
    * Year: `2023`
    * Authors: Jun Xia, Lecheng Zhang, Xiao Zhu, Yue Liu, Zhangyang Gao, Bozhen Hu, Cheng Tan, Jiangbin Zheng, Siyuan Li, Stan Z. Li
    * Abstract: Molecular Property Prediction (MPP) is a crucial task in the AI-driven Drug Discovery (AIDD) pipeline, which has recently gained considerable attention thanks to advancements in deep learning. However, recent research has revealed that deep models struggle to beat traditional non-deep ones on MPP. In this study, we benchmark 12 representative models (3 non-deep models and 9 deep models) on 15 molecule datasets. Through the most comprehensive study to date, we make the following key observations: \textbf{(\romannumeral 1)} Deep models are generally unable to outperform non-deep ones; \textbf{(\romannumeral 2)} The failure of deep models on MPP cannot be solely attributed to the small size of molecular datasets; \textbf{(\romannumeral 3)} In particular, some traditional models including XGB and RF that use molecular fingerprints as inputs tend to perform better than other competitors. Furthermore, we conduct extensive empirical investigations into the unique patterns of molecule data and inductive biases of various models underlying these phenomena. These findings stimulate us to develop a simple-yet-effective feature mapping method for molecule data prior to feeding them into deep models. Empirically, deep models equipped with this mapping method can beat non-deep ones in most MoleculeNet datasets. Notably, the effectiveness is further corroborated by extensive experiments on cutting-edge dataset related to COVID-19 and activity cliff datasets.
count=2
* ADGym: Design Choices for Deep Anomaly Detection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/de670b9d118229d09d9a9bd9dec2598b-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/de670b9d118229d09d9a9bd9dec2598b-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: ADGym: Design Choices for Deep Anomaly Detection
    * Year: `2023`
    * Authors: Minqi Jiang, Chaochuan Hou, Ao Zheng, Songqiao Han, Hailiang Huang, Qingsong Wen, Xiyang Hu, Yue Zhao
    * Abstract: Deep learning (DL) techniques have recently found success in anomaly detection (AD) across various fields such as finance, medical services, and cloud computing. However, most of the current research tends to view deep AD algorithms as a whole, without dissecting the contributions of individual design choices like loss functions and network architectures. This view tends to diminish the value of preliminary steps like data preprocessing, as more attention is given to newly designed loss functions, network architectures, and learning paradigms. In this paper, we aim to bridge this gap by asking two key questions: (i) Which design choices in deep AD methods are crucial for detecting anomalies? (ii) How can we automatically select the optimal design choices for a given AD dataset, instead of relying on generic, pre-existing solutions? To address these questions, we introduce ADGym, a platform specifically crafted for comprehensive evaluation and automatic selection of AD design elements in deep methods. Our extensive experiments reveal that relying solely on existing leading methods is not sufficient. In contrast, models developed using ADGym significantly surpass current state-of-the-art techniques.
count=2
* Finding Safe Zones of Markov Decision Processes Policies
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/dfaa29ed28dfa175bcc5e2a54aa199f8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/dfaa29ed28dfa175bcc5e2a54aa199f8-Paper-Conference.pdf)]
    * Title: Finding Safe Zones of Markov Decision Processes Policies
    * Year: `2023`
    * Authors: Lee Cohen, Yishay Mansour, Michal Moshkovitz
    * Abstract: Given a policy of a Markov Decision Process, we define a SafeZone as a subset of states, such that most of the policy's trajectories are confined to this subset. The quality of a SafeZone is parameterized by the number of states and the escape probability, i.e., the probability that a random trajectory will leave the subset. SafeZones are especially interesting when they have a small number of states and low escape probability. We study the complexity of finding optimal SafeZones, and show that in general, the problem is computationally hard. For this reason, we concentrate on finding approximate SafeZones. Our main result is a bi-criteria approximation learning algorithm with a factor of almost $2$ approximation for both the escape probability and \newprob size, using a polynomial size sample complexity.
count=2
* Learning Functional Transduction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/e9b8a3362a6d9a7f9f842bd2d919e1a0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/e9b8a3362a6d9a7f9f842bd2d919e1a0-Paper-Conference.pdf)]
    * Title: Learning Functional Transduction
    * Year: `2023`
    * Authors: Mathieu Chalvidal, Thomas Serre, Rufin VanRullen
    * Abstract: Research in statistical learning has polarized into two general approaches to perform regression analysis: Transductive methods construct estimates directly based on exemplar data using generic relational principles which might suffer from the curse of dimensionality. Conversely, inductive methods can potentially fit highly complex functions at the cost of compute-intensive solution searches. In this work, we leverage the theory of vector-valued Reproducing Kernel Banach Spaces (RKBS) to propose a hybrid approach: We show that transductive regression systems can be meta-learned with gradient descent to form efficient in-context neural approximators of function defined over both finite and infinite-dimensional spaces (operator regression). Once trained, our Transducer can almost instantaneously capture new functional relationships and produce original image estimates, given a few pairs of input and output examples. We demonstrate the benefit of our meta-learned transductive approach to model physical systems influenced by varying external factors with little data at a fraction of the usual deep learning training costs for partial differential equations and climate modeling applications.
count=2
* On Robust Streaming for Learning with Experts: Algorithms and Lower Bounds
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/fb71332951af4ae27fbd457daadc5341-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/fb71332951af4ae27fbd457daadc5341-Paper-Conference.pdf)]
    * Title: On Robust Streaming for Learning with Experts: Algorithms and Lower Bounds
    * Year: `2023`
    * Authors: David Woodruff, Fred Zhang, Samson Zhou
    * Abstract: In the online learning with experts problem, an algorithm makes predictions about an outcome on each of $T$ days, given a set of $n$ experts who make predictions on each day. The algorithm is given feedback on the outcomes of each day, including the cost of its prediction and the cost of the expert predictions, and the goal is to make a prediction with the minimum cost, compared to the best expert in hindsight. However, often the predictions made by experts or algorithms at some time influence future outcomes, so that the input is adaptively generated. In this paper, we study robust algorithms for the experts problem under memory constraints. We first give a randomized algorithm that is robust to adaptive inputs that uses $\widetilde{O}\left(\frac{n}{R\sqrt{T}}\right)$ space for $M=O\left(\frac{R^2 T}{\log^2 n}\right)$, thereby showing a smooth space-regret trade-off. We then show a space lower bound of $\widetilde{\Omega}\left(\frac{nM}{RT}\right)$ for any randomized algorithm that achieves regret $R$ with probability $1-2^{-\Omega(T)}$, when the best expert makes $M$ mistakes. Our result implies that the natural deterministic algorithm, which iterates through pools of experts until each expert in the pool has erred, is optimal up to polylogarithmic factors. Finally, we empirically demonstrate the benefit of using robust procedures against a white-box adversary that has access to the internal state of the algorithm.
count=2
* CascadeXML: Rethinking Transformers for End-to-end Multi-resolution Training in Extreme Multi-label Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/0e0157ce5ea15831072be4744cbd5334-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/0e0157ce5ea15831072be4744cbd5334-Paper-Conference.pdf)]
    * Title: CascadeXML: Rethinking Transformers for End-to-end Multi-resolution Training in Extreme Multi-label Classification
    * Year: `2022`
    * Authors: Siddhant Kharbanda, Atmadeep Banerjee, Erik Schultheis, Rohit Babbar
    * Abstract: Extreme Multi-label Text Classification (XMC) involves learning a classifier that can assign an input with a subset of most relevant labels from millions of label choices. Recent approaches, such as XR-Transformer and LightXML, leverage a transformer instance to achieve state-of-the-art performance. However, in this process, these approaches need to make various trade-offs between performance and computational requirements. A major shortcoming, as compared to the Bi-LSTM based AttentionXML, is that they fail to keep separate feature representations for each resolution in a label tree. We thus propose CascadeXML, an end-to-end multi-resolution learning pipeline, which can harness the multi-layered architecture of a transformer model for attending to different label resolutions with separate feature representations. CascadeXML significantly outperforms all existing approaches with non-trivial gains obtained on benchmark datasets consisting of up to three million labels. Code for CascadeXML will be made publicly available at https://github.com/xmc-aalto/cascadexml.
count=2
* Towards Disentangling Information Paths with Coded ResNeXt
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/3a819a53408e20b75d1954bf617ccc0a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/3a819a53408e20b75d1954bf617ccc0a-Paper-Conference.pdf)]
    * Title: Towards Disentangling Information Paths with Coded ResNeXt
    * Year: `2022`
    * Authors: Apostolos Avranas, Marios Kountouris
    * Abstract: The conventional, widely used treatment of deep learning models as black boxes provides limited or no insights into the mechanisms that guide neural network decisions. Significant research effort has been dedicated to building interpretable models to address this issue. Most efforts either focus on the high-level features associated with the last layers, or attempt to interpret the output of a single layer. In this paper, we take a novel approach to enhance the transparency of the function of the whole network. We propose a neural network architecture for classification, in which the information that is relevant to each class flows through specific paths. These paths are designed in advance before training leveraging coding theory and without depending on the semantic similarities between classes. A key property is that each path can be used as an autonomous single-purpose model. This enables us to obtain, without any additional training and for any class, a lightweight binary classifier that has at least $60\%$ fewer parameters than the original network. Furthermore, our coding theory based approach allows the neural network to make early predictions at intermediate layers during inference, without requiring its full evaluation. Remarkably, the proposed architecture provides all the aforementioned properties while improving the overall accuracy. We demonstrate these properties on a slightly modified ResNeXt model tested on CIFAR-10/100 and ImageNet-1k.
count=2
* Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/408cf1a1d9ff35d5fea7075565dbf434-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/408cf1a1d9ff35d5fea7075565dbf434-Paper-Conference.pdf)]
    * Title: Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation
    * Year: `2022`
    * Authors: Josh Gardner, Zoran Popovic, Ludwig Schmidt
    * Abstract: Researchers have proposed many methods for fair and robust machine learning, but comprehensive empirical evaluation of their subgroup robustness is lacking. In this work, we address this gap in the context of tabular data, where sensitive subgroups are clearly-defined, real-world fairness problems abound, and prior works often do not compare to state-of-the-art tree-based models as baselines. We conduct an empirical comparison of several previously-proposed methods for fair and robust learning alongside state-of-the-art tree-based methods and other baselines. Via experiments with more than $340{,}000$ model configurations on eight datasets, we show that tree-based methods have strong subgroup robustness, even when compared to robustness- and fairness-enhancing methods. Moreover, the best tree-based models tend to show good performance over a range of metrics, while robust or group-fair models can show brittleness, with significant performance differences across different metrics for a fixed model. We also demonstrate that tree-based models show less sensitivity to hyperparameter configurations, and are less costly to train. Our work suggests that tree-based ensemble models make an effective baseline for tabular data, and are a sensible default when subgroup robustness is desired. See https://github.com/jpgard/subgroup-robustness-grows-on-trees for code to reproduce our experiments and detailed experimental results.
count=2
* Hierarchical Lattice Layer for Partially Monotone Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/47ed62021460f2e9bba7be3e74260090-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/47ed62021460f2e9bba7be3e74260090-Paper-Conference.pdf)]
    * Title: Hierarchical Lattice Layer for Partially Monotone Neural Networks
    * Year: `2022`
    * Authors: Hiroki Yanagisawa, Kohei Miyaguchi, Takayuki Katsuki
    * Abstract: Partially monotone regression is a regression analysis in which the target values are monotonically increasing with respect to a subset of input features. The TensorFlow Lattice library is one of the standard machine learning libraries for partially monotone regression. It consists of several neural network layers, and its core component is the lattice layer. One of the problems of the lattice layer is that it requires the projected gradient descent algorithm with many constraints to train it. Another problem is that it cannot receive a high-dimensional input vector due to the memory consumption. We propose a novel neural network layer, the hierarchical lattice layer (HLL), as an extension of the lattice layer so that we can use a standard stochastic gradient descent algorithm to train HLL while satisfying monotonicity constraints and so that it can receive a high-dimensional input vector. Our experiments demonstrate that HLL did not sacrifice its prediction performance on real datasets compared with the lattice layer.
count=2
* Instance-Based Uncertainty Estimation for Gradient-Boosted Regression Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/48088756ec0ce6ba362bddc7ebeb3915-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/48088756ec0ce6ba362bddc7ebeb3915-Paper-Conference.pdf)]
    * Title: Instance-Based Uncertainty Estimation for Gradient-Boosted Regression Trees
    * Year: `2022`
    * Authors: Jonathan Brophy, Daniel Lowd
    * Abstract: Gradient-boosted regression trees (GBRTs) are hugely popular for solving tabular regression problems, but provide no estimate of uncertainty. We propose Instance-Based Uncertainty estimation for Gradient-boosted regression trees (IBUG), a simple method for extending any GBRT point predictor to produce probabilistic predictions. IBUG computes a non-parametric distribution around a prediction using the $k$-nearest training instances, where distance is measured with a tree-ensemble kernel. The runtime of IBUG depends on the number of training examples at each leaf in the ensemble, and can be improved by sampling trees or training instances. Empirically, we find that IBUG achieves similar or better performance than the previous state-of-the-art across 22 benchmark regression datasets. We also find that IBUG can achieve improved probabilistic performance by using different base GBRT models, and can more flexibly model the posterior distribution of a prediction than competing methods. We also find that previous methods suffer from poor probabilistic calibration on some datasets, which can be mitigated using a scalar factor tuned on the validation data. Source code is available at https://github.com/jjbrophy47/ibug.
count=2
* LIFT: Language-Interfaced Fine-Tuning for Non-language Machine Learning Tasks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/4ce7fe1d2730f53cb3857032952cd1b8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/4ce7fe1d2730f53cb3857032952cd1b8-Paper-Conference.pdf)]
    * Title: LIFT: Language-Interfaced Fine-Tuning for Non-language Machine Learning Tasks
    * Year: `2022`
    * Authors: Tuan Dinh, Yuchen Zeng, Ruisu Zhang, Ziqian Lin, Michael Gira, Shashank Rajput, Jy-yong Sohn, Dimitris Papailiopoulos, Kangwook Lee
    * Abstract: Fine-tuning pretrained language models (LMs) without making any architectural changes has become a norm for learning various language downstream tasks. However, for non-language downstream tasks, a common practice is to employ task-specific designs for input, output layers, and loss functions. For instance, it is possible to fine-tune an LM into an MNIST classifier by replacing the word embedding layer with an image patch embedding layer, the word token output layer with a 10-way output layer, and the word prediction loss with a 10-way classification loss, respectively. A natural question arises: Can LM fine-tuning solve non-language downstream tasks without changing the model architecture or loss function? To answer this, we propose Language-Interfaced Fine-Tuning (LIFT) and study its efficacy and limitations by conducting an extensive empirical study on a suite of non-language classification and regression tasks. LIFT does not make any changes to the model architecture or loss function, and it solely relies on the natural language interface, enabling "no-code machine learning with LMs." We find that LIFT performs comparably well across a wide range of low-dimensional classification and regression tasks, matching the performances of the best baselines in many cases, especially for the classification tasks. We also report experimental results on the fundamental properties of LIFT, including inductive bias, robustness, and sample complexity. We also analyze the effect of pretraining on LIFT and a few properties/techniques specific to LIFT, e.g., context-aware learning via appropriate prompting, calibrated predictions, data generation, and two-stage fine-tuning. Our code is available at https://github.com/UW-Madison-Lee-Lab/LanguageInterfacedFineTuning.
count=2
* Sparse Interaction Additive Networks via Feature Interaction Detection and Sparse Selection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/5a3674849d6d6d23ac088b9a2552f323-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/5a3674849d6d6d23ac088b9a2552f323-Paper-Conference.pdf)]
    * Title: Sparse Interaction Additive Networks via Feature Interaction Detection and Sparse Selection
    * Year: `2022`
    * Authors: James Enouen, Yan Liu
    * Abstract: There is currently a large gap in performance between the statistically rigorous methods like linear regression or additive splines and the powerful deep methods using neural networks. Previous works attempting to close this gap have failed to fully consider the exponentially growing number of feature combinations which deep networks consider automatically during training. In this work, we develop a tractable selection algorithm to efficiently identify the necessary feature combinations by leveraging techniques in feature interaction detection.Our proposed Sparse Interaction Additive Networks (SIAN) construct a bridge from these simple and interpretable models to a fully connected neural network. SIAN achieves competitive performance against state-of-the-art methods across multiple large-scale tabular datasets and consistently finds an optimal tradeoff between the modeling capacity of neural networks and the generalizability of simpler methods.
count=2
* FasterRisk: Fast and Accurate Interpretable Risk Scores
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/7103444259031cc58051f8c9a4868533-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/7103444259031cc58051f8c9a4868533-Paper-Conference.pdf)]
    * Title: FasterRisk: Fast and Accurate Interpretable Risk Scores
    * Year: `2022`
    * Authors: Jiachang Liu, Chudi Zhong, Boxuan Li, Margo Seltzer, Cynthia Rudin
    * Abstract: Over the last century, risk scores have been the most popular form of predictive model used in healthcare and criminal justice. Risk scores are sparse linear models with integer coefficients; often these models can be memorized or placed on an index card. Typically, risk scores have been created either without data or by rounding logistic regression coefficients, but these methods do not reliably produce high-quality risk scores. Recent work used mathematical programming, which is computationally slow. We introduce an approach for efficiently producing a collection of high-quality risk scores learned from data. Specifically, our approach produces a pool of almost-optimal sparse continuous solutions, each with a different support set, using a beam-search algorithm. Each of these continuous solutions is transformed into a separate risk score through a "star ray" search, where a range of multipliers are considered before rounding the coefficients sequentially to maintain low logistic loss. Our algorithm returns all of these high-quality risk scores for the user to consider. This method completes within minutes and can be valuable in a broad variety of applications.
count=2
* Kernel Multimodal Continuous Attention
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/727a5a5c77be15d053b47b7c391800c2-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/727a5a5c77be15d053b47b7c391800c2-Paper-Conference.pdf)]
    * Title: Kernel Multimodal Continuous Attention
    * Year: `2022`
    * Authors: Alexander Moreno, Zhenke Wu, Supriya Nagesh, Walter Dempsey, James M. Rehg
    * Abstract: Attention mechanisms take an expectation of a data representation with respect to probability weights. Recently, (Martins et al. 2020, 2021) proposed continuous attention mechanisms, focusing on unimodal attention densities from the exponential and deformed exponential families: the latter has sparse support. (Farinhas et al 2021) extended this to to multimodality via Gaussian mixture attention densities. In this paper, we extend this to kernel exponential families (Canu and Smola 2006) and our new sparse counterpart, kernel deformed exponential families. Theoretically, we show new existence results for both kernel exponential and deformed exponential families, and that the deformed case has similar approximation capabilities to kernel exponential families. Lacking closed form expressions for the context vector, we use numerical integration: we show exponential convergence for both kernel exponential and deformed exponential families. Experiments show that kernel continuous attention often outperforms unimodal continuous attention, and the sparse variant tends to highlight peaks of time series.
count=2
* A Dataset for Efforts Towards Achieving the Sustainable Development Goal of Safe Working Environments
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/93e4d161bdd93d1dc0202b4044159edb-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/93e4d161bdd93d1dc0202b4044159edb-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: A Dataset for Efforts Towards Achieving the Sustainable Development Goal of Safe Working Environments
    * Year: `2022`
    * Authors: Eirik Lund Flogard, Ole Jakob Mengshoel
    * Abstract: Among United Nations' 17 Sustainable Development Goals (SDGs), we highlight SDG 8 on Decent Work and Economic Growth. Specifically, we consider how to achieve subgoal 8.8, "protect labour rights and promote safe working environments for all workers [...]", in light of poor health, safety and environment (HSE) conditions being a widespread problem at workplaces. In EU alone, it is estimated that more than 4000 deaths occur each year due to poor working conditions. To handle the problem and achieve SDG 8, governmental agencies conduct labour inspections and it is therefore essential that these are carried out efficiently. Current research suggests that machine learning (ML) can be used to improve labour inspections, for instance by selecting organisations for inspections more effectively. However, the research in this area is very limited, in part due to a lack of publicly available data. Consequently, we introduce a new dataset called the Labour Inspection Checklists Dataset (LICD), which we have made publicly available. LICD consists of 63634 instances where each instance is an inspection conducted by the Norwegian Labour Inspection Authority. LICD has 577 features and labels. The dataset provides several ML research opportunities; we discuss two demonstration experiments. One experiment deals with the problem of selecting a relevant checklist for inspecting a given target organisation. The other experiment concerns the problem of predicting HSE violations, given a specific checklist and a target organisation. Our experimental results, while promising, suggest that achieving good ML classification performance is difficult for both problems. This motivates future research to improve ML performance, inspire other data analysis efforts, and ultimately achieve SDG 8.
count=2
* Sparse Probabilistic Circuits via Pruning and Growing
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/b6089408f4893289296ad0499783b3a6-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/b6089408f4893289296ad0499783b3a6-Paper-Conference.pdf)]
    * Title: Sparse Probabilistic Circuits via Pruning and Growing
    * Year: `2022`
    * Authors: Meihua Dang, Anji Liu, Guy Van den Broeck
    * Abstract: Probabilistic circuits (PCs) are a tractable representation of probability distributions allowing for exact and efficient computation of likelihoods and marginals. There has been significant recent progress on improving the scale and expressiveness of PCs. However, PC training performance plateaus as model size increases. We discover that most capacity in existing large PC structures is wasted: fully-connected parameter layers are only sparsely used. We propose two operations: pruning and growing, that exploit the sparsity of PC structures. Specifically, the pruning operation removes unimportant sub-networks of the PC for model compression and comes with theoretical guarantees. The growing operation increases model capacity by increasing the dimensions of latent states. By alternatingly applying pruning and growing, we increase the capacity that is meaningfully used, allowing us to significantly scale up PC learning. Empirically, our learner achieves state-of-the-art likelihoods on MNIST-family image datasets and an Penn Tree Bank language data compared to other PC learners and less tractable deep generative models such as flow-based models and variational autoencoders (VAEs).
count=2
* Rashomon Capacity: A Metric for Predictive Multiplicity in Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/ba4caa85ecdcafbf9102ab8ec384182d-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/ba4caa85ecdcafbf9102ab8ec384182d-Paper-Conference.pdf)]
    * Title: Rashomon Capacity: A Metric for Predictive Multiplicity in Classification
    * Year: `2022`
    * Authors: Hsiang Hsu, Flavio Calmon
    * Abstract: Predictive multiplicity occurs when classification models with statistically indistinguishable performances assign conflicting predictions to individual samples. When used for decision-making in applications of consequence (e.g., lending, education, criminal justice), models developed without regard for predictive multiplicity may result in unjustified and arbitrary decisions for specific individuals. We introduce a new metric, called Rashomon Capacity, to measure predictive multiplicity in probabilistic classification. Prior metrics for predictive multiplicity focus on classifiers that output thresholded (i.e., 0-1) predicted classes. In contrast, Rashomon Capacity applies to probabilistic classifiers, capturing more nuanced score variations for individual samples. We provide a rigorous derivation for Rashomon Capacity, argue its intuitive appeal, and demonstrate how to estimate it in practice. We show that Rashomon Capacity yields principled strategies for disclosing conflicting models to stakeholders. Our numerical experiments illustrate how Rashomon Capacity captures predictive multiplicity in various datasets and learning models, including neural networks. The tools introduced in this paper can help data scientists measure and report predictive multiplicity prior to model deployment.
count=2
* Semantic Probabilistic Layers for Neuro-Symbolic Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/c182ec594f38926b7fcb827635b9a8f4-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/c182ec594f38926b7fcb827635b9a8f4-Paper-Conference.pdf)]
    * Title: Semantic Probabilistic Layers for Neuro-Symbolic Learning
    * Year: `2022`
    * Authors: Kareem Ahmed, Stefano Teso, Kai-Wei Chang, Guy Van den Broeck, Antonio Vergari
    * Abstract: We design a predictive layer for structured-output prediction (SOP) that can be plugged into any neural network guaranteeing its predictions are consistent with a set of predefined symbolic constraints. Our Semantic Probabilistic Layer (SPL) can model intricate correlations, and hard constraints, over a structured output space all while being amenable to end-to-end learning via maximum likelihood.SPLs combine exact probabilistic inference with logical reasoning in a clean and modular way, learning complex distributions and restricting their support to solutions of the constraint. As such, they can faithfully, and efficiently, model complex SOP tasks beyond the reach of alternative neuro-symbolic approaches. We empirically demonstrate that SPLs outperform these competitors in terms of accuracy on challenging SOP tasks such as hierarchical multi-label classification, pathfinding and preference learning, while retaining perfect constraint satisfaction.
count=2
* BagFlip: A Certified Defense Against Data Poisoning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/cc19e4ffde5540ac3fcda240e6d975cb-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/cc19e4ffde5540ac3fcda240e6d975cb-Paper-Conference.pdf)]
    * Title: BagFlip: A Certified Defense Against Data Poisoning
    * Year: `2022`
    * Authors: Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni
    * Abstract: Machine learning models are vulnerable to data-poisoning attacks, in which an attacker maliciously modifies the training set to change the prediction of a learned model. In a trigger-less attack, the attacker can modify the training set but not the test inputs, while in a backdoor attack the attacker can also modify test inputs. Existing model-agnostic defense approaches either cannot handle backdoor attacks or do not provide effective certificates (i.e., a proof of a defense). We present BagFlip, a model-agnostic certified approach that can effectively defend against both trigger-less and backdoor attacks. We evaluate BagFlip on image classification and malware detection datasets. BagFlip is equal to or more effective than the state-of-the-art approaches for trigger-less attacks and more effective than the state-of-the-art approaches for backdoor attacks.
count=2
* A Boosting Approach to Reinforcement Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/daf8364f0715a41a469c677c0adc4754-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/daf8364f0715a41a469c677c0adc4754-Paper-Conference.pdf)]
    * Title: A Boosting Approach to Reinforcement Learning
    * Year: `2022`
    * Authors: Nataly Brukhim, Elad Hazan, Karan Singh
    * Abstract: Reducing reinforcement learning to supervised learning is a well-studied and effective approach that leverages the benefits of compact function approximation to deal with large-scale Markov decision processes. Independently, the boosting methodology (e.g. AdaBoost) has proven to be indispensable in designing efficient and accurate classification algorithms by combining rough and inaccurate rules-of-thumb.In this paper, we take a further step: we reduce reinforcement learning to a sequence of weak learning problems. Since weak learners perform only marginally better than random guesses, such subroutines constitute a weaker assumption than the availability of an accurate supervised learning oracle. We prove that the sample complexity and running time bounds of the proposed method do not explicitly depend on the number of states.While existing results on boosting operate on convex losses, the value function over policies is non-convex. We show how to use a non-convex variant of the Frank-Wolfe method for boosting, that additionally improves upon the known sample complexity and running time bounds even for reductions to supervised learning.
count=2
* Recruitment Strategies That Take a Chance
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/e1f351706ab4417524e1b17f9adcc657-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/e1f351706ab4417524e1b17f9adcc657-Paper-Conference.pdf)]
    * Title: Recruitment Strategies That Take a Chance
    * Year: `2022`
    * Authors: Gregory Kehne, Ariel D. Procaccia, Jingyan Wang
    * Abstract: In academic recruitment settings, including faculty hiring and PhD admissions, committees aim to maximize the overall quality of recruited candidates, but there is uncertainty about whether a candidate would accept an offer if given one. Previous work has considered algorithms that make offers sequentially and are subject to a hard budget constraint. We argue that these modeling choices may be inconsistent with the practice of academic recruitment. Instead, we restrict ourselves to a single batch of offers, and we treat the target number of positions as a soft constraint, so we risk overshooting or undershooting the target. Specifically, our objective is to select a subset of candidates that maximizes the overall expected value associated with candidates who accept, minus an expected penalty for deviating from the target. We first analyze the guarantees provided by natural greedy heuristics, showing their desirable properties despite the simplicity. Depending on the structure of the penalty function, we further develop algorithms that provide fully polynomial-time approximation schemes and constant-factor approximations to this objective. Empirical evaluation of our algorithms corroborates these theoretical results.
count=2
* A Direct Approximation of AIXI Using Logical State Abstractions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/ed91353f700d113e5d848c7e04a858b0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/ed91353f700d113e5d848c7e04a858b0-Paper-Conference.pdf)]
    * Title: A Direct Approximation of AIXI Using Logical State Abstractions
    * Year: `2022`
    * Authors: Samuel Yang-Zhao, Tianyu Wang, Kee Siong Ng
    * Abstract: We propose a practical integration of logical state abstraction with AIXI, a Bayesian optimality notion for reinforcement learning agents, to significantly expand the model class that AIXI agents can be approximated over to complex history-dependent and structured environments. The state representation and reasoning framework is based on higher-order logic, which can be used to define and enumerate complex features on non-Markovian and structured environments. We address the problem of selecting the right subset of features to form state abstractions by adapting the $\Phi$-MDP optimisation criterion from state abstraction theory. Exact Bayesian model learning is then achieved using a suitable generalisation of Context Tree Weighting over abstract state sequences. The resultant architecture can be integrated with different planning algorithms. Experimental results on controlling epidemics on large-scale contact networks validates the agent's performance.
count=2
* Fuzzy Learning Machine
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/ee26c68c6d62b7d8333815264aa28577-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/ee26c68c6d62b7d8333815264aa28577-Paper-Conference.pdf)]
    * Title: Fuzzy Learning Machine
    * Year: `2022`
    * Authors: Junbiao Cui, Jiye Liang
    * Abstract: Classification is one of the most important problems in machine learning and the nature of it is concept cognition. So far, dozens of different classifiers have been designed. Although their working mechanisms vary widely, few of them fully consider concept cognition. In this paper, a new learning machine, fuzzy learning machine (FLM), is proposed from the perspective of concept cognition. Inspired by cognitive science, its working mechanism is of strong interpretability. At the same time, FLM roots in set theory and fuzzy set theory, so FLM has a solid mathematical foundation. The systematic experimental results on a large number of data sets show that FLM can achieve excellent performance, even with the simple implementation.
count=2
* Scalable Interpretability via Polynomials
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/ee81a23d6b83ac15fbeb5b7a30934e0b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/ee81a23d6b83ac15fbeb5b7a30934e0b-Paper-Conference.pdf)]
    * Title: Scalable Interpretability via Polynomials
    * Year: `2022`
    * Authors: Abhimanyu Dubey, Filip Radenovic, Dhruv Mahajan
    * Abstract: Generalized Additive Models (GAMs) have quickly become the leading choice for interpretable machine learning. However, unlike uninterpretable methods such as DNNs, they lack expressive power and easy scalability, and are hence not a feasible alternative for real-world tasks. We present a new class of GAMs that use tensor rank decompositions of polynomials to learn powerful, {\em inherently-interpretable} models. Our approach, titled Scalable Polynomial Additive Models (SPAM) is effortlessly scalable and models {\em all} higher-order feature interactions without a combinatorial parameter explosion. SPAM outperforms all current interpretable approaches, and matches DNN/XGBoost performance on a series of real-world benchmarks with up to hundreds of thousands of features. We demonstrate by human subject evaluations that SPAMs are demonstrably more interpretable in practice, and are hence an effortless replacement for DNNs for creating interpretable and high-performance systems suitable for large-scale machine learning.Source code is available at \href{https://github.com/facebookresearch/nbm-spam}{\ttfamily github.com/facebookresearch/nbm-spam}.
count=2
* Pruning Neural Networks via Coresets and Convex Geometry: Towards No Assumptions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/f7fc38fdd95fd146a471791b93ff9f12-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/f7fc38fdd95fd146a471791b93ff9f12-Paper-Conference.pdf)]
    * Title: Pruning Neural Networks via Coresets and Convex Geometry: Towards No Assumptions
    * Year: `2022`
    * Authors: Murad Tukan, Loay Mualem, Alaa Maalouf
    * Abstract: Pruning is one of the predominant approaches for compressing deep neural networks (DNNs). Lately, coresets (provable data summarizations) were leveraged for pruning DNNs, adding the advantage of theoretical guarantees on the trade-off between the compression rate and the approximation error. However, coresets in this domain were either data dependant or generated under restrictive assumptions on both the model's weights and inputs. In real-world scenarios, such assumptions are rarely satisfied, limiting the applicability of coresets. To this end, we suggest a novel and robust framework for computing such coresets under mild assumptions on the model's weights and without any assumption on the training data. The idea is to compute the importance of each neuron in each layer with respect to the output of the following layer. This is achieved by an elegant combination of L\"{o}wner ellipsoid and Caratheodory theorem.Our method is simultaneously data-independent, applicable to various networks and datasets (due to the simplified assumptions), and theoretically supported. Experimental results show that our method outperforms existing coreset based neural pruning approaches across a wide range of networks and datasets. For example, our method achieved a $62\%$ compression rate on ResNet50 on ImageNet with $1.09\%$ drop in accuracy.
count=2
* Learning Stochastic Majority Votes by Minimizing a PAC-Bayes Generalization Bound
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/0415740eaa4d9decbc8da001d3fd805f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/0415740eaa4d9decbc8da001d3fd805f-Paper.pdf)]
    * Title: Learning Stochastic Majority Votes by Minimizing a PAC-Bayes Generalization Bound
    * Year: `2021`
    * Authors: Valentina Zantedeschi, Paul Viallard, Emilie Morvant, Rémi Emonet, Amaury Habrard, Pascal Germain, Benjamin Guedj
    * Abstract: We investigate a stochastic counterpart of majority votes over finite ensembles of classifiers, and study its generalization properties. While our approach holds for arbitrary distributions, we instantiate it with Dirichlet distributions: this allows for a closed-form and differentiable expression for the expected risk, which then turns the generalization bound into a tractable training objective.The resulting stochastic majority vote learning algorithm achieves state-of-the-art accuracy and benefits from (non-vacuous) tight generalization bounds, in a series of numerical experiments when compared to competing algorithms which also minimize PAC-Bayes objectives -- both with uninformed (data-independent) and informed (data-dependent) priors.
count=2
* Learning Optimal Predictive Checklists
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/09676fac73eda6cac726c43e43e86c58-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/09676fac73eda6cac726c43e43e86c58-Paper.pdf)]
    * Title: Learning Optimal Predictive Checklists
    * Year: `2021`
    * Authors: Haoran Zhang, Quaid Morris, Berk Ustun, Marzyeh Ghassemi
    * Abstract: Checklists are simple decision aids that are often used to promote safety and reliability in clinical applications. In this paper, we present a method to learn checklists for clinical decision support. We represent predictive checklists as discrete linear classifiers with binary features and unit weights. We then learn globally optimal predictive checklists from data by solving an integer programming problem. Our method allows users to customize checklists to obey complex constraints, including constraints to enforce group fairness and to binarize real-valued features at training time. In addition, it pairs models with an optimality gap that can inform model development and determine the feasibility of learning sufficiently accurate checklists on a given dataset. We pair our method with specialized techniques that speed up its ability to train a predictive checklist that performs well and has a small optimality gap. We benchmark the performance of our method on seven clinical classification problems, and demonstrate its practical benefits by training a short-form checklist for PTSD screening. Our results show that our method can fit simple predictive checklists that perform well and that can easily be customized to obey a rich class of custom constraints.
count=2
* Mixture Proportion Estimation and PU Learning:A Modern Approach
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/47b4f1bfdf6d298682e610ad74b37dca-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/47b4f1bfdf6d298682e610ad74b37dca-Paper.pdf)]
    * Title: Mixture Proportion Estimation and PU Learning:A Modern Approach
    * Year: `2021`
    * Authors: Saurabh Garg, Yifan Wu, Alexander J. Smola, Sivaraman Balakrishnan, Zachary Lipton
    * Abstract: Given only positive examples and unlabeled examples (from both positive and negative classes), we might hope nevertheless to estimate an accurate positive-versus-negative classifier. Formally, this task is broken down into two subtasks: (i) Mixture Proportion Estimation (MPE)---determining the fraction of positive examples in the unlabeled data; and (ii) PU-learning---given such an estimate, learning the desired positive-versus-negative classifier. Unfortunately, classical methods for both problems break down in high-dimensional settings. Meanwhile, recently proposed heuristics lack theoretical coherence and depend precariously on hyperparameter tuning. In this paper, we propose two simple techniques: Best Bin Estimation (BBE) (for MPE); and Conditional Value Ignoring Risk (CVIR), a simple objective for PU-learning. Both methods dominate previous approaches empirically, and for BBE, we establish formal guarantees that hold whenever we can train a model to cleanly separate out a small subset of positive examples. Our final algorithm (TED)$^n$, alternates between the two procedures, significantly improving both our mixture proportion estimator and classifier
count=2
* Differentially Private Federated Bayesian Optimization with Distributed Exploration
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/4c27cea8526af8cfee3be5e183ac9605-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/4c27cea8526af8cfee3be5e183ac9605-Paper.pdf)]
    * Title: Differentially Private Federated Bayesian Optimization with Distributed Exploration
    * Year: `2021`
    * Authors: Zhongxiang Dai, Bryan Kian Hsiang Low, Patrick Jaillet
    * Abstract: Bayesian optimization (BO) has recently been extended to the federated learning (FL) setting by the federated Thompson sampling (FTS) algorithm, which has promising applications such as federated hyperparameter tuning. However, FTS is not equipped with a rigorous privacy guarantee which is an important consideration in FL. Recent works have incorporated differential privacy (DP) into the training of deep neural networks through a general framework for adding DP to iterative algorithms. Following this general DP framework, our work here integrates DP into FTS to preserve user-level privacy. We also leverage the ability of this general DP framework to handle different parameter vectors, as well as the technique of local modeling for BO, to further improve the utility of our algorithm through distributed exploration (DE). The resulting differentially private FTS with DE (DP-FTS-DE) algorithm is endowed with theoretical guarantees for both the privacy and utility and is amenable to interesting theoretical insights about the privacy-utility trade-off. We also use real-world experiments to show that DP-FTS-DE achieves high utility (competitive performance) with a strong privacy guarantee (small privacy loss) and induces a trade-off between privacy and utility.
count=2
* Controlling Neural Networks with Rule Representations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/5cd5058bca53951ffa7801bcdf421651-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/5cd5058bca53951ffa7801bcdf421651-Paper.pdf)]
    * Title: Controlling Neural Networks with Rule Representations
    * Year: `2021`
    * Authors: Sungyong Seo, Sercan Arik, Jinsung Yoon, Xiang Zhang, Kihyuk Sohn, Tomas Pfister
    * Abstract: We propose a novel training method that integrates rules into deep learning, in a way the strengths of the rules are controllable at inference. Deep Neural Networks with Controllable Rule Representations (DeepCTRL) incorporates a rule encoder into the model coupled with a rule-based objective, enabling a shared representation for decision making. DeepCTRL is agnostic to data type and model architecture. It can be applied to any kind of rule defined for inputs and outputs. The key aspect of DeepCTRL is that it does not require retraining to adapt the rule strength -- at inference, the user can adjust it based on the desired operation point on accuracy vs. rule verification ratio. In real-world domains where incorporating rules is critical -- such as Physics, Retail and Healthcare -- we show the effectiveness of DeepCTRL in teaching rules for deep learning. DeepCTRL improves the trust and reliability of the trained models by significantly increasing their rule verification ratio, while also providing accuracy gains at downstream tasks. Additionally, DeepCTRL enables novel use cases such as hypothesis testing of the rules on data samples, and unsupervised adaptation based on shared rules between datasets.
count=2
* Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/619427579e7b067421f6aa89d4a8990c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/619427579e7b067421f6aa89d4a8990c-Paper.pdf)]
    * Title: Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems
    * Year: `2021`
    * Authors: Ruihan Wu, Chuan Guo, Awni Hannun, Laurens van der Maaten
    * Abstract: Machine-learning systems such as self-driving cars or virtual assistants are composed of a large number of machine-learning models that recognize image content, transcribe speech, analyze natural language, infer preferences, rank options, etc. Models in these systems are often developed and trained independently, which raises an obvious concern: Can improving a machine-learning model make the overall system worse? We answer this question affirmatively by showing that improving a model can deteriorate the performance of downstream models, even after those downstream models are retrained. Such self-defeating improvements are the result of entanglement between the models in the system. We perform an error decomposition of systems with multiple machine-learning models, which sheds light on the types of errors that can lead to self-defeating improvements. We also present the results of experiments which show that self-defeating improvements emerge in a realistic stereo-based detection system for cars and pedestrians.
count=2
* Credal Self-Supervised Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/7866c91c59f8bffc92a79a7cd09f9af9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/7866c91c59f8bffc92a79a7cd09f9af9-Paper.pdf)]
    * Title: Credal Self-Supervised Learning
    * Year: `2021`
    * Authors: Julian Lienen, Eyke Hüllermeier
    * Abstract: Self-training is an effective approach to semi-supervised learning. The key idea is to let the learner itself iteratively generate "pseudo-supervision" for unlabeled instances based on its current hypothesis. In combination with consistency regularization, pseudo-labeling has shown promising performance in various domains, for example in computer vision. To account for the hypothetical nature of the pseudo-labels, these are commonly provided in the form of probability distributions. Still, one may argue that even a probability distribution represents an excessive level of informedness, as it suggests that the learner precisely knows the ground-truth conditional probabilities. In our approach, we therefore allow the learner to label instances in the form of credal sets, that is, sets of (candidate) probability distributions. Thanks to this increased expressiveness, the learner is able to represent uncertainty and a lack of knowledge in a more flexible and more faithful manner. To learn from weakly labeled data of that kind, we leverage methods that have recently been proposed in the realm of so-called superset learning. In an exhaustive empirical evaluation, we compare our methodology to state-of-the-art self-supervision approaches, showing competitive to superior performance especially in low-label scenarios incorporating a high degree of uncertainty.
count=2
* Monte Carlo Tree Search With Iteratively Refining State Abstractions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/9b0ead00a217ea2c12e06a72eec4923f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/9b0ead00a217ea2c12e06a72eec4923f-Paper.pdf)]
    * Title: Monte Carlo Tree Search With Iteratively Refining State Abstractions
    * Year: `2021`
    * Authors: Samuel Sokota, Caleb Y Ho, Zaheen Ahmad, J. Zico Kolter
    * Abstract: Decision-time planning is the process of constructing a transient, local policy with the intent of using it to make the immediate decision. Monte Carlo tree search (MCTS), which has been leveraged to great success in Go, chess, shogi, Hex, Atari, and other settings, is perhaps the most celebrated decision-time planning algorithm. Unfortunately, in its original form, MCTS can degenerate to one-step search in domains with stochasticity. Progressive widening is one way to ameliorate this issue, but we argue that it possesses undesirable properties for some settings. In this work, we present a method, called abstraction refining, for extending MCTS to stochastic environments which, unlike progressive widening, leverages the geometry of the state space. We argue that leveraging the geometry of the space can offer advantages. To support this claim, we present a series of experimental examples in which abstraction refining outperforms progressive widening, given equal simulation budgets.
count=2
* Adaptive wavelet distillation from neural networks through interpretations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/acaa23f71f963e96c8847585e71352d6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/acaa23f71f963e96c8847585e71352d6-Paper.pdf)]
    * Title: Adaptive wavelet distillation from neural networks through interpretations
    * Year: `2021`
    * Authors: Wooseok Ha, Chandan Singh, Francois Lanusse, Srigokul Upadhyayula, Bin Yu
    * Abstract: Recent deep-learning models have achieved impressive prediction performance, but often sacrifice interpretability and computational efficiency. Interpretability is crucial in many disciplines, such as science and medicine, where models must be carefully vetted or where interpretation is the goal itself. Moreover, interpretable models are concise and often yield computational efficiency. Here, we propose adaptive wavelet distillation (AWD), a method which aims to distill information from a trained neural network into a wavelet transform. Specifically, AWD penalizes feature attributions of a neural network in the wavelet domain to learn an effective multi-resolution wavelet transform. The resulting model is highly predictive, concise, computationally efficient, and has properties (such as a multi-scale structure) which make it easy to interpret. In close collaboration with domain experts, we showcase how AWD addresses challenges in two real-world settings: cosmological parameter inference and molecular-partner prediction. In both cases, AWD yields a scientifically interpretable and concise model which gives predictive performance better than state-of-the-art neural networks. Moreover, AWD identifies predictive features that are scientifically meaningful in the context of respective domains. All code and models are released in a full-fledged package available on Github.
count=2
* Closing the loop in medical decision support by understanding clinical decision-making: A case study on organ transplantation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/c344336196d5ec19bd54fd14befdde87-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/c344336196d5ec19bd54fd14befdde87-Paper.pdf)]
    * Title: Closing the loop in medical decision support by understanding clinical decision-making: A case study on organ transplantation
    * Year: `2021`
    * Authors: Yuchao Qin, Fergus Imrie, Alihan Hüyük, Daniel Jarrett, alexander gimson, Mihaela van der Schaar
    * Abstract: Significant effort has been placed on developing decision support tools to improve patient care. However, drivers of real-world clinical decisions in complex medical scenarios are not yet well-understood, resulting in substantial gaps between these tools and practical applications. In light of this, we highlight that more attention on understanding clinical decision-making is required both to elucidate current clinical practices and to enable effective human-machine interactions. This is imperative in high-stakes scenarios with scarce available resources. Using organ transplantation as a case study, we formalize the desiderata of methods for understanding clinical decision-making. We show that most existing machine learning methods are insufficient to meet these requirements and propose iTransplant, a novel data-driven framework to learn the factors affecting decisions on organ offers in an instance-wise fashion directly from clinical data, as a possible solution. Through experiments on real-world liver transplantation data from OPTN, we demonstrate the use of iTransplant to: (1) discover which criteria are most important to clinicians for organ offer acceptance; (2) identify patient-specific organ preferences of clinicians allowing automatic patient stratification; and (3) explore variations in transplantation practices between different transplant centers. Finally, we emphasize that the insights gained by iTransplant can be used to inform the development of future decision support tools.
count=2
* Minimax Classification with 0-1 Loss and Performance Guarantees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/02f657d55eaf1c4840ce8d66fcdaf90c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/02f657d55eaf1c4840ce8d66fcdaf90c-Paper.pdf)]
    * Title: Minimax Classification with 0-1 Loss and Performance Guarantees
    * Year: `2020`
    * Authors: Santiago Mazuelas, Andrea Zanoni, Aritz Pérez
    * Abstract: Supervised classification techniques use training samples to find classification rules with small expected 0-1 loss. Conventional methods achieve efficient learning and out-of-sample generalization by minimizing surrogate losses over specific families of rules. This paper presents minimax risk classifiers (MRCs) that do not rely on a choice of surrogate loss and family of rules. MRCs achieve efficient learning and out-of-sample generalization by minimizing worst-case expected 0-1 loss w.r.t. uncertainty sets that are defined by linear constraints and include the true underlying distribution. In addition, MRCs' learning stage provides performance guarantees as lower and upper tight bounds for expected 0-1 loss. We also present MRCs' finite-sample generalization bounds in terms of training size and smallest minimax risk, and show their competitive classification performance w.r.t. state-of-the-art techniques using benchmark datasets.
count=2
* Contextual Reserve Price Optimization in Auctions via Mixed Integer Programming
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/0e1bacf07b14673fcdb553da51b999a5-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/0e1bacf07b14673fcdb553da51b999a5-Paper.pdf)]
    * Title: Contextual Reserve Price Optimization in Auctions via Mixed Integer Programming
    * Year: `2020`
    * Authors: Joey Huchette, Haihao Lu, Hossein Esfandiari, Vahab Mirrokni
    * Abstract: We study the problem of learning a linear model to set the reserve price in an auction, given contextual information, in order to maximize expected revenue from the seller side. First, we show that it is not possible to solve this problem in polynomial time unless the Exponential Time Hypothesis fails. Second, we present a strong mixed-integer programming (MIP) formulation for this problem, which is capable of exactly modeling the nonconvex and discontinuous expected reward function. Moreover, we show that this MIP formulation is ideal (i.e. the strongest possible formulation) for the revenue function of a single impression. Since it can be computationally expensive to exactly solve the MIP formulation in practice, we also study the performance of its linear programming (LP) relaxation. Though it may work well in practice, we show that, unfortunately, in the worst case the optimal objective of the LP relaxation can be O(number of samples) times larger than the optimal objective of the true problem. Finally, we present computational results, showcasing that the MIP formulation, along with its LP relaxation, are able to achieve superior in- and out-of-sample performance, as compared to state-of-the-art algorithms on both real and synthetic datasets. More broadly, we believe this work offers an indication of the strength of optimization methodologies like MIP to exactly model intrinsic discontinuities in machine learning problems.
count=2
* The Implications of Local Correlation on Learning Some Deep Functions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/0e4ceef65add6cf21c0f3f9da53b71c0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/0e4ceef65add6cf21c0f3f9da53b71c0-Paper.pdf)]
    * Title: The Implications of Local Correlation on Learning Some Deep Functions
    * Year: `2020`
    * Authors: Eran Malach, Shai Shalev-Shwartz
    * Abstract: It is known that learning deep neural-networks is computationally hard in the worst-case. In fact, the proofs of such hardness results show that even weakly learning deep networks is hard. In other words, no efficient algorithm can find a predictor that is slightly better than a random guess. However, we observe that on natural distributions of images, small patches of the input image are corre- lated to the target label, which implies that on such natural data, efficient weak learning is trivial. While in the distribution-free setting, the celebrated boosting results show that weak learning implies strong learning, in the distribution-specific setting this is not necessarily the case. We introduce a property of distributions, denoted “local correlation”, which requires that small patches of the input image and of intermediate layers of the target function are correlated to the target label. We empirically demonstrate that this property holds for the CIFAR and ImageNet data sets. The main technical results of the paper is proving that, for some classes of deep functions, weak learning implies efficient strong learning under the “local correlation” assumption.
count=2
* Learning to search efficiently for causally near-optimal treatments
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/0e900ad84f63618452210ab8baae0218-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/0e900ad84f63618452210ab8baae0218-Paper.pdf)]
    * Title: Learning to search efficiently for causally near-optimal treatments
    * Year: `2020`
    * Authors: Samuel Håkansson, Viktor Lindblom, Omer Gottesman, Fredrik D. Johansson
    * Abstract: Finding an effective medical treatment often requires a search by trial and error. Making this search more efficient by minimizing the number of unnecessary trials could lower both costs and patient suffering. We formalize this problem as learning a policy for finding a near-optimal treatment in a minimum number of trials using a causal inference framework. We give a model-based dynamic programming algorithm which learns from observational data while being robust to unmeasured confounding. To reduce time complexity, we suggest a greedy algorithm which bounds the near-optimality constraint. The methods are evaluated on synthetic and real-world healthcare data and compared to model-free reinforcement learning. We find that our methods compare favorably to the model-free baseline while offering a more transparent trade-off between search time and treatment efficacy.
count=2
* Learning Graph Structure With A Finite-State Automaton Layer
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/1fdc0ee9d95c71d73df82ac8f0721459-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/1fdc0ee9d95c71d73df82ac8f0721459-Paper.pdf)]
    * Title: Learning Graph Structure With A Finite-State Automaton Layer
    * Year: `2020`
    * Authors: Daniel Johnson, Hugo Larochelle, Daniel Tarlow
    * Abstract: Graph-based neural network models are producing strong results in a number of domains, in part because graphs provide flexibility to encode domain knowledge in the form of relational structure (edges) between nodes in the graph. In practice, edges are used both to represent intrinsic structure (e.g., abstract syntax trees of programs) and more abstract relations that aid reasoning for a downstream task (e.g., results of relevant program analyses). In this work, we study the problem of learning to derive abstract relations from the intrinsic graph structure. Motivated by their power in program analyses, we consider relations defined by paths on the base graph accepted by a finite-state automaton. We show how to learn these relations end-to-end by relaxing the problem into learning finite-state automata policies on a graph-based POMDP and then training these policies using implicit differentiation. The result is a differentiable Graph Finite-State Automaton (GFSA) layer that adds a new edge type (expressed as a weighted adjacency matrix) to a base graph. We demonstrate that this layer can find shortcuts in grid-world graphs and reproduce simple static analyses on Python programs. Additionally, we combine the GFSA layer with a larger graph-based model trained end-to-end on the variable misuse program understanding task, and find that using the GFSA layer leads to better performance than using hand-engineered semantic edges or other baseline methods for adding learned edge types.
count=2
* Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/32e54441e6382a7fbacbbbaf3c450059-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/32e54441e6382a7fbacbbbaf3c450059-Paper.pdf)]
    * Title: Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models
    * Year: `2020`
    * Authors: Tom Heskes, Evi Sijben, Ioan Gabriel Bucur, Tom Claassen
    * Abstract: Shapley values underlie one of the most popular model-agnostic methods within explainable artificial intelligence. These values are designed to attribute the difference between a model's prediction and an average baseline to the different features used as input to the model. Being based on solid game-theoretic principles, Shapley values uniquely satisfy several desirable properties, which is why they are increasingly used to explain the predictions of possibly complex and highly non-linear machine learning models. Shapley values are well calibrated to a user’s intuition when features are independent, but may lead to undesirable, counterintuitive explanations when the independence assumption is violated. In this paper, we propose a novel framework for computing Shapley values that generalizes recent work that aims to circumvent the independence assumption. By employing Pearl's do-calculus, we show how these `causal' Shapley values can be derived for general causal graphs without sacrificing any of their desirable properties. Moreover, causal Shapley values enable us to separate the contribution of direct and indirect effects. We provide a practical implementation for computing causal Shapley values based on causal chain graphs when only partial information is available and illustrate their utility on a real-world example.
count=2
* Exact expressions for double descent and implicit regularization via surrogate random design
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/37740d59bb0eb7b4493725b2e0e5289b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/37740d59bb0eb7b4493725b2e0e5289b-Paper.pdf)]
    * Title: Exact expressions for double descent and implicit regularization via surrogate random design
    * Year: `2020`
    * Authors: Michal Derezinski, Feynman T. Liang, Michael W. Mahoney
    * Abstract: Double descent refers to the phase transition that is exhibited by the generalization error of unregularized learning models when varying the ratio between the number of parameters and the number of training samples. The recent success of highly over-parameterized machine learning models such as deep neural networks has motivated a theoretical analysis of the double descent phenomenon in classical models such as linear regression which can also generalize well in the over-parameterized regime. We provide the first exact non-asymptotic expressions for double descent of the minimum norm linear estimator. Our approach involves constructing a special determinantal point process which we call surrogate random design, to replace the standard i.i.d. design of the training sample. This surrogate design admits exact expressions for the mean squared error of the estimator while preserving the key properties of the standard design. We also establish an exact implicit regularization result for over-parameterized training samples. In particular, we show that, for the surrogate design, the implicit bias of the unregularized minimum norm estimator precisely corresponds to solving a ridge-regularized least squares problem on the population distribution. In our analysis we introduce a new mathematical tool of independent interest: the class of random matrices for which determinant commutes with expectation.
count=2
* Robust Optimization for Fairness with Noisy Protected Groups
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/37d097caf1299d9aa79c2c2b843d2d78-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/37d097caf1299d9aa79c2c2b843d2d78-Paper.pdf)]
    * Title: Robust Optimization for Fairness with Noisy Protected Groups
    * Year: `2020`
    * Authors: Serena Wang, Wenshuo Guo, Harikrishna Narasimhan, Andrew Cotter, Maya Gupta, Michael Jordan
    * Abstract: Many existing fairness criteria for machine learning involve equalizing some metric across protected groups such as race or gender. However, practitioners trying to audit or enforce such group-based criteria can easily face the problem of noisy or biased protected group information. First, we study the consequences of naively relying on noisy protected group labels: we provide an upper bound on the fairness violations on the true groups $G$ when the fairness criteria are satisfied on noisy groups $\hat{G}$. Second, we introduce two new approaches using robust optimization that, unlike the naive approach of only relying on $\hat{G}$, are guaranteed to satisfy fairness criteria on the true protected groups $G$ while minimizing a training objective. We provide theoretical guarantees that one such approach converges to an optimal feasible solution. Using two case studies, we show empirically that the robust approaches achieve better true group fairness guarantees than the naive approach.
count=2
* The Power of Comparisons for Actively Learning Linear Classifiers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/4607f7fff0dce694258e1c637512aa9d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/4607f7fff0dce694258e1c637512aa9d-Paper.pdf)]
    * Title: The Power of Comparisons for Actively Learning Linear Classifiers
    * Year: `2020`
    * Authors: Max Hopkins, Daniel Kane, Shachar Lovett
    * Abstract: In the world of big data, large but costly to label datasets dominate many fields. Active learning, a semi-supervised alternative to the standard PAC-learning model, was introduced to explore whether adaptive labeling could learn concepts with exponentially fewer labeled samples. While previous results show that active learning performs no better than its supervised alternative for important concept classes such as linear separators, we show that by adding weak distributional assumptions and allowing comparison queries, active learning requires exponentially fewer samples. Further, we show that these results hold as well for a stronger model of learning called Reliable and Probably Useful (RPU) learning. In this model, our learner is not allowed to make mistakes, but may instead answer ``I don't know.'' While previous negative results showed this model to have intractably large sample complexity for label queries, we show that comparison queries make RPU-learning at worst logarithmically more expensive in both the passive and active regimes.
count=2
* Generalized Boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/63f44623dd8686aba388944c8810087f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/63f44623dd8686aba388944c8810087f-Paper.pdf)]
    * Title: Generalized Boosting
    * Year: `2020`
    * Authors: Arun Suggala, Bingbin Liu, Pradeep Ravikumar
    * Abstract: Boosting is a widely used learning technique in machine learning for solving classification problems. In boosting, one predicts the label of an example using an ensemble of weak classifiers. While boosting has shown tremendous success on many classification problems involving tabular data, it performs poorly on complex classification tasks involving low-level features such as image classification tasks. This drawback stems from the fact that boosting builds an additive model of weak classifiers, each of which has very little predictive power. Often, the resulting additive models are not powerful enough to approximate the complex decision boundaries of real-world classification problems. In this work, we present a general framework for boosting where, similar to traditional boosting, we aim to boost the performance of a weak learner and transform it into a strong learner. However, unlike traditional boosting, our framework allows for more complex forms of aggregation of weak learners. In this work, we specifically focus on one form of aggregation - \emph{function composition}. We show that many popular greedy algorithms for learning deep neural networks (DNNs) can be derived from our framework using function compositions for aggregation. Moreover, we identify the drawbacks of these greedy algorithms and propose new algorithms that fix these issues. Using thorough empirical evaluation, we show that our learning algorithms have superior performance over traditional additive boosting algorithms, as well as existing greedy learning techniques for DNNs. An important feature of our algorithms is that they come with strong theoretical guarantees.
count=2
* Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/6ad4174eba19ecb5fed17411a34ff5e6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/6ad4174eba19ecb5fed17411a34ff5e6-Paper.pdf)]
    * Title: Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction
    * Year: `2020`
    * Authors: Yaodong Yu, Kwan Ho Ryan Chan, Chong You, Chaobing Song, Yi Ma
    * Abstract: To learn intrinsic low-dimensional structures from high-dimensional data that most discriminate between classes, we propose the principle of {\em Maximal Coding Rate Reduction} ($\text{MCR}^2$), an information-theoretic measure that maximizes the coding rate difference between the whole dataset and the sum of each individual class. We clarify its relationships with most existing frameworks such as cross-entropy, information bottleneck, information gain, contractive and contrastive learning, and provide theoretical guarantees for learning diverse and discriminative features. The coding rate can be accurately computed from finite samples of degenerate subspace-like distributions and can learn intrinsic representations in supervised, self-supervised, and unsupervised settings in a unified manner. Empirically, the representations learned using this principle alone are significantly more robust to label corruptions in classification than those using cross-entropy, and can lead to state-of-the-art results in clustering mixed data from self-learned invariant features.
count=2
* Coherent Hierarchical Multi-Label Classification Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/6dd4e10e3296fa63738371ec0d5df818-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/6dd4e10e3296fa63738371ec0d5df818-Paper.pdf)]
    * Title: Coherent Hierarchical Multi-Label Classification Networks
    * Year: `2020`
    * Authors: Eleonora Giunchiglia, Thomas Lukasiewicz
    * Abstract: Hierarchical multi-label classification (HMC) is a challenging classification task extending standard multi-label classification problems by imposing a hierarchy constraint on the classes. In this paper, we propose C-HMCNN(h), a novel approach for HMC problems, which, given a network h for the underlying multi-label classification problem, exploits the hierarchy information in order to produce predictions coherent with the constraint and improve performance. We conduct an extensive experimental analysis showing the superior performance of C-HMCNN(h) when compared to state-of-the-art models.
count=2
* Field-wise Learning for Multi-field Categorical Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/7078971350bcefbc6ec2779c9b84a9bd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/7078971350bcefbc6ec2779c9b84a9bd-Paper.pdf)]
    * Title: Field-wise Learning for Multi-field Categorical Data
    * Year: `2020`
    * Authors: Zhibin Li, Jian Zhang, Yongshun Gong, Yazhou Yao, Qiang Wu
    * Abstract: We propose a new method for learning with multi-field categorical data. Multi-field categorical data are usually collected over many heterogeneous groups. These groups can reflect in the categories under a field. The existing methods try to learn a universal model that fits all data, which is challenging and inevitably results in learning a complex model. In contrast, we propose a field-wise learning method leveraging the natural structure of data to learn simple yet efficient one-to-one field-focused models with appropriate constraints. In doing this, the models can be fitted to each category and thus can better capture the underlying differences in data. We present a model that utilizes linear models with variance and low-rank constraints, to help it generalize better and reduce the number of parameters. The model is also interpretable in a field-wise manner. As the dimensionality of multi-field categorical data can be very high, the models applied to such data are mostly over-parameterized. Our theoretical analysis can potentially explain the effect of over-parametrization on the generalization of our model. It also supports the variance constraints in the learning objective. The experiment results on two large-scale datasets show the superior performance of our model, the trend of the generalization error bound, and the interpretability of learning outcomes. Our code is available at https://github.com/lzb5600/Field-wise-Learning.
count=2
* Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/86b94dae7c6517ec1ac767fd2c136580-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/86b94dae7c6517ec1ac767fd2c136580-Paper.pdf)]
    * Title: Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web
    * Year: `2020`
    * Authors: Zhenwei Dai, Anshumali Shrivastava
    * Abstract: Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We propose new algorithms that generalize the learned Bloom filter by using the complete spectrum of the score regions. We prove our algorithms have lower false positive rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrate the improved performance of our algorithms on real-world information filtering tasks over the web.
count=2
* Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/8ee7730e97c67473a424ccfeff49ab20-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/8ee7730e97c67473a424ccfeff49ab20-Paper.pdf)]
    * Title: Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses
    * Year: `2020`
    * Authors: Kaivalya Rawal, Himabindu Lakkaraju
    * Abstract: As predictive models are increasingly being deployed in high-stakes decision-making, there has been a lot of interest in developing algorithms which can provide recourses to affected individuals. While developing such tools is important, it is even more critical to analyze and interpret a predictive model, and vet it thoroughly to ensure that the recourses it offers are meaningful and non-discriminatory before it is deployed in the real world. To this end, we propose a novel model agnostic framework called Actionable Recourse Summaries (AReS) to construct global counterfactual explanations which provide an interpretable and accurate summary of recourses for the entire population. We formulate a novel objective which simultaneously optimizes for correctness of the recourses and interpretability of the explanations, while minimizing overall recourse costs across the entire population. More specifically, our objective enables us to learn, with optimality guarantees on recourse correctness, a small number of compact rule sets each of which capture recourses for well defined subpopulations within the data. We also demonstrate theoretically that several of the prior approaches proposed to generate recourses for individuals are special cases of our framework. Experimental evaluation with real world datasets and user studies demonstrate that our framework can provide decision makers with a comprehensive overview of recourses corresponding to any black box model, and consequently help detect undesirable model biases and discrimination.
count=2
* Minimax Estimation of Conditional Moment Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/8fcd9e5482a62a5fa130468f4cf641ef-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Paper.pdf)]
    * Title: Minimax Estimation of Conditional Moment Models
    * Year: `2020`
    * Authors: Nishanth Dikkala, Greg Lewis, Lester Mackey, Vasilis Syrgkanis
    * Abstract: We develop an approach for estimating models described via conditional moment restrictions, with a prototypical application being non-parametric instrumental variable regression. We introduce a min-max criterion function, under which the estimation problem can be thought of as solving a zero-sum game between a modeler who is optimizing over the hypothesis space of the target model and an adversary who identifies violating moments over a test function space. We analyze the statistical estimation rate of the resulting estimator for arbitrary hypothesis spaces, with respect to an appropriate analogue of the mean squared error metric, for ill-posed inverse problems. We show that when the minimax criterion is regularized with a second moment penalty on the test function and the test function space is sufficiently rich, then the estimation rate scales with the critical radius of the hypothesis and test function spaces, a quantity which typically gives tight fast rates. Our main result follows from a novel localized Rademacher analysis of statistical learning problems defined via minimax objectives. We provide applications of our main results for several hypothesis spaces used in practice such as: reproducing kernel Hilbert spaces, high dimensional sparse linear functions, spaces defined via shape constraints, ensemble estimators such as random forests, and neural networks. For each of these applications we provide computationally efficient optimization methods for solving the corresponding minimax problem (e.g. stochastic first-order heuristics for neural networks). In several applications, we show how our modified mean squared error rate, combined with conditions that bound the ill-posedness of the inverse problem, lead to mean squared error rates. We conclude with an extensive experimental analysis of the proposed methods.
count=2
* Fast Adversarial Robustness Certification of Nearest Prototype Classifiers for Arbitrary Seminorms
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/9da187a7a191431db943a9a5a6fec6f4-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/9da187a7a191431db943a9a5a6fec6f4-Paper.pdf)]
    * Title: Fast Adversarial Robustness Certification of Nearest Prototype Classifiers for Arbitrary Seminorms
    * Year: `2020`
    * Authors: Sascha Saralajew, Lars Holdijk, Thomas Villmann
    * Abstract: Methods for adversarial robustness certification aim to provide an upper bound on the test error of a classifier under adversarial manipulation of its input. Current certification methods are computationally expensive and limited to attacks that optimize the manipulation with respect to a norm. We overcome these limitations by investigating the robustness properties of Nearest Prototype Classifiers (NPCs) like learning vector quantization and large margin nearest neighbor. For this purpose, we study the hypothesis margin. We prove that if NPCs use a dissimilarity measure induced by a seminorm, the hypothesis margin is a tight lower bound on the size of adversarial attacks and can be calculated in constant time—this provides the first adversarial robustness certificate calculable in reasonable time. Finally, we show that each NPC trained by a triplet loss maximizes the hypothesis margin and is therefore optimized for adversarial robustness. In the presented evaluation, we demonstrate that NPCs optimized for adversarial robustness are competitive with state-of-the-art methods and set a new benchmark with respect to computational complexity for robustness certification.
count=2
* Assisted Learning: A Framework for Multi-Organization Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/a7b23e6eefbe6cf04b8e62a6f0915550-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/a7b23e6eefbe6cf04b8e62a6f0915550-Paper.pdf)]
    * Title: Assisted Learning: A Framework for Multi-Organization Learning
    * Year: `2020`
    * Authors: Xun Xian, Xinran Wang, Jie Ding, Reza Ghanadan
    * Abstract: In an increasing number of AI scenarios, collaborations among different organizations or agents (e.g., human and robots, mobile units) are often essential to accomplish an organization-specific mission. However, to avoid leaking useful and possibly proprietary information, organizations typically enforce stringent security constraints on sharing modeling algorithms and data, which significantly limits collaborations. In this work, we introduce the Assisted Learning framework for organizations to assist each other in supervised learning tasks without revealing any organization's algorithm, data, or even task. An organization seeks assistance by broadcasting task-specific but nonsensitive statistics and incorporating others' feedback in one or more iterations to eventually improve its predictive performance. Theoretical and experimental studies, including real-world medical benchmarks, show that Assisted Learning can often achieve near-oracle learning performance as if data and training processes were centralized.
count=2
* Cross-validation Confidence Intervals for Test Error
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/bce9abf229ffd7e570818476ee5d7dde-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/bce9abf229ffd7e570818476ee5d7dde-Paper.pdf)]
    * Title: Cross-validation Confidence Intervals for Test Error
    * Year: `2020`
    * Authors: Pierre Bayle, Alexandre Bayle, Lucas Janson, Lester Mackey
    * Abstract: This work develops central limit theorems for cross-validation and consistent estimators of the asymptotic variance under weak stability conditions on the learning algorithm. Together, these results provide practical, asymptotically-exact confidence intervals for k-fold test error and valid, powerful hypothesis tests of whether one learning algorithm has smaller k-fold test error than another. These results are also the first of their kind for the popular choice of leave-one-out cross-validation. In our experiments with diverse learning algorithms, the resulting intervals and tests outperform the most popular alternative methods from the literature.
count=2
* What Did You Think Would Happen? Explaining Agent Behaviour through Intended Outcomes
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/d5ab8dc7ef67ca92e41d730982c5c602-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/d5ab8dc7ef67ca92e41d730982c5c602-Paper.pdf)]
    * Title: What Did You Think Would Happen? Explaining Agent Behaviour through Intended Outcomes
    * Year: `2020`
    * Authors: Herman Yau, Chris Russell, Simon Hadfield
    * Abstract: We present a novel form of explanation for Reinforcement Learning, based around the notion of intended outcome. These explanations describe the outcome an agent is trying to achieve by its actions. We provide a simple proof that general methods for post-hoc explanations of this nature are impossible in traditional reinforcement learning. Rather, the information needed for the explanations must be collected in conjunction with training the agent. We derive approaches designed to extract local explanations based on intention for several variants of Q-function approximation and prove consistency between the explanations and the Q-values learned. We demonstrate our method on multiple reinforcement learning problems, and provide code to help researchers introspecting their RL environments and algorithms.
count=2
* Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/eccd2a86bae4728b38627162ba297828-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/eccd2a86bae4728b38627162ba297828-Paper.pdf)]
    * Title: Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay
    * Year: `2020`
    * Authors: Joao Marques-Silva, Thomas Gerspacher, Martin Cooper, Alexey Ignatiev, Nina Narodytska
    * Abstract: Recent work proposed the computation of so-called PI-explanations of Naive Bayes Classifiers (NBCs). PI-explanations are subset-minimal sets of feature-value pairs that are sufficient for the prediction, and have been computed with state-of-the-art exact algorithms that are worst-case exponential in time and space. In contrast, we show that the computation of one PI-explanation for an NBC can be achieved in log-linear time, and that the same result also applies to the more general class of linear classifiers. Furthermore, we show that the enumeration of PI-explanations can be obtained with polynomial delay. Experimental results demonstrate the performance gains of the new algorithms when compared with earlier work. The experimental results also investigate ways to measure the quality of heuristic explanations.
count=2
* Modeling Tabular data using Conditional GAN
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/254ed7d2de3b23ab10936522dd547b78-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/254ed7d2de3b23ab10936522dd547b78-Paper.pdf)]
    * Title: Modeling Tabular data using Conditional GAN
    * Year: `2019`
    * Authors: Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, Kalyan Veeramachaneni
    * Abstract: Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design CTGAN, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. CTGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.
count=2
* Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/46f76a4bda9a9579eab38a8f6eabcda1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/46f76a4bda9a9579eab38a8f6eabcda1-Paper.pdf)]
    * Title: Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness
    * Year: `2019`
    * Authors: Saeed Mahloujifar, Xiao Zhang, Mohammad Mahmoody, David Evans
    * Abstract: Many recent works have shown that adversarial examples that fool classifiers can be found by minimally perturbing a normal input. Recent theoretical results, starting with Gilmer et al. (2018b), show that if the inputs are drawn from a concentrated metric probability space, then adversarial examples with small perturbation are inevitable. A concentrated space has the property that any subset with Ω(1) (e.g.,1/100) measure, according to the imposed distribution, has small distance to almost all (e.g., 99/100) of the points in the space. It is not clear, however, whether these theoretical results apply to actual distributions such as images. This paper presents a method for empirically measuring and bounding the concentration of a concrete dataset which is proven to converge to the actual concentration. We use it to empirically estimate the intrinsic robustness to and L2 and Linfinity perturbations of several image classification benchmarks. Code for our experiments is available at https://github.com/xiaozhanguva/Measure-Concentration.
count=2
* Fast and Accurate Least-Mean-Squares Solvers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/475fbefa9ebfba9233364533aafd02a3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/475fbefa9ebfba9233364533aafd02a3-Paper.pdf)]
    * Title: Fast and Accurate Least-Mean-Squares Solvers
    * Year: `2019`
    * Authors: Alaa Maalouf, Ibrahim Jubran, Dan Feldman
    * Abstract: Least-mean squares (LMS) solvers such as Linear / Ridge / Lasso-Regression, SVD and Elastic-Net not only solve fundamental machine learning problems, but are also the building blocks in a variety of other methods, such as decision trees and matrix factorizations.  We suggest an algorithm that gets a finite set of $n$ $d$-dimensional real vectors and returns a weighted subset of $d+1$ vectors whose sum is \emph{exactly} the same. The proof in Caratheodory's Theorem (1907) computes such a subset in $O(n^2d^2)$ time and thus not used in practice. Our algorithm computes this subset in $O(nd)$ time, using $O(\log n)$ calls to Caratheodory's construction on small but "smart" subsets. This is based on a novel paradigm of fusion between different data summarization techniques, known as sketches and coresets.  As an example application, we show how it can be used to boost the performance of existing LMS solvers, such as those in scikit-learn library, up to x100. Generalization for streaming and distributed (big) data is trivial. Extensive experimental results and complete open source code are also provided.
count=2
* Value Function in Frequency Domain and the Characteristic Value Iteration Algorithm
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/4e38d30e656da5ae9d3a425109ce9e04-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/4e38d30e656da5ae9d3a425109ce9e04-Paper.pdf)]
    * Title: Value Function in Frequency Domain and the Characteristic Value Iteration Algorithm
    * Year: `2019`
    * Authors: Amir-massoud Farahmand
    * Abstract: This paper considers the problem of estimating the distribution of returns in reinforcement learning (i.e., distributional RL problem). It presents a new representational framework to maintain the uncertainty of returns and provides mathematical tools to compute it. We show that instead of representing a probability distribution function of returns, one can represent their characteristic function instead, the Fourier transform of their distribution. We call the new representation Characteristic Value Function (CVF), which can be interpreted as the frequency domain representation of the probability distribution of returns. We show that the CVF satisfies a Bellman-like equation, and its corresponding Bellman operator is contraction with respect to certain metrics. The contraction property allows us to devise an iterative procedure to compute the CVF, which we call Characteristic Value Iteration (CVI). We analyze CVI and its approximate variant and show how approximation errors affect the quality of computed CVF.
count=2
* Differentially Private Bagging: Improved utility and cheaper privacy than subsample-and-aggregate
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/5dec707028b05bcbd3a1db5640f842c5-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/5dec707028b05bcbd3a1db5640f842c5-Paper.pdf)]
    * Title: Differentially Private Bagging: Improved utility and cheaper privacy than subsample-and-aggregate
    * Year: `2019`
    * Authors: James Jordon, Jinsung Yoon, Mihaela van der Schaar
    * Abstract: Differential Privacy is a popular and well-studied notion of privacy. In the era ofbig data that we are in, privacy concerns are becoming ever more prevalent and thusdifferential privacy is being turned to as one such solution. A popular method forensuring differential privacy of a classifier is known as subsample-and-aggregate,in which the dataset is divided into distinct chunks and a model is learned on eachchunk, after which it is aggregated. This approach allows for easy analysis of themodel on the data and thus differential privacy can be easily applied. In this paper,we extend this approach by dividing the data several times (rather than just once)and learning models on each chunk within each division. The first benefit of thisapproach is the natural improvement of utility by aggregating models trained ona more diverse range of subsets of the data (as demonstrated by the well-knownbagging technique). The second benefit is that, through analysis that we provide inthe paper, we can derive tighter differential privacy guarantees when several queriesare made to this mechanism. In order to derive these guarantees, we introducethe upwards and downwards moments accountants and derive bounds for thesemoments accountants in a data-driven fashion. We demonstrate the improvementsour model makes over standard subsample-and-aggregate in two datasets (HeartFailure (private) and UCI Adult (public)).
count=2
* Single-Model Uncertainties for Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/73c03186765e199c116224b68adc5fa0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/73c03186765e199c116224b68adc5fa0-Paper.pdf)]
    * Title: Single-Model Uncertainties for Deep Learning
    * Year: `2019`
    * Authors: Natasa Tagasovska, David Lopez-Paz
    * Abstract: We provide single-model estimates of aleatoric and epistemic uncertainty for deep neural networks. To estimate aleatoric uncertainty, we propose Simultaneous Quantile Regression (SQR), a loss function to learn all the conditional quantiles of a given target variable. These quantiles can be used to compute well-calibrated prediction intervals. To estimate epistemic uncertainty, we propose Orthonormal Certificates (OCs), a collection of diverse non-constant functions that map all training samples to zero. These certificates map out-of-distribution examples to non-zero values, signaling epistemic uncertainty. Our uncertainty estimators are computationally attractive, as they do not require ensembling or retraining deep models, and achieve state-of-the-art performance.
count=2
* A Zero-Positive Learning Approach for Diagnosing Software Performance Regressions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/9d1827dc5f75b9d65d80e25eb862e676-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/9d1827dc5f75b9d65d80e25eb862e676-Paper.pdf)]
    * Title: A Zero-Positive Learning Approach for Diagnosing Software Performance Regressions
    * Year: `2019`
    * Authors: Mejbah Alam, Justin Gottschlich, Nesime Tatbul, Javier S. Turek, Tim Mattson, Abdullah Muzahid
    * Abstract: The field of machine programming (MP), the automation of the development of software, is making notable research advances. This is, in part, due to the emergence of a wide range of novel techniques in machine learning. In this paper, we apply MP to the automation of software performance regression testing. A performance regression is a software performance degradation caused by a code change. We present AutoPerf – a novel approach to automate regression testing that utilizes three core techniques: (i) zero-positive learning, (ii) autoencoders, and (iii) hardware telemetry. We demonstrate AutoPerf’s generality and efficacy against 3 types of performance regressions across 10 real performance bugs in 7 benchmark and open-source programs. On average, AutoPerf exhibits 4% profiling overhead and accurately diagnoses more performance bugs than prior state-of-the-art approaches. Thus far, AutoPerf has produced no false negatives.
count=2
* Policy Learning for Fairness in Ranking
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/9e82757e9a1c12cb710ad680db11f6f1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/9e82757e9a1c12cb710ad680db11f6f1-Paper.pdf)]
    * Title: Policy Learning for Fairness in Ranking
    * Year: `2019`
    * Authors: Ashudeep Singh, Thorsten Joachims
    * Abstract: Conventional Learning-to-Rank (LTR) methods optimize the utility of the rankings to the users, but they are oblivious to their impact on the ranked items. However, there has been a growing understanding that the latter is important to consider for a wide range of ranking applications (e.g. online marketplaces, job placement, admissions). To address this need, we propose a general LTR framework that can optimize a wide range of utility metrics (e.g. NDCG) while satisfying fairness of exposure constraints with respect to the items. This framework expands the class of learnable ranking functions to stochastic ranking policies, which provides a language for rigorously expressing fairness specifications. Furthermore, we provide a new LTR algorithm called Fair-PG-Rank for directly searching the space of fair ranking policies via a policy-gradient approach. Beyond the theoretical evidence in deriving the framework and the algorithm, we provide empirical results on simulated and real-world datasets verifying the effectiveness of the approach in individual and group-fairness settings.
count=2
* Margin-Based Generalization Lower Bounds for Boosted Classifiers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/e1dc4bf1f94e87fdfeb2d91ae3dc10ef-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/e1dc4bf1f94e87fdfeb2d91ae3dc10ef-Paper.pdf)]
    * Title: Margin-Based Generalization Lower Bounds for Boosted Classifiers
    * Year: `2019`
    * Authors: Allan Grønlund, Lior Kamma, Kasper Green Larsen, Alexander Mathiasen, Jelani Nelson
    * Abstract: Boosting is one of the most successful ideas in machine learning. The most well-accepted explanations for the low generalization error of boosting algorithms such as AdaBoost stem from margin theory. The study of margins in the context of boosting algorithms was initiated by Schapire, Freund, Bartlett and Lee (1998), and has inspired numerous boosting algorithms and generalization bounds. To date, the strongest known generalization (upper bound) is the $k$th margin bound of Gao and Zhou (2013). Despite the numerous generalization upper bounds that have been proved over the last two decades, nothing is known about the tightness of these bounds. In this paper, we give the first margin-based lower bounds on the generalization error of boosted classifiers. Our lower bounds nearly match the $k$th margin bound and thus almost settle the generalization performance of boosted classifiers in terms of margins.
count=2
* PIDForest: Anomaly Detection via Partial Identification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/eb6dc8aba23375061b6f07b137617096-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/eb6dc8aba23375061b6f07b137617096-Paper.pdf)]
    * Title: PIDForest: Anomaly Detection via Partial Identification
    * Year: `2019`
    * Authors: Parikshit Gopalan, Vatsal Sharan, Udi Wieder
    * Abstract: We consider the problem of detecting anomalies in a large dataset. We propose a framework called Partial Identification which captures the intuition that anomalies are easy to distinguish from the overwhelming majority of points by relatively few attribute values. Formalizing this intuition, we propose a geometric anomaly measure for a point that we call PIDScore, which measures the minimum density of data points over all subcubes containing the point. We present PIDForest: a random forest based algorithm that finds anomalies based on this definition. We show that it performs favorably in comparison to several popular anomaly detection methods, across a broad range of benchmarks. PIDForest also provides a succinct explanation for why a point is labelled anomalous, by providing a set of features and ranges for them which are relatively uncommon in the dataset.
count=2
* Contextual bandits with surrogate losses: Margin bounds and efficient algorithms
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/01e9565cecc4e989123f9620c1d09c09-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/01e9565cecc4e989123f9620c1d09c09-Paper.pdf)]
    * Title: Contextual bandits with surrogate losses: Margin bounds and efficient algorithms
    * Year: `2018`
    * Authors: Dylan J. Foster, Akshay Krishnamurthy
    * Abstract: We use surrogate losses to obtain several new regret bounds and new algorithms for contextual bandit learning. Using the ramp loss, we derive a new margin-based regret bound in terms of standard sequential complexity measures of a benchmark class of real-valued regression functions. Using the hinge loss, we derive an efficient algorithm with a $\sqrt{dT}$-type mistake bound against benchmark policies induced by $d$-dimensional regressors. Under realizability assumptions, our results also yield classical regret bounds.
count=2
* Learning SMaLL Predictors
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/03b2ceb73723f8b53cd533e4fba898ee-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/03b2ceb73723f8b53cd533e4fba898ee-Paper.pdf)]
    * Title: Learning SMaLL Predictors
    * Year: `2018`
    * Authors: Vikas Garg, Ofer Dekel, Lin Xiao
    * Abstract: We introduce a new framework for learning in severely resource-constrained settings. Our technique delicately amalgamates the representational richness of multiple linear predictors with the sparsity of Boolean relaxations, and thereby yields classifiers that are compact, interpretable, and accurate. We provide a rigorous formalism of the learning problem, and establish fast convergence of the ensuing algorithm via relaxation to a minimax saddle point objective. We supplement the theoretical foundations of our work with an extensive empirical evaluation.
count=2
* Explaining Deep Learning Models -- A Bayesian Non-parametric Approach
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/4b4edc2630fe75800ddc29a7b4070add-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/4b4edc2630fe75800ddc29a7b4070add-Paper.pdf)]
    * Title: Explaining Deep Learning Models -- A Bayesian Non-parametric Approach
    * Year: `2018`
    * Authors: Wenbo Guo, Sui Huang, Yunzhe Tao, Xinyu Xing, Lin Lin
    * Abstract: Understanding and interpreting how machine learning (ML) models make decisions have been a big challenge. While recent research has proposed various technical approaches to provide some clues as to how an ML model makes individual predictions, they cannot provide users with an ability to inspect a model as a complete entity. In this work, we propose a novel technical approach that augments a Bayesian non-parametric regression mixture model with multiple elastic nets. Using the enhanced mixture model, we can extract generalizable insights for a target model through a global approximation. To demonstrate the utility of our approach, we evaluate it on different ML models in the context of image recognition. The empirical results indicate that our proposed approach not only outperforms the state-of-the-art techniques in explaining individual decisions but also provides users with an ability to discover the vulnerabilities of the target ML models.
count=2
* Boolean Decision Rules via Column Generation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/743394beff4b1282ba735e5e3723ed74-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/743394beff4b1282ba735e5e3723ed74-Paper.pdf)]
    * Title: Boolean Decision Rules via Column Generation
    * Year: `2018`
    * Authors: Sanjeeb Dash, Oktay Gunluk, Dennis Wei
    * Abstract: This paper considers the learning of Boolean rules in either disjunctive normal form (DNF, OR-of-ANDs, equivalent to decision rule sets) or conjunctive normal form (CNF, AND-of-ORs) as an interpretable model for classification. An integer program is formulated to optimally trade classification accuracy for rule simplicity. Column generation (CG) is used to efficiently search over an exponential number of candidate clauses (conjunctions or disjunctions) without the need for heuristic rule mining. This approach also bounds the gap between the selected rule set and the best possible rule set on the training data. To handle large datasets, we propose an approximate CG algorithm using randomization. Compared to three recently proposed alternatives, the CG algorithm dominates the accuracy-simplicity trade-off in 8 out of 16 datasets. When maximized for accuracy, CG is competitive with rule learners designed for this purpose, sometimes finding significantly simpler solutions that are no less accurate.
count=2
* Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/74378afe5e8b20910cf1f939e57f0480-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/74378afe5e8b20910cf1f939e57f0480-Paper.pdf)]
    * Title: Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability
    * Year: `2018`
    * Authors: Michael Tsang, Hanpeng Liu, Sanjay Purushotham, Pavankumar Murali, Yan Liu
    * Abstract: Neural networks are known to model statistical interactions, but they entangle the interactions at intermediate hidden layers for shared representation learning. We propose a framework, Neural Interaction Transparency (NIT), that disentangles the shared learning across different interactions to obtain their intrinsic lower-order and interpretable structure. This is done through a novel regularizer that directly penalizes interaction order. We show that disentangling interactions reduces a feedforward neural network to a generalized additive model with interactions, which can lead to transparent models that perform comparably to the state-of-the-art models. NIT is also flexible and efficient; it can learn generalized additive models with maximum $K$-order interactions by training only $O(1)$ models.
count=2
* Does mitigating ML's impact disparity require treatment disparity?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/8e0384779e58ce2af40eb365b318cc32-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/8e0384779e58ce2af40eb365b318cc32-Paper.pdf)]
    * Title: Does mitigating ML's impact disparity require treatment disparity?
    * Year: `2018`
    * Authors: Zachary Lipton, Julian McAuley, Alexandra Chouldechova
    * Abstract: Following precedent in employment discrimination law, two notions of disparity are widely-discussed in papers on fairness and ML. Algorithms exhibit treatment disparity if they formally treat members of protected subgroups differently; algorithms exhibit impact disparity when outcomes differ across subgroups (even unintentionally). Naturally, we can achieve impact parity through purposeful treatment disparity. One line of papers aims to reconcile the two parities proposing disparate learning processes (DLPs). Here, the sensitive feature is used during training but a group-blind classifier is produced. In this paper, we show that: (i) when sensitive and (nominally) nonsensitive features are correlated, DLPs will indirectly implement treatment disparity, undermining the policy desiderata they are designed to address; (ii) when group membership is partly revealed by other features, DLPs induce within-class discrimination; and (iii) in general, DLPs provide suboptimal trade-offs between accuracy and impact parity. Experimental results on several real-world datasets highlight the practical consequences of applying DLPs.
count=2
* A Structured Prediction Approach for Label Ranking
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/b3dd760eb02d2e669c604f6b2f1e803f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/b3dd760eb02d2e669c604f6b2f1e803f-Paper.pdf)]
    * Title: A Structured Prediction Approach for Label Ranking
    * Year: `2018`
    * Authors: Anna Korba, Alexandre Garcia, Florence d'Alché-Buc
    * Abstract: We propose to solve a label ranking problem as a structured output regression task. In this view, we adopt a least square surrogate loss approach that solves a supervised learning problem in two steps: a regression step in a well-chosen feature space and a pre-image (or decoding) step. We use specific feature maps/embeddings for ranking data, which convert any ranking/permutation into a vector representation. These embeddings are all well-tailored for our approach, either by resulting in consistent estimators, or by solving trivially the pre-image problem which is often the bottleneck in structured prediction. Their extension to the case of incomplete or partial rankings is also discussed. Finally, we provide empirical results on synthetic and real-world datasets showing the relevance of our method.
count=2
* Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/be3159ad04564bfb90db9e32851ebf9c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/be3159ad04564bfb90db9e32851ebf9c-Paper.pdf)]
    * Title: Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making
    * Year: `2018`
    * Authors: Hoda Heidari, Claudio Ferrari, Krishna Gummadi, Andreas Krause
    * Abstract: We draw attention to an important, yet largely overlooked aspect of evaluating fairness for automated decision making systems---namely risk and welfare considerations. Our proposed family of measures corresponds to the long-established formulations of cardinal social welfare in economics, and is justified by the Rawlsian conception of fairness behind a veil of ignorance. The convex formulation of our welfare-based measures of fairness allows us to integrate them as a constraint into any convex loss minimization pipeline. Our empirical analysis reveals interesting trade-offs between our proposal and (a) prediction accuracy, (b) group discrimination, and (c) Dwork et al's notion of individual fairness. Furthermore and perhaps most importantly, our work provides both heuristic justification and empirical evidence suggesting that a lower-bound on our measures often leads to bounded inequality in algorithmic outcomes; hence presenting the first computationally feasible mechanism for bounding individual-level inequality.
count=2
* Fairness Through Computationally-Bounded Awareness
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/c8dfece5cc68249206e4690fc4737a8d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/c8dfece5cc68249206e4690fc4737a8d-Paper.pdf)]
    * Title: Fairness Through Computationally-Bounded Awareness
    * Year: `2018`
    * Authors: Michael Kim, Omer Reingold, Guy Rothblum
    * Abstract: We study the problem of fair classification within the versatile framework of Dwork et al. [ITCS '12], which assumes the existence of a metric that measures similarity between pairs of individuals. Unlike earlier work, we do not assume that the entire metric is known to the learning algorithm; instead, the learner can query this arbitrary metric a bounded number of times. We propose a new notion of fairness called metric multifairness and show how to achieve this notion in our setting. Metric multifairness is parameterized by a similarity metric d on pairs of individuals to classify and a rich collection C of (possibly overlapping) "comparison sets" over pairs of individuals. At a high level, metric multifairness guarantees that similar subpopulations are treated similarly, as long as these subpopulations are identified within the class C.
count=2
* Tight Bounds for Collaborative PAC Learning via Multiplicative Weights
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/ed519dacc89b2bead3f453b0b05a4a8b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/ed519dacc89b2bead3f453b0b05a4a8b-Paper.pdf)]
    * Title: Tight Bounds for Collaborative PAC Learning via Multiplicative Weights
    * Year: `2018`
    * Authors: Jiecao Chen, Qin Zhang, Yuan Zhou
    * Abstract: We study the collaborative PAC learning problem recently proposed in Blum et al.~\cite{BHPQ17}, in which we have $k$ players and they want to learn a target function collaboratively, such that the learned function approximates the target function well on all players' distributions simultaneously. The quality of the collaborative learning algorithm is measured by the ratio between the sample complexity of the algorithm and that of the learning algorithm for a single distribution (called the overhead). We obtain a collaborative learning algorithm with overhead $O(\ln k)$, improving the one with overhead $O(\ln^2 k)$ in \cite{BHPQ17}. We also show that an $\Omega(\ln k)$ overhead is inevitable when $k$ is polynomial bounded by the VC dimension of the hypothesis class. Finally, our experimental study has demonstrated the superiority of our algorithm compared with the one in Blum et al.~\cite{BHPQ17} on real-world datasets.
count=2
* Random Projection Filter Bank for Time Series Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/ca3ec598002d2e7662e2ef4bdd58278b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/ca3ec598002d2e7662e2ef4bdd58278b-Paper.pdf)]
    * Title: Random Projection Filter Bank for Time Series Data
    * Year: `2017`
    * Authors: Amir-massoud Farahmand, Sepideh Pourazarm, Daniel Nikovski
    * Abstract: We propose Random Projection Filter Bank (RPFB) as a generic and simple approach to extract features from time series data. RPFB is a set of randomly generated stable autoregressive filters that are convolved with the input time series to generate the features. These features can be used by any conventional machine learning algorithm for solving tasks such as time series prediction, classification with time series data, etc. Different filters in RPFB extract different aspects of the time series, and together they provide a reasonably good summary of the time series. RPFB is easy to implement, fast to compute, and parallelizable. We provide an error upper bound indicating that RPFB provides a reasonable approximation to a class of dynamical systems. The empirical results in a series of synthetic and real-world problems show that RPFB is an effective method to extract features from time series.
count=2
* Near-Optimal Edge Evaluation in Explicit Generalized Binomial Graphs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/e139c454239bfde741e893edb46a06cc-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/e139c454239bfde741e893edb46a06cc-Paper.pdf)]
    * Title: Near-Optimal Edge Evaluation in Explicit Generalized Binomial Graphs
    * Year: `2017`
    * Authors: Sanjiban Choudhury, Shervin Javdani, Siddhartha Srinivasa, Sebastian Scherer
    * Abstract: Robotic motion-planning problems, such as a UAV flying fast in a partially-known environment or a robot arm moving around cluttered objects, require finding collision-free paths quickly. Typically, this is solved by constructing a graph, where vertices represent robot configurations and edges represent potentially valid movements of the robot between theses configurations. The main computational bottlenecks are expensive edge evaluations to check for collisions. State of the art planning methods do not reason about the optimal sequence of edges to evaluate in order to find a collision free path quickly. In this paper, we do so by drawing a novel equivalence between motion planning and the Bayesian active learning paradigm of decision region determination (DRD). Unfortunately, a straight application of ex- isting methods requires computation exponential in the number of edges in a graph. We present BISECT, an efficient and near-optimal algorithm to solve the DRD problem when edges are independent Bernoulli random variables. By leveraging this property, we are able to significantly reduce computational complexity from exponential to linear in the number of edges. We show that BISECT outperforms several state of the art algorithms on a spectrum of planning problems for mobile robots, manipulators, and real flight data collected from a full scale helicopter. Open-source code and details can be found here: https://github.com/sanjibac/matlablearningcollision_checking
count=2
* A Probabilistic Framework for Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/c70daf247944fe3add32218f914c75a6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/c70daf247944fe3add32218f914c75a6-Paper.pdf)]
    * Title: A Probabilistic Framework for Deep Learning
    * Year: `2016`
    * Authors: Ankit B. Patel, Minh Tan Nguyen, Richard Baraniuk
    * Abstract: We develop a probabilistic framework for deep learning based on the Deep Rendering Mixture Model (DRMM), a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables. We demonstrate that max-sum inference in the DRMM yields an algorithm that exactly reproduces the operations in deep convolutional neural networks (DCNs), providing a first principles derivation. Our framework provides new insights into the successes and shortcomings of DCNs as well as a principled route to their improvement. DRMM training via the Expectation-Maximization (EM) algorithm is a powerful alternative to DCN back-propagation, and initial training results are promising. Classification based on the DRMM and other variants outperforms DCNs in supervised digit classification, training 2-3x faster while achieving similar accuracy. Moreover, the DRMM is applicable to semi-supervised and unsupervised learning tasks, achieving results that are state-of-the-art in several categories on the MNIST benchmark and comparable to state of the art on the CIFAR10 benchmark.
count=2
* Learning to Communicate with Deep Multi-Agent Reinforcement Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/c7635bfd99248a2cdef8249ef7bfbef4-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/c7635bfd99248a2cdef8249ef7bfbef4-Paper.pdf)]
    * Title: Learning to Communicate with Deep Multi-Agent Reinforcement Learning
    * Year: `2016`
    * Authors: Jakob Foerster, Ioannis Alexandros Assael, Nando de Freitas, Shimon Whiteson
    * Abstract: We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.
count=2
* Online Gradient Boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/0a1bf96b7165e962e90cb14648c9462d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/0a1bf96b7165e962e90cb14648c9462d-Paper.pdf)]
    * Title: Online Gradient Boosting
    * Year: `2015`
    * Authors: Alina Beygelzimer, Elad Hazan, Satyen Kale, Haipeng Luo
    * Abstract: We extend the theory of boosting for regression problems to the online learning setting. Generalizing from the batch setting for boosting, the notion of a weak learning algorithm is modeled as an online learning algorithm with linear loss functions that competes with a base class of regression functions, while a strong learning algorithm is an online learning algorithm with smooth convex loss functions that competes with a larger class of regression functions. Our main result is an online gradient boosting algorithm which converts a weak online learning algorithm into a strong one where the larger class of functions is the linear span of the base class. We also give a simpler boosting algorithm that converts a weak online learning algorithm into a strong one where the larger class of functions is the convex hull of the base class, and prove its optimality.
count=2
* Barrier Frank-Wolfe for Marginal Inference
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/0c74b7f78409a4022a2c4c5a5ca3ee19-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/0c74b7f78409a4022a2c4c5a5ca3ee19-Paper.pdf)]
    * Title: Barrier Frank-Wolfe for Marginal Inference
    * Year: `2015`
    * Authors: Rahul G. Krishnan, Simon Lacoste-Julien, David Sontag
    * Abstract: We introduce a globally-convergent algorithm for optimizing the tree-reweighted (TRW) variational objective over the marginal polytope. The algorithm is based on the conditional gradient method (Frank-Wolfe) and moves pseudomarginals within the marginal polytope through repeated maximum a posteriori (MAP) calls. This modular structure enables us to leverage black-box MAP solvers (both exact and approximate) for variational inference, and obtains more accurate results than tree-reweighted algorithms that optimize over the local consistency relaxation. Theoretically, we bound the sub-optimality for the proposed algorithm despite the TRW objective having unbounded gradients at the boundary of the marginal polytope. Empirically, we demonstrate the increased quality of results found by tightening the relaxation over the marginal polytope as well as the spanning tree polytope on synthetic and real-world instances.
count=2
* Online Learning with Adversarial Delays
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/72da7fd6d1302c0a159f6436d01e9eb0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/72da7fd6d1302c0a159f6436d01e9eb0-Paper.pdf)]
    * Title: Online Learning with Adversarial Delays
    * Year: `2015`
    * Authors: Kent Quanrud, Daniel Khashabi
    * Abstract: We study the performance of standard online learning algorithms when the feedback is delayed by an adversary. We show that \texttt{online-gradient-descent} and \texttt{follow-the-perturbed-leader} achieve regret $O(\sqrt{D})$ in the delayed setting, where $D$ is the sum of delays of each round's feedback. This bound collapses to an optimal $O(\sqrt{T})$ bound in the usual setting of no delays (where $D = T$). Our main contribution is to show that standard algorithms for online learning already have simple regret bounds in the most general setting of delayed feedback, making adjustments to the analysis and not to the algorithms themselves. Our results help affirm and clarify the success of recent algorithms in optimization and machine learning that operate in a delayed feedback model.
count=2
* On the Optimality of Classifier Chain for Multi-label Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/854d9fca60b4bd07f9bb215d59ef5561-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/854d9fca60b4bd07f9bb215d59ef5561-Paper.pdf)]
    * Title: On the Optimality of Classifier Chain for Multi-label Classification
    * Year: `2015`
    * Authors: Weiwei Liu, Ivor Tsang
    * Abstract: To capture the interdependencies between labels in multi-label classification problems, classifier chain (CC) tries to take the multiple labels of each instance into account under a deterministic high-order Markov Chain model. Since its performance is sensitive to the choice of label order, the key issue is how to determine the optimal label order for CC. In this work, we first generalize the CC model over a random label order. Then, we present a theoretical analysis of the generalization error for the proposed generalized model. Based on our results, we propose a dynamic programming based classifier chain (CC-DP) algorithm to search the globally optimal label order for CC and a greedy classifier chain (CC-Greedy) algorithm to find a locally optimal CC. Comprehensive experiments on a number of real-world multi-label data sets from various domains demonstrate that our proposed CC-DP algorithm outperforms state-of-the-art approaches and the CC-Greedy algorithm achieves comparable prediction performance with CC-DP.
count=2
* Learning From Small Samples: An Analysis of Simple Decision Heuristics
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/94e4451ad23909020c28b26ca3a13cb8-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/94e4451ad23909020c28b26ca3a13cb8-Paper.pdf)]
    * Title: Learning From Small Samples: An Analysis of Simple Decision Heuristics
    * Year: `2015`
    * Authors: Özgür Şimşek, Marcus Buckmann
    * Abstract: Simple decision heuristics are models of human and animal behavior that use few pieces of information---perhaps only a single piece of information---and integrate the pieces in simple ways, for example, by considering them sequentially, one at a time, or by giving them equal weight. It is unknown how quickly these heuristics can be learned from experience. We show, analytically and empirically, that only a few training samples lead to substantial progress in learning. We focus on three families of heuristics: single-cue decision making, lexicographic decision making, and tallying. Our empirical analysis is the most extensive to date, employing 63 natural data sets on diverse subjects.
count=2
* Sparse Random Feature Algorithm as Coordinate Descent in Hilbert Space
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/459a4ddcb586f24efd9395aa7662bc7c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/459a4ddcb586f24efd9395aa7662bc7c-Paper.pdf)]
    * Title: Sparse Random Feature Algorithm as Coordinate Descent in Hilbert Space
    * Year: `2014`
    * Authors: Ian En-Hsu Yen, Ting-Wei Lin, Shou-De Lin, Pradeep K. Ravikumar, Inderjit S. Dhillon
    * Abstract: In this paper, we propose a Sparse Random Feature algorithm, which learns a sparse non-linear predictor by minimizing an $\ell_1$-regularized objective function over the Hilbert Space induced from kernel function. By interpreting the algorithm as Randomized Coordinate Descent in the infinite-dimensional space, we show the proposed approach converges to a solution comparable within $\eps$-precision to exact kernel method by drawing $O(1/\eps)$ number of random features, contrasted to the $O(1/\eps^2)$-type convergence achieved by Monte-Carlo analysis in current Random Feature literature. In our experiments, the Sparse Random Feature algorithm obtains sparse solution that requires less memory and prediction time while maintains comparable performance on tasks of regression and classification. In the meantime, as an approximate solver for infinite-dimensional $\ell_1$-regularized problem, the randomized approach converges to better solution than Boosting approach when the greedy step of Boosting cannot be performed exactly.
count=2
* Sparse Polynomial Learning and Graph Sketching
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/71a58e8cb75904f24cde464161c3e766-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/71a58e8cb75904f24cde464161c3e766-Paper.pdf)]
    * Title: Sparse Polynomial Learning and Graph Sketching
    * Year: `2014`
    * Authors: Murat Kocaoglu, Karthikeyan Shanmugam, Alexandros G. Dimakis, Adam Klivans
    * Abstract: Let $f: \{-1,1\}^n \rightarrow \mathbb{R}$ be a polynomial with at most $s$ non-zero real coefficients. We give an algorithm for exactly reconstructing $f$ given random examples from the uniform distribution on $\{-1,1\}^n$ that runs in time polynomial in $n$ and $2^{s}$ and succeeds if the function satisfies the \textit{unique sign property}: there is one output value which corresponds to a unique set of values of the participating parities. This sufficient condition is satisfied when every coefficient of $f$ is perturbed by a small random noise, or satisfied with high probability when $s$ parity functions are chosen randomly or when all the coefficients are positive. Learning sparse polynomials over the Boolean domain in time polynomial in $n$ and $2^{s}$ is considered notoriously hard in the worst-case. Our result shows that the problem is tractable for almost all sparse polynomials. Then, we show an application of this result to hypergraph sketching which is the problem of learning a sparse (both in the number of hyperedges and the size of the hyperedges) hypergraph from uniformly drawn random cuts. We also provide experimental results on a real world dataset.
count=2
* Large-Margin Convex Polytope Machine
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/b147a61c1d07c1c999560f62add6dbc7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/b147a61c1d07c1c999560f62add6dbc7-Paper.pdf)]
    * Title: Large-Margin Convex Polytope Machine
    * Year: `2014`
    * Authors: Alex Kantchelian, Michael C. Tschantz, Ling Huang, Peter L. Bartlett, Anthony D. Joseph, J. D. Tygar
    * Abstract: We present the Convex Polytope Machine (CPM), a novel non-linear learning algorithm for large-scale binary classification tasks. The CPM finds a large margin convex polytope separator which encloses one class. We develop a stochastic gradient descent based algorithm that is amenable to massive datasets, and augment it with a heuristic procedure to avoid sub-optimal local minima. Our experimental evaluations of the CPM on large-scale datasets from distinct domains (MNIST handwritten digit recognition, text topic, and web security) demonstrate that the CPM trains models faster, sometimes several orders of magnitude, than state-of-the-art similar approaches and kernel-SVM methods while achieving comparable or better classification performance. Our empirical results suggest that, unlike prior similar approaches, we do not need to control the number of sub-classifiers (sides of the polytope) to avoid overfitting.
count=2
* Auditing: Active Learning with Outcome-Dependent Query Costs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/40008b9a5380fcacce3976bf7c08af5b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/40008b9a5380fcacce3976bf7c08af5b-Paper.pdf)]
    * Title: Auditing: Active Learning with Outcome-Dependent Query Costs
    * Year: `2013`
    * Authors: Sivan Sabato, Anand D. Sarwate, Nati Srebro
    * Abstract: We propose a learning setting in which unlabeled data is free, and the cost of a label depends on its value, which is not known in advance. We study binary classification in an extreme case, where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection, in which investigating an honest transaction should be avoided if possible. We term the setting auditing, and consider the auditing complexity of an algorithm: The number of negative points it labels to learn a hypothesis with low relative error. We design auditing algorithms for thresholds on the line and axis-aligned rectangles, and show that with these algorithms, the auditing complexity can be significantly lower than the active label complexity. We discuss a general approach for auditing for a general hypothesis class, and describe several interesting directions for future work.
count=2
* Transferring Expectations in Model-based Reinforcement Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/3f67fd97162d20e6fe27748b5b372509-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/3f67fd97162d20e6fe27748b5b372509-Paper.pdf)]
    * Title: Transferring Expectations in Model-based Reinforcement Learning
    * Year: `2012`
    * Authors: Trung Nguyen, Tomi Silander, Tze Leong
    * Abstract: We study how to automatically select and adapt multiple abstractions or representations of the world to support model-based reinforcement learning. We address the challenges of transfer learning in heterogeneous environments with varying tasks. We present an efficient, online framework that, through a sequence of tasks, learns a set of relevant representations to be used in future tasks. Without pre-defined mapping strategies, we introduce a general approach to support transfer learning across different state spaces. We demonstrate the potential impact of our system through improved jumpstart and faster convergence to near optimum policy in two benchmark domains.
count=2
* Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/c0c7c76d30bd3dcaefc96f40275bdc0a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/c0c7c76d30bd3dcaefc96f40275bdc0a-Paper.pdf)]
    * Title: Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction
    * Year: `2012`
    * Authors: Christoph H. Lampert
    * Abstract: We study the problem of maximum marginal prediction (MMP) in probabilistic graphical models, a task that occurs, for example, as the Bayes optimal decision rule under a Hamming loss. MMP is typically performed as a two-stage procedure: one estimates each variable's marginal probability and then forms a prediction from the states of maximal probability. In this work we propose a simple yet effective technique for accelerating MMP when inference is sampling-based: instead of the above two-stage procedure we directly estimate the posterior probability of each decision variable. This allows us to identify the point of time when we are sufficiently certain about any individual decision. Whenever this is the case, we dynamically prune the variable we are confident about from the underlying factor graph. Consequently, at any time only samples of variable whose decision is still uncertain need to be created. Experiments in two prototypical scenarios, multi-label classification and image inpainting, shows that adaptive sampling can drastically accelerate MMP without sacrificing prediction accuracy.
count=1
* Multi-modal Learning for Geospatial Vegetation Forecasting
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Benson_Multi-modal_Learning_for_Geospatial_Vegetation_Forecasting_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Benson_Multi-modal_Learning_for_Geospatial_Vegetation_Forecasting_CVPR_2024_paper.pdf)]
    * Title: Multi-modal Learning for Geospatial Vegetation Forecasting
    * Year: `2024`
    * Authors: Vitus Benson, Claire Robin, Christian Requena-Mesa, Lazaro Alonso, Nuno Carvalhais, José Cortés, Zhihan Gao, Nora Linscheid, Mélanie Weynants, Markus Reichstein
    * Abstract: Precise geospatial vegetation forecasting holds potential across diverse sectors including agriculture forestry humanitarian aid and carbon accounting. To leverage the vast availability of satellite imagery for this task various works have applied deep neural networks for predicting multispectral images in photorealistic quality. However the important area of vegetation dynamics has not been thoroughly explored. Our study introduces GreenEarthNet the first dataset specifically designed for high-resolution vegetation forecasting and Contextformer a novel deep learning approach for predicting vegetation greenness from Sentinel 2 satellite images with fine resolution across Europe. Our multi-modal transformer model Contextformer leverages spatial context through a vision backbone and predicts the temporal dynamics on local context patches incorporating meteorological time series in a parameter-efficient manner. The GreenEarthNet dataset features a learned cloud mask and an appropriate evaluation scheme for vegetation modeling. It also maintains compatibility with the existing satellite imagery forecasting dataset EarthNet2021 enabling cross-dataset model comparisons. Our extensive qualitative and quantitative analyses reveal that our methods outperform a broad range of baseline techniques. This includes surpassing previous state-of-the-art models on EarthNet2021 as well as adapted models from time series forecasting and video prediction. To the best of our knowledge this work presents the first models for continental-scale vegetation modeling at fine resolution able to capture anomalies beyond the seasonal cycle thereby paving the way for predicting vegetation health and behaviour in response to climate variability and extremes. We provide open source code and pre-trained weights to reproduce our experimental results under https://github.com/vitusbenson/greenearthnet.
count=1
* UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio Video Point Cloud Time-Series and Image Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Ding_UniRepLKNet_A_Universal_Perception_Large-Kernel_ConvNet_for_Audio_Video_Point_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Ding_UniRepLKNet_A_Universal_Perception_Large-Kernel_ConvNet_for_Audio_Video_Point_CVPR_2024_paper.pdf)]
    * Title: UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio Video Point Cloud Time-Series and Image Recognition
    * Year: `2024`
    * Authors: Xiaohan Ding, Yiyuan Zhang, Yixiao Ge, Sijie Zhao, Lin Song, Xiangyu Yue, Ying Shan
    * Abstract: Large-kernel convolutional neural networks (ConvNets) have recently received extensive research attention but two unresolved and critical issues demand further investigation. 1) The architectures of existing large-kernel ConvNets largely follow the design principles of conventional ConvNets or transformers while the architectural design for large-kernel ConvNets remains under-addressed. 2) As transformers have dominated multiple modalities it remains to be investigated whether ConvNets also have a strong universal perception ability in domains beyond vision. In this paper we contribute from two aspects. 1) We propose four architectural guidelines for designing large-kernel ConvNets the core of which is to exploit the essential characteristics of large kernels that distinguish them from small kernels - they can see wide without going deep. Following such guidelines our proposed large-kernel ConvNet shows leading performance in image recognition (ImageNet accuracy of 88.0% ADE20K mIoU of 55.6% and COCO box AP of 56.4%) demonstrating better performance and higher speed than the recent powerful competitors. 2) We discover large kernels are the key to unlocking the exceptional performance of ConvNets in domains where they were originally not proficient. With certain modality-related preprocessing approaches the proposed model achieves state-of-the-art performance on time-series forecasting and audio recognition tasks even without modality-specific customization to the architecture. All the code and models are publicly available on GitHub and Huggingface.
count=1
* Uncovering What Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Du_Uncovering_What_Why_and_How_A_Comprehensive_Benchmark_for_Causation_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Du_Uncovering_What_Why_and_How_A_Comprehensive_Benchmark_for_Causation_CVPR_2024_paper.pdf)]
    * Title: Uncovering What Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly
    * Year: `2024`
    * Authors: Hang Du, Sicheng Zhang, Binzhu Xie, Guoshun Nan, Jiayang Zhang, Junrui Xu, Hangyu Liu, Sicong Leng, Jiangming Liu, Hehe Fan, Dajiu Huang, Jing Feng, Linli Chen, Can Zhang, Xuhuan Li, Hao Zhang, Jianhang Chen, Qimei Cui, Xiaofeng Tao
    * Abstract: Video anomaly understanding (VAU) aims to automatically comprehend unusual occurrences in videos thereby enabling various applications such as traffic surveillance and industrial manufacturing. While existing VAU benchmarks primarily concentrate on anomaly detection and localization our focus is on more practicality prompting us to raise the following crucial questions: "what anomaly occurred?" "why did it happen?" and "how severe is this abnormal event?". In pursuit of these answers we present a comprehensive benchmark for Causation Understanding of Video Anomaly (CUVA). Specifically each instance of the proposed benchmark involves three sets of human annotations to indicate the "what" "why" and "how" of an anomaly including 1) anomaly type start and end times and event descriptions 2) natural language explanations for the cause of an anomaly and 3) free text reflecting the effect of the abnormality. In addition we also introduce MMEval a novel evaluation metric designed to better align with human preferences for CUVA facilitating the measurement of existing LLMs in comprehending the underlying cause and corresponding effect of video anomalies. Finally we propose a novel prompt-based method that can serve as a baseline approach for the challenging CUVA. We conduct extensive experiments to show the superiority of our evaluation metric and the prompt-based approach.
count=1
* Test-Time Linear Out-of-Distribution Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Test-Time_Linear_Out-of-Distribution_Detection_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Fan_Test-Time_Linear_Out-of-Distribution_Detection_CVPR_2024_paper.pdf)]
    * Title: Test-Time Linear Out-of-Distribution Detection
    * Year: `2024`
    * Authors: Ke Fan, Tong Liu, Xingyu Qiu, Yikai Wang, Lian Huai, Zeyu Shangguan, Shuang Gou, Fengjian Liu, Yuqian Fu, Yanwei Fu, Xingqun Jiang
    * Abstract: Out-of-Distribution (OOD) detection aims to address the excessive confidence prediction by neural networks by triggering an alert when the input sample deviates significantly from the training distribution (in-distribution) indicating that the output may not be reliable. Current OOD detection approaches explore all kinds of cues to identify OOD data such as finding irregular patterns in the feature space logit space gradient space or the raw image space. Surprisingly we observe a linear trend between the OOD score produced by current OOD detection algorithms and the network features on several datasets. We conduct a thorough investigation theoretically and empirically to analyze and understand the meaning of such a linear trend in OOD detection. This paper proposes a Robust Test-time Linear method (RTL) to utilize such linear trends like a `free lunch' when we have a batch of data to perform OOD detection. By using a simple linear regression as a test time adaptation we can make a more precise OOD prediction. We further propose an online variant of the proposed method which achieves promising performance and is more practical for real applications. Theoretical analysis is given to prove the effectiveness of our methods. Extensive experiments on several OOD datasets show the efficacy of RTL for OOD detection tasks significantly improving the results of base OOD detectors. Project will be available at https://github.com/kfan21/RTL.
count=1
* FADES: Fair Disentanglement with Sensitive Relevance
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Jang_FADES_Fair_Disentanglement_with_Sensitive_Relevance_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Jang_FADES_Fair_Disentanglement_with_Sensitive_Relevance_CVPR_2024_paper.pdf)]
    * Title: FADES: Fair Disentanglement with Sensitive Relevance
    * Year: `2024`
    * Authors: Taeuk Jang, Xiaoqian Wang
    * Abstract: Learning fair representation in deep learning is essential to mitigate discriminatory outcomes and enhance trustworthiness. However previous research has been commonly established on inappropriate assumptions prone to unrealistic counterfactuals and performance degradation. Although some proposed alternative approaches such as employing correlation-aware causal graphs or proxies for mutual information these methods are less practical and not applicable in general. In this work we propose FAir DisEntanglement with Sensitive relevance (FADES) a novel approach that leverages conditional mutual information from the information theory perspective to address these challenges. We employ sensitive relevant code to direct correlated information between target labels and sensitive attributes by imposing conditional independence allowing better separation of the features of interest in the latent space. Utilizing an intuitive disentangling approach FADES consistently achieves superior performance and fairness both quantitatively and qualitatively with its straightforward structure. Specifically the proposed method outperforms existing works in downstream classification and counterfactual generations on various benchmarks.
count=1
* Visual Concept Connectome (VCC): Open World Concept Discovery and their Interlayer Connections in Deep Models
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Kowal_Visual_Concept_Connectome_VCC_Open_World_Concept_Discovery_and_their_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Kowal_Visual_Concept_Connectome_VCC_Open_World_Concept_Discovery_and_their_CVPR_2024_paper.pdf)]
    * Title: Visual Concept Connectome (VCC): Open World Concept Discovery and their Interlayer Connections in Deep Models
    * Year: `2024`
    * Authors: Matthew Kowal, Richard P. Wildes, Konstantinos G. Derpanis
    * Abstract: Understanding what deep network models capture in their learned representations is a fundamental challenge in computer vision. We present a new methodology to understanding such vision models the Visual Concept Connectome (VCC) which discovers human interpretable concepts and their interlayer connections in a fully unsupervised manner. Our approach simultaneously reveals fine-grained concepts at a layer connection weightings across all layers and is amendable to global analysis of network structure (e.g. branching pattern of hierarchical concept assemblies). Previous work yielded ways to extract interpretable concepts from single layers and examine their impact on classification but did not afford multilayer concept analysis across an entire network architecture. Quantitative and qualitative empirical results show the effectiveness of VCCs in the domain of image classification. Also we leverage VCCs for the application of failure mode debugging to reveal where mistakes arise in deep networks.
count=1
* Self-Calibrating Vicinal Risk Minimisation for Model Calibration
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Self-Calibrating_Vicinal_Risk_Minimisation_for_Model_Calibration_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Self-Calibrating_Vicinal_Risk_Minimisation_for_Model_Calibration_CVPR_2024_paper.pdf)]
    * Title: Self-Calibrating Vicinal Risk Minimisation for Model Calibration
    * Year: `2024`
    * Authors: Jiawei Liu, Changkun Ye, Ruikai Cui, Nick Barnes
    * Abstract: Model calibration measuring the alignment between the prediction accuracy and model confidence is an important metric reflecting model trustworthiness. Existing dense binary classification methods without proper regularisation of model confidence are prone to being over-confident. To calibrate Deep Neural Networks (DNNs) we propose a Self-Calibrating Vicinal Risk Minimisation (SCVRM) that explores the vicinity space of labeled data where vicinal images that are farther away from labeled images adopt the groundtruth label with decreasing label confidence. We prove that in the logistic regression problem SCVRM can be seen as a Vicinal Risk Minimisation plus a regularisation term that penalises the over-confident predictions. In practical implementation SCVRM is approximated using Monte Carlo sampling that samples additional augmented training images and labels from the vicinal distributions. Experimental results demonstrate that SCVRM can significantly enhance model calibration for different dense classification tasks on both in-distribution and out-of-distribution data. Code is available at https://github.com/Carlisle-Liu/SCVRM.
count=1
* Positive-Unlabeled Learning by Latent Group-Aware Meta Disambiguation
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Long_Positive-Unlabeled_Learning_by_Latent_Group-Aware_Meta_Disambiguation_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Long_Positive-Unlabeled_Learning_by_Latent_Group-Aware_Meta_Disambiguation_CVPR_2024_paper.pdf)]
    * Title: Positive-Unlabeled Learning by Latent Group-Aware Meta Disambiguation
    * Year: `2024`
    * Authors: Lin Long, Haobo Wang, Zhijie Jiang, Lei Feng, Chang Yao, Gang Chen, Junbo Zhao
    * Abstract: Positive-Unlabeled (PU) learning aims to train a binary classifier using minimal positive data supplemented by a substantially larger pool of unlabeled data in the specific absence of explicitly annotated negatives. Despite its straightforward nature as a binary classification task the currently best-performing PU algorithms still largely lag behind the supervised counterpart. In this work we identify that the primary bottleneck lies in the difficulty of deriving discriminative representations under unreliable binary supervision with poor semantics which subsequently hinders the common label disambiguation procedures. To cope with this problem we propose a novel PU learning framework namely Latent Group-Aware Meta Disambiguation (LaGAM) which incorporates a hierarchical contrastive learning module to extract the underlying grouping semantics within PU data and produce compact representations. As a result LaGAM enables a more aggressive label disambiguation strategy where we enhance the robustness of training by iteratively distilling the true labels of unlabeled data directly through meta-learning. Extensive experiments show that LaGAM significantly outperforms the current state-of-the-art methods by an average of 6.8% accuracy on common benchmarks approaching the supervised baseline. We also provide comprehensive ablations as well as visualized analysis to verify the effectiveness of our LaGAM.
count=1
* Federated Generalized Category Discovery
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Pu_Federated_Generalized_Category_Discovery_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Pu_Federated_Generalized_Category_Discovery_CVPR_2024_paper.pdf)]
    * Title: Federated Generalized Category Discovery
    * Year: `2024`
    * Authors: Nan Pu, Wenjing Li, Xingyuan Ji, Yalan Qin, Nicu Sebe, Zhun Zhong
    * Abstract: Generalized category discovery (GCD) aims at grouping unlabeled samples from known and unknown classes given labeled data of known classes. To meet the recent decentralization trend in the community we introduce a practical yet challenging task Federated GCD (Fed-GCD) where the training data are distributed in local clients and cannot be shared among clients. Fed-GCD aims to train a generic GCD model by client collaboration under the privacy-protected constraint. The Fed-GCD leads to two challenges: 1) representation degradation caused by training each client model with fewer data than centralized GCD learning and 2) highly heterogeneous label spaces across different clients. To this end we propose a novel Associated Gaussian Contrastive Learning (AGCL) framework based on learnable GMMs which consists of a Client Semantics Association (CSA) and a global-local GMM Contrastive Learning (GCL). On the server CSA aggregates the heterogeneous categories of local-client GMMs to generate a global GMM containing more comprehensive category knowledge. On each client GCL builds class-level contrastive learning with both local and global GMMs. The local GCL learns robust representation with limited local data. The global GCL encourages the model to produce more discriminative representation with the comprehensive category relationships that may not exist in local data. We build a benchmark based on six visual datasets to facilitate the study of Fed-GCD. Extensive experiments show that our AGCL outperforms multiple baselines on all datasets.
count=1
* Visual Objectification in Films: Towards a New AI Task for Video Interpretation
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Tores_Visual_Objectification_in_Films_Towards_a_New_AI_Task_for_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Tores_Visual_Objectification_in_Films_Towards_a_New_AI_Task_for_CVPR_2024_paper.pdf)]
    * Title: Visual Objectification in Films: Towards a New AI Task for Video Interpretation
    * Year: `2024`
    * Authors: Julie Tores, Lucile Sassatelli, Hui-Yin Wu, Clement Bergman, Léa Andolfi, Victor Ecrement, Frédéric Precioso, Thierry Devars, Magali Guaresi, Virginie Julliard, Sarah Lecossais
    * Abstract: In film gender studies the concept of "male gaze" refers to the way the characters are portrayed on-screen as objects of desire rather than subjects. In this article we introduce a novel video-interpretation task to detect character objectification in films. The purpose is to reveal and quantify the usage of complex temporal patterns operated in cinema to produce the cognitive perception of objectification. We introduce the ObyGaze12 dataset made of 1914 movie clips densely annotated by experts for objectification concepts identified in film studies and psychology. We evaluate recent vision models show the feasibility of the task and where the challenges remain with concept bottleneck models. Our new dataset and code are made available to the community.
count=1
* Flattening the Parent Bias: Hierarchical Semantic Segmentation in the Poincare Ball
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Weber_Flattening_the_Parent_Bias_Hierarchical_Semantic_Segmentation_in_the_Poincare_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Weber_Flattening_the_Parent_Bias_Hierarchical_Semantic_Segmentation_in_the_Poincare_CVPR_2024_paper.pdf)]
    * Title: Flattening the Parent Bias: Hierarchical Semantic Segmentation in the Poincare Ball
    * Year: `2024`
    * Authors: Simon Weber, Bar?? Zöngür, Nikita Araslanov, Daniel Cremers
    * Abstract: Hierarchy is a natural representation of semantic taxonomies including the ones routinely used in image segmentation. Indeed recent work on semantic segmentation reports improved accuracy from supervised training leveraging hierarchical label structures. Encouraged by these results we revisit the fundamental assumptions behind that work. We postulate and then empirically verify that the reasons for the observed improvement in segmentation accuracy may be entirely unrelated to the use of the semantic hierarchy. To demonstrate this we design a range of cross-domain experiments with a representative hierarchical approach. We find that on the new testing domains a flat (non-hierarchical) segmentation network in which the parents are inferred from the children has superior segmentation accuracy to the hierarchical approach across the board. Complementing these findings and inspired by the intrinsic properties of hyperbolic spaces we study a more principled approach to hierarchical segmentation using the Poincare ball model. The hyperbolic representation largely outperforms the previous (Euclidean) hierarchical approach as well and is on par with our flat Euclidean baseline in terms of segmentation accuracy. However it additionally exhibits surprisingly strong calibration quality of the parent nodes in the semantic hierarchy especially on the more challenging domains. Our combined analysis suggests that the established practice of hierarchical segmentation may be limited to in-domain settings whereas flat classifiers generalize substantially better especially if they are modeled in the hyperbolic space.
count=1
* Learning for Transductive Threshold Calibration in Open-World Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Learning_for_Transductive_Threshold_Calibration_in_Open-World_Recognition_CVPR_2024_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Learning_for_Transductive_Threshold_Calibration_in_Open-World_Recognition_CVPR_2024_paper.pdf)]
    * Title: Learning for Transductive Threshold Calibration in Open-World Recognition
    * Year: `2024`
    * Authors: Qin Zhang, Dongsheng An, Tianjun Xiao, Tong He, Qingming Tang, Ying Nian Wu, Joseph Tighe, Yifan Xing
    * Abstract: In deep metric learning for visual recognition the calibration of distance thresholds is crucial for achieving desired model performance in the true positive rates (TPR) or true negative rates (TNR). However calibrating this thresh- old presents challenges in open-world scenarios where the test classes can be entirely disjoint from those encountered during training. We define the problem of finding distance thresholds for a trained embedding model to achieve target performance metrics over unseen open-world test classes as open-world threshold calibration. Existing posthoc threshold calibration methods reliant on inductive inference and requiring a calibration dataset with a similar distance distribution as the test data often prove ineffective in open- world scenarios. To address this we introduce OpenGCN a Graph Neural Network-based transductive threshold calibration method with enhanced adaptability and robustness. OpenGCN learns to predict pairwise connectivity for the unlabeled test instances embedded in a graph to determine its TPR and TNR at various distance thresholds allowing for transductive inference of the distance thresholds which also incorporates test-time information. Extensive experiments across open-world visual recognition benchmarks validate OpenGCN's superiority over existing posthoc calibration methods for open-world threshold calibration.
count=1
* Leveraging Inter-Rater Agreement for Classification in the Presence of Noisy Labels
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Bucarelli_Leveraging_Inter-Rater_Agreement_for_Classification_in_the_Presence_of_Noisy_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Bucarelli_Leveraging_Inter-Rater_Agreement_for_Classification_in_the_Presence_of_Noisy_CVPR_2023_paper.pdf)]
    * Title: Leveraging Inter-Rater Agreement for Classification in the Presence of Noisy Labels
    * Year: `2023`
    * Authors: Maria Sofia Bucarelli, Lucas Cassano, Federico Siciliano, Amin Mantrach, Fabrizio Silvestri
    * Abstract: In practical settings, classification datasets are obtained through a labelling process that is usually done by humans. Labels can be noisy as they are obtained by aggregating the different individual labels assigned to the same sample by multiple, and possibly disagreeing, annotators. The inter-rater agreement on these datasets can be measured while the underlying noise distribution to which the labels are subject is assumed to be unknown. In this work, we: (i) show how to leverage the inter-annotator statistics to estimate the noise distribution to which labels are subject; (ii) introduce methods that use the estimate of the noise distribution to learn from the noisy dataset; and (iii) establish generalization bounds in the empirical risk minimization framework that depend on the estimated quantities. We conclude the paper by providing experiments that illustrate our findings.
count=1
* NeuralEditor: Editing Neural Radiance Fields via Manipulating Point Clouds
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_NeuralEditor_Editing_Neural_Radiance_Fields_via_Manipulating_Point_Clouds_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_NeuralEditor_Editing_Neural_Radiance_Fields_via_Manipulating_Point_Clouds_CVPR_2023_paper.pdf)]
    * Title: NeuralEditor: Editing Neural Radiance Fields via Manipulating Point Clouds
    * Year: `2023`
    * Authors: Jun-Kun Chen, Jipeng Lyu, Yu-Xiong Wang
    * Abstract: This paper proposes NeuralEditor that enables neural radiance fields (NeRFs) natively editable for general shape editing tasks. Despite their impressive results on novel-view synthesis, it remains a fundamental challenge for NeRFs to edit the shape of the scene. Our key insight is to exploit the explicit point cloud representation as the underlying structure to construct NeRFs, inspired by the intuitive interpretation of NeRF rendering as a process that projects or "plots" the associated 3D point cloud to a 2D image plane. To this end, NeuralEditor introduces a novel rendering scheme based on deterministic integration within K-D tree-guided density-adaptive voxels, which produces both high-quality rendering results and precise point clouds through optimization. NeuralEditor then performs shape editing via mapping associated points between point clouds. Extensive evaluation shows that NeuralEditor achieves state-of-the-art performance in both shape deformation and scene morphing tasks. Notably, NeuralEditor supports both zero-shot inference and further fine-tuning over the edited scene. Our code, benchmark, and demo video are available at https://immortalco.github.io/NeuralEditor.
count=1
* Feature Aggregated Queries for Transformer-Based Video Object Detectors
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Cui_Feature_Aggregated_Queries_for_Transformer-Based_Video_Object_Detectors_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Cui_Feature_Aggregated_Queries_for_Transformer-Based_Video_Object_Detectors_CVPR_2023_paper.pdf)]
    * Title: Feature Aggregated Queries for Transformer-Based Video Object Detectors
    * Year: `2023`
    * Authors: Yiming Cui
    * Abstract: Video object detection needs to solve feature degradation situations that rarely happen in the image domain. One solution is to use the temporal information and fuse the features from the neighboring frames. With Transformer-based object detectors getting a better performance on the image domain tasks, recent works began to extend those methods to video object detection. However, those existing Transformer-based video object detectors still follow the same pipeline as those used for classical object detectors, like enhancing the object feature representations by aggregation. In this work, we take a different perspective on video object detection. In detail, we improve the qualities of queries for the Transformer-based models by aggregation. To achieve this goal, we first propose a vanilla query aggregation module that weighted averages the queries according to the features of the neighboring frames. Then, we extend the vanilla module to a more practical version, which generates and aggregates queries according to the features of the input frames. Extensive experimental results validate the effectiveness of our proposed methods: On the challenging ImageNet VID benchmark, when integrated with our proposed modules, the current state-of-the-art Transformer-based object detectors can be improved by more than 2.4% on mAP and 4.2% on AP50.
count=1
* Reconstructing Signing Avatars From Video Using Linguistic Priors
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Forte_Reconstructing_Signing_Avatars_From_Video_Using_Linguistic_Priors_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Forte_Reconstructing_Signing_Avatars_From_Video_Using_Linguistic_Priors_CVPR_2023_paper.pdf)]
    * Title: Reconstructing Signing Avatars From Video Using Linguistic Priors
    * Year: `2023`
    * Authors: Maria-Paola Forte, Peter Kulits, Chun-Hao P. Huang, Vasileios Choutas, Dimitrios Tzionas, Katherine J. Kuchenbecker, Michael J. Black
    * Abstract: Sign language (SL) is the primary method of communication for the 70 million Deaf people around the world. Video dictionaries of isolated signs are a core SL learning tool. Replacing these with 3D avatars can aid learning and enable AR/VR applications, improving access to technology and online media. However, little work has attempted to estimate expressive 3D avatars from SL video; occlusion, noise, and motion blur make this task difficult. We address this by introducing novel linguistic priors that are universally applicable to SL and provide constraints on 3D hand pose that help resolve ambiguities within isolated signs. Our method, SGNify, captures fine-grained hand pose, facial expression, and body movement fully automatically from in-the-wild monocular SL videos. We evaluate SGNify quantitatively by using a commercial motion-capture system to compute 3D avatars synchronized with monocular video. SGNify outperforms state-of-the-art 3D body-pose- and shape-estimation methods on SL videos. A perceptual study shows that SGNify's 3D reconstructions are significantly more comprehensible and natural than those of previous methods and are on par with the source videos. Code and data are available at sgnify.is.tue.mpg.de.
count=1
* Bias in Pruned Vision Models: In-Depth Analysis and Countermeasures
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Iofinova_Bias_in_Pruned_Vision_Models_In-Depth_Analysis_and_Countermeasures_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Iofinova_Bias_in_Pruned_Vision_Models_In-Depth_Analysis_and_Countermeasures_CVPR_2023_paper.pdf)]
    * Title: Bias in Pruned Vision Models: In-Depth Analysis and Countermeasures
    * Year: `2023`
    * Authors: Eugenia Iofinova, Alexandra Peste, Dan Alistarh
    * Abstract: Pruning - that is, setting a significant subset of the parameters of a neural network to zero - is one of the most popular methods of model compression. Yet, several recent works have raised the issue that pruning may induce or exacerbate bias in the output of the compressed model. Despite existing evidence for this phenomenon, the relationship between neural network pruning and induced bias is not well-understood. In this work, we systematically investigate and characterize this phenomenon in Convolutional Neural Networks for computer vision. First, we show that it is in fact possible to obtain highly-sparse models, e.g. with less than 10% remaining weights, which do not decrease in accuracy nor substantially increase in bias when compared to dense models. At the same time, we also find that, at higher sparsities, pruned models exhibit higher uncertainty in their outputs, as well as increased correlations, which we directly link to increased bias. We propose easy-to-use criteria which, based only on the uncompressed model, establish whether bias will increase with pruning, and identify the samples most susceptible to biased predictions post-compression.
count=1
* Difficulty-Based Sampling for Debiased Contrastive Representation Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Jang_Difficulty-Based_Sampling_for_Debiased_Contrastive_Representation_Learning_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Jang_Difficulty-Based_Sampling_for_Debiased_Contrastive_Representation_Learning_CVPR_2023_paper.pdf)]
    * Title: Difficulty-Based Sampling for Debiased Contrastive Representation Learning
    * Year: `2023`
    * Authors: Taeuk Jang, Xiaoqian Wang
    * Abstract: Contrastive learning is a self-supervised representation learning method that achieves milestone performance in various classification tasks. However, due to its unsupervised fashion, it suffers from the false negative sample problem: randomly drawn negative samples that are assumed to have a different label but actually have the same label as the anchor. This deteriorates the performance of contrastive learning as it contradicts the motivation of contrasting semantically similar and dissimilar pairs. This raised the attention and the importance of finding legitimate negative samples, which should be addressed by distinguishing between 1) true vs. false negatives; 2) easy vs. hard negatives. However, previous works were limited to the statistical approach to handle false negative and hard negative samples with hyperparameters tuning. In this paper, we go beyond the statistical approach and explore the connection between hard negative samples and data bias. We introduce a novel debiased contrastive learning method to explore hard negatives by relative difficulty referencing the bias-amplifying counterpart. We propose triplet loss for training a biased encoder that focuses more on easy negative samples. We theoretically show that the triplet loss amplifies the bias in self-supervised representation learning. Finally, we empirically show the proposed method improves downstream classification performance.
count=1
* PIP-Net: Patch-Based Intuitive Prototypes for Interpretable Image Classification
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Nauta_PIP-Net_Patch-Based_Intuitive_Prototypes_for_Interpretable_Image_Classification_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Nauta_PIP-Net_Patch-Based_Intuitive_Prototypes_for_Interpretable_Image_Classification_CVPR_2023_paper.pdf)]
    * Title: PIP-Net: Patch-Based Intuitive Prototypes for Interpretable Image Classification
    * Year: `2023`
    * Authors: Meike Nauta, Jörg Schlötterer, Maurice van Keulen, Christin Seifert
    * Abstract: Interpretable methods based on prototypical patches recognize various components in an image in order to explain their reasoning to humans. However, existing prototype-based methods can learn prototypes that are not in line with human visual perception, i.e., the same prototype can refer to different concepts in the real world, making interpretation not intuitive. Driven by the principle of explainability-by-design, we introduce PIP-Net (Patch-based Intuitive Prototypes Network): an interpretable image classification model that learns prototypical parts in a self-supervised fashion which correlate better with human vision. PIP-Net can be interpreted as a sparse scoring sheet where the presence of a prototypical part in an image adds evidence for a class. The model can also abstain from a decision for out-of-distribution data by saying "I haven't seen this before". We only use image-level labels and do not rely on any part annotations. PIP-Net is globally interpretable since the set of learned prototypes shows the entire reasoning of the model. A smaller local explanation locates the relevant prototypes in one image. We show that our prototypes correlate with ground-truth object parts, indicating that PIP-Net closes the "semantic gap" between latent space and pixel space. Hence, our PIP-Net with interpretable prototypes enables users to interpret the decision making process in an intuitive, faithful and semantically meaningful way. Code is available at https://github.com/M-Nauta/PIPNet.
count=1
* Towards Building Self-Aware Object Detectors via Reliable Uncertainty Quantification and Calibration
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Oksuz_Towards_Building_Self-Aware_Object_Detectors_via_Reliable_Uncertainty_Quantification_and_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Oksuz_Towards_Building_Self-Aware_Object_Detectors_via_Reliable_Uncertainty_Quantification_and_CVPR_2023_paper.pdf)]
    * Title: Towards Building Self-Aware Object Detectors via Reliable Uncertainty Quantification and Calibration
    * Year: `2023`
    * Authors: Kemal Oksuz, Tom Joy, Puneet K. Dokania
    * Abstract: The current approach for testing the robustness of object detectors suffers from serious deficiencies such as improper methods of performing out-of-distribution detection and using calibration metrics which do not consider both localisation and classification quality. In this work, we address these issues, and introduce the Self Aware Object Detection (SAOD) task, a unified testing framework which respects and adheres to the challenges that object detectors face in safety-critical environments such as autonomous driving. Specifically, the SAOD task requires an object detector to be: robust to domain shift; obtain reliable uncertainty estimates for the entire scene; and provide calibrated confidence scores for the detections. We extensively use our framework, which introduces novel metrics and large scale test datasets, to test numerous object detectors in two different use-cases, allowing us to highlight critical insights into their robustness performance. Finally, we introduce a simple baseline for the SAOD task, enabling researchers to benchmark future proposed methods and move towards robust object detectors which are fit for purpose. Code is available at: https://github.com/fiveai/saod
count=1
* Perception and Semantic Aware Regularization for Sequential Confidence Calibration
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Peng_Perception_and_Semantic_Aware_Regularization_for_Sequential_Confidence_Calibration_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Peng_Perception_and_Semantic_Aware_Regularization_for_Sequential_Confidence_Calibration_CVPR_2023_paper.pdf)]
    * Title: Perception and Semantic Aware Regularization for Sequential Confidence Calibration
    * Year: `2023`
    * Authors: Zhenghua Peng, Yu Luo, Tianshui Chen, Keke Xu, Shuangping Huang
    * Abstract: Deep sequence recognition (DSR) models receive increasing attention due to their superior application to various applications. Most DSR models use merely the target sequences as supervision without considering other related sequences, leading to over-confidence in their predictions. The DSR models trained with label smoothing regularize labels by equally and independently smoothing each token, reallocating a small value to other tokens for mitigating overconfidence. However, they do not consider tokens/sequences correlations that may provide more effective information to regularize training and thus lead to sub-optimal performance. In this work, we find tokens/sequences with high perception and semantic correlations with the target ones contain more correlated and effective information and thus facilitate more effective regularization. To this end, we propose a Perception and Semantic aware Sequence Regularization framework, which explore perceptively and semantically correlated tokens/sequences as regularization. Specifically, we introduce a semantic context-free recognition and a language model to acquire similar sequences with high perceptive similarities and semantic correlation, respectively. Moreover, over-confidence degree varies across samples according to their difficulties. Thus, we further design an adaptive calibration intensity module to compute a difficulty score for each samples to obtain finer-grained regularization. Extensive experiments on canonical sequence recognition tasks, including scene text and speech recognition, demonstrate that our method sets novel state-of-the-art results. Code is available at https://github.com/husterpzh/PSSR.
count=1
* Defining and Quantifying the Emergence of Sparse Concepts in DNNs
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Ren_Defining_and_Quantifying_the_Emergence_of_Sparse_Concepts_in_DNNs_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_Defining_and_Quantifying_the_Emergence_of_Sparse_Concepts_in_DNNs_CVPR_2023_paper.pdf)]
    * Title: Defining and Quantifying the Emergence of Sparse Concepts in DNNs
    * Year: `2023`
    * Authors: Jie Ren, Mingjie Li, Qirui Chen, Huiqi Deng, Quanshi Zhang
    * Abstract: This paper aims to illustrate the concept-emerging phenomenon in a trained DNN. Specifically, we find that the inference score of a DNN can be disentangled into the effects of a few interactive concepts. These concepts can be understood as inference patterns in a sparse, symbolic graphical model, which explains the DNN. The faithfulness of using such a graphical model to explain the DNN is theoretically guaranteed, because we prove that the graphical model can well mimic the DNN's outputs on an exponential number of different masked samples. Besides, such a graphical model can be further simplified and re-written as an And-Or graph (AOG), without losing much explanation accuracy. The code is released at https://github.com/sjtu-xai-lab/aog.
count=1
* On the Pitfall of Mixup for Uncertainty Calibration
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_On_the_Pitfall_of_Mixup_for_Uncertainty_Calibration_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_On_the_Pitfall_of_Mixup_for_Uncertainty_Calibration_CVPR_2023_paper.pdf)]
    * Title: On the Pitfall of Mixup for Uncertainty Calibration
    * Year: `2023`
    * Authors: Deng-Bao Wang, Lanqing Li, Peilin Zhao, Pheng-Ann Heng, Min-Ling Zhang
    * Abstract: By simply taking convex combinations between pairs of samples and their labels, mixup training has been shown to easily improve predictive accuracy. It has been recently found that models trained with mixup also perform well on uncertainty calibration. However, in this study, we found that mixup training usually makes models less calibratable than vanilla empirical risk minimization, which means that it would harm uncertainty estimation when post-hoc calibration is considered. By decomposing the mixup process into data transformation and random perturbation, we suggest that the confidence penalty nature of the data transformation is the reason of calibration degradation. To mitigate this problem, we first investigate the mixup inference strategy and found that despite it improves calibration on mixup, this ensemble-like strategy does not necessarily outperform simple ensemble. Then, we propose a general strategy named mixup inference in training, which adopts a simple decoupling principle for recovering the outputs of raw samples at the end of forward network pass. By embedding the mixup inference, models can be learned from the original one-hot labels and hence avoid the negative impact of confidence penalty. Our experiments show this strategy properly solves mixup's calibration issue without sacrificing the predictive performance, while even improves accuracy than vanilla mixup.
count=1
* Switchable Representation Learning Framework With Self-Compatibility
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_Switchable_Representation_Learning_Framework_With_Self-Compatibility_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Switchable_Representation_Learning_Framework_With_Self-Compatibility_CVPR_2023_paper.pdf)]
    * Title: Switchable Representation Learning Framework With Self-Compatibility
    * Year: `2023`
    * Authors: Shengsen Wu, Yan Bai, Yihang Lou, Xiongkun Linghu, Jianzhong He, Ling-Yu Duan
    * Abstract: Real-world visual search systems involve deployments on multiple platforms with different computing and storage resources. Deploying a unified model that suits the minimal-constrain platforms leads to limited accuracy. It is expected to deploy models with different capacities adapting to the resource constraints, which requires features extracted by these models to be aligned in the metric space. The method to achieve feature alignments is called "compatible learning". Existing research mainly focuses on the one-to-one compatible paradigm, which is limited in learning compatibility among multiple models. We propose a Switchable representation learning Framework with Self-Compatibility (SFSC). SFSC generates a series of compatible sub-models with different capacities through one training process. The optimization of sub-models faces gradients conflict, and we mitigate this problem from the perspective of the magnitude and direction. We adjust the priorities of sub-models dynamically through uncertainty estimation to co-optimize sub-models properly. Besides, the gradients with conflicting directions are projected to avoid mutual interference. SFSC achieves state-of-the-art performance on the evaluated datasets.
count=1
* Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Yan_Towards_Trustable_Skin_Cancer_Diagnosis_via_Rewriting_Models_Decision_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_Towards_Trustable_Skin_Cancer_Diagnosis_via_Rewriting_Models_Decision_CVPR_2023_paper.pdf)]
    * Title: Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision
    * Year: `2023`
    * Authors: Siyuan Yan, Zhen Yu, Xuelin Zhang, Dwarikanath Mahapatra, Shekhar S. Chandra, Monika Janda, Peter Soyer, Zongyuan Ge
    * Abstract: Deep neural networks have demonstrated promising performance on image recognition tasks. However, they may heavily rely on confounding factors, using irrelevant artifacts or bias within the dataset as the cue to improve performance. When a model performs decision-making based on these spurious correlations, it can become untrustable and lead to catastrophic outcomes when deployed in the real-world scene. In this paper, we explore and try to solve this problem in the context of skin cancer diagnosis. We introduce a human-in-the-loop framework in the model training process such that users can observe and correct the model's decision logic when confounding behaviors happen. Specifically, our method can automatically discover confounding factors by analyzing the co-occurrence behavior of the samples. It is capable of learning confounding concepts using easily obtained concept exemplars. By mapping the blackbox model's feature representation onto an explainable concept space, human users can interpret the concept and intervene via first order-logic instruction. We systematically evaluate our method on our newly crafted, well-controlled skin lesion dataset and several public skin lesion datasets. Experiments show that our method can effectively detect and remove confounding factors from datasets without any prior knowledge about the category distribution and does not require fully annotated concept labels. We also show that our method enables the model to focus on clinicalrelated concepts, improving the model's performance and trustworthiness during model inference.
count=1
* OCTET: Object-Aware Counterfactual Explanations
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2023/html/Zemni_OCTET_Object-Aware_Counterfactual_Explanations_CVPR_2023_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Zemni_OCTET_Object-Aware_Counterfactual_Explanations_CVPR_2023_paper.pdf)]
    * Title: OCTET: Object-Aware Counterfactual Explanations
    * Year: `2023`
    * Authors: Mehdi Zemni, Mickaël Chen, Éloi Zablocki, Hédi Ben-Younes, Patrick Pérez, Matthieu Cord
    * Abstract: Nowadays, deep vision models are being widely deployed in safety-critical applications, e.g., autonomous driving, and explainability of such models is becoming a pressing concern. Among explanation methods, counterfactual explanations aim to find minimal and interpretable changes to the input image that would also change the output of the model to be explained. Such explanations point end-users at the main factors that impact the decision of the model. However, previous methods struggle to explain decision models trained on images with many objects, e.g., urban scenes, which are more difficult to work with but also arguably more critical to explain. In this work, we propose to tackle this issue with an object-centric framework for counterfactual explanation generation. Our method, inspired by recent generative modeling works, encodes the query image into a latent space that is structured in a way to ease object-level manipulations. Doing so, it provides the end-user with control over which search directions (e.g., spatial displacement of objects, style modification, etc.) are to be explored during the counterfactual generation. We conduct a set of experiments on counterfactual explanation benchmarks for driving scenes, and we show that our method can be adapted beyond classification, e.g., to explain semantic segmentation models. To complete our analysis, we design and run a user study that measures the usefulness of counterfactual explanations in understanding a decision model. Code is available at https://github.com/valeoai/OCTET.
count=1
* VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Aflalo_VL-InterpreT_An_Interactive_Visualization_Tool_for_Interpreting_Vision-Language_Transformers_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Aflalo_VL-InterpreT_An_Interactive_Visualization_Tool_for_Interpreting_Vision-Language_Transformers_CVPR_2022_paper.pdf)]
    * Title: VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers
    * Year: `2022`
    * Authors: Estelle Aflalo, Meng Du, Shao-Yen Tseng, Yongfei Liu, Chenfei Wu, Nan Duan, Vasudev Lal
    * Abstract: Breakthroughs in transformer-based models have revolutionized not only the NLP field, but also vision and multimodal systems. However, although visualization and interpretability tools have become available for NLP models, internal mechanisms of vision and multimodal transformers remain largely opaque. With the success of these transformers, it is increasingly critical to understand their inner workings, as unraveling these black-boxes will lead to more capable and trustworthy models. To contribute to this quest, we propose VL-InterpreT, which provides novel interactive visualizations for interpreting the attentions and hidden representations in multimodal transformers. VL-InterpreT is a task agnostic and integrated tool that (1) tracks a variety of statistics in attention heads throughout all layers for both vision and language components, (2) visualizes cross-modal and intra-modal attentions through easily readable heatmaps, and (3) plots the hidden representations of vision and language tokens as they pass through the transformer layers. In this paper, we demonstrate the functionalities of VL-InterpreT through the analysis of KD-VLP, an end-to-end pretraining vision-language multimodal transformer-based model, in the tasks of Visual Commonsense Reasoning (VCR) and WebQA, two visual question answering benchmarks. Furthermore, we also present a few interesting findings about multimodal transformer behaviors that were learned through our tool.
count=1
* Calibrating Deep Neural Networks by Pairwise Constraints
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Calibrating_Deep_Neural_Networks_by_Pairwise_Constraints_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Calibrating_Deep_Neural_Networks_by_Pairwise_Constraints_CVPR_2022_paper.pdf)]
    * Title: Calibrating Deep Neural Networks by Pairwise Constraints
    * Year: `2022`
    * Authors: Jiacheng Cheng, Nuno Vasconcelos
    * Abstract: It is well known that deep neural networks (DNNs) produce poorly calibrated estimates of class-posterior probabilities. We hypothesize that this is due to the limited calibration supervision provided by the cross-entropy loss, which places all emphasis on the probability of the true class and mostly ignores the remaining. We consider how each example can supervise all classes and show that the calibration of a C-way classification problem is equivalent to the calibration of C(C-1)/2 pairwise binary classification problems that can be derived from it. This suggests the hypothesis that DNN calibration can be improved by providing calibration supervision to all such binary problems. An implementation of this calibration by pairwise constraints (CPC) is then proposed, based on two types of binary calibration constraints. This is finally shown to be implementable with a very minimal increase in the complexity of cross-entropy training. Empirical evaluations of the proposed CPC method across multiple datasets and DNN architectures demonstrate state-of-the-art calibration performance.
count=1
* Cluster-Guided Image Synthesis With Unconditional Models
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.pdf)]
    * Title: Cluster-Guided Image Synthesis With Unconditional Models
    * Year: `2022`
    * Authors: Markos Georgopoulos, James Oldfield, Grigorios G. Chrysos, Yannis Panagakis
    * Abstract: Generative Adversarial Networks (GANs) are the driving force behind the state-of-the-art in image generation. Despite their ability to synthesize high-resolution photo-realistic images, generating content with on-demand conditioning of different granularity remains a challenge. This challenge is usually tackled by annotating massive datasets with the attributes of interest, a laborious task that is not always a viable option. Therefore, it is vital to introduce control into the generation process of unsupervised generative models. In this work, we focus on controllable image generation by leveraging GANs that are well-trained in an unsupervised fashion. To this end, we discover that the representation space of intermediate layers of the generator forms a number of clusters that separate the data according to semantically meaningful attributes (e.g., hair color and pose). By conditioning on the cluster assignments, the proposed method is able to control the semantic class of the generated image. Our approach enables sampling from each cluster by Implicit Maximum Likelihood Estimation (IMLE). We showcase the efficacy of our approach on faces (CelebA-HQ and FFHQ), animals (Imagenet) and objects (LSUN) using different pre-trained generative models. The results highlight the ability of our approach to condition image generation on attributes like gender, pose and hair style on faces, as well as a variety of features on different object classes.
count=1
* Cycle-Consistent Counterfactuals by Latent Transformations
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Khorram_Cycle-Consistent_Counterfactuals_by_Latent_Transformations_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Khorram_Cycle-Consistent_Counterfactuals_by_Latent_Transformations_CVPR_2022_paper.pdf)]
    * Title: Cycle-Consistent Counterfactuals by Latent Transformations
    * Year: `2022`
    * Authors: Saeed Khorram, Li Fuxin
    * Abstract: CounterFactual (CF) visual explanations try to find images similar to the query image that change the decision of a vision system to a specified outcome. Existing methods either require inference-time optimization or joint training with a generative adversarial model which makes them time-consuming and difficult to use in practice. We propose a novel approach, Cycle-Consistent Counterfactuals by Latent Transformations (C3LT), which learns a latent transformation that automatically generates visual CFs by steering in the latent space of generative models. Our method uses cycle consistency between the query and CF latent representations which helps our training to find better solutions. C3LT can be easily plugged into any state-of-the-art pretrained generative network. This enables our method to generate high-quality and interpretable CF images at high resolution such as those in ImageNet. In addition to several established metrics for evaluating CF explanations, we introduce a novel metric tailored to assess the quality of the generated CF examples and validate the effectiveness of our method on an extensive set of experiments.
count=1
* Unimodal-Concentrated Loss: Fully Adaptive Label Distribution Learning for Ordinal Regression
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Unimodal-Concentrated_Loss_Fully_Adaptive_Label_Distribution_Learning_for_Ordinal_Regression_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Unimodal-Concentrated_Loss_Fully_Adaptive_Label_Distribution_Learning_for_Ordinal_Regression_CVPR_2022_paper.pdf)]
    * Title: Unimodal-Concentrated Loss: Fully Adaptive Label Distribution Learning for Ordinal Regression
    * Year: `2022`
    * Authors: Qiang Li, Jingjing Wang, Zhaoliang Yao, Yachun Li, Pengju Yang, Jingwei Yan, Chunmao Wang, Shiliang Pu
    * Abstract: Learning from a label distribution has achieved promising results on ordinal regression tasks such as facial age and head pose estimation wherein, the concept of adaptive label distribution learning (ALDL) has drawn lots of attention recently for its superiority in theory. However, compared with the methods assuming fixed form label distribution, ALDL methods have not achieved better performance. We argue that existing ALDL algorithms do not fully exploit the intrinsic properties of ordinal regression. In this paper, we emphatically summarize that learning an adaptive label distribution on ordinal regression tasks should follow three principles. First, the probability corresponding to the ground-truth should be the highest in label distribution. Second, the probabilities of neighboring labels should decrease with the increase of distance away from the ground-truth, i.e., the distribution is unimodal. Third, the label distribution should vary with samples changing, and even be distinct for different instances with the same label, due to the different levels of difficulty and ambiguity. Under the premise of these principles, we propose a novel loss function for fully adaptive label distribution learning, namely unimodal-concentrated loss. Specifically, the unimodal loss derived from the learning to rank strategy constrains the distribution to be unimodal. Furthermore, the estimation error and the variance of the predicted distribution for a specific sample are integrated into the proposed concentrated loss to make the predicted distribution maximize at the ground-truth and vary according to the predicting uncertainty. Extensive experimental results on typical ordinal regression tasks including age and head pose estimation, show the superiority of our proposed unimodal-concentrated loss compared with existing loss functions.
count=1
* Progressive Minimal Path Method With Embedded CNN
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Progressive_Minimal_Path_Method_With_Embedded_CNN_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Progressive_Minimal_Path_Method_With_Embedded_CNN_CVPR_2022_paper.pdf)]
    * Title: Progressive Minimal Path Method With Embedded CNN
    * Year: `2022`
    * Authors: Wei Liao
    * Abstract: We propose Path-CNN, a method for the segmentation of centerlines of tubular structures by embedding convolutional neural networks (CNNs) into the progressive minimal path method. Minimal path methods are widely used for topology-aware centerline segmentation, but usually these methods rely on weak, hand-tuned image features. In contrast, CNNs use strong image features which are learned automatically from images. But CNNs usually do not take the topology of the results into account, and often require a large amount of annotations for training. We integrate CNNs into the minimal path method, so that both techniques benefit from each other: CNNs employ learned image features to improve the determination of minimal paths, while the minimal path method ensures the correct topology of the segmented centerlines, provides strong geometric priors to increase the performance of CNNs, and reduces the amount of annotations for the training of CNNs significantly. Our method has lower hardware requirements than many recent methods. Qualitative and quantitative comparison with other methods shows that Path-CNN achieves better performance, especially when dealing with tubular structures with complex shapes in challenging environments.
count=1
* How Much More Data Do I Need? Estimating Requirements for Downstream Tasks
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Mahmood_How_Much_More_Data_Do_I_Need_Estimating_Requirements_for_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Mahmood_How_Much_More_Data_Do_I_Need_Estimating_Requirements_for_CVPR_2022_paper.pdf)]
    * Title: How Much More Data Do I Need? Estimating Requirements for Downstream Tasks
    * Year: `2022`
    * Authors: Rafid Mahmood, James Lucas, David Acuna, Daiqing Li, Jonah Philion, Jose M. Alvarez, Zhiding Yu, Sanja Fidler, Marc T. Law
    * Abstract: Given a small training data set and a learning algorithm, how much more data is necessary to reach a target validation or test performance? This question is of critical importance in applications such as autonomous driving or medical imaging where collecting data is expensive and time-consuming. Overestimating or underestimating data requirements incurs substantial costs that could be avoided with an adequate budget. Prior work on neural scaling laws suggest that the power-law function can fit the validation performance curve and extrapolate it to larger data set sizes. We find that this does not immediately translate to the more difficult downstream task of estimating the required data set size to meet a target performance. In this work, we consider a broad class of computer vision tasks and systematically investigate a family of functions that generalize the power-law function to allow for better estimation of data requirements. Finally, we show that incorporating a tuned correction factor and collecting over multiple rounds significantly improves the performance of the data estimators. Using our guidelines, practitioners can accurately estimate data requirements of machine learning systems to gain savings in both development time and data acquisition costs.
count=1
* A-ViT: Adaptive Tokens for Efficient Vision Transformer
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.pdf)]
    * Title: A-ViT: Adaptive Tokens for Efficient Vision Transformer
    * Year: `2022`
    * Authors: Hongxu Yin, Arash Vahdat, Jose M. Alvarez, Arun Mallya, Jan Kautz, Pavlo Molchanov
    * Abstract: We introduce A-ViT, a method that adaptively adjusts the inference cost of vision transformer ViT for images of different complexity. A-ViT achieves this by automatically reducing the number of tokens in vision transformers that are processed in the network as inference proceeds. We reformulate Adaptive Computation Time (ACT) for this task, extending halting to discard redundant spatial tokens. The appealing architectural properties of vision transformers enables our adaptive token reduction mechanism to speed up inference without modifying the network architecture or inference hardware. We demonstrate that A-ViT requires no extra parameters or sub-network for halting, as we base the learning of adaptive halting on the original network parameters. We further introduce distributional prior regularization that stabilizes training compared to prior ACT approaches. On the image classification task (ImageNet1K), we show that our proposed A-ViT yields high efficacy in filtering informative spatial features and cutting down on the overall compute. The proposed method improves the throughput of DeiT-Tiny by 62% and DeiT-Small by 38% with only 0.3% accuracy drop, outperforming prior art by a large margin.
count=1
* Localized Adversarial Domain Generalization
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Localized_Adversarial_Domain_Generalization_CVPR_2022_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Localized_Adversarial_Domain_Generalization_CVPR_2022_paper.pdf)]
    * Title: Localized Adversarial Domain Generalization
    * Year: `2022`
    * Authors: Wei Zhu, Le Lu, Jing Xiao, Mei Han, Jiebo Luo, Adam P. Harrison
    * Abstract: Deep learning methods can struggle to handle domain shifts not seen in training data, which can cause them to not generalize well to unseen domains. This has led to research attention on domain generalization (DG), which aims to the model's generalization ability to out-of-distribution. Adversarial domain generalization is a popular approach to DG, but conventional approaches (1) struggle to sufficiently align features so that local neighborhoods are mixed across domains; and (2) can suffer from feature space over collapse which can threaten generalization performance. To address these limitations, we propose localized adversarial domain generalization with space compactness maintenance (LADG) which constitutes two major contributions. First, we propose an adversarial localized classifier as the domain discriminator, along with a principled primary branch. This constructs a min-max game whereby the aim of the featurizer is to produce locally mixed domains. Second, we propose to use a coding-rate loss to alleviate feature space over collapse. We conduct comprehensive experiments on the Wilds DG benchmark to validate our approach, where LADG outperforms leading competitors on most datasets.
count=1
* Cloud2Curve: Generation and Vectorization of Parametric Sketches
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Das_Cloud2Curve_Generation_and_Vectorization_of_Parametric_Sketches_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Das_Cloud2Curve_Generation_and_Vectorization_of_Parametric_Sketches_CVPR_2021_paper.pdf)]
    * Title: Cloud2Curve: Generation and Vectorization of Parametric Sketches
    * Year: `2021`
    * Authors: Ayan Das, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song
    * Abstract: Analysis of human sketches in deep learning has advanced immensely through the use of waypoint-sequences rather than raster-graphic representations. We further aim to model sketches as a sequence of low-dimensional parametric curves. To this end, we propose an inverse graphics framework capable of approximating a raster or waypoint based stroke encoded as a point-cloud with a variable-degree Bezier curve. Building on this module, we present Cloud2Curve, a generative model for scalable high-resolution vector sketches that can be trained end-to-end using point-cloud data alone. As a consequence, our model is also capable of deterministic vectorization which can map novel raster or waypoint based sketches to their corresponding high-resolution scalable Bezier equivalent. We evaluate the generation and vectorization capabilities of our model on Quick, Draw! and K-MNIST datasets.
count=1
* Mitigating Face Recognition Bias via Group Adaptive Classifier
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Gong_Mitigating_Face_Recognition_Bias_via_Group_Adaptive_Classifier_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Gong_Mitigating_Face_Recognition_Bias_via_Group_Adaptive_Classifier_CVPR_2021_paper.pdf)]
    * Title: Mitigating Face Recognition Bias via Group Adaptive Classifier
    * Year: `2021`
    * Authors: Sixue Gong, Xiaoming Liu, Anil K. Jain
    * Abstract: Face recognition is known to exhibit bias -- subjects in a certain demographic group can be better recognized than other groups. This work aims to learn a fair face representation, where faces of every group could be more equally represented. Our proposed group adaptive classifier mitigates bias by using adaptive convolution kernels and attention mechanisms on faces based on their demographic attributes. The adaptive module comprises kernel masks and channel-wise attention maps for each demographic group so as to activate different facial regions for identification, leading to more discriminative features pertinent to their demographics. Our introduced automated adaptation strategy determines whether to apply adaptation to a certain layer by iteratively computing the dissimilarity among demographic-adaptive parameters. A new de-biasing loss function is proposed to mitigate the gap of average intra-class distance between demographic groups. Experiments on face benchmarks (RFW, LFW, IJB-A, and IJB-C) show that our work is able to mitigate face recognition bias across demographic groups while maintaining the competitive accuracy.
count=1
* Bidirectional Projection Network for Cross Dimension Scene Understanding
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Bidirectional_Projection_Network_for_Cross_Dimension_Scene_Understanding_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Bidirectional_Projection_Network_for_Cross_Dimension_Scene_Understanding_CVPR_2021_paper.pdf)]
    * Title: Bidirectional Projection Network for Cross Dimension Scene Understanding
    * Year: `2021`
    * Authors: Wenbo Hu, Hengshuang Zhao, Li Jiang, Jiaya Jia, Tien-Tsin Wong
    * Abstract: 2D image representations are in regular grids and can be processed efficiently, whereas 3D point clouds are unordered and scattered in 3D space. The information inside these two visual domains is well complementary, e.g., 2D images have fine-grained texture while 3D point clouds contain plentiful geometry information. However, most current visual recognition systems process them individually. In this paper, we present a bidirectional projection network (BPNet) for joint 2D and 3D reasoning in an end-to-end manner. It contains 2D and 3D sub-networks with symmetric architectures, that are connected by our proposed bidirectional projection module (BPM). Via the BPM, complementary 2D and 3D information can interact with each other in multiple architectural levels, such that advantages in these two visual domains can be combined for better scene recognition. Extensive quantitative and qualitative experimental evaluations show that joint reasoning over 2D and 3D visual domains can benefit both 2D and 3D scene understanding simultaneously. Our BPNet achieves top performance on the ScanNetV2 benchmark for both 2D and 3D semantic segmentation. Code is available at https://github.com/wbhu/BPNet.
count=1
* Scalability vs. Utility: Do We Have To Sacrifice One for the Other in Data Importance Quantification?
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Jia_Scalability_vs._Utility_Do_We_Have_To_Sacrifice_One_for_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Jia_Scalability_vs._Utility_Do_We_Have_To_Sacrifice_One_for_CVPR_2021_paper.pdf)]
    * Title: Scalability vs. Utility: Do We Have To Sacrifice One for the Other in Data Importance Quantification?
    * Year: `2021`
    * Authors: Ruoxi Jia, Fan Wu, Xuehui Sun, Jiacen Xu, David Dao, Bhavya Kailkhura, Ce Zhang, Bo Li, Dawn Song
    * Abstract: Quantifying the importance of each training point to a learning task is a fundamental problem in machine learning and the estimated importance scores have been leveraged to guide a range of data workflows such as data summarization and domain adaption. One simple idea is to use the leave-one-out error of each training point to indicate its importance. Recent work has also proposed to use the Shapley value, as it defines a unique value distribution scheme that satisfies a set of appealing properties. However, calculating Shapley values is often expensive, which limits its applicability in real-world applications at scale. Multiple heuristics to improve the scalability of calculating Shapley values have been proposed recently, with the potential risk of compromising their utility in real-world applications. How well do existing data quantification methods perform on existing workflows? How do these methods compare with each other, empirically and theoretically? Must we sacrifice scalability for the utility in these workflows when using these methods? In this paper, we conduct a novel theoretical analysis comparing the utility of different importance quantification methods, and report extensive experimental studies on settings such as noisy label detection, watermark removal, data summarization, data acquisition, and domain adaptation on existing and proposed workflows. We show that Shapley value approximation based on a KNN surrogate over pre-trained feature embeddings obtains comparable utility with existing algorithms while achieving significant scalability improvement, often by orders of magnitude. Our theoretical analysis also justifies its advantage over the leave-one-out error. The code is available at https://github.com/AI-secure/Shapley-Study.
count=1
* Model-Contrastive Federated Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Li_Model-Contrastive_Federated_Learning_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Model-Contrastive_Federated_Learning_CVPR_2021_paper.pdf)]
    * Title: Model-Contrastive Federated Learning
    * Year: `2021`
    * Authors: Qinbin Li, Bingsheng He, Dawn Song
    * Abstract: Federated learning enables multiple parties to collaboratively train a machine learning model without communicating their local data. A key challenge in federated learning is to handle the heterogeneity of local data distribution across parties. Although many studies have been proposed to address this challenge, we find that they fail to achieve high performance in image datasets with deep learning models. In this paper, we propose MOON: model-contrastive federated learning. MOON is a simple and effective federated learning framework. The key idea of MOON is to utilize the similarity between model representations to correct the local training of individual parties, i.e., conducting contrastive learning in model-level. Our extensive experiments show that MOON significantly outperforms the other state-of-the-art federated learning algorithms on various image classification tasks.
count=1
* Verifiability and Predictability: Interpreting Utilities of Network Architectures for Point Cloud Processing
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Verifiability_and_Predictability_Interpreting_Utilities_of_Network_Architectures_for_Point_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Verifiability_and_Predictability_Interpreting_Utilities_of_Network_Architectures_for_Point_CVPR_2021_paper.pdf)]
    * Title: Verifiability and Predictability: Interpreting Utilities of Network Architectures for Point Cloud Processing
    * Year: `2021`
    * Authors: Wen Shen, Zhihua Wei, Shikun Huang, Binbin Zhang, Panyue Chen, Ping Zhao, Quanshi Zhang
    * Abstract: In this paper, we diagnose deep neural networks for 3D point cloud processing to explore utilities of different network architectures. We propose a number of hypotheses on the effects of specific network architectures on the representation capacity of DNNs. In order to prove the hypotheses, we design five metrics to diagnose various types of DNNs from the following perspectives, information discarding, information concentration, rotation robustness, adversarial robustness, and neighborhood inconsistency. We conduct comparative studies based on such metrics to verify the hypotheses. We further use the verified hypotheses to revise architectures of existing DNNs and improve their utilities. Experiments demonstrate the effectiveness of our method. The code will be released when this paper is accepted.
count=1
* Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting With Their Explanations
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Stammer_Right_for_the_Right_Concept_Revising_Neuro-Symbolic_Concepts_by_Interacting_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Stammer_Right_for_the_Right_Concept_Revising_Neuro-Symbolic_Concepts_by_Interacting_CVPR_2021_paper.pdf)]
    * Title: Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting With Their Explanations
    * Year: `2021`
    * Authors: Wolfgang Stammer, Patrick Schramowski, Kristian Kersting
    * Abstract: Most explanation methods in deep learning map importance estimates for a model's prediction back to the original input space. These "visual" explanations are often insufficient, as the model's actual concept remains elusive. Moreover, without insights into the model's semantic concept, it is difficult --if not impossible-- to intervene on the model's behavior via its explanations, called Explanatory Interactive Learning. Consequently, we propose to intervene on a Neuro-Symbolic scene representation, which allows one to revise the model on the semantic level, e.g. "never focus on the color to make your decision". We compiled a novel con-founded visual scene data set, the CLEVR-Hans data set,capturing complex compositions of different objects. The results of our experiments on CLEVR-Hans demonstrate that our semantic explanations, i.e. compositional explanations at a per-object level, can identify confounders that are not identifiable using "visual" explanations only. More importantly, feedback on this semantic level makes it possible to revise the model from focusing on these factors.
count=1
* HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Tankovich_HITNet_Hierarchical_Iterative_Tile_Refinement_Network_for_Real-time_Stereo_Matching_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Tankovich_HITNet_Hierarchical_Iterative_Tile_Refinement_Network_for_Real-time_Stereo_Matching_CVPR_2021_paper.pdf)]
    * Title: HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching
    * Year: `2021`
    * Authors: Vladimir Tankovich, Christian Hane, Yinda Zhang, Adarsh Kowdle, Sean Fanello, Sofien Bouaziz
    * Abstract: This paper presents HITNet, a novel neural network architecture for real-time stereo matching. Contrary to many recent neural network approaches that operate on a full costvolume and rely on 3D convolutions, our approach does not explicitly build a volume and instead relies on a fast multi-resolution initialization step, differentiable 2D geometric propagation and warping mechanisms to infer disparity hypotheses. To achieve a high level of accuracy, our network not only geometrically reasons about disparities but also infers slanted plane hypotheses allowing to more accurately perform geometric warping and upsampling operations. Our architecture is inherently multi-resolution allowing the propagation of information across different levels. Multiple experiments prove the effectiveness of the proposed approach at a fraction of the computation required by the state-of-the-art methods. At the time of writing, HITNet ranks 1st-3rd on all the metrics published on the ETH3D website for two view stereo, ranks 1st on most of the metrics amongst all the end-to-end learning approaches on Middleburyv3, ranks 1st on the popular KITTI 2012 and 2015 benchmarks among the published methods faster than 100ms.
count=1
* Post-Hoc Uncertainty Calibration for Domain Drift Scenarios
    [[abs-CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Tomani_Post-Hoc_Uncertainty_Calibration_for_Domain_Drift_Scenarios_CVPR_2021_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Tomani_Post-Hoc_Uncertainty_Calibration_for_Domain_Drift_Scenarios_CVPR_2021_paper.pdf)]
    * Title: Post-Hoc Uncertainty Calibration for Domain Drift Scenarios
    * Year: `2021`
    * Authors: Christian Tomani, Sebastian Gruber, Muhammed Ebrar Erdem, Daniel Cremers, Florian Buettner
    * Abstract: We address the problem of uncertainty calibration. While standard deep neural networks typically yield uncalibrated predictions, calibrated confidence scores that are representative of the true likelihood of a prediction can be achieved using post-hoc calibration methods. However, to date, the focus of these approaches has been on in-domain calibration. Our contribution is two-fold. First, we show that existing post-hoc calibration methods yield highly over-confident predictions under domain shift. Second, we introduce a simple strategy where perturbations are applied to samples in the validation set before performing the post-hoc calibration step. In extensive experiments, we demonstrate that this perturbation step results in substantially better calibration under domain shift on a wide range of architectures and modelling tasks.
count=1
* Disentangled Image Generation Through Structured Noise Injection
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Alharbi_Disentangled_Image_Generation_Through_Structured_Noise_Injection_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Alharbi_Disentangled_Image_Generation_Through_Structured_Noise_Injection_CVPR_2020_paper.pdf)]
    * Title: Disentangled Image Generation Through Structured Noise Injection
    * Year: `2020`
    * Authors: Yazeed Alharbi,  Peter Wonka
    * Abstract: We explore different design choices for injecting noise into generative adversarial networks (GANs) with the goal of disentangling the latent space. Instead of traditional approaches, we propose feeding multiple noise codes through separate fully-connected layers respectively. The aim is restricting the influence of each noise code to specific parts of the generated image. We show that disentanglement in the first layer of the generator network leads to disentanglement in the generated image. Through a grid-based structure, we achieve several aspects of disentanglement without complicating the network architecture and without requiring labels. We achieve spatial disentanglement, scale-space disentanglement, and disentanglement of the foreground object from the background style allowing fine-grained control over the generated images. Examples include changing facial expressions in face images, changing beak length in bird images, and changing car dimensions in car images. This empirically leads to better disentanglement scores than state-of-the-art methods on the FFHQ dataset.
count=1
* Interpretable and Accurate Fine-grained Recognition via Region Grouping
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Huang_Interpretable_and_Accurate_Fine-grained_Recognition_via_Region_Grouping_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Interpretable_and_Accurate_Fine-grained_Recognition_via_Region_Grouping_CVPR_2020_paper.pdf)]
    * Title: Interpretable and Accurate Fine-grained Recognition via Region Grouping
    * Year: `2020`
    * Authors: Zixuan Huang,  Yin Li
    * Abstract: We present an interpretable deep model for fine-grained visual recognition. At the core of our method lies the integration of region-based part discovery and attribution within a deep neural network. Our model is trained using image-level object labels, and provides an interpretation of its results via the segmentation of object parts and the identification of their contributions towards classification. To facilitate the learning of object parts without direct supervision, we explore a simple prior of the occurrence of object parts. We demonstrate that this prior, when combined with our region-based part discovery and attribution, leads to an interpretable model that remains highly accurate. Our model is evaluated on major fine-grained recognition datasets, including CUB-200, CelebA and iNaturalist. Our results compares favourably to state-of-the-art methods on classification tasks, and outperforms previous approaches on the localization of object parts.
count=1
* Probability Weighted Compact Feature for Domain Adaptive Retrieval
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Huang_Probability_Weighted_Compact_Feature_for_Domain_Adaptive_Retrieval_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Probability_Weighted_Compact_Feature_for_Domain_Adaptive_Retrieval_CVPR_2020_paper.pdf)]
    * Title: Probability Weighted Compact Feature for Domain Adaptive Retrieval
    * Year: `2020`
    * Authors: Fuxiang Huang,  Lei Zhang,  Yang Yang,  Xichuan Zhou
    * Abstract: Domain adaptive image retrieval includes single-domain retrieval and cross-domain retrieval. Most of the existing image retrieval methods only focus on single-domain retrieval, which assumes that the distributions of retrieval databases and queries are similar. However, in practical application, the discrepancies between retrieval databases often taken in ideal illumination/pose/background/camera conditions and queries usually obtained in uncontrolled conditions are very large. In this paper, considering the practical application, we focus on challenging cross-domain retrieval. To address the problem, we propose an effective method named Probability Weighted Compact Feature Learning (PWCF), which provides inter-domain correlation guidance to promote cross-domain retrieval accuracy and learns a series of compact binary codes to improve the retrieval speed. First, we derive our loss function through the Maximum A Posteriori Estimation (MAP): Bayesian Perspective (BP) induced focal-triplet loss, BP induced quantization loss and BP induced classification loss. Second, we propose a common manifold structure between domains to explore the potential correlation across domains. Considering the original feature representation is biased due to the inter-domain discrepancy, the manifold structure is difficult to be constructed. Therefore, we propose a new feature named Histogram Feature of Neighbors (HFON) from the sample statistics perspective. Extensive experiments on various benchmark databases validate that our method outperforms many state-of-the-art image retrieval methods for domain adaptive image retrieval. The source code is available at https://github.com/fuxianghuang1/PWCF .
count=1
* Learning Augmentation Network via Influence Functions
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Lee_Learning_Augmentation_Network_via_Influence_Functions_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Lee_Learning_Augmentation_Network_via_Influence_Functions_CVPR_2020_paper.pdf)]
    * Title: Learning Augmentation Network via Influence Functions
    * Year: `2020`
    * Authors: Donghoon Lee,  Hyunsin Park,  Trung Pham,  Chang D. Yoo
    * Abstract: Data augmentation can impact the generalization performance of an image classification model in a significant way. However, it is currently conducted on the basis of trial and error, and its impact on the generalization performance cannot be predicted during training. This paper considers an influence function that predicts how generalization performance, in terms of validation loss, is affected by a particular augmented training sample. The influence function provides an approximation of the change in validation loss without actually comparing the performances that include and exclude the sample in the training process. Based on this function, a differentiable augmentation network is learned to augment an input training sample to reduce validation loss. The augmented sample is fed into the classification network, and its influence is approximated as a function of the parameters of the last fully-connected layer of the classification network. By backpropagating the influence to the augmentation network, the augmentation network parameters are learned. Experimental results on CIFAR-10, CIFAR-100, and ImageNet show that the proposed method provides better generalization performance than conventional data augmentation methods do.
count=1
* Learning to Optimize Non-Rigid Tracking
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Learning_to_Optimize_Non-Rigid_Tracking_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Learning_to_Optimize_Non-Rigid_Tracking_CVPR_2020_paper.pdf)]
    * Title: Learning to Optimize Non-Rigid Tracking
    * Year: `2020`
    * Authors: Yang Li,  Aljaz Bozic,  Tianwei Zhang,  Yanli Ji,  Tatsuya Harada,  Matthias Niessner
    * Abstract: One of the widespread solutions for non-rigid tracking has a nested-loop structure: with Gauss-Newton to minimize a tracking objective in the outer loop, and Preconditioned Conjugate Gradient (PCG) to solve a sparse linear system in the inner loop. In this paper, we employ learnable optimizations to improve tracking robustness and speed up solver convergence. First, we upgrade the tracking objective by integrating an alignment data term on deep features which are learned end-to-end through CNN. The new tracking objective can capture the global deformation which helps Gauss-Newton to jump over local minimum, leading to robust tracking on large non-rigid motions. Second, we bridge the gap between the preconditioning technique and learning method by introducing a ConditionNet which is trained to generate a preconditioner such that PCG can converge within a small number of steps. Experimental results indicate that the proposed learning method converges faster than the original PCG by a large margin.
count=1
* Learning Better Lossless Compression Using Lossy Compression
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Mentzer_Learning_Better_Lossless_Compression_Using_Lossy_Compression_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Mentzer_Learning_Better_Lossless_Compression_Using_Lossy_Compression_CVPR_2020_paper.pdf)]
    * Title: Learning Better Lossless Compression Using Lossy Compression
    * Year: `2020`
    * Authors: Fabian Mentzer,  Luc Van Gool,  Michael Tschannen
    * Abstract: We leverage the powerful lossy image compression algorithm BPG to build a lossless image compression system. Specifically, the original image is first decomposed into the lossy reconstruction obtained after compressing it with BPG and the corresponding residual. We then model the distribution of the residual with a convolutional neural network-based probabilistic model that is conditioned on the BPG reconstruction, and combine it with entropy coding to losslessly encode the residual. Finally, the image is stored using the concatenation of the bitstreams produced by BPG and the learned residual coder. The resulting compression system achieves state-of-the-art performance in learned lossless full-resolution image compression, outperforming previous learned approaches as well as PNG, WebP, and JPEG2000.
count=1
* Exploring Data Aggregation in Policy Learning for Vision-Based Urban Autonomous Driving
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Prakash_Exploring_Data_Aggregation_in_Policy_Learning_for_Vision-Based_Urban_Autonomous_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Prakash_Exploring_Data_Aggregation_in_Policy_Learning_for_Vision-Based_Urban_Autonomous_CVPR_2020_paper.pdf)]
    * Title: Exploring Data Aggregation in Policy Learning for Vision-Based Urban Autonomous Driving
    * Year: `2020`
    * Authors: Aditya Prakash,  Aseem Behl,  Eshed Ohn-Bar,  Kashyap Chitta,  Andreas Geiger
    * Abstract: Data aggregation techniques can significantly improve vision-based policy learning within a training environment, e.g., learning to drive in a specific simulation condition. However, as on-policy data is sequentially sampled and added in an iterative manner, the policy can specialize and overfit to the training conditions. For real-world applications, it is useful for the learned policy to generalize to novel scenarios that differ from the training conditions. To improve policy learning while maintaining robustness when training end-to-end driving policies, we perform an extensive analysis of data aggregation techniques in the CARLA environment. We demonstrate how the majority of them have poor generalization performance, and develop a novel approach with empirically better generalization performance compared to existing techniques. Our two key ideas are (1) to sample critical states from the collected on-policy data based on the utility they provide to the learned policy in terms of driving behavior, and (2) to incorporate a replay buffer which progressively focuses on the high uncertainty regions of the policy's state distribution. We evaluate the proposed approach on the CARLA NoCrash benchmark, focusing on the most challenging driving scenarios with dense pedestrian and vehicle traffic. Our approach improves driving success rate by 16% over state-of-the-art, achieving 87% of the expert performance while also reducing the collision rate by an order of magnitude without the use of any additional modality, auxiliary tasks, architectural modifications or reward from the environment.
count=1
* There and Back Again: Revisiting Backpropagation Saliency Methods
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Rebuffi_There_and_Back_Again_Revisiting_Backpropagation_Saliency_Methods_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Rebuffi_There_and_Back_Again_Revisiting_Backpropagation_Saliency_Methods_CVPR_2020_paper.pdf)]
    * Title: There and Back Again: Revisiting Backpropagation Saliency Methods
    * Year: `2020`
    * Authors: Sylvestre-Alvise Rebuffi,  Ruth Fong,  Xu Ji,  Andrea Vedaldi
    * Abstract: Saliency methods seek to explain the predictions of a model by producing an importance map across each input sample. A popular class of such methods is based on backpropagating a signal and analyzing the resulting gradient. Despite much research on such methods, relatively little work has been done to clarify the differences between such methods as well as the desiderata of these techniques. Thus, there is a need for rigorously understanding the relationships between different methods as well as their failure modes. In this work, we conduct a thorough analysis of backpropagation-based saliency methods and propose a single framework under which several such methods can be unified. As a result of our study, we make three additional contributions. First, we use our framework to propose NormGrad, a novel saliency method based on the spatial contribution of gradients of convolutional weights. Second, we combine saliency maps at different layers to test the ability of saliency methods to extract complementary information at different network levels (e.g. trading off spatial resolution and distinctiveness) and we explain why some methods fail at specific layers (e.g., Grad-CAM anywhere besides the last convolutional layer). Third, we introduce a class-sensitivity metric and a meta-learning inspired paradigm applicable to any saliency method for improving sensitivity to the output class being explained.
count=1
* DeFeat-Net: General Monocular Depth via Simultaneous Unsupervised Representation Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Spencer_DeFeat-Net_General_Monocular_Depth_via_Simultaneous_Unsupervised_Representation_Learning_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Spencer_DeFeat-Net_General_Monocular_Depth_via_Simultaneous_Unsupervised_Representation_Learning_CVPR_2020_paper.pdf)]
    * Title: DeFeat-Net: General Monocular Depth via Simultaneous Unsupervised Representation Learning
    * Year: `2020`
    * Authors: Jaime Spencer,  Richard Bowden,  Simon Hadfield
    * Abstract: In the current monocular depth research, the dominant approach is to employ unsupervised training on large datasets, driven by warped photometric consistency. Such approaches lack robustness and are unable to generalize to challenging domains such as nighttime scenes or adverse weather conditions where assumptions about photometric consistency break down. We propose DeFeat-Net (Depth & Feature network), an approach to simultaneously learn a cross-domain dense feature representation, alongside a robust depth-estimation framework based on warped feature consistency. The resulting feature representation is learned in an unsupervised manner with no explicit ground-truth correspondences required. We show that within a single domain, our technique is comparable to both the current state of the art in monocular depth estimation and supervised feature representation learning. However, by simultaneously learning features, depth and motion, our technique is able to generalize to challenging domains, allowing DeFeat-Net to outperform the current state-of-the-art with around 10% reduction in all error measures on more challenging sequences such as nighttime driving.
count=1
* Active Vision for Early Recognition of Human Actions
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_Active_Vision_for_Early_Recognition_of_Human_Actions_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Active_Vision_for_Early_Recognition_of_Human_Actions_CVPR_2020_paper.pdf)]
    * Title: Active Vision for Early Recognition of Human Actions
    * Year: `2020`
    * Authors: Boyu Wang,  Lihan Huang,  Minh Hoai
    * Abstract: We propose a method for early recognition of human actions, one that can take advantages of multiple cameras while satisfying the constraints due to limited communication bandwidth and processing power. Our method considers multiple cameras, and at each time step, it will decide the best camera to use so that a confident recognition decision can be reached as soon as possible. We formulate the camera selection problem as a sequential decision process, and learn a view selection policy based on reinforcement learning. We also develop a novel recurrent neural network architecture to account for the unobserved video frames and the irregular intervals between the observed frames. Experiments on three datasets demonstrate the effectiveness of our approach for early recognition of human actions.
count=1
* Instance Shadow Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_Instance_Shadow_Detection_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Instance_Shadow_Detection_CVPR_2020_paper.pdf)]
    * Title: Instance Shadow Detection
    * Year: `2020`
    * Authors: Tianyu Wang,  Xiaowei Hu,  Qiong Wang,  Pheng-Ann Heng,  Chi-Wing Fu
    * Abstract: Instance shadow detection is a brand new problem, aiming to find shadow instances paired with object instances. To approach it, we first prepare a new dataset called SOBA, named after Shadow-OBject Association, with 3,623 pairs of shadow and object instances in 1,000 photos, each with individual labeled masks. Second, we design LISA, named after Light-guided Instance Shadow-object Association, an end-to-end framework to automatically predict the shadow and object instances, together with the shadow-object associations and light direction. Then, we pair up the predicted shadow and object instances, and match them with the predicted shadow-object associations to generate the final results. In our evaluations, we formulate a new metric named the shadow-object average precision to measure the performance of our results. Further, we conducted various experiments and demonstrate our method's applicability on light direction estimation and photo editing.
count=1
* Towards Global Explanations of Convolutional Neural Networks With Concept Attribution
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Wu_Towards_Global_Explanations_of_Convolutional_Neural_Networks_With_Concept_Attribution_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_Towards_Global_Explanations_of_Convolutional_Neural_Networks_With_Concept_Attribution_CVPR_2020_paper.pdf)]
    * Title: Towards Global Explanations of Convolutional Neural Networks With Concept Attribution
    * Year: `2020`
    * Authors: Weibin Wu,  Yuxin Su,  Xixian Chen,  Shenglin Zhao,  Irwin King,  Michael R. Lyu,  Yu-Wing Tai
    * Abstract: With the growing prevalence of convolutional neural networks (CNNs), there is an urgent demand to explain their behaviors. Global explanations contribute to understanding model predictions on a whole category of samples, and thus have attracted increasing interest recently. However, existing methods overwhelmingly conduct separate input attribution or rely on local approximations of models, making them fail to offer faithful global explanations of CNNs. To overcome such drawbacks, we propose a novel two-stage framework, Attacking for Interpretability (AfI), which explains model decisions in terms of the importance of user-defined concepts. AfI first conducts a feature occlusion analysis, which resembles a process of attacking models to derive the category-wide importance of different features. We then map the feature importance to concept importance through ad-hoc semantic tasks. Experimental results confirm the effectiveness of AfI and its superiority in providing more accurate estimations of concept importance than existing proposals.
count=1
* Multi-Domain Learning for Accurate and Few-Shot Color Constancy
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Xiao_Multi-Domain_Learning_for_Accurate_and_Few-Shot_Color_Constancy_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Xiao_Multi-Domain_Learning_for_Accurate_and_Few-Shot_Color_Constancy_CVPR_2020_paper.pdf)]
    * Title: Multi-Domain Learning for Accurate and Few-Shot Color Constancy
    * Year: `2020`
    * Authors: Jin Xiao,  Shuhang Gu,  Lei Zhang
    * Abstract: Color constancy is an important process in camera pipeline to remove the color bias of captured image caused by scene illumination. Recently, significant improvements in color constancy accuracy have been achieved by using deep neural networks (DNNs). However, existing DNNbased color constancy methods learn distinct mappings for different cameras, which require a costly data acquisition process for each camera device. In this paper, we start a pioneer work to introduce multi-domain learning to color constancy area. For different camera devices, we train a branch of networks which share the same feature extractor and illuminant estimator, and only employ a camera-specific channel re-weighting module to adapt to the camera-specific characteristics. Such a multi-domain learning strategy enables us to take benefit from crossdevice training data. The proposed multi-domain learning color constancy method achieved state-of-the-art performance on three commonly used benchmark datasets. Furthermore, we also validate the proposed method in a fewshot color constancy setting. Given a new unseen device with limited number of training samples, our method is capable of delivering accurate color constancy by merely learning the camera-specific parameters from the few-shot dataset. Our project page is publicly available at https://github.com/msxiaojin/MDLCC.
count=1
* The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural Networks
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_The_Secret_Revealer_Generative_Model-Inversion_Attacks_Against_Deep_Neural_Networks_CVPR_2020_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_The_Secret_Revealer_Generative_Model-Inversion_Attacks_Against_Deep_Neural_Networks_CVPR_2020_paper.pdf)]
    * Title: The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural Networks
    * Year: `2020`
    * Authors: Yuheng Zhang,  Ruoxi Jia,  Hengzhi Pei,  Wenxiao Wang,  Bo Li,  Dawn Song
    * Abstract: This paper studies model-inversion attacks, in which the access to a model is abused to infer information about the training data. Since its first introduction by [??], such attacks have raised serious concerns given that training data usually contain privacy sensitive information. Thus far, successful model-inversion attacks have only been demonstrated on simple models, such as linear regression and logistic regression. Previous attempts to invert neural networks, even the ones with simple architectures, have failed to produce convincing results. Here we present a novel attack method, termed the generative model-inversion attack, which can invert deep neural networks with high success rates. Rather than reconstructing private training data from scratch, we leverage partial public information, which can be very generic, to learn a distributional prior via generative adversarial networks (GANs) and use it to guide the inversion process. Moreover, we theoretically prove that a model's predictive power and its vulnerability to inversion attacks are indeed two sides of the same coin---highly predictive models are able to establish a strong correlation between features and labels, which coincides exactly with what an adversary exploits to mount the attacks. Our extensive experiments demonstrate that the proposed attack improves identification accuracy over the existing work by about 75% for reconstructing face images from a state-of-the-art face recognition classifier. We also show that differential privacy, in its canonical form, is of little avail to defend against our attacks.
count=1
* End-To-End Learned Random Walker for Seeded Image Segmentation
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Cerrone_End-To-End_Learned_Random_Walker_for_Seeded_Image_Segmentation_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Cerrone_End-To-End_Learned_Random_Walker_for_Seeded_Image_Segmentation_CVPR_2019_paper.pdf)]
    * Title: End-To-End Learned Random Walker for Seeded Image Segmentation
    * Year: `2019`
    * Authors: Lorenzo Cerrone,  Alexander Zeilmann,  Fred A. Hamprecht
    * Abstract: We present an end-to-end learned algorithm for seeded segmentation. Our method is based on the Random Walker algorithm, where we predict the edge weights of the un- derlying graph using a convolutional neural network. This can be interpreted as learning context-dependent diffusiv- ities for a linear diffusion process. After calculating the exact gradient for optimizing these diffusivities, we pro- pose simplifications that sparsely sample the gradient while still maintaining competitive results. The proposed method achieves the currently best results on the seeded CREMI neuron segmentation challenge.
count=1
* Joint Face Detection and Facial Motion Retargeting for Multiple Faces
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Chaudhuri_Joint_Face_Detection_and_Facial_Motion_Retargeting_for_Multiple_Faces_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Chaudhuri_Joint_Face_Detection_and_Facial_Motion_Retargeting_for_Multiple_Faces_CVPR_2019_paper.pdf)]
    * Title: Joint Face Detection and Facial Motion Retargeting for Multiple Faces
    * Year: `2019`
    * Authors: Bindita Chaudhuri,  Noranart Vesdapunt,  Baoyuan Wang
    * Abstract: Facial motion retargeting is an important problem in both computer graphics and vision, which involves capturing the performance of a human face and transferring it to another 3D character. Learning 3D morphable model (3DMM) parameters from 2D face images using convolutional neural networks is common in 2D face alignment, 3D face reconstruction etc. However, existing methods either require an additional face detection step before retargeting or use a cascade of separate networks to perform detection followed by retargeting in a sequence. In this paper, we present a single end-to-end network to jointly predict the bounding box locations and 3DMM parameters for multiple faces. First, we design a novel multitask learning framework that learns a disentangled representation of 3DMM parameters for a single face. Then, we leverage the trained single face model to generate ground truth 3DMM parameters for multiple faces to train another network that performs joint face detection and motion retargeting for images with multiple faces. Experimental results show that our joint detection and retargeting network has high face detection accuracy and is robust to extreme expressions and poses while being faster than state-of-the-art methods.
count=1
* Deep Sketch-Shape Hashing With Segmented 3D Stochastic Viewing
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Deep_Sketch-Shape_Hashing_With_Segmented_3D_Stochastic_Viewing_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Deep_Sketch-Shape_Hashing_With_Segmented_3D_Stochastic_Viewing_CVPR_2019_paper.pdf)]
    * Title: Deep Sketch-Shape Hashing With Segmented 3D Stochastic Viewing
    * Year: `2019`
    * Authors: Jiaxin Chen,  Jie Qin,  Li Liu,  Fan Zhu,  Fumin Shen,  Jin Xie,  Ling Shao
    * Abstract: Sketch-based 3D shape retrieval has been extensively studied in recent works, most of which focus on improving the retrieval accuracy, whilst neglecting the efficiency. In this paper, we propose a novel framework for efficient sketch-based 3D shape retrieval, i.e., Deep Sketch-Shape Hashing (DSSH), which tackles the challenging problem from two perspectives. Firstly, we propose an intuitive 3D shape representation method to deal with unaligned shapes with arbitrary poses. Specifically, the proposed Segmented Stochastic-viewing Shape Network models discriminative 3D representations by a set of 2D images rendered from multiple views, which are stochastically selected from non-overlapping spatial segments of a 3D sphere. Secondly, Batch-Hard Binary Coding (BHBC) is developed to learn semantics-preserving compact binary codes by mining the hardest samples. The overall framework is jointly learned by developing an alternating iteration algorithm. Extensive experimental results on three benchmarks show that DSSH improves both the retrieval efficiency and accuracy remarkably, compared to the state-of-the-art methods.
count=1
* Embedding Complementary Deep Networks for Image Classification
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Embedding_Complementary_Deep_Networks_for_Image_Classification_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Embedding_Complementary_Deep_Networks_for_Image_Classification_CVPR_2019_paper.pdf)]
    * Title: Embedding Complementary Deep Networks for Image Classification
    * Year: `2019`
    * Authors: Qiuyu Chen,  Wei Zhang,  Jun Yu,  Jianping Fan
    * Abstract: In this paper, a deep embedding algorithm is developed to achieve higher accuracy rates on large-scale image classification. By adapting the importance of the object classes to their error rates, our deep embedding algorithm can train multiple complementary deep networks sequentially, where each of them focuses on achieving higher accuracy rates for different subsets of object classes in an easy-to-hard way. By integrating such complementary deep networks to generate an ensemble network, our deep embedding algorithm can improve the accuracy rates for the hard object classes (which initially have higher error rates) at certain degrees while effectively preserving high accuracy rates for the easy object classes. Our deep embedding algorithm has achieved higher overall accuracy rates on large scale image classification.
count=1
* Feature Space Perturbations Yield More Transferable Adversarial Examples
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.pdf)]
    * Title: Feature Space Perturbations Yield More Transferable Adversarial Examples
    * Year: `2019`
    * Authors: Nathan Inkawhich,  Wei Wen,  Hai (Helen) Li,  Yiran Chen
    * Abstract: Many recent works have shown that deep learning models are vulnerable to quasi-imperceptible input perturbations, yet practitioners cannot fully explain this behavior. This work describes a transfer-based blackbox targeted adversarial attack of deep feature space representations that also provides insights into cross-model class representations of deep CNNs. The attack is explicitly designed for transferability and drives feature space representation of a source image at layer L towards the representation of a target image at L. The attack yields highly transferable targeted examples, which outperform competition winning methods by over 30% in targeted attack metrics. We also show the choice of L to generate examples from is important, transferability characteristics are blackbox model agnostic, and indicate that well trained deep models have similar highly-abstract representations.
count=1
* Label-Noise Robust Generative Adversarial Networks
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Kaneko_Label-Noise_Robust_Generative_Adversarial_Networks_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Kaneko_Label-Noise_Robust_Generative_Adversarial_Networks_CVPR_2019_paper.pdf)]
    * Title: Label-Noise Robust Generative Adversarial Networks
    * Year: `2019`
    * Authors: Takuhiro Kaneko,  Yoshitaka Ushiku,  Tatsuya Harada
    * Abstract: Generative adversarial networks (GANs) are a framework that learns a generative distribution through adversarial training. Recently, their class conditional extensions (e.g., conditional GAN (cGAN) and auxiliary classifier GAN (AC-GAN)) have attracted much attention owing to their ability to learn the disentangled representations and to improve the training stability. However, their training requires the availability of large-scale accurate class-labeled data, which are often laborious or impractical to collect in a real-world scenario. To remedy this, we propose a novel family of GANs called label-noise robust GANs (rGANs), which, by incorporating a noise transition model, can learn a clean label conditional generative distribution even when training labels are noisy. In particular, we propose two variants: rAC-GAN, which is a bridging model between AC-GAN and the label-noise robust classification model, and rcGAN, which is an extension of cGAN and solves this problem with no reliance on any classifier. In addition to providing the theoretical background, we demonstrate the effectiveness of our models through extensive experiments using diverse GAN configurations, various noise settings, and multiple evaluation metrics (in which we tested 402 conditions in total).
count=1
* Practical Full Resolution Learned Lossless Image Compression
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Mentzer_Practical_Full_Resolution_Learned_Lossless_Image_Compression_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Mentzer_Practical_Full_Resolution_Learned_Lossless_Image_Compression_CVPR_2019_paper.pdf)]
    * Title: Practical Full Resolution Learned Lossless Image Compression
    * Year: `2019`
    * Authors: Fabian Mentzer,  Eirikur Agustsson,  Michael Tschannen,  Radu Timofte,  Luc Van Gool
    * Abstract: We propose the first practical learned lossless image compression system, L3C, and show that it outperforms the popular engineered codecs, PNG, WebP and JPEG 2000. At the core of our method is a fully parallelizable hierarchical probabilistic model for adaptive entropy coding which is optimized end-to-end for the compression task. In contrast to recent autoregressive discrete probabilistic models such as PixelCNN, our method i) models the image distribution jointly with learned auxiliary representations instead of exclusively modeling the image distribution in RGB space, and ii) only requires three forward-passes to predict all pixel probabilities instead of one for each pixel. As a result, L3C obtains over two orders of magnitude speedups when sampling compared to the fastest PixelCNN variant (Multiscale-PixelCNN). Furthermore, we find that learning the auxiliary representation is crucial and outperforms predefined auxiliary representations such as an RGB pyramid significantly.
count=1
* Learning for Single-Shot Confidence Calibration in Deep Neural Networks Through Stochastic Inferences
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Seo_Learning_for_Single-Shot_Confidence_Calibration_in_Deep_Neural_Networks_Through_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Seo_Learning_for_Single-Shot_Confidence_Calibration_in_Deep_Neural_Networks_Through_CVPR_2019_paper.pdf)]
    * Title: Learning for Single-Shot Confidence Calibration in Deep Neural Networks Through Stochastic Inferences
    * Year: `2019`
    * Authors: Seonguk Seo,  Paul Hongsuck Seo,  Bohyung Han
    * Abstract: We propose a generic framework to calibrate accuracy and confidence of a prediction in deep neural networks through stochastic inferences. We interpret stochastic regularization using a Bayesian model, and analyze the relation between predictive uncertainty of networks and variance of the prediction scores obtained by stochastic inferences for a single example. Our empirical study shows that the accuracy and the score of a prediction are highly correlated with the variance of multiple stochastic inferences given by stochastic depth or dropout. Motivated by this observation, we design a novel variance-weighted confidence-integrated loss function that is composed of two cross-entropy loss terms with respect to ground-truth and uniform distribution, which are balanced by variance of stochastic prediction scores. The proposed loss function enables us to learn deep neural networks that predict confidence calibrated scores using a single inference. Our algorithm presents outstanding confidence calibration performance and improves classification accuracy when combined with two popular stochastic regularization techniques---stochastic depth and dropout---in multiple models and datasets; it alleviates overconfidence issue in deep neural networks significantly by training networks to achieve prediction accuracy proportional to confidence of prediction.
count=1
* Versatile Multiple Choice Learning and Its Application to Vision Computing
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Tian_Versatile_Multiple_Choice_Learning_and_Its_Application_to_Vision_Computing_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Tian_Versatile_Multiple_Choice_Learning_and_Its_Application_to_Vision_Computing_CVPR_2019_paper.pdf)]
    * Title: Versatile Multiple Choice Learning and Its Application to Vision Computing
    * Year: `2019`
    * Authors: Kai Tian,  Yi Xu,  Shuigeng Zhou,  Jihong Guan
    * Abstract: Most existing ensemble methods aim to train the underlying embedded models independently and simply aggregate their final outputs via averaging or weighted voting. As many prediction tasks contain uncertainty, most of these ensemble methods just reduce variance of the predictions without considering the collaborations among the ensembles. Different from these ensemble methods, multiple choice learning (MCL) methods exploit the cooperation among all the embedded models to generate multiple diverse hypotheses. In this paper, a new MCL method, called vMCL (the abbreviation of versatile Multiple Choice Learning), is developed to extend the application scenarios of MCL methods by ensembling deep neural networks. Our vMCL method keeps the advantage of existing MCL methods while overcoming their major drawback, thus achieves better performance. The novelty of our vMCL lies in three aspects: (1) a choice network is designed to learn the confidence level of each specialist which can provide the best prediction base on multiple hypotheses; (2) a hinge loss is introduced to alleviate the overconfidence issue in MCL settings; (3) Easy to be implemented and can be trained in an end-to-end manner, which is a very attractive feature for many real-world applications. Experiments on image classification and image segmentation task show that vMCL outperforms the existing state-of-the-art MCL methods.
count=1
* RepNet: Weakly Supervised Training of an Adversarial Reprojection Network for 3D Human Pose Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Wandt_RepNet_Weakly_Supervised_Training_of_an_Adversarial_Reprojection_Network_for_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wandt_RepNet_Weakly_Supervised_Training_of_an_Adversarial_Reprojection_Network_for_CVPR_2019_paper.pdf)]
    * Title: RepNet: Weakly Supervised Training of an Adversarial Reprojection Network for 3D Human Pose Estimation
    * Year: `2019`
    * Authors: Bastian Wandt,  Bodo Rosenhahn
    * Abstract: This paper addresses the problem of 3D human pose estimation from single images. While for a long time human skeletons were parameterized and fitted to the observation by satisfying a reprojection error, nowadays researchers directly use neural networks to infer the 3D pose from the observations. However, most of these approaches ignore the fact that a reprojection constraint has to be satisfied and are sensitive to overfitting. We tackle the overfitting problem by ignoring 2D to 3D correspondences. This efficiently avoids a simple memorization of the training data and allows for a weakly supervised training. One part of the proposed reprojection network (RepNet) learns a mapping from a distribution of 2D poses to a distribution of 3D poses using an adversarial training approach. Another part of the network estimates the camera. This allows for the definition of a network layer that performs the reprojection of the estimated 3D pose back to 2D which results in a reprojection loss function. Our experiments show that RepNet generalizes well to unknown data and outperforms state-of-the-art methods when applied to unseen data. Moreover, our implementation runs in real-time on a standard desktop PC.
count=1
* Deep Incremental Hashing Network for Efficient Image Retrieval
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Deep_Incremental_Hashing_Network_for_Efficient_Image_Retrieval_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_Deep_Incremental_Hashing_Network_for_Efficient_Image_Retrieval_CVPR_2019_paper.pdf)]
    * Title: Deep Incremental Hashing Network for Efficient Image Retrieval
    * Year: `2019`
    * Authors: Dayan Wu,  Qi Dai,  Jing Liu,  Bo Li,  Weiping Wang
    * Abstract: Hashing has shown great potential in large-scale image retrieval due to its storage and computation efficiency, especially the recent deep supervised hashing methods. To achieve promising performance, deep supervised hashing methods require a large amount of training data from different classes. However, when images of new categories emerge, existing deep hashing methods have to retrain the CNN model and generate hash codes for all the database images again, which is impractical for large-scale retrieval system. In this paper, we propose a novel deep hashing framework, called Deep Incremental Hashing Network (DIHN), for learning hash codes in an incremental manner. DIHN learns the hash codes for the new coming images directly, while keeping the old ones unchanged. Simultaneously, a deep hash function for query set is learned by preserving the similarities between training points. Extensive experiments on two widely used image retrieval benchmarks demonstrate that the proposed DIHN framework can significantly decrease the training time while keeping the state-of-the-art retrieval accuracy.
count=1
* Deep Robust Subjective Visual Property Prediction in Crowdsourcing
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Deep_Robust_Subjective_Visual_Property_Prediction_in_Crowdsourcing_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Deep_Robust_Subjective_Visual_Property_Prediction_in_Crowdsourcing_CVPR_2019_paper.pdf)]
    * Title: Deep Robust Subjective Visual Property Prediction in Crowdsourcing
    * Year: `2019`
    * Authors: Qianqian Xu,  Zhiyong Yang,  Yangbangyan Jiang,  Xiaochun Cao,  Qingming Huang,  Yuan Yao
    * Abstract: The problem of estimating subjective visual properties (SVP) of images (e.g., Shoes A is more comfortable than B) is gaining rising attention. Due to its highly subjective nature, different annotators often exhibit different interpretations of scales when adopting absolute value tests. Therefore, recent investigations turn to collect pairwise comparisons via crowdsourcing platforms. However, crowdsourcing data usually contains outliers. For this purpose, it is desired to develop a robust model for learning SVP from crowdsourced noisy annotations. In this paper, we construct a deep SVP prediction model which not only leads to better detection of annotation outliers but also enables learning with extremely sparse annotations. Specifically, we construct a comparison multi-graph based on the collected annotations, where different labeling results correspond to edges with different directions between two vertexes. Then, we propose a generalized deep probabilistic framework which consists of an SVP prediction module and an outlier modeling module that work collaboratively and are optimized jointly. Extensive experiments on various benchmark datasets demonstrate that our new approach guarantees promising results.
count=1
* DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_DistillHash_Unsupervised_Deep_Hashing_by_Distilling_Data_Pairs_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_DistillHash_Unsupervised_Deep_Hashing_by_Distilling_Data_Pairs_CVPR_2019_paper.pdf)]
    * Title: DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs
    * Year: `2019`
    * Authors: Erkun Yang,  Tongliang Liu,  Cheng Deng,  Wei Liu,  Dacheng Tao
    * Abstract: Due to storage and search efficiency, hashing has become significantly prevalent for nearest neighbor search. Particularly, deep hashing methods have greatly improved the search performance, typically under supervised scenarios. In contrast, unsupervised deep hashing models can hardly achieve satisfactory performance due to the lack of supervisory similarity signals. To address this problem, in this paper, we propose a new deep unsupervised hashing model, called DistilHash, which can learn a distilled data set, where data pairs have confident similarity signals. Specifically, we investigate the relationship between the initial but noisy similarity signals learned from local structures and the semantic similarity labels assigned by the optimal Bayesian classifier. We show that, under a mild assumption, some data pairs, of which labels are consistent with those assigned by the optimal Bayesian classifier, can be potentially distilled. With this understanding, we design a simple but effective method to distill data pairs automatically and further adopt a Bayesian learning framework to learn hashing functions from the distilled data set. Extensive experimental results on three widely used benchmark datasets demonstrate that our method achieves state-of-the-art search performance.
count=1
* Probabilistic End-To-End Noise Correction for Learning With Noisy Labels
    [[abs-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/html/Yi_Probabilistic_End-To-End_Noise_Correction_for_Learning_With_Noisy_Labels_CVPR_2019_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yi_Probabilistic_End-To-End_Noise_Correction_for_Learning_With_Noisy_Labels_CVPR_2019_paper.pdf)]
    * Title: Probabilistic End-To-End Noise Correction for Learning With Noisy Labels
    * Year: `2019`
    * Authors: Kun Yi,  Jianxin Wu
    * Abstract: Deep learning has achieved excellent performance in various computer vision tasks, but requires a lot of training examples with clean labels. It is easy to collect a dataset with noisy labels, but such noise makes networks overfit seriously and accuracies drop dramatically. To address this problem, we propose an end-to-end framework called PENCIL, which can update both network parameters and label estimations as label distributions. PENCIL is independent of the backbone network structure and does not need an auxiliary clean dataset or prior information about noise, thus it is more general and robust than existing methods and is easy to apply. PENCIL outperformed previous state-of-the-art methods by large margins on both synthetic and real-world datasets with different noise types and noise rates. Experiments show that PENCIL is robust on clean datasets, too.
count=1
* Learning Distributions of Shape Trajectories From Longitudinal Datasets: A Hierarchical Model on a Manifold of Diffeomorphisms
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Bone_Learning_Distributions_of_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Bone_Learning_Distributions_of_CVPR_2018_paper.pdf)]
    * Title: Learning Distributions of Shape Trajectories From Longitudinal Datasets: A Hierarchical Model on a Manifold of Diffeomorphisms
    * Year: `2018`
    * Authors: Alexandre Bône, Olivier Colliot, Stanley Durrleman
    * Abstract: We propose a method to learn a distribution of shape trajectories from longitudinal data, i.e. the collection of individual objects repeatedly observed at multiple time-points. The method allows to compute an average spatiotemporal trajectory of shape changes at the group level, and the individual variations of this trajectory both in terms of geometry and time dynamics. First, we formulate a non-linear mixed-effects statistical model as the combination of a generic statistical model for manifold-valued longitudinal data, a deformation model defining shape trajectories via the action of a finite-dimensional set of diffeomorphisms with a manifold structure, and an efficient numerical scheme to compute parallel transport on this manifold. Second, we introduce a MCMC-SAEM algorithm with a specific approach to shape sampling, an adaptive scheme for proposal variances, and a log-likelihood tempering strategy to estimate our model. Third, we validate our algorithm on 2D simulated data, and then estimate a scenario of alteration of the shape of the hippocampus 3D brain structure during the course of Alzheimer's disease. The method shows for instance that hippocampal atrophy progresses more quickly in female subjects, and occurs earlier in APOE4 mutation carriers. We finally illustrate the potential of our method for classifying pathological trajectories versus normal ageing.
count=1
* Deep Hashing via Discrepancy Minimization
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Deep_Hashing_via_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Deep_Hashing_via_CVPR_2018_paper.pdf)]
    * Title: Deep Hashing via Discrepancy Minimization
    * Year: `2018`
    * Authors: Zhixiang Chen, Xin Yuan, Jiwen Lu, Qi Tian, Jie Zhou
    * Abstract: This paper presents a discrepancy minimizing model to address the discrete optimization problem in hashing learning. The discrete optimization introduced by binary constraint is an NP-hard mixed integer programming problem. It is usually addressed by relaxing the binary variables into continuous variables to adapt to the gradient based learning of hashing functions, especially the training of deep neural networks. To deal with the objective discrepancy caused by relaxation, we transform the original binary optimization into differentiable optimization problem over hash functions through series expansion. This transformation decouples the binary constraint and the similarity preserving hashing function optimization. The transformed objective is optimized in a tractable alternating optimization framework with gradual discrepancy minimization. Extensive experimental results on three benchmark datasets validate the efficacy of the proposed discrepancy minimizing hashing.
count=1
* Unsupervised Deep Generative Adversarial Hashing Network
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Dizaji_Unsupervised_Deep_Generative_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Dizaji_Unsupervised_Deep_Generative_CVPR_2018_paper.pdf)]
    * Title: Unsupervised Deep Generative Adversarial Hashing Network
    * Year: `2018`
    * Authors: Kamran Ghasedi Dizaji, Feng Zheng, Najmeh Sadoughi, Yanhua Yang, Cheng Deng, Heng Huang
    * Abstract: Unsupervised deep hash functions have not shown satisfactory improvements against the shallow alternatives, and usually, require supervised pretraining to avoid getting stuck in bad local minima. In this paper, we propose a deep unsupervised hashing function, called HashGAN, which outperforms unsupervised hashing models with significant margins without any supervised pretraining. HashGAN consists of three networks, a generator, a discriminator and an encoder. By sharing the parameters of the encoder and discriminator, we benefit from the adversarial loss as a data dependent regularization in training our deep hash function. Moreover, a novel loss function is introduced for hashing real images, resulting in minimum entropy, uniform frequency, consistent and independent hash bits. Furthermore, we train the generator conditioning on random binary inputs and also use these binary variables in a triplet ranking loss for improving hash codes. In our experiments, HashGAN outperforms the previous unsupervised hash functions in image retrieval and achieves the state-of-the-art performance in image clustering. We also provide an ablation study, showing the contribution of each component in our loss function.
count=1
* Deep Ordinal Regression Network for Monocular Depth Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.pdf)]
    * Title: Deep Ordinal Regression Network for Monocular Depth Estimation
    * Year: `2018`
    * Authors: Huan Fu, Mingming Gong, Chaohui Wang, Kayhan Batmanghelich, Dacheng Tao
    * Abstract: Monocular depth estimation, which plays a crucial role in understanding 3D scene geometry, is an ill-posed prob- lem. Recent methods have gained significant improvement by exploring image-level information and hierarchical features from deep convolutional neural networks (DCNNs). These methods model depth estimation as a regression problem and train the regression networks by minimizing mean squared error, which suffers from slow convergence and unsatisfactory local solutions. Besides, existing depth estimation networks employ repeated spatial pooling operations, resulting in undesirable low-resolution feature maps. To obtain high-resolution depth maps, skip-connections or multi- layer deconvolution networks are required, which complicates network training and consumes much more computations. To eliminate or at least largely reduce these problems, we introduce a spacing-increasing discretization (SID) strategy to discretize depth and recast depth network learning as an ordinal regression problem. By training the network using an ordinary regression loss, our method achieves much higher accuracy and faster convergence in synch. Furthermore, we adopt a multi-scale network structure which avoids unnecessary spatial pooling and captures multi-scale information in parallel. The proposed deep ordinal regression network (DORN) achieves state-of-the-art results on three challenging benchmarks, i.e., KITTI [16], Make3D [49], and NYU Depth v2 [41], and outperforms existing methods by a large margin.
count=1
* Direction-Aware Spatial Context Features for Shadow Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.pdf)]
    * Title: Direction-Aware Spatial Context Features for Shadow Detection
    * Year: `2018`
    * Authors: Xiaowei Hu, Lei Zhu, Chi-Wing Fu, Jing Qin, Pheng-Ann Heng
    * Abstract: Shadow detection is a fundamental and challenging task, since it requires an understanding of global image semantics and there are various backgrounds around shadows. This paper presents a novel network for shadow detection by analyzing image context in a direction-aware manner. To achieve this, we first formulate the direction-aware attention mechanism in a spatial recurrent neural network (RNN) by introducing attention weights when aggregating spatial context features in the RNN. By learning these weights through training, we can recover direction-aware spatial context (DSC) for detecting shadows. This design is developed into the DSC module and embedded in a CNN to learn DSC features at different levels. Moreover, a weighted cross entropy loss is designed to make the training more effective. We employ two common shadow detection benchmark datasets and perform various experiments to evaluate our network. Experimental results show that our network outperforms state-of-the-art methods and achieves 97% accuracy and 38% reduction on balance error rate.
count=1
* Learning Deep Descriptors With Scale-Aware Triplet Networks
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Keller_Learning_Deep_Descriptors_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Keller_Learning_Deep_Descriptors_CVPR_2018_paper.pdf)]
    * Title: Learning Deep Descriptors With Scale-Aware Triplet Networks
    * Year: `2018`
    * Authors: Michel Keller, Zetao Chen, Fabiola Maffra, Patrik Schmuck, Margarita Chli
    * Abstract: Research on learning suitable feature descriptors for Computer Vision has recently shifted to deep learning where the biggest challenge lies with the formulation of appropriate loss functions, especially since the descriptors to be learned are not known at training time. While approaches such as Siamese and triplet losses have been applied with success, it is still not well understood what makes a good loss function. In this spirit, this work demonstrates that many commonly used losses suffer from a range of problems. Based on this analysis, we introduce mixed-context losses and scale-aware sampling, two methods that when combined enable networks to learn consistently scaled descriptors for the first time.
count=1
* Efficient Optimization for Rank-Based Loss Functions
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Mohapatra_Efficient_Optimization_for_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Mohapatra_Efficient_Optimization_for_CVPR_2018_paper.pdf)]
    * Title: Efficient Optimization for Rank-Based Loss Functions
    * Year: `2018`
    * Authors: Pritish Mohapatra, Michal Rolínek, C.V. Jawahar, Vladimir Kolmogorov, M. Pawan Kumar
    * Abstract: The accuracy of information retrieval systems is often measured using complex loss functions such as the average precision (AP) or the normalized discounted cumulative gain (NDCG). Given a set of positive and negative samples, the parameters of a retrieval system can be estimated by minimizing these loss functions. However, the non-differentiability and non-decomposability of these loss functions does not allow for simple gradient based optimization algorithms. This issue is generally circumvented by either optimizing a structured hinge-loss upper bound to the loss function or by using asymptotic methods like the direct-loss minimization framework. Yet, the high computational complexity of loss-augmented inference, which is necessary for both the frameworks, prohibits its use in large training data sets. To alleviate this deficiency, we present a novel quicksort flavored algorithm for a large class of non-decomposable loss functions. We provide a complete characterization of the loss functions that are amenable to our algorithm, and show that it includes both AP and NDCG based loss functions. Furthermore, we prove that no comparison based algorithm can improve upon the computational complexity of our approach asymptotically. We demonstrate the effectiveness of our approach in the context of optimizing the structured hinge loss upper bound of AP and NDCG loss for learning models for a variety of vision tasks. We show that our approach provides significantly better results than simpler decomposable loss functions, while requiring a comparable training time.
count=1
* Crowd Counting With Deep Negative Correlation Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/html/Shi_Crowd_Counting_With_CVPR_2018_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2018/papers/Shi_Crowd_Counting_With_CVPR_2018_paper.pdf)]
    * Title: Crowd Counting With Deep Negative Correlation Learning
    * Year: `2018`
    * Authors: Zenglin Shi, Le Zhang, Yun Liu, Xiaofeng Cao, Yangdong Ye, Ming-Ming Cheng, Guoyan Zheng
    * Abstract: Deep convolutional networks (ConvNets) have achieved unprecedented performances on many computer vision tasks. However, their adaptations to crowd counting on single images are still in their infancy and suffer from severe over-fitting. Here we propose a new learning strategy to produce generalizable features by way of deep negative correlation learning (NCL). More specifically, we deeply learn a pool of decorrelated regressors with sound generalization capabilities through managing their intrinsic diversities. Our proposed method, named decorrelated ConvNet (D-ConvNet), is end-to-end-trainable and independent of the backbone fully-convolutional network architectures. Extensive experiments on very deep VGGNet as well as our customized network structure indicate the superiority of D-ConvNet when compared with several state-of-the-art methods. Our implementation will be released at https://github.com/shizenglin/Deep-NCL
count=1
* Social Scene Understanding: End-To-End Multi-Person Action Localization and Collective Activity Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Bagautdinov_Social_Scene_Understanding_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Bagautdinov_Social_Scene_Understanding_CVPR_2017_paper.pdf)]
    * Title: Social Scene Understanding: End-To-End Multi-Person Action Localization and Collective Activity Recognition
    * Year: `2017`
    * Authors: Timur Bagautdinov, Alexandre Alahi, Francois Fleuret, Pascal Fua, Silvio Savarese
    * Abstract: We present a unified framework for understanding human social behaviors in raw image sequences. Our model jointly detects multiple individuals, infers their social actions, and estimates the collective actions with a single feed-forward pass through a neural network. We propose a single architecture that does not rely on external detection algorithms but rather is trained end-to-end to generate dense proposal maps that are refined via a novel inference scheme. The temporal consistency is handled via a person-level matching Recurrent Neural Network. The complete model takes as input a sequence of frames and outputs detections along with the estimates of individual actions and collective activities. We demonstrate state-of-the-art performance of our algorithm on multiple publicly available benchmarks.
count=1
* Multi-Modal Mean-Fields via Cardinality-Based Clamping
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Baque_Multi-Modal_Mean-Fields_via_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Baque_Multi-Modal_Mean-Fields_via_CVPR_2017_paper.pdf)]
    * Title: Multi-Modal Mean-Fields via Cardinality-Based Clamping
    * Year: `2017`
    * Authors: Pierre Baque, Francois Fleuret, Pascal Fua
    * Abstract: Mean Field inference is central to statistical physics. It has attracted much interest in the Computer Vision community to efficiently solve problems expressible in terms of large Conditional Random Fields. However, since it models the posterior probability distribution as a product of marginal probabilities, it may fail to properly account for important dependencies between variables. We therefore replace the fully factorized distribution of Mean Field by a weighted mixture of such distributions, that similarly minimizes the KL-Divergence to the true posterior. By introducing two new ideas, namely, conditioning on groups of variables instead of single ones and using a parameter of the conditional random field potentials, that we identify to the temperature in the sense of statistical physics to select such groups, we can perform this minimization efficiently. Our extension of the clamping method proposed in previous works allows us to both produce a more descriptive approximation of the true posterior and, inspired by the diverse MAP paradigms, fit a mixture of Mean Field approximations. We demonstrate that this positively impacts real-world algorithms that initially relied on mean fields.
count=1
* Designing Illuminant Spectral Power Distributions for Surface Classification
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Blasinski_Designing_Illuminant_Spectral_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Blasinski_Designing_Illuminant_Spectral_CVPR_2017_paper.pdf)]
    * Title: Designing Illuminant Spectral Power Distributions for Surface Classification
    * Year: `2017`
    * Authors: Henryk Blasinski, Joyce Farrell, Brian Wandell
    * Abstract: There are many scientific, medical and industrial imaging applications where users have full control of the scene illumination and color reproduction is not the primary objective For example, it is possible to co-design sensors and spectral illumination in order to classify and detect changes in biological tissues, organic and inorganic materials, and object surface properties. In this paper, we propose two different approaches to illuminant spectrum selection for surface classification. In the supervised framework we formulate a biconvex optimization problem where we alternate between optimizing support vector classifier weights and optimal illuminants. We also describe a sparse Principal Component Analysis (PCA) dimensionality reduction approach that can be used with unlabeled data. We efficiently solve the non-convex PCA problem using a convex relaxation and Alternating Direction Method of Multipliers (ADMM). We compare the classification accuracy of a monochrome imaging sensor with optimized illuminants to the classification accuracy of conventional RGB cameras with natural broadband illumination.
count=1
* DeepNav: Learning to Navigate Large Cities
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Brahmbhatt_DeepNav_Learning_to_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Brahmbhatt_DeepNav_Learning_to_CVPR_2017_paper.pdf)]
    * Title: DeepNav: Learning to Navigate Large Cities
    * Year: `2017`
    * Authors: Samarth Brahmbhatt, James Hays
    * Abstract: We present DeepNav, a Convolutional Neural Network (CNN) based algorithm for navigating large cities using locally visible street-view images. The DeepNav agent learns to reach its destination quickly by making the correct navigation decisions at intersections. We collect a large-scale dataset of street-view images organized in a graph where nodes are connected by roads. This dataset contains 10 city graphs and a total of more than 1 million street-view images. We propose 3 supervised learning approaches for the navigation task, and show how A* search in the city graph can be used to generate labels for the images. Our annotation process is fully automated using publicly available mapping services, and requires no human input. We evaluate the proposed DeepNav models on 4 held-out cities for navigating to 5 different types of destinations and show that our algorithms outperform previous work that uses hand-crafted features and Support Vector Regression (SVR).
count=1
* On-The-Fly Adaptation of Regression Forests for Online Camera Relocalisation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Cavallari_On-The-Fly_Adaptation_of_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Cavallari_On-The-Fly_Adaptation_of_CVPR_2017_paper.pdf)]
    * Title: On-The-Fly Adaptation of Regression Forests for Online Camera Relocalisation
    * Year: `2017`
    * Authors: Tommaso Cavallari, Stuart Golodetz, Nicholas A. Lord, Julien Valentin, Luigi Di Stefano, Philip H. S. Torr
    * Abstract: Camera relocalisation is an important problem in computer vision, with applications in simultaneous localisation and mapping, virtual/augmented reality and navigation. Common techniques either match the current image against keyframes with known poses coming from a tracker, or establish 2D-to-3D correspondences between keypoints in the current image and points in the scene in order to estimate the camera pose. Recently, regression forests have become a popular alternative to establish such correspondences. They achieve accurate results, but must be trained offline on the target scene, preventing relocalisation in new environments. In this paper, we show how to circumvent this limitation by adapting a pre-trained forest to a new scene on the fly. Our adapted forests achieve relocalisation performance that is on par with that of offline forests, and our approach runs in under 150ms, making it desirable for real-time systems that require online relocalisation.
count=1
* Fast Person Re-Identification via Cross-Camera Semantic Binary Transformation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Chen_Fast_Person_Re-Identification_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_Fast_Person_Re-Identification_CVPR_2017_paper.pdf)]
    * Title: Fast Person Re-Identification via Cross-Camera Semantic Binary Transformation
    * Year: `2017`
    * Authors: Jiaxin Chen, Yunhong Wang, Jie Qin, Li Liu, Ling Shao
    * Abstract: Numerous methods have been proposed for person re-identification, most of which however neglect the matching efficiency. Recently, several hashing based approaches have been developed to make re-identification more scalable for large-scale gallery sets. Despite their efficiency, these works ignore cross-camera variations, which severely deteriorate the final matching accuracy. To address the above issues, we propose a novel hashing based method for fast person re-identification, namely Cross-camera Semantic Binary Transformation (CSBT). CSBT aims to transform original high-dimensional feature vectors into compact identity-preserving binary codes. To this end, CSBT first employs a subspace projection to mitigate cross-camera variations, by maximizing intra-person similarities and inter-person discrepancies. Subsequently, a binary coding scheme is proposed via seamlessly incorporating both the semantic pairwise relationships and local affinity information. Finally, a joint learning framework is proposed for simultaneous subspace projection learning and binary coding based on discrete alternating optimization. Experimental results on four benchmarks clearly demonstrate the superiority of CSBT over the state-of-the-art methods.
count=1
* Fast Boosting Based Detection Using Scale Invariant Multimodal Multiresolution Filtered Features
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Costea_Fast_Boosting_Based_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Costea_Fast_Boosting_Based_CVPR_2017_paper.pdf)]
    * Title: Fast Boosting Based Detection Using Scale Invariant Multimodal Multiresolution Filtered Features
    * Year: `2017`
    * Authors: Arthur Daniel Costea, Robert Varga, Sergiu Nedevschi
    * Abstract: In this paper we propose a novel boosting-based sliding window solution for object detection which can keep up with the precision of the state-of-the art deep learning approaches, while being 10 to 100 times faster. The solution takes advantage of multisensorial perception and exploits information from color, motion and depth. We introduce multimodal multiresolution filtering of signal intensity, gradient magnitude and orientation channels, in order to capture structure at multiple scales and orientations. To achieve scale invariant classification features, we analyze the effect of scale change on features for different filter types and propose a correction scheme. To improve recognition we incorporate 2D and 3D context by generating spatial, geometric and symmetrical channels. Finally, we evaluate the proposed solution on multiple benchmarks for the detection of pedestrians, cars and bicyclists. We achieve competitive results at over 25 frames per second.
count=1
* AMVH: Asymmetric Multi-Valued Hashing
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Da_AMVH_Asymmetric_Multi-Valued_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Da_AMVH_Asymmetric_Multi-Valued_CVPR_2017_paper.pdf)]
    * Title: AMVH: Asymmetric Multi-Valued Hashing
    * Year: `2017`
    * Authors: Cheng Da, Shibiao Xu, Kun Ding, Gaofeng Meng, Shiming Xiang, Chunhong Pan
    * Abstract: Most existing hashing methods resort to binary codes for similarity search, owing to the high efficiency of computation and storage. However, binary codes lack enough capability in similarity preservation, resulting in less desirable performance. To address this issue, we propose an asymmetric multi-valued hashing method supported by two different non-binary embeddings. (1) A real-valued embedding is used for representing the newly-coming query. (2) A multi-integer-embedding is employed for compressing the whole database, which is modeled by binary sparse representation with fixed sparsity. With these two non-binary embeddings, the similarities between data points can be preserved precisely. To perform meaningful asymmetric similarity computation for efficient semantic search, these embeddings are jointly learnt by preserving the label-based similarity. Technically, this results in a mixed integer programming problem, which is efficiently solved by alternative optimization. Extensive experiments on three multilabel datasets demonstrate that our approach not only outperforms the existing binary hashing methods in search accuracy, but also retains their query and storage efficiency.
count=1
* Simultaneous Feature Aggregating and Hashing for Large-Scale Image Search
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Do_Simultaneous_Feature_Aggregating_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Do_Simultaneous_Feature_Aggregating_CVPR_2017_paper.pdf)]
    * Title: Simultaneous Feature Aggregating and Hashing for Large-Scale Image Search
    * Year: `2017`
    * Authors: Thanh-Toan Do, Dang-Khoa Le Tan, Trung T. Pham, Ngai-Man Cheung
    * Abstract: In most state-of-the-art hashing-based visual search systems, local image descriptors of an image are first aggregated as a single feature vector. This feature vector is then subjected to a hashing function that produces a binary hash code. In previous work, the aggregating and the hashing processes are designed independently. In this paper, we propose a novel framework where feature aggregating and hashing are designed simultaneously and optimized jointly. Specifically, our joint optimization produces aggregated representations that can be better reconstructed by some binary codes. This leads to more discriminative binary hash codes and improved retrieval accuracy. In addition, we also propose a fast version of the recently-proposed Binary Autoencoder to be used in our proposed framework. We perform extensive retrieval experiments on several benchmark datasets with both SIFT and convolutional features. Our results suggest that the proposed framework achieves significant improvements over the state of the art.
count=1
* BRISKS: Binary Features for Spherical Images on a Geodesic Grid
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Guan_BRISKS_Binary_Features_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Guan_BRISKS_Binary_Features_CVPR_2017_paper.pdf)]
    * Title: BRISKS: Binary Features for Spherical Images on a Geodesic Grid
    * Year: `2017`
    * Authors: Hao Guan, William A. P. Smith
    * Abstract: In this paper, we develop an interest point detector and binary feature descriptor for spherical images. We take as inspiration a recent framework developed for planar images, BRISK (Binary Robust Invariant Scalable Keypoints), and adapt the method to operate on spherical images. All of our processing is intrinsic to the sphere and avoids the distortion inherent in storing and indexing spherical images in a 2D representation. We discretise images on a spherical geodesic grid formed by recursive subdivision of a triangular mesh. This leads to a multiscale pixel grid comprising mainly hexagonal pixels that lends itself naturally to a spherical image pyramid representation. For interest point detection, we use a variant of the Accelerated Segment Test (AST) corner detector which operates on our geodesic grid. We estimate a continuous scale and location for features and descriptors are built by sampling onto a regular pattern in the tangent space. We evaluate repeatability, precision and recall on both synthetic spherical images with known ground truth correspondences and real images.
count=1
* Bayesian Supervised Hashing
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Hu_Bayesian_Supervised_Hashing_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Hu_Bayesian_Supervised_Hashing_CVPR_2017_paper.pdf)]
    * Title: Bayesian Supervised Hashing
    * Year: `2017`
    * Authors: Zihao Hu, Junxuan Chen, Hongtao Lu, Tongzhen Zhang
    * Abstract: Among learning based hashing methods, supervised hashing seeks compact binary representation of the training data to preserve semantic similarities. Recent years have witnessed various problem formulations and optimization methods for supervised hashing. Most of them optimize a form of loss function with a regulization term, which can be viewed as a maximum a posterior (MAP) estimation of the hashing codes. However, these approaches are prone to overfitting unless hyperparameters are tuned carefully. To address this problem, we present a novel fully Bayesian treatment for supervised hashing problem, named Bayesian Supervised Hashing (BSH), in which hyperparameters are automatically tuned during optimization. Additionally, by utilizing automatic relevance determination (ARD), we can figure out relative discriminating ability of different hashing bits and select most informative bits among them. Experimental results on three real-world image datasets with semantic information show that BSH can achieve superior performance over state-of-the-art methods with comparable training time.
count=1
* Deep 360 Pilot: Learning a Deep Agent for Piloting Through 360deg Sports Videos
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Hu_Deep_360_Pilot_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Hu_Deep_360_Pilot_CVPR_2017_paper.pdf)]
    * Title: Deep 360 Pilot: Learning a Deep Agent for Piloting Through 360deg Sports Videos
    * Year: `2017`
    * Authors: Hou-Ning Hu, Yen-Chen Lin, Ming-Yu Liu, Hsien-Tzu Cheng, Yung-Ju Chang, Min Sun
    * Abstract: Watching a 360* sports video requires a viewer to continuously select a viewing angle, either through a sequence of mouse clicks or head movements. To relieve the viewer from this "360 piloting" task, we propose "deep 360 pilot" - a deep learning-based agent for piloting through 360* sports videos automatically. At each frame, the agent observes a panoramic image and has the knowledge of previously selected viewing angles. The task of the agent is to shift the current viewing angle (i.e. action) to the next preferred one (i.e., goal). We propose to directly learn an online policy of the agent from data. Specifically, we leverage a state-of-the-art object detector to propose a few candidate objects of interest (yellow boxes in Fig. 1). Then, a recurrent neural network is used to select the main object (green dash boxes in Fig. 1). Given the main object and previously selected viewing angles, our method regresses a shift in viewing angle to move to the next one. We use the policy gradient technique to jointly train our pipeline, by minimizing: (1) a regression loss measuring the distance between the selected and ground truth viewing angles, (2) a smoothness loss encouraging smooth transition in viewing angle, and (3) maximizing an expected reward of focusing on a foreground object. To evaluate our method, we built a new 360-Sports video dataset consisting of five sports domains. We trained domain-specific agents and achieved the best performance on viewing angle selection accuracy and users' preference compared to [54] and other baselines.
count=1
* Deep Cross-Modal Hashing
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Jiang_Deep_Cross-Modal_Hashing_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Jiang_Deep_Cross-Modal_Hashing_CVPR_2017_paper.pdf)]
    * Title: Deep Cross-Modal Hashing
    * Year: `2017`
    * Authors: Qing-Yuan Jiang, Wu-Jun Li
    * Abstract: Due to its low storage cost and fast query speed, cross-modal hashing (CMH) has been widely used for similarity search in multimedia retrieval applications. However, most existing CMH methods are based on hand-crafted features which might not be optimally compatible with the hash-code learning procedure. As a result, existing CMH methods with hand-crafted features may not achieve satisfactory performance. In this paper, we propose a novel CMH method, called deep cross-modal hashing (DCMH), by integrating feature learning and hash-code learning intothe same framework. DCMH is an end-to-end learning framework with deep neural networks, one for each modality, to perform feature learning from scratch. Experiments on three real datasets with image-text modalities show that DCMH can outperform other baselines to achieve the state-of-the-art performance in cross-modal retrieval applications.
count=1
* Discretely Coding Semantic Rank Orders for Supervised Image Hashing
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Liu_Discretely_Coding_Semantic_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Liu_Discretely_Coding_Semantic_CVPR_2017_paper.pdf)]
    * Title: Discretely Coding Semantic Rank Orders for Supervised Image Hashing
    * Year: `2017`
    * Authors: Li Liu, Ling Shao, Fumin Shen, Mengyang Yu
    * Abstract: Learning to hash has been recognized to accomplish highly efficient storage and retrieval for large-scale visual data. Particularly, ranking-based hashing techniques have recently attracted broad research attention because ranking accuracy among the retrieved data is well explored and their objective is more applicable to realistic search tasks. However, directly optimizing discrete hash codes without continuous-relaxations on a nonlinear ranking objective is infeasible by either traditional optimization methods or even recent discrete hashing algorithms. To address this challenging issue, in this paper, we introduce a novel supervised hashing method, dubbed Discrete Semantic Ranking Hashing (DSeRH), which aims to directly embed semantic rank orders into binary codes. In DSeRH, a generalized Adaptive Discrete Minimization (ADM) approach is proposed to discretely optimize binary codes with the quadratic nonlinear ranking objective in an iterative manner and is guaranteed to converge quickly. Additionally, instead of using 0/1 independent labels to form rank orders as in previous works, we generate the listwise rank orders from the high-level semantic word embeddings which can quantitatively capture the intrinsic correlation between different categories. We evaluate our DSeRH, coupled with both linear and deep convolutional neural network (CNN) hash functions, on three image datasets, i.e., CIFAR-10, SUN397 and ImageNet100, and the results manifest that DSeRH can outperform the state-of-the-art ranking-based hashing methods.
count=1
* Global Hypothesis Generation for 6D Object Pose Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Michel_Global_Hypothesis_Generation_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Michel_Global_Hypothesis_Generation_CVPR_2017_paper.pdf)]
    * Title: Global Hypothesis Generation for 6D Object Pose Estimation
    * Year: `2017`
    * Authors: Frank Michel, Alexander Kirillov, Eric Brachmann, Alexander Krull, Stefan Gumhold, Bogdan Savchynskyy, Carsten Rother
    * Abstract: This paper addresses the task of estimating the 6D-pose of a known 3D object from a single RGB-D image. Most modern approaches solve this task in three steps: i) compute local features; ii) generate a pool of pose-hypotheses; iii) select and refine a pose from the pool. This work focuses on the second step. While all existing approaches generate the hypotheses pool via local reasoning, e.g. RANSAC or Hough-Voting, we are the first to show that global reasoning is beneficial at this stage. In particular, we formulate a novel fully-connected Conditional Random Field (CRF) that outputs a very small number of pose-hypotheses. Despite the potential functions of the CRF being non-Gaussian, we give a new, efficient two-step optimization procedure, with some guarantees for optimality. We utilize our global hypotheses generation procedure to produce results that exceed state-of-the-art for the challenging "Occluded Object Dataset".
count=1
* Binary Coding for Partial Action Analysis With Limited Observation Ratios
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Qin_Binary_Coding_for_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Qin_Binary_Coding_for_CVPR_2017_paper.pdf)]
    * Title: Binary Coding for Partial Action Analysis With Limited Observation Ratios
    * Year: `2017`
    * Authors: Jie Qin, Li Liu, Ling Shao, Bingbing Ni, Chen Chen, Fumin Shen, Yunhong Wang
    * Abstract: Traditional action recognition methods aim to recognize actions with complete observations/executions. However, it is often difficult to capture fully executed actions due to occlusions, interruptions, etc. Meanwhile, action prediction/recognition in advance based on partial observations is essential for preventing the situation from deteriorating. Besides, fast spotting human activities using partially observed data is a critical ingredient for retrieval systems. Inspired by the recent success of data binarization in efficient retrieval/recognition, we propose a novel approach, named Partial Reconstructive Binary Coding (PRBC), for action analysis based on limited frame glimpses during any period of the complete execution. Specifically, we learn discriminative compact binary codes for partial actions via a joint learning framework, which collaboratively tackles feature reconstruction as well as binary coding. We obtain the solution to PRBC based on a discrete alternating iteration algorithm. Extensive experiments on four realistic action datasets in terms of three tasks (i.e., partial action retrieval, recognition and prediction) clearly show the superiority of PRBC over the state-of-the-art methods, along with significantly reduced memory load and computational costs during the online test.
count=1
* Dynamic Time-Of-Flight
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Schober_Dynamic_Time-Of-Flight_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Schober_Dynamic_Time-Of-Flight_CVPR_2017_paper.pdf)]
    * Title: Dynamic Time-Of-Flight
    * Year: `2017`
    * Authors: Michael Schober, Amit Adam, Omer Yair, Shai Mazor, Sebastian Nowozin
    * Abstract: Time-of-flight (TOF) depth cameras provide robust depth inference at low power requirements in a wide variety of consumer and industrial applications. These cameras reconstruct a single depth frame from a given set of infrared (IR) frames captured over a very short exposure period. Operating in this mode the camera essentially forgets all information previously captured - and performs depth inference from scratch for every frame. We challenge this practice and propose using previously captured information when inferring depth. An inherent problem we have to address is camera motion over this longer period of collecting observations. We derive a probabilistic framework combining a simple but robust model of camera and object motion, together with an observation model. This combination allows us to integrate information over multiple frames while remaining robust to rapid changes. Operating the camera in this manner has implications in terms of both computational efficiency and how information should be captured. We address these two issues and demonstrate a realtime TOF system with robust temporal integration that improves depth accuracy over strong baseline methods including adaptive spatio-temporal filters.
count=1
* CASENet: Deep Category-Aware Semantic Edge Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/html/Yu_CASENet_Deep_Category-Aware_CVPR_2017_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_CASENet_Deep_Category-Aware_CVPR_2017_paper.pdf)]
    * Title: CASENet: Deep Category-Aware Semantic Edge Detection
    * Year: `2017`
    * Authors: Zhiding Yu, Chen Feng, Ming-Yu Liu, Srikumar Ramalingam
    * Abstract: Boundary and edge cues are highly beneficial in improving a wide variety of vision tasks such as semantic segmentation, object recognition, stereo, and object proposal generation. Recently, the problem of edge detection has been revisited and significant progress has been made with deep learning. While classical edge detection is a challenging binary problem in itself, the category-aware semantic edge detection by nature is an even more challenging multi-label problem. We model the problem such that each edge pixel can be associated with more than one class as they appear in contours or junctions belonging to two or more semantic classes. To this end, we propose a novel end-to-end deep semantic edge learning architecture based on ResNet and a new skip-layer architecture where category-wise edge activations at the top convolution layer share and are fused with the same set of bottom layer features. We then propose a multi-label loss function to supervise the fused activations. We show that our proposed architecture benefits this problem with better performance, and we outperform the current state-of-the-art semantic edge detection methods by a large margin on standard data sets such as SBD and Cityscapes.
count=1
* Staple: Complementary Learners for Real-Time Tracking
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Bertinetto_Staple_Complementary_Learners_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Bertinetto_Staple_Complementary_Learners_CVPR_2016_paper.pdf)]
    * Title: Staple: Complementary Learners for Real-Time Tracking
    * Year: `2016`
    * Authors: Luca Bertinetto, Jack Valmadre, Stuart Golodetz, Ondrej Miksik, Philip H. S. Torr
    * Abstract: Correlation Filter-based trackers have recently achieved excellent performance, showing great robustness to challenging situations exhibiting motion blur and illumination changes. However, since the model that they learn depends strongly on the spatial layout of the tracked object, they are notoriously sensitive to deformation. Models based on colour statistics have complementary traits: they cope well with variation in shape, but suffer when illumination is not consistent throughout a sequence. Moreover, colour distributions alone can be insufficiently discriminative. In this paper, we show that a simple tracker combining complementary cues in a ridge regression framework can operate faster than 80 FPS and outperform not only all entries in the popular VOT14 competition, but also recent and far more sophisticated trackers according to multiple benchmarks.
count=1
* Volumetric 3D Tracking by Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Huang_Volumetric_3D_Tracking_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Huang_Volumetric_3D_Tracking_CVPR_2016_paper.pdf)]
    * Title: Volumetric 3D Tracking by Detection
    * Year: `2016`
    * Authors: Chun-Hao Huang, Benjamin Allain, Jean-Sebastien Franco, Nassir Navab, Slobodan Ilic, Edmond Boyer
    * Abstract: In this paper, we propose a new framework for 3D tracking by detection based on fully volumetric representations. On one hand, 3D tracking by detection has shown robust use in the context of interaction (Kinect) and surface tracking. On the other hand, volumetric representations have recently been proven efficient both for building 3D features and for addressing the 3D tracking problem. We leverage these benefits by unifying both families of approaches into a single, fully volumetric tracking-by-detection framework. We use a centroidal Voronoi tessellation (CVT) representation to compactly tessellate shapes with optimal discretization, construct a feature space, and perform the tracking according to the correspondences provided by trained random forests. Our results show improved tracking and training computational efficiency and improved memory performance. This in turn enables the use of larger training databases than state of the art approaches, which we leverage by proposing a cross-tracking subject training scheme to benefit from all subject sequences for all tracking situations, thus yielding better detection and less overfitting.
count=1
* Pairwise Decomposition of Image Sequences for Active Multi-View Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Johns_Pairwise_Decomposition_of_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Johns_Pairwise_Decomposition_of_CVPR_2016_paper.pdf)]
    * Title: Pairwise Decomposition of Image Sequences for Active Multi-View Recognition
    * Year: `2016`
    * Authors: Edward Johns, Stefan Leutenegger, Andrew J. Davison
    * Abstract: A multi-view image sequence provides a much richer capacity for object recognition than from a single image. However, most existing solutions to multi-view recognition typically adopt hand-crafted, model-based geometric methods, which do not readily embrace recent trends in deep learning. We propose to bring Convolutional Neural Networks to generic multi-view recognition, by decomposing an image sequence into a set of image pairs, classifying each pair independently, and then learning an object classifier by weighting the contribution of each pair. This allows for recognition over arbitrary camera trajectories, without requiring explicit training over the potentially infinite number of camera paths and lengths. Building these pairwise relationships then naturally extends to the next-best-view problem in an active recognition framework. To achieve this, we train a second Convolutional Neural Network to map directly from an observed image to next viewpoint. Finally, we incorporate this into a trajectory optimisation task, whereby the best recognition confidence is sought for a given trajectory length. We present state-of-the-art results in both guided and unguided multi-view recognition on the ModelNet dataset, and show how our method can be used with depth images, greyscale images, or both.
count=1
* An Empirical Evaluation of Current Convolutional Architectures' Ability to Manage Nuisance Location and Scale Variability
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Karianakis_An_Empirical_Evaluation_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Karianakis_An_Empirical_Evaluation_CVPR_2016_paper.pdf)]
    * Title: An Empirical Evaluation of Current Convolutional Architectures' Ability to Manage Nuisance Location and Scale Variability
    * Year: `2016`
    * Authors: Nikolaos Karianakis, Jingming Dong, Stefano Soatto
    * Abstract: We conduct an empirical study to test the ability of convolutional neural networks (CNNs) to reduce the effects of nuisance transformations of the input data, such as location, scale and aspect ratio. We isolate factors by adopting a common convolutional architecture either deployed globally on the image to compute class posterior distributions, or restricted locally to compute class conditional distributions given location, scale and aspect ratios of bounding boxes determined by proposal heuristics. In theory, averaging the latter should yield inferior performance compared to proper marginalization. Yet empirical evidence suggests the converse, leading us to conclude that - at the current level of complexity of convolutional architectures and scale of the data sets used to train them - CNNs are not very effective at marginalizing nuisance variability. We also quantify the effects of context on the overall classification task and its impact on the performance of CNNs, and propose improved sampling techniques for heuristic proposal schemes that improve end-to-end performance to state-of-the-art levels. We test our hypothesis on a classification task using the ImageNet Challenge benchmark and on a wide-baseline matching task using the Oxford and Fischer's datasets.
count=1
* Weakly Supervised Object Boundaries
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Khoreva_Weakly_Supervised_Object_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Khoreva_Weakly_Supervised_Object_CVPR_2016_paper.pdf)]
    * Title: Weakly Supervised Object Boundaries
    * Year: `2016`
    * Authors: Anna Khoreva, Rodrigo Benenson, Mohamed Omran, Matthias Hein, Bernt Schiele
    * Abstract: State-of-the-art learning based boundary detection methods require extensive training data. Since labelling object boundaries is one of the most expensive types of annotations, there is a need to relax the requirement to carefully annotate images to make both the training more affordable and to extend the amount of training data. In this paper we propose a technique to generate weakly supervised annotations and show that bounding box annotations alone suffice to reach high-quality object boundaries without using any object-specific boundary annotations. With the proposed weak supervision techniques we achieve the top performance on the object boundary detection task, outperforming by a large margin the current fully supervised state-of-the-art methods.
count=1
* TI-Pooling: Transformation-Invariant Pooling for Feature Learning in Convolutional Neural Networks
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Laptev_TI-Pooling_Transformation-Invariant_Pooling_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Laptev_TI-Pooling_Transformation-Invariant_Pooling_CVPR_2016_paper.pdf)]
    * Title: TI-Pooling: Transformation-Invariant Pooling for Feature Learning in Convolutional Neural Networks
    * Year: `2016`
    * Authors: Dmitry Laptev, Nikolay Savinov, Joachim M. Buhmann, Marc Pollefeys
    * Abstract: In this paper we present a deep neural network topology that incorporates a simple to implement transformation-invariant pooling operator (TI-pooling). This operator is able to efficiently handle prior knowledge on nuisance variations in the data, such as rotation or scale changes. Most current methods usually make use of dataset augmentation to address this issue, but this requires larger number of model parameters and more training data, and results in significantly increased training time and larger chance of under- or overfitting. The main reason for these drawbacks is that that the learned model needs to capture adequate features for all the possible transformations of the input. On the other hand, we formulate features in convolutional neural networks to be transformation-invariant. We achieve that using parallel siamese architectures for the considered transformation set and applying the TI-pooling operator on their outputs before the fully-connected layers. We show that this topology internally finds the most optimal "canonical" instance of the input image for training and therefore limits the redundancy in learned features. This more efficient use of training data results in better performance on popular benchmark datasets with smaller number of parameters when comparing to standard convolutional neural networks with dataset augmentation and to other baselines.
count=1
* Active Learning for Delineation of Curvilinear Structures
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Mosinska-Domanska_Active_Learning_for_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Mosinska-Domanska_Active_Learning_for_CVPR_2016_paper.pdf)]
    * Title: Active Learning for Delineation of Curvilinear Structures
    * Year: `2016`
    * Authors: Agata Mosinska-Domanska, Raphael Sznitman, Przemyslaw Glowacki, Pascal Fua
    * Abstract: Many recent delineation techniques owe much of their increased effectiveness to path classification algorithms that make it possible to distinguish promising paths from others. The downside of this development is that they require annotated training data, which is tedious to produce. In this paper, we propose an Active Learning approach that considerably speeds up the annotation process. Unlike standard ones, it takes advantage of the specificities of the delineation problem. It operates on a graph and can reduce the training set size by up to 80% without compromising the reconstruction quality. We will show that our approach outperforms conventional ones on various biomedical and natural image datasets, thus showing that it is broadly applicable.
count=1
* Learning Multi-Domain Convolutional Neural Networks for Visual Tracking
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Nam_Learning_Multi-Domain_Convolutional_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Nam_Learning_Multi-Domain_Convolutional_CVPR_2016_paper.pdf)]
    * Title: Learning Multi-Domain Convolutional Neural Networks for Visual Tracking
    * Year: `2016`
    * Authors: Hyeonseob Nam, Bohyung Han
    * Abstract: We propose a novel visual tracking algorithm based on the representations from a discriminatively trained Convolutional Neural Network (CNN). Our algorithm pretrains a CNN using a large set of videos with tracking ground-truths to obtain a generic target representation. Our network is composed of shared layers and multiple branches of domain-specific layers, where domains correspond to individual training sequences and each branch is responsible for binary classification to identify target in each domain. We train each domain in the network iteratively to obtain generic target representations in the shared layers. When tracking a target in a new sequence, we construct a new network by combining the shared layers in the pretrained CNN with a new binary classification layer, which is updated online. Online tracking is performed by evaluating the candidate windows randomly sampled around the previous target state. The proposed algorithm illustrates outstanding performance in existing tracking benchmarks.
count=1
* Ordinal Regression With Multiple Output CNN for Age Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Niu_Ordinal_Regression_With_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Niu_Ordinal_Regression_With_CVPR_2016_paper.pdf)]
    * Title: Ordinal Regression With Multiple Output CNN for Age Estimation
    * Year: `2016`
    * Authors: Zhenxing Niu, Mo Zhou, Le Wang, Xinbo Gao, Gang Hua
    * Abstract: To address the non-stationary property of aging patterns, age estimation can be cast as an ordinal regression problem. However, the processes of extracting features and learning a regression model are often separated and optimized independently in previous work. In this paper, we propose an End-to-End learning approach to address ordinal regression problems using deep Convolutional Neural Network, which could simultaneously conduct feature learning and regression modeling. In particular, an ordinal regression problem is transformed into a series of binary classification sub-problems. And we propose a multiple output CNN learning algorithm to collectively solve these classification sub-problems, so that the correlation between these tasks could be explored. In addition, we publish an Asian Face Age Dataset (AFAD) containing more than 160K facial images with precise age ground-truths, which is the largest public age dataset to date. To the best of our knowledge, this is the first work to address ordinal regression problems by using CNN, and achieves the state-of-the-art performance on both the MORPH and AFAD datasets.
count=1
* Refining Architectures of Deep Convolutional Neural Networks
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Shankar_Refining_Architectures_of_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Shankar_Refining_Architectures_of_CVPR_2016_paper.pdf)]
    * Title: Refining Architectures of Deep Convolutional Neural Networks
    * Year: `2016`
    * Authors: Sukrit Shankar, Duncan Robertson, Yani Ioannou, Antonio Criminisi, Roberto Cipolla
    * Abstract: Deep Convolutional Neural Networks (CNNs) have recently evinced immense success for various image recognition tasks. However, a question of paramount importance is somewhat unanswered in deep learning research - is the selected CNN optimal for the dataset in terms of accuracy and model size? In this paper, we intend to answer this question and introduce a novel strategy that alters the architecture of a given CNN for a specified dataset, to potentially enhance the original accuracy while possibly reducing the model size. We use two operations for architecture refinement, viz. stretching and symmetrical splitting. Stretching increases the number of hidden units (nodes) in a given CNN layer, while a symmetrical split of say K between two layers separates the input and output channels into K equal groups, and connects only the corresponding input-output channel groups. Our procedure starts with a pre-trained CNN for a given dataset, and optimally decides the stretch and split factors across the network to refine the architecture. We empirically demonstrate the necessity of the two operations. We evaluate our approach on two natural scenes attributes datasets, SUN Attributes and CAMIT-NSAD, with architectures of GoogleNet and VGG-11, that are quite contrasting in their construction. We justify our choice of datasets, and show that they are interestingly distinct from each other, and together pose a challenge to our architectural refinement algorithm. Our results substantiate the usefulness of the proposed method.
count=1
* Supervised Quantization for Similarity Search
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Wang_Supervised_Quantization_for_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Wang_Supervised_Quantization_for_CVPR_2016_paper.pdf)]
    * Title: Supervised Quantization for Similarity Search
    * Year: `2016`
    * Authors: Xiaojuan Wang, Ting Zhang, Guo-Jun Qi, Jinhui Tang, Jingdong Wang
    * Abstract: In this paper, we address the problem of searching for semantically similar images from a large database. We present a compact coding approach, supervised quantization. Our approach simultaneously learns feature selection that linearly transforms the database points into a low-dimensional discriminative subspace, and quantizes the data points in the transformed space. The optimization criterion is that the quantized points not only approximate the transformed points accurately, but also are semantically separable: the points belonging to a class lie in a cluster that is not overlapped with other clusters corresponding to other classes, which is formulated as a classification problem. The experiments on several standard datasets show the superiority of our approach over the state-of-the art supervised hashing and unsupervised quantization algorithms.
count=1
* Logistic Boosting Regression for Label Distribution Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Xing_Logistic_Boosting_Regression_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Xing_Logistic_Boosting_Regression_CVPR_2016_paper.pdf)]
    * Title: Logistic Boosting Regression for Label Distribution Learning
    * Year: `2016`
    * Authors: Chao Xing, Xin Geng, Hui Xue
    * Abstract: Label Distribution Learning (LDL) is a general learning framework which includes both single label and multi-label learning as its special cases. One of the main assumptions made in traditional LDL algorithms is the derivation of the parametric model as the maximum entropy model. While it is a reasonable assumption without additional information, there is no particular evidence supporting it in the problem of LDL. Alternatively, using a general LDL model family to approximate this parametric model can avoid the potential influence of the specific model. In order to learn this general model family, this paper uses a method called Logistic Boosting Regression (LogitBoost) which can be seen as an additive weighted function regression from the statistical viewpoint. For each step, we can fit individual weighted regression function (base learner) to realize the optimization gradually. The base learners are chosen as weighted regression tree and vector tree, which constitute two algorithms named LDLogitBoost and AOSO-LDLogitBoost in this paper. Experiments on facial expression recognition, crowd opinion prediction on movies and apparent age estimation show that LDLogitBoost and AOSO-LDLogitBoost can achieve better performance than traditional LDL algorithms as well as other LogitBoost algorithms.
count=1
* Efficient Training of Very Deep Neural Networks for Supervised Hashing
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Zhang_Efficient_Training_of_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Zhang_Efficient_Training_of_CVPR_2016_paper.pdf)]
    * Title: Efficient Training of Very Deep Neural Networks for Supervised Hashing
    * Year: `2016`
    * Authors: Ziming Zhang, Yuting Chen, Venkatesh Saligrama
    * Abstract: In this paper, we propose training very deep neural networks (DNNs) for supervised learning of hash codes. Existing methods in this context train relatively "shallow" networks limited by the issues arising in back propagation (e.g. vanishing gradients) as well as computational efficiency. We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations. Our method decomposes the training process into independent layer-wise local updates through auxiliary variables. Empirically we observe that our training algorithm always converges and its computational complexity is linearly proportional to the number of edges in the networks. Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU. Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-the-art on several benchmark datasets.
count=1
* Unconstrained Face Alignment via Cascaded Compositional Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/html/Zhu_Unconstrained_Face_Alignment_CVPR_2016_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2016/papers/Zhu_Unconstrained_Face_Alignment_CVPR_2016_paper.pdf)]
    * Title: Unconstrained Face Alignment via Cascaded Compositional Learning
    * Year: `2016`
    * Authors: Shizhan Zhu, Cheng Li, Chen-Change Loy, Xiaoou Tang
    * Abstract: We present a practical approach to address the problem of unconstrained face alignment for a single image. In our unconstrained problem, we need to deal with large shape and appearance variations under extreme head poses and rich shape deformation. To equip cascaded regressors with the capability to handle global shape variation and irregular appearance-shape relation in the unconstrained scenario, we partition the optimisation space into multiple domains of homogeneous descent, and predict a shape as a composition of estimations from multiple domain-specific regressors. With a specially formulated learning objective and a novel tree splitting function, our approach is capable of estimating a robust and meaningful composition. In addition to achieving state-of-the-art accuracy over existing approaches, our framework is also an efficient solution (350 FPS), thanks to the on-the-fly domain exclusion mechanism and the capability of leveraging the fast pixel feature.
count=1
* Hashing With Binary Autoencoders
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Carreira-Perpinan_Hashing_With_Binary_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Carreira-Perpinan_Hashing_With_Binary_2015_CVPR_paper.pdf)]
    * Title: Hashing With Binary Autoencoders
    * Year: `2015`
    * Authors: Miguel A. Carreira-Perpinan, Ramin Raziperchikolaei
    * Abstract: An attractive approach for fast search in image databases is binary hashing, where each high-dimensional, real-valued image is mapped onto a low-dimensional, binary vector and the search is done in this binary space. Finding the optimal hash function is difficult because it involves binary constraints, and most approaches approximate the optimization by relaxing the constraints and then binarizing the result. Here, we focus on the binary autoencoder model, which seeks to reconstruct an image from the binary code produced by the hash function. We show that the optimization can be simplified with the method of auxiliary coordinates. This reformulates the optimization as alternating two easier steps: one that learns the encoder and decoder separately, and one that optimizes the code for each image. Image retrieval experiments show the resulting hash function outperforms or is competitive with state-of-the-art methods for binary hashing.
count=1
* Image Parsing With a Wide Range of Classes and Scene-Level Context
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/George_Image_Parsing_With_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/George_Image_Parsing_With_2015_CVPR_paper.pdf)]
    * Title: Image Parsing With a Wide Range of Classes and Scene-Level Context
    * Year: `2015`
    * Authors: Marian George
    * Abstract: This paper presents a nonparametric scene parsing approach that improves the overall accuracy, as well as the coverage of foreground classes in scene images. We first improve the label likelihood estimates at superpixels by merging likelihood scores from different probabilistic classifiers. This boosts the classification performance and enriches the representation of less-represented classes. Our second contribution consists of incorporating semantic context in the parsing process through global label costs. Our method does not rely on image retrieval sets but rather assigns a global likelihood estimate to each label, which is plugged into the overall energy function. We evaluate our system on two large-scale datasets, SIFTflow and LMSun. We achieve state-of-the-art performance on the SIFTflow dataset and near-record results on LMSun.
count=1
* An Active Search Strategy for Efficient Object Class Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Gonzalez-Garcia_An_Active_Search_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Gonzalez-Garcia_An_Active_Search_2015_CVPR_paper.pdf)]
    * Title: An Active Search Strategy for Efficient Object Class Detection
    * Year: `2015`
    * Authors: Abel Gonzalez-Garcia, Alexander Vezhnevets, Vittorio Ferrari
    * Abstract: Object class detectors typically apply a window classifier to all the windows in a large set, either in a sliding window manner or using object proposals. In this paper, we develop an active search strategy that sequentially chooses the next window to evaluate based on all the information gathered before. This results in a substantial reduction in the number of classifier evaluations and in a more elegant approach in general. Our search strategy is guided by two forces. First, we exploit context as the statistical relation between the appearance of a window and its location relative to the object, as observed in the training set. This enables to jump across distant regions in the image (e.g. observing a sky region suggests that cars might be far below) and is done efficiently in a Random Forest framework. Second, we exploit the score of the classifier to attract the search to promising areas surrounding a highly scored window, and to keep away from areas near low scored ones. Our search strategy can be applied on top of any classifier as it treats it as a black-box. In experiments with R-CNN on the challenging SUN2012 dataset, our method matches the detection accuracy of evaluating all windows independently, while evaluating 9x fewer windows.
count=1
* Mapping Visual Features to Semantic Profiles for Retrieval in Medical Imaging
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Hofmanninger_Mapping_Visual_Features_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Hofmanninger_Mapping_Visual_Features_2015_CVPR_paper.pdf)]
    * Title: Mapping Visual Features to Semantic Profiles for Retrieval in Medical Imaging
    * Year: `2015`
    * Authors: Johannes Hofmanninger, Georg Langs
    * Abstract: Content based image retrieval is highly relevant in medical imaging, since it makes vast amounts of imaging data accessible for comparison during diagnosis. Finding image similarity measures that reflect diagnostically relevant relationships is challenging, since the overall appearance variability is high compared to often subtle signatures of diseases. To learn models that capture the relationship between semantic clinical information and image elements at scale, we have to rely on data generated during clinical routine (images and radiology reports), since expert annotation is prohibitively costly. Here we show that re-mapping visual features extracted from medical imaging data based on weak labels that can be found in corresponding radiology reports creates descriptions of local image content capturing clinically relevant information. We show that these semantic profiles enable higher recall and precision during retrieval compared to visual features, and that we can even map semantic terms describing clinical findings from radiology reports to localized image volume areas.
count=1
* Toward User-Specific Tracking by Detection of Human Shapes in Multi-Cameras
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Huang_Toward_User-Specific_Tracking_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Huang_Toward_User-Specific_Tracking_2015_CVPR_paper.pdf)]
    * Title: Toward User-Specific Tracking by Detection of Human Shapes in Multi-Cameras
    * Year: `2015`
    * Authors: Chun-Hao Huang, Edmond Boyer, Bibiana do Canto Angonese, Nassir Navab, Slobodan Ilic
    * Abstract: Human shape tracking consists in fitting a template model to temporal sequences of visual observations. It usually comprises an association step, that finds correspondences between the model and the input data, and a deformation step, that fits the model to the observations given correspondences. Most current approaches find their common ground with the Iterative-Closest-Point (ICP) algorithm, which facilitates the association step with local distance considerations. It fails when large deformations occur, and errors in the association tend to propagate over time. In this paper, we propose a discriminative alternative for the association, that leverages random forests to infer correspondences in one shot. It allows for large deformations and prevents tracking errors from accumulating. The approach is successfully integrated to a surface tracking framework that recovers human shapes and poses jointly. When combined with ICP, this discriminative association proves to yield better accuracy in registration, more stability when tracking over time, and faster convergence. Evaluations on existing datasets demonstrate the benefits with respect to the state-of-the-art.
count=1
* Multispectral Pedestrian Detection: Benchmark Dataset and Baseline
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Hwang_Multispectral_Pedestrian_Detection_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Hwang_Multispectral_Pedestrian_Detection_2015_CVPR_paper.pdf)]
    * Title: Multispectral Pedestrian Detection: Benchmark Dataset and Baseline
    * Year: `2015`
    * Authors: Soonmin Hwang, Jaesik Park, Namil Kim, Yukyung Choi, In So Kweon
    * Abstract: With the increasing interest in pedestrian detection, pedestrian datasets have also been the subject of research in the past decades. However, most existing datasets focus on a color channel, while a thermal channel is helpful for detection even in a dark environment. With this in mind, we propose a multispectral pedestrian dataset which provides well aligned color-thermal image pairs, captured by beam splitter-based special hardware. The color-thermal dataset is as large as previous color-based datasets and provides dense annotations including temporal correspondences. With this dataset, we introduce multispectral ACF, which is an extension of aggregated channel features (ACF) to simultaneously handle color-thermal image pairs. Multispectral ACF reduces the average miss rate of ACF by 15%, and achieves another breakthrough in the pedestrian detection task.
count=1
* A Convolutional Neural Network Cascade for Face Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Li_A_Convolutional_Neural_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Li_A_Convolutional_Neural_2015_CVPR_paper.pdf)]
    * Title: A Convolutional Neural Network Cascade for Face Detection
    * Year: `2015`
    * Authors: Haoxiang Li, Zhe Lin, Xiaohui Shen, Jonathan Brandt, Gang Hua
    * Abstract: In real-world face detection, large visual variations, such as those due to pose, expression, and lighting, demand an advanced discriminative model to accurately differentiate faces from the backgrounds. Consequently, effective models for the problem tend to be computationally prohibitive. To address these two conflicting challenges, we propose a cascade architecture built on convolutional neural networks (CNNs) with very powerful discriminative capability, while maintaining high performance. The proposed CNN cascade operates at multiple resolutions, quickly rejects the background regions in the fast low resolution stages, and carefully evaluates a small number of challenging candidates in the last high resolution stage. To improve localization effectiveness, and reduce the number of candidates at later stages, we introduce a CNN-based calibration stage after each of the detection stages in the cascade. The output of each calibration stage is used to adjust the detection window position for input to the subsequent stage. The proposed method runs at 14 FPS on a single CPU core for VGA-resolution images and 100 FPS using a GPU, and achieves state-of-the-art detection performance on two public face detection benchmarks.
count=1
* Semantics-Preserving Hashing for Cross-View Retrieval
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Lin_Semantics-Preserving_Hashing_for_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Lin_Semantics-Preserving_Hashing_for_2015_CVPR_paper.pdf)]
    * Title: Semantics-Preserving Hashing for Cross-View Retrieval
    * Year: `2015`
    * Authors: Zijia Lin, Guiguang Ding, Mingqing Hu, Jianmin Wang
    * Abstract: With benefits of low storage costs and high query speeds, hashing methods are widely researched for efficiently retrieving large-scale data, which commonly contains multiple views, e.g. a news report with images, videos and texts. In this paper, we study the problem of cross-view retrieval and propose an effective Semantics-Preserving Hashing method, termed SePH. Given semantic affinities of training data as supervised information, SePH transforms them into a probability distribution and approximates it with to-be-learnt hash codes in Hamming space via minimizing the Kullback-Leibler divergence. Then kernel logistic regression with a sampling strategy is utilized to learn the nonlinear projections from features in each view to the learnt hash codes. And for any unseen instance, predicted hash codes and their corresponding output probabilities from observed views are utilized to determine its unified hash code, using a novel probabilistic approach. Extensive experiments conducted on three benchmark datasets well demonstrate the effectiveness and reasonableness of SePH.
count=1
* Joint Calibration of Ensemble of Exemplar SVMs
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Modolo_Joint_Calibration_of_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Modolo_Joint_Calibration_of_2015_CVPR_paper.pdf)]
    * Title: Joint Calibration of Ensemble of Exemplar SVMs
    * Year: `2015`
    * Authors: Davide Modolo, Alexander Vezhnevets, Olga Russakovsky, Vittorio Ferrari
    * Abstract: We present a method for calibrating the Ensemble of Exemplar SVMs model. Unlike the standard approach, which calibrates each SVM independently, our method optimizes their joint performance as an ensemble. We formulate joint calibration as a constrained optimization problem and devise an efficient optimization algorithm to find its global optimum. The algorithm dynamically discards parts of the solution space that cannot contain the optimum early on, making the optimization computationally feasible. We experiment with EE-SVM trained on state-of-the-art CNN descriptors. Results on the ILSVRC 2014 and PASCAL VOC 2007 datasets show that (i) our joint calibration procedure outperforms independent calibration on the task of classifying windows as belonging to an object class or not; and (ii) this improved window classifier leads to better performance on the object detection task.
count=1
* Discriminative and Consistent Similarities in Instance-Level Multiple Instance Learning
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Rastegari_Discriminative_and_Consistent_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Rastegari_Discriminative_and_Consistent_2015_CVPR_paper.pdf)]
    * Title: Discriminative and Consistent Similarities in Instance-Level Multiple Instance Learning
    * Year: `2015`
    * Authors: Mohammad Rastegari, Hannaneh Hajishirzi, Ali Farhadi
    * Abstract: In this paper we present a bottom-up method to instance-level Multiple Instance Learning (MIL) that learns to discover positive instances with globally constrained reasoning about local pairwise similarities. We discover positive instances by optimizing for a ranking such that positive (top rank) instances are {\it highly and consistently similar} to each other and dissimilar to negative instances. Our approach takes advantage of a discriminative notion of pairwise similarity coupled with a structural cue in the form of a consistency metric that measures the quality of each similarity. We learn a similarity function for every pair of instances in positive bags by how similarly they differ from instances in negative bags, the only certain labels in MIL. Our experiments demonstrate that our method consistently outperforms state-of-the-art MIL methods both at bag-level and instance-level predictions in standard benchmarks, image category recognition, and text categorization datasets.
count=1
* From Categories to Subcategories: Large-Scale Image Classification With Partial Class Label Refinement
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Ristin_From_Categories_to_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Ristin_From_Categories_to_2015_CVPR_paper.pdf)]
    * Title: From Categories to Subcategories: Large-Scale Image Classification With Partial Class Label Refinement
    * Year: `2015`
    * Authors: Marko Ristin, Juergen Gall, Matthieu Guillaumin, Luc Van Gool
    * Abstract: The number of digital images is growing extremely rapidly, and so is the need for their classification. But, as more images of pre-defined categories become available, they also become more diverse and cover finer semantic differences. Ultimately, the categories themselves need to be divided into subcategories to account for that semantic refinement. Image classification in general has improved significantly over the last few years, but it still requires a massive amount of manually annotated data. Subdividing categories into subcategories multiples the number of labels, aggravating the annotation problem. Hence, we can expect the annotations to be refined only for a subset of the already labeled data, and exploit coarser labeled data to improve classification. In this work, we investigate how coarse category labels can be used to improve the classification of subcategories. To this end, we adopt the framework of Random Forests and propose a regularized objective function that takes into account relations between categories and subcategories. Compared to approaches that disregard the extra coarse labeled data, we achieve a relative improvement in subcategory classification accuracy of up to 22% in our large-scale image classification experiments.
count=1
* PAIGE: PAirwise Image Geometry Encoding for Improved Efficiency in Structure-From-Motion
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Schonberger_PAIGE_PAirwise_Image_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Schonberger_PAIGE_PAirwise_Image_2015_CVPR_paper.pdf)]
    * Title: PAIGE: PAirwise Image Geometry Encoding for Improved Efficiency in Structure-From-Motion
    * Year: `2015`
    * Authors: Johannes L. Schonberger, Alexander C. Berg, Jan-Michael Frahm
    * Abstract: Large-scale Structure-from-Motion systems typically spend major computational effort on pairwise image matching and geometric verification in order to discover connected components in large-scale, unordered image collections. In recent years, the research community has spent significant effort on improving the efficiency of this stage. In this paper, we present a comprehensive overview of various state-of-the-art methods, evaluating and analyzing their performance. Based on the insights of this evaluation, we propose a learning-based approach, the PAirwise Image Geometry Encoding (PAIGE), to efficiently identify image pairs with scene overlap without the need to perform exhaustive putative matching and geometric verification. PAIGE achieves state-of-the-art performance and integrates well into existing Structure-from-Motion pipelines.
count=1
* Supervised Discrete Hashing
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Shen_Supervised_Discrete_Hashing_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Shen_Supervised_Discrete_Hashing_2015_CVPR_paper.pdf)]
    * Title: Supervised Discrete Hashing
    * Year: `2015`
    * Authors: Fumin Shen, Chunhua Shen, Wei Liu, Heng Tao Shen
    * Abstract: Recently, learning based hashing techniques have attracted broad research interests due to the resulting efficient storage and retrieval of images, videos, documents, etc. However, a major difficulty of learning to hash lies in handling the discrete constraints imposed on the needed hash codes, which typically makes hash optimizations very challenging (NP-hard in general). In this work, we propose a new supervised hashing framework, where the learning objective for hashing is to make the optimal binary hash codes for classification. By introducing an auxiliary variable, we reformulate the objective such that it can be solved substantially efficiently by using a regularization algorithm. One of the key steps in the algorithm is to solve the regularization sub-problem associated with the NP-hard binary optimization. We show that with cyclic coordinate descent, the sub-problem admits an analytical solution. As such, a high-quality discrete solution can eventually be obtained in an efficient computing manner, which enables to tackle massive datasets. We evaluate the proposed approach, dubbed Supervised Discrete Hashing (SDH), on four large image datasets, and demonstrate that SDH outperforms the state-of-the-art hashing methods in large-scale image retrieval.
count=1
* Exploiting Uncertainty in Regression Forests for Accurate Camera Relocalization
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/html/Valentin_Exploiting_Uncertainty_in_2015_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2015/papers/Valentin_Exploiting_Uncertainty_in_2015_CVPR_paper.pdf)]
    * Title: Exploiting Uncertainty in Regression Forests for Accurate Camera Relocalization
    * Year: `2015`
    * Authors: Julien Valentin, Matthias Niessner, Jamie Shotton, Andrew Fitzgibbon, Shahram Izadi, Philip H. S. Torr
    * Abstract: Recent advances in camera relocalization use predictions from a regression forest to guide the camera pose optimization procedure. In these methods, each tree associates one pixel with a point in the scene's 3D world coordinate frame. In previous work, these predictions were point estimates and the subsequent camera pose optimization implicitly assumed an isotropic distribution of these estimates. In this paper, we train a regression forest to predict mixtures of anisotropic 3D Gaussians and show how the predicted uncertainties can be taken into account for continuous pose optimization. Experiments show that our proposed method is able to relocalize up to 40% more frames than the state-of-the-art.
count=1
* Confidence-Rated Multiple Instance Boosting for Object Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Ali_Confidence-Rated_Multiple_Instance_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Ali_Confidence-Rated_Multiple_Instance_2014_CVPR_paper.pdf)]
    * Title: Confidence-Rated Multiple Instance Boosting for Object Detection
    * Year: `2014`
    * Authors: Karim Ali, Kate Saenko
    * Abstract: Over the past years, Multiple Instance Learning (MIL) has proven to be an effective framework for learning with weakly labeled data. Applications of MIL to object detection, however, were limited to handling the uncertainties of manual annotations. In this paper, we propose a new MIL method for object detection that is capable of handling the noisier automatically obtained annotations. Our approach consists in first obtaining confidence estimates over the label space and, second, incorporating these estimates within a new Boosting procedure. We demonstrate the efficiency of our procedure on two detection tasks, namely, horse detection and pedestrian detection, where the training data is primarily annotated by a coarse area of interest detector. We show dramatic improvements over existing MIL methods. In both cases, we demonstrate that an efficient appearance model can be learned using our approach.
count=1
* Efficient Structured Parsing of Facades Using Dynamic Programming
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Cohen_Efficient_Structured_Parsing_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Cohen_Efficient_Structured_Parsing_2014_CVPR_paper.pdf)]
    * Title: Efficient Structured Parsing of Facades Using Dynamic Programming
    * Year: `2014`
    * Authors: Andrea Cohen, Alexander G. Schwing, Marc Pollefeys
    * Abstract: We propose a sequential optimization technique for segmenting a rectified image of a facade into semantic categories. Our method retrieves a parsing which respects common architectural constraints and also returns a certificate for global optimality. Contrasting the suggested method, the considered facade labeling problem is typically tackled as a classification task or as grammar parsing. Both approaches are not capable of fully exploiting the regularity of the problem. Therefore, our technique very significantly improves the accuracy compared to the state-of-the-art while being an order of magnitude faster. In addition, in 85% of the test images we obtain a certificate for optimality.
count=1
* Discrete-Continuous Gradient Orientation Estimation for Faster Image Segmentation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Donoser_Discrete-Continuous_Gradient_Orientation_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Donoser_Discrete-Continuous_Gradient_Orientation_2014_CVPR_paper.pdf)]
    * Title: Discrete-Continuous Gradient Orientation Estimation for Faster Image Segmentation
    * Year: `2014`
    * Authors: Michael Donoser, Dieter Schmalstieg
    * Abstract: The state-of-the-art in image segmentation builds hierarchical segmentation structures based on analyzing local feature cues in spectral settings. Due to their impressive performance, such segmentation approaches have become building blocks in many computer vision applications. Nevertheless, the main bottlenecks are still the computationally demanding processes of local feature processing and spectral analysis. In this paper, we demonstrate that based on a discrete-continuous optimization of oriented gradient signals, we are able to provide segmentation performance competitive to state-of-the-art on BSDS 500 (even without any spectral analysis) while reducing computation time by a factor of 40 and memory demands by a factor of 10.
count=1
* Predicting Matchability
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Hartmann_Predicting_Matchability_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Hartmann_Predicting_Matchability_2014_CVPR_paper.pdf)]
    * Title: Predicting Matchability
    * Year: `2014`
    * Authors: Wilfried Hartmann, Michal Havlena, Konrad Schindler
    * Abstract: The initial steps of many computer vision algorithms are interest point extraction and matching. In larger image sets the pairwise matching of interest point descriptors between images is an important bottleneck. For each descriptor in one image the (approximate) nearest neighbor in the other one has to be found and checked against the second-nearest neighbor to ensure the correspondence is unambiguous. Here, we asked the question how to best decimate the list of interest points without losing matches, i.e. we aim to speed up matching by filtering out, in advance, those points which would not survive the matching stage. It turns out that the best filtering criterion is not the response of the interest point detector, which in fact is not surprising: the goal of detection are repeatable and well-localized points, whereas the objective of the selection are points whose descriptors can be matched successfully. We show that one can in fact learn to predict which descriptors are matchable, and thus reduce the number of interest points significantly without losing too many matches. We show that this strategy, as simple as it is, greatly improves the matching success with the same number of points per image. Moreover, we embed the prediction in a state-of-the-art Structure-from-Motion pipeline and demonstrate that it also outperforms other selection methods at system level.
count=1
* Discrete-Continuous Depth Estimation from a Single Image
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Liu_Discrete-Continuous_Depth_Estimation_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Liu_Discrete-Continuous_Depth_Estimation_2014_CVPR_paper.pdf)]
    * Title: Discrete-Continuous Depth Estimation from a Single Image
    * Year: `2014`
    * Authors: Miaomiao Liu, Mathieu Salzmann, Xuming He
    * Abstract: In this paper, we tackle the problem of estimating the depth of a scene from a single image. This is a challenging task, since a single image on its own does not provide any depth cue. To address this, we exploit the availability of a pool of images for which the depth is known. More specifically, we formulate monocular depth estimation as a discrete-continuous optimization problem, where the continuous variables encode the depth of the superpixels in the input image, and the discrete ones represent relationships between neighboring superpixels. The solution to this discrete-continuous optimization problem is then obtained by performing inference in a graphical model using particle belief propagation. The unary potentials in this graphical model are computed by making use of the images with known depth. We demonstrate the effectiveness of our model in both the indoor and outdoor scenarios. Our experimental evaluation shows that our depth estimates are more accurate than existing methods on standard datasets.
count=1
* Learning Optimal Seeds for Diffusion-based Salient Object Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Lu_Learning_Optimal_Seeds_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Lu_Learning_Optimal_Seeds_2014_CVPR_paper.pdf)]
    * Title: Learning Optimal Seeds for Diffusion-based Salient Object Detection
    * Year: `2014`
    * Authors: Song Lu, Vijay Mahadevan, Nuno Vasconcelos
    * Abstract: In diffusion-based saliency detection, an image is partitioned into superpixels and mapped to a graph, with superpixels as nodes and edge strengths proportional to superpixel similarity. Saliency information is then propagated over the graph using a diffusion process, whose equilibrium state yields the object saliency map. The optimal solution is the product of a propagation matrix and a saliency seed vector that contains a prior saliency assessment. This is obtained from either a bottom-up saliency detector or some heuristics. In this work, we propose a method to learn optimal seeds for object saliency. Two types of features are computed per superpixel: the bottom-up saliency of the superpixel region and a set of mid-level vision features informative of how likely the superpixel is to belong to an object. The combination of features that best discriminates between object and background saliency is then learned, using a large-margin formulation of the discriminant saliency principle. The propagation of the resulting saliency seeds, using a diffusion process, is finally shown to outperform the state of the art on a number of salient object detection datasets.
count=1
* Sign Spotting using Hierarchical Sequential Patterns with Temporal Intervals
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Ong_Sign_Spotting_using_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Ong_Sign_Spotting_using_2014_CVPR_paper.pdf)]
    * Title: Sign Spotting using Hierarchical Sequential Patterns with Temporal Intervals
    * Year: `2014`
    * Authors: Eng-Jon Ong, Oscar Koller, Nicolas Pugeault, Richard Bowden
    * Abstract: This paper tackles the problem of spotting a set of signs occuring in videos with sequences of signs. To achieve this, we propose to model the spatio-temporal signatures of a sign using an extension of sequential patterns that contain temporal intervals called {\em Sequential Interval Patterns} (SIP). We then propose a novel multi-class classifier that organises different sequential interval patterns in a hierarchical tree structure called a Hierarchical SIP Tree (HSP-Tree). This allows one to exploit any subsequence sharing that exists between different SIPs of different classes. Multiple trees are then combined together into a forest of HSP-Trees resulting in a strong classifier that can be used to spot signs. We then show how the HSP-Forest can be used to spot sequences of signs that occur in an input video. We have evaluated the method on both concatenated sequences of isolated signs and continuous sign sequences. We also show that the proposed method is superior in robustness and accuracy to a state of the art sign recogniser when applied to spotting a sequence of signs.
count=1
* Incremental Learning of NCM Forests for Large-Scale Image Classification
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Ristin_Incremental_Learning_of_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Ristin_Incremental_Learning_of_2014_CVPR_paper.pdf)]
    * Title: Incremental Learning of NCM Forests for Large-Scale Image Classification
    * Year: `2014`
    * Authors: Marko Ristin, Matthieu Guillaumin, Juergen Gall, Luc Van Gool
    * Abstract: In recent years, large image data sets such as "ImageNet", "TinyImages" or ever-growing social networks like "Flickr" have emerged, posing new challenges to image classification that were not apparent in smaller image sets. In particular, the efficient handling of dynamically growing data sets, where not only the amount of training images, but also the number of classes increases over time, is a relatively unexplored problem. To remedy this, we introduce Nearest Class Mean Forests (NCMF), a variant of Random Forests where the decision nodes are based on nearest class mean (NCM) classification. NCMFs not only outperform conventional random forests, but are also well suited for integrating new classes. To this end, we propose and compare several approaches to incorporate data from new classes, so as to seamlessly extend the previously trained forest instead of re-training them from scratch. In our experiments, we show that NCMFs trained on small data sets with 10 classes can be extended to large data sets with 1000 classes without significant loss of accuracy compared to training from scratch on the full data.
count=1
* Learning to Detect Ground Control Points for Improving the Accuracy of Stereo Matching
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Spyropoulos_Learning_to_Detect_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Spyropoulos_Learning_to_Detect_2014_CVPR_paper.pdf)]
    * Title: Learning to Detect Ground Control Points for Improving the Accuracy of Stereo Matching
    * Year: `2014`
    * Authors: Aristotle Spyropoulos, Nikos Komodakis, Philippos Mordohai
    * Abstract: While machine learning has been instrumental to the ongoing progress in most areas of computer vision, it has not been applied to the problem of stereo matching with similar frequency or success. We present a supervised learning approach for predicting the correctness of stereo matches based on a random forest and a set of features that capture various forms of information about each pixel. We show highly competitive results in predicting the correctness of matches and in confidence estimation, which allows us to rank pixels according to the reliability of their assigned disparities. Moreover, we show how these confidence values can be used to improve the accuracy of disparity maps by integrating them with an MRF-based stereo algorithm. This is an important distinction from current literature that has mainly focused on sparsification by removing potentially erroneous disparities to generate quasi-dense disparity maps.
count=1
* Learning-by-Synthesis for Appearance-based 3D Gaze Estimation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Sugano_Learning-by-Synthesis_for_Appearance-based_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Sugano_Learning-by-Synthesis_for_Appearance-based_2014_CVPR_paper.pdf)]
    * Title: Learning-by-Synthesis for Appearance-based 3D Gaze Estimation
    * Year: `2014`
    * Authors: Yusuke Sugano, Yasuyuki Matsushita, Yoichi Sato
    * Abstract: Inferring human gaze from low-resolution eye images is still a challenging task despite its practical importance in many application scenarios. This paper presents a learning-by-synthesis approach to accurate image-based gaze estimation that is person- and head pose-independent. Unlike existing appearance-based methods that assume person-specific training data, we use a large amount of cross-subject training data to train a 3D gaze estimator. We collect the largest and fully calibrated multi-view gaze dataset and perform a 3D reconstruction in order to generate dense training data of eye images. By using the synthesized dataset to learn a random regression forest, we show that our method outperforms existing methods that use low-resolution eye images.
count=1
* Histograms of Pattern Sets for Image Classification and Object Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Voravuthikunchai_Histograms_of_Pattern_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Voravuthikunchai_Histograms_of_Pattern_2014_CVPR_paper.pdf)]
    * Title: Histograms of Pattern Sets for Image Classification and Object Recognition
    * Year: `2014`
    * Authors: Winn Voravuthikunchai, Bruno Cremilleux, Frederic Jurie
    * Abstract: This paper introduces a novel image representation capturing feature dependencies through the mining of meaningful combinations of visual features. This representation leads to a compact and discriminative encoding of images that can be used for image classification, object detection or object recognition. The method relies on (i) multiple random projections of the input space followed by local binarization of projected histograms encoded as sets of items, and (ii) the representation of images as Histograms of Pattern Sets (HoPS). The approach is validated on four publicly available datasets (Daimler Pedestrian, Oxford Flowers, KTH Texture and PASCAL VOC2007), allowing comparisons with many recent approaches. The proposed image representation reaches state-of-the-art performance on each one of these datasets.
count=1
* Shadow Removal from Single RGB-D Images
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/html/Xiao_Shadow_Removal_from_2014_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2014/papers/Xiao_Shadow_Removal_from_2014_CVPR_paper.pdf)]
    * Title: Shadow Removal from Single RGB-D Images
    * Year: `2014`
    * Authors: Yao Xiao, Efstratios Tsougenis, Chi-Keung Tang
    * Abstract: We present the first automatic method to remove shadows from single RGB-D images. Using normal cues directly derived from depth, we can remove hard and soft shadows while preserving surface texture and shading. Our key assumption is: pixels with similar normals, spatial locations and chromaticity should have similar colors. A modified nonlocal matching is used to compute a shadow confidence map that localizes well hard shadow boundary, thus handling hard and soft shadows within the same framework. We compare our results produced using state-of-the-art shadow removal on single RGB images, and intrinsic image decomposition on standard RGB-D datasets.
count=1
* Augmenting Bag-of-Words: Data-Driven Discovery of Temporal and Structural Information for Activity Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Bettadapura_Augmenting_Bag-of-Words_Data-Driven_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Bettadapura_Augmenting_Bag-of-Words_Data-Driven_2013_CVPR_paper.pdf)]
    * Title: Augmenting Bag-of-Words: Data-Driven Discovery of Temporal and Structural Information for Activity Recognition
    * Year: `2013`
    * Authors: Vinay Bettadapura, Grant Schindler, Thomas Ploetz, Irfan Essa
    * Abstract: We present data-driven techniques to augment Bag of Words (BoW) models, which allow for more robust modeling and recognition of complex long-term activities, especially when the structure and topology of the activities are not known a priori. Our approach specifically addresses the limitations of standard BoW approaches, which fail to represent the underlying temporal and causal information that is inherent in activity streams. In addition, we also propose the use of randomly sampled regular expressions to discover and encode patterns in activities. We demonstrate the effectiveness of our approach in experimental evaluations where we successfully recognize activities and detect anomalies in four complex datasets.
count=1
* Human Pose Estimation Using Body Parts Dependent Joint Regressors
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Dantone_Human_Pose_Estimation_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Dantone_Human_Pose_Estimation_2013_CVPR_paper.pdf)]
    * Title: Human Pose Estimation Using Body Parts Dependent Joint Regressors
    * Year: `2013`
    * Authors: Matthias Dantone, Juergen Gall, Christian Leistner, Luc Van Gool
    * Abstract: In this work, we address the problem of estimating 2d human pose from still images. Recent methods that rely on discriminatively trained deformable parts organized in a tree model have shown to be very successful in solving this task. Within such a pictorial structure framework, we address the problem of obtaining good part templates by proposing novel, non-linear joint regressors. In particular, we employ two-layered random forests as joint regressors. The first layer acts as a discriminative, independent body part classifier. The second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This results in a pose estimation framework that takes dependencies between body parts already for joint localization into account and is thus able to circumvent typical ambiguities of tree structures, such as for legs and arms. In the experiments, we demonstrate that our body parts dependent joint regressors achieve a higher joint localization accuracy than tree-based state-of-the-art methods.
count=1
* Learning Collections of Part Models for Object Recognition
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Endres_Learning_Collections_of_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Endres_Learning_Collections_of_2013_CVPR_paper.pdf)]
    * Title: Learning Collections of Part Models for Object Recognition
    * Year: `2013`
    * Authors: Ian Endres, Kevin J. Shih, Johnston Jiaa, Derek Hoiem
    * Abstract: We propose a method to learn a diverse collection of discriminative parts from object bounding box annotations. Part detectors can be trained and applied individually, which simplifies learning and extension to new features or categories. We apply the parts to object category detection, pooling part detections within bottom-up proposed regions and using a boosted classifier with proposed sigmoid weak learners for scoring. On PASCAL VOC 2010, we evaluate the part detectors' ability to discriminate and localize annotated keypoints. Our detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories.
count=1
* Tracking Sports Players with Context-Conditioned Motion Models
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Liu_Tracking_Sports_Players_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Liu_Tracking_Sports_Players_2013_CVPR_paper.pdf)]
    * Title: Tracking Sports Players with Context-Conditioned Motion Models
    * Year: `2013`
    * Authors: Jingchen Liu, Peter Carr, Robert T. Collins, Yanxi Liu
    * Abstract: We employ hierarchical data association to track players in team sports. Player movements are often complex and highly correlated with both nearby and distant players. A single model would require many degrees of freedom to represent the full motion diversity and could be difficult to use in practice. Instead, we introduce a set of Game Context Features extracted from noisy detections to describe the current state of the match, such as how the players are spatially distributed. Our assumption is that players react to the current situation in only a finite number of ways. As a result, we are able to select an appropriate simplified affinity model for each player and time instant using a random decision forest based on current track and game context features. Our context-conditioned motion models implicitly incorporate complex inter-object correlations while remaining tractable. We demonstrate significant performance improvements over existing multi-target tracking algorithms on basketball and field hockey sequences several minutes in duration and containing 10 and 20 players respectively.
count=1
* Tensor-Based High-Order Semantic Relation Transfer for Semantic Scene Segmentation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Myeong_Tensor-Based_High-Order_Semantic_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Myeong_Tensor-Based_High-Order_Semantic_2013_CVPR_paper.pdf)]
    * Title: Tensor-Based High-Order Semantic Relation Transfer for Semantic Scene Segmentation
    * Year: `2013`
    * Authors: Heesoo Myeong, Kyoung Mu Lee
    * Abstract: We propose a novel nonparametric approach for semantic segmentation using high-order semantic relations. Conventional context models mainly focus on learning pairwise relationships between objects. Pairwise relations, however, are not enough to represent high-level contextual knowledge within images. In this paper, we propose semantic relation transfer, a method to transfer high-order semantic relations of objects from annotated images to unlabeled images analogous to label transfer techniques where label information are transferred. We first define semantic tensors representing high-order relations of objects. Semantic relation transfer problem is then formulated as semi-supervised learning using a quadratic objective function of the semantic tensors. By exploiting low-rank property of the semantic tensors and employing Kronecker sum similarity, an efficient approximation algorithm is developed. Based on the predicted high-order semantic relations, we reason semantic segmentation and evaluate the performance on several challenging datasets.
count=1
* Histograms of Sparse Codes for Object Detection
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Ren_Histograms_of_Sparse_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Ren_Histograms_of_Sparse_2013_CVPR_paper.pdf)]
    * Title: Histograms of Sparse Codes for Object Detection
    * Year: `2013`
    * Authors: Xiaofeng Ren, Deva Ramanan
    * Abstract: Object detection has seen huge progress in recent years, much thanks to the heavily-engineered Histograms of Oriented Gradients (HOG) features. Can we go beyond gradients and do better than HOG? We provide an affirmative answer by proposing and investigating a sparse representation for object detection, Histograms of Sparse Codes (HSC). We compute sparse codes with dictionaries learned from data using K-SVD, and aggregate per-pixel sparse codes to form local histograms. We intentionally keep true to the sliding window framework (with mixtures and parts) and only change the underlying features. To keep training (and testing) efficient, we apply dimension reduction by computing SVD on learned models, and adopt supervised training where latent positions of roots and parts are given externally e.g. from a HOG-based detector. By learning and using local representations that are much more expressive than gradients, we demonstrate large improvements over the state of the art on the PASCAL benchmark for both rootonly and part-based models.
count=1
* Spatial Inference Machines
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Shapovalov_Spatial_Inference_Machines_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Shapovalov_Spatial_Inference_Machines_2013_CVPR_paper.pdf)]
    * Title: Spatial Inference Machines
    * Year: `2013`
    * Authors: Roman Shapovalov, Dmitry Vetrov, Pushmeet Kohli
    * Abstract: This paper addresses the problem of semantic segmentation of 3D point clouds. We extend the inference machines framework of Ross et al. by adding spatial factors that model mid-range and long-range dependencies inherent in the data. The new model is able to account for semantic spatial context. During training, our method automatically isolates and retains factors modelling spatial dependencies between variables that are relevant for achieving higher prediction accuracy. We evaluate the proposed method by using it to predict 17-category semantic segmentations on sets of stitched Kinect scans. Experimental results show that the spatial dependencies learned by our method significantly improve the accuracy of segmentation. They also show that our method outperforms the existing segmentation technique of Koppula et al.
count=1
* Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Shotton_Scene_Coordinate_Regression_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Shotton_Scene_Coordinate_Regression_2013_CVPR_paper.pdf)]
    * Title: Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images
    * Year: `2013`
    * Authors: Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, Andrew Fitzgibbon
    * Abstract: We address the problem of inferring the pose of an RGB-D camera relative to a known 3D scene, given only a single acquired image. Our approach employs a regression forest that is capable of inferring an estimate of each pixel's correspondence to 3D points in the scene's world coordinate frame. The forest uses only simple depth and RGB pixel comparison features, and does not require the computation of feature descriptors. The forest is trained to be capable of predicting correspondences at any pixel, so no interest point detectors are required. The camera pose is inferred using a robust optimization scheme. This starts with an initial set of hypothesized camera poses, constructed by applying the forest at a small fraction of image pixels. Preemptive RANSAC then iterates sampling more pixels at which to evaluate the forest, counting inliers, and refining the hypothesized poses. We evaluate on several varied scenes captured with an RGB-D camera and observe that the proposed technique achieves highly accurate relocalization and substantially out-performs two state of the art baselines.
count=1
* Fast Object Detection with Entropy-Driven Evaluation
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Sznitman_Fast_Object_Detection_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Sznitman_Fast_Object_Detection_2013_CVPR_paper.pdf)]
    * Title: Fast Object Detection with Entropy-Driven Evaluation
    * Year: `2013`
    * Authors: Raphael Sznitman, Carlos Becker, Francois Fleuret, Pascal Fua
    * Abstract: Cascade-style approaches to implementing ensemble classifiers can deliver significant speed-ups at test time. While highly effective, they remain challenging to tune and their overall performance depends on the availability of large validation sets to estimate rejection thresholds. These characteristics are often prohibitive and thus limit their applicability. We introduce an alternative approach to speeding-up classifier evaluation which overcomes these limitations. It involves maintaining a probability estimate of the class label at each intermediary response and stopping when the corresponding uncertainty becomes small enough. As a result, the evaluation terminates early based on the sequence of responses observed. Furthermore, it does so independently of the type of ensemble classifier used or the way it was trained. We show through extensive experimentation that our method provides 2 to 10 fold speed-ups, over existing state-of-the-art methods, at almost no loss in accuracy on a number of object classification tasks.
count=1
* Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Wanner_Globally_Consistent_Multi-label_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Wanner_Globally_Consistent_Multi-label_2013_CVPR_paper.pdf)]
    * Title: Globally Consistent Multi-label Assignment on the Ray Space of 4D Light Fields
    * Year: `2013`
    * Authors: Sven Wanner, Christoph Straehle, Bastian Goldluecke
    * Abstract: We present the first variational framework for multi-label segmentation on the ray space of 4D light fields. For traditional segmentation of single images, features need to be extracted from the 2D projection of a three-dimensional scene. The associated loss of geometry information can cause severe problems, for example if different objects have a very similar visual appearance. In this work, we show that using a light field instead of an image not only enables to train classifiers which can overcome many of these problems, but also provides an optimal data structure for label optimization by implicitly providing scene geometry information. It is thus possible to consistently optimize label assignment over all views simultaneously. As a further contribution, we make all light fields available online with complete depth and segmentation ground truth data where available, and thus establish the first benchmark data set for light field analysis to facilitate competitive further development of algorithms.
count=1
* Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest
    [[abs-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/html/Yu_Unconstrained_Monocular_3D_2013_CVPR_paper.html)]
    [[pdf-CVPR](https://openaccess.thecvf.com/content_cvpr_2013/papers/Yu_Unconstrained_Monocular_3D_2013_CVPR_paper.pdf)]
    * Title: Unconstrained Monocular 3D Human Pose Estimation by Action Detection and Cross-Modality Regression Forest
    * Year: `2013`
    * Authors: Tsz-Ho Yu, Tae-Kyun Kim, Roberto Cipolla
    * Abstract: This work addresses the challenging problem of unconstrained 3D human pose estimation (HPE) from a novel perspective. Existing approaches struggle to operate in realistic applications, mainly due to their scene-dependent priors, such as background segmentation and multi-camera network, which restrict their use in unconstrained environments. We therfore present a framework which applies action detection and 2D pose estimation techniques to infer 3D poses in an unconstrained video. Action detection offers spatiotemporal priors to 3D human pose estimation by both recognising and localising actions in space-time. Instead of holistic features, e.g. silhouettes, we leverage the flexibility of deformable part model to detect 2D body parts as a feature to estimate 3D poses. A new unconstrained pose dataset has been collected to justify the feasibility of our method, which demonstrated promising results, significantly outperforming the relevant state-of-the-arts.
count=1
* FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.pdf)]
    * Title: FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods
    * Year: `2023`
    * Authors: Robin Hesse, Simone Schaub-Meyer, Stefan Roth
    * Abstract: The field of explainable artificial intelligence (XAI) aims to uncover the inner workings of complex deep neural models. While being crucial for safety-critical domains, XAI inherently lacks ground-truth explanations, making its automatic evaluation an unsolved problem. We address this challenge by proposing a novel synthetic vision dataset, named FunnyBirds, and accompanying automatic evaluation protocols. Our dataset allows performing semantically meaningful image interventions, e.g., removing individual object parts, which has three important implications. First, it enables analyzing explanations on a part level, which is closer to human comprehension than existing methods that evaluate on a pixel level. Second, by comparing the model output for inputs with removed parts, we can estimate ground-truth part importances that should be reflected in the explanations. Third, by mapping individual explanations into a common space of part importances, we can analyze a variety of different explanation types in a single common framework. Using our tools, we report results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.
count=1
* 2D3D-MATR: 2D-3D Matching Transformer for Detection-Free Registration Between Images and Point Clouds
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.pdf)]
    * Title: 2D3D-MATR: 2D-3D Matching Transformer for Detection-Free Registration Between Images and Point Clouds
    * Year: `2023`
    * Authors: Minhao Li, Zheng Qin, Zhirui Gao, Renjiao Yi, Chenyang Zhu, Yulan Guo, Kai Xu
    * Abstract: The commonly adopted detect-then-match approach to registration finds difficulties in the cross-modality cases due to the incompatible keypoint detection and inconsistent feature description. We propose, 2D3D-MATR, a detection-free method for accurate and robust registration between images and point clouds. Our method adopts a coarse-to-fine pipeline where it first computes coarse correspondences between downsampled patches of the input image and the point cloud and then extends them to form dense correspondences between pixels and points within the patch region. The coarse-level patch matching is based on transformer which jointly learns global contextual constraints with self-attention and cross-modality correlations with cross-attention. To resolve the scale ambiguity in patch matching, we construct a multi-scale pyramid for each image patch and learn to find for each point patch the best matching image patch at a proper resolution level. Extensive experiments on two public benchmarks demonstrate that 2D3D-MATR outperforms the previous state-of-the-art P2-Net by around 20 percentage points on inlier ratio and over 10 points on registration recall. Our code and models will be publicly released.
count=1
* Discovering Spatio-Temporal Rationales for Video Question Answering
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.pdf)]
    * Title: Discovering Spatio-Temporal Rationales for Video Question Answering
    * Year: `2023`
    * Authors: Yicong Li, Junbin Xiao, Chun Feng, Xiang Wang, Tat-Seng Chua
    * Abstract: This paper strives to solve complex video question answering (VideoQA) which features long videos containing multiple objects and events at different time. To tackle the challenge, we highlight the importance of identifying question-critical temporal moments and spatial objects from the vast amount of video content. Towards this, we propose a Spatio-Temporal Rationalizer (STR), a differentiable selection module that adaptively collects question-critical moments and objects using cross-modal interaction. The discovered video moments and objects are then served as grounded rationales to support answer reasoning. Based on STR, we further propose TranSTR, a Transformer-style neural network architecture that takes STR as the core and additionally underscores a novel answer interaction mechanism to coordinate STR for answer decoding. Experiments on four datasets show that TranSTR achieves new state-of-the-art (SoTA). Especially, on NExT-QA and Causal-VidQA which feature complex VideoQA, it significantly surpasses the previous SoTA by 5.8% and 6.8%, respectively. We then conduct extensive studies to verify the importance of STR as well as the proposed answer interaction mechanism. With the success of TranSTR and our comprehensive analysis, we hope this work can spark more future efforts in complex VideoQA. Our results are fully reproducible at https://anonymous.4open.science/r/TranSTR/.
count=1
* Model Calibration in Dense Classification with Adaptive Label Perturbation
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.pdf)]
    * Title: Model Calibration in Dense Classification with Adaptive Label Perturbation
    * Year: `2023`
    * Authors: Jiawei Liu, Changkun Ye, Shan Wang, Ruikai Cui, Jing Zhang, Kaihao Zhang, Nick Barnes
    * Abstract: For safety-related applications, it is crucial to produce trustworthy deep neural networks whose prediction is associated with confidence that can represent the likelihood of correctness for subsequent decision-making. Existing dense binary classification models are prone to being over-confident. To improve model calibration, we propose Adaptive Stochastic Label Perturbation (ASLP) which learns a unique label perturbation level for each training image. ASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss, which unifies label perturbation processes including stochastic approaches (like DisturbLabel), and label smoothing, to correct calibration while maintaining classification rates. ASLP follows Maximum Entropy Inference of classic statistical mechanics to maximise prediction entropy with respect to missing information. It performs this while: (1) preserving classification accuracy on known data as a conservative solution, or (2) specifically improves model calibration degree by minimising the gap between the prediction accuracy and expected confidence of target training label. Extensive results demonstrate that ASLP can significantly improve calibration degrees of dense binary classification models on both in-distribution and out-of-distribution data.
count=1
* The Devil is in the Upsampling: Architectural Decisions Made Simpler for Denoising with Deep Image Prior
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.pdf)]
    * Title: The Devil is in the Upsampling: Architectural Decisions Made Simpler for Denoising with Deep Image Prior
    * Year: `2023`
    * Authors: Yilin Liu, Jiang Li, Yunkui Pang, Dong Nie, Pew-Thian Yap
    * Abstract: Deep Image Prior (DIP) shows that some network architectures inherently tend towards generating smooth images while resisting noise, a phenomenon known as spectral bias. Image denoising is a natural application of this property. Although denoising with DIP mitigates the need for large training sets, two often intertwined practical challenges need to be overcome: architectural design and noise fitting. Existing methods either handcraft or search for suitable architectures from a vast design space, due to the limited understanding of how architectural choices affect the denoising outcome. In this study, we demonstrate from a frequency perspective that unlearnt upsampling is the main driving force behind the denoising phenomenon with DIP. This finding leads to straightforward strategies for identifying a suitable architecture for every image without laborious search. Extensive experiments show that the estimated architectures achieve superior denoising results than existing methods with up to 95% fewer parameters. Thanks to this under-parameterization, the resulting architectures are less prone to noise-fitting.
count=1
* Learning Support and Trivial Prototypes for Interpretable Image Classification
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.pdf)]
    * Title: Learning Support and Trivial Prototypes for Interpretable Image Classification
    * Year: `2023`
    * Authors: Chong Wang, Yuyuan Liu, Yuanhong Chen, Fengbei Liu, Yu Tian, Davis McCarthy, Helen Frazer, Gustavo Carneiro
    * Abstract: Prototypical part network (ProtoPNet) methods have been designed to achieve interpretable classification by associating predictions with a set of training prototypes, which we refer to as trivial prototypes because they are trained to lie far from the classification boundary in the feature space. Note that it is possible to make an analogy between ProtoPNet and support vector machine (SVM) given that the classification from both methods relies on computing similarity with a set of training points (i.e., trivial prototypes in ProtoPNet, and support vectors in SVM). However, while trivial prototypes are located far from the classification boundary, support vectors are located close to this boundary, and we argue that this discrepancy with the well-established SVM theory can result in ProtoPNet models with inferior classification accuracy. In this paper, we aim to improve the classification of ProtoPNet with a new method to learn support prototypes that lie near the classification boundary in the feature space, as suggested by the SVM theory. In addition, we target the improvement of classification results with a new model, named ST-ProtoPNet, which exploits our support prototypes and the trivial prototypes to provide more effective classification. Experimental results on CUB-200-2011, Stanford Cars, and Stanford Dogs datasets demonstrate that ST-ProtoPNet achieves state-of-the-art classification accuracy and interpretability results. We also show that the proposed support prototypes tend to be better localised in the object of interest rather than in the background region. Code is available at https://github.com/cwangrun/ST-ProtoPNet.
count=1
* Ordinal Label Distribution Learning
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.pdf)]
    * Title: Ordinal Label Distribution Learning
    * Year: `2023`
    * Authors: Changsong Wen, Xin Zhang, Xingxu Yao, Jufeng Yang
    * Abstract: Label distribution learning (LDL) is a recent hot topic, in which ambiguity is modeled via description degrees of the labels. However, in common LDL tasks, e.g., age estimation, labels are in an intrinsic order. The conventional LDL paradigm adopts a per-label manner for optimization, neglecting the internal sequential patterns of labels. Therefore, we propose a new paradigm, termed ordinal label distribution learning (OLDL). We model the sequential patterns of labels from aspects of spatial, semantic, and temporal order relationships. The spatial order depicts the relative position between arbitrary labels. We build cross-label transformation between distributions, which is determined by the spatial margin in labels. Labels naturally yield different semantics, so the semantic order is represented by constructing semantic correlations between arbitrary labels. The temporal order describes that the presence of labels is determined by their order, i.e. five after four. The value of a particular label contains information about previous labels, and we adopt cumulative distribution to construct this relationship. Based on these characteristics of ordinal labels, we propose the learning objectives and evaluation metrics for OLDL, namely CAD, QFD, and CJS. Comprehensive experiments conducted on four tasks demonstrate the superiority of OLDL against other existing LDL methods in both traditional and newly proposed metrics. Our project page can be found at https://downdric23.github.io/.
count=1
* Prototypical Mixing and Retrieval-Based Refinement for Label Noise-Resistant Image Retrieval
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.pdf)]
    * Title: Prototypical Mixing and Retrieval-Based Refinement for Label Noise-Resistant Image Retrieval
    * Year: `2023`
    * Authors: Xinlong Yang, Haixin Wang, Jinan Sun, Shikun Zhang, Chong Chen, Xian-Sheng Hua, Xiao Luo
    * Abstract: Label noise is pervasive in real-world applications, which influences the optimization of neural network models. This paper investigates a realistic but understudied problem of image retrieval under label noise, which could lead to severe overfitting or memorization of noisy samples during optimization. Moreover, identifying noisy samples correctly is still a challenging problem for retrieval models. In this paper, we propose a novel approach called Prototypical Mixing and Retrieval-based Refinement (TITAN) for label noise-resistant image retrieval, which corrects label noise and mitigates the effects of the memorization simultaneously. Specifically, we first characterize numerous prototypes with Gaussian distributions in the hidden space, which would direct the Mixing procedure in providing synthesized samples. These samples are fed into a similarity learning framework with varying emphasis based on the prototypical structure to learn semantics with reduced overfitting. In addition, we retrieve comparable samples for each prototype from simple to complex, which refine noisy samples in an accurate and class-balanced manner. Comprehensive experiments on five benchmark datasets demonstrate the superiority of our proposed TITAN compared with various competing baselines.
count=1
* FACTS: First Amplify Correlations and Then Slice to Discover Bias
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.pdf)]
    * Title: FACTS: First Amplify Correlations and Then Slice to Discover Bias
    * Year: `2023`
    * Authors: Sriram Yenamandra, Pratik Ramesh, Viraj Prabhu, Judy Hoffman
    * Abstract: Computer vision datasets frequently contain spurious correlations between task-relevant labels and (easy to learn) latent task-irrelevant attributes (e.g. context). Models trained on such datasets learn "shortcuts" and underperform on bias-conflicting slices of data where the correlation does not hold. In this work, we study the problem of identifying such slices to inform downstream bias mitigation strategies. We propose First Amplify Correlations and Then Slice (FACTS), wherein we first amplify correlations to fit a simple bias-aligned hypothesis via strongly regularized empirical risk minimization. Next, we perform correlation-aware slicing via mixture modeling in bias-aligned feature space to discover underperforming data slices that capture distinct correlations. Despite its simplicity, our method considerably improves over prior work (by as much as 35% precision@10) in correlation bias identification across a range of diverse evaluation settings. Our code is available at https://github.com/yvsriram/FACTS.
count=1
* Adaptive Calibrator Ensemble: Navigating Test Set Difficulty in Out-of-Distribution Scenarios
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.pdf)]
    * Title: Adaptive Calibrator Ensemble: Navigating Test Set Difficulty in Out-of-Distribution Scenarios
    * Year: `2023`
    * Authors: Yuli Zou, Weijian Deng, Liang Zheng
    * Abstract: Model calibration usually requires optimizing some parameters (e.g., temperature) w.r.t an objective function like negative log-likelihood. This work uncovers a significant aspect often overlooked that the objective function is influenced by calibration set difficulty: the ratio of misclassified to correctly classified samples. If a test set has a drastically different difficulty level from the calibration set, a phenomenon out-of-distribution (OOD) data often exhibit: the optimal calibration parameters of the two datasets would be different, rendering an optimal calibrator on the calibration set suboptimal on the OOD test set and thus degraded calibration performance. With this knowledge, we propose a simple and effective method named adaptive calibrator ensemble (ACE) to calibrate OOD datasets whose difficulty is usually higher than the calibration set. Specifically, two calibration functions are trained, one for in-distribution data (low difficulty), and the other for severely OOD data (high difficulty). To achieve desirable calibration on a new OOD dataset, ACE uses an adaptive weighting method that strikes a balance between the two extreme functions. When plugged in, ACE generally improves the performance of a few state-of-the-art calibration schemes on a series of OOD benchmarks. Importantly, such improvement does not come at the cost of the in-distribution calibration performance. Project Website: https://github.com/insysgroup/Adaptive-Calibrators-Ensemble.git.
count=1
* Triggering Failures: Out-of-Distribution Detection by Learning From Local Adversarial Attacks in Semantic Segmentation
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Besnier_Triggering_Failures_Out-of-Distribution_Detection_by_Learning_From_Local_Adversarial_Attacks_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Besnier_Triggering_Failures_Out-of-Distribution_Detection_by_Learning_From_Local_Adversarial_Attacks_ICCV_2021_paper.pdf)]
    * Title: Triggering Failures: Out-of-Distribution Detection by Learning From Local Adversarial Attacks in Semantic Segmentation
    * Year: `2021`
    * Authors: Victor Besnier, Andrei Bursuc, David Picard, Alexandre Briot
    * Abstract: In this paper, we tackle the detection of out-of-distribution (OOD) objects in semantic segmentation. By analyzing the literature, we found that current methods are either accurate or fast but not both which limits their usability in real world applications. To get the best of both aspects, we propose to mitigate the common shortcomings by following four design principles: decoupling the OOD detection from the segmentation task, observing the entire segmentation network instead of just its output, generating training data for the OOD detector by leveraging blind spots in the segmentation network and focusing the generated data on localized regions in the image to simulate OOD objects. Our main contribution is a new OOD detection architecture called ObsNet associated with a dedicated training scheme based on Local Adversarial Attacks (LAA). We validate the soundness of our approach across numerous ablation studies. We also show it obtains top performances both in speed and accuracy when compared to ten recent methods of the literature on three different datasets.
count=1
* Knowledge-Enriched Distributional Model Inversion Attacks
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Knowledge-Enriched_Distributional_Model_Inversion_Attacks_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Knowledge-Enriched_Distributional_Model_Inversion_Attacks_ICCV_2021_paper.pdf)]
    * Title: Knowledge-Enriched Distributional Model Inversion Attacks
    * Year: `2021`
    * Authors: Si Chen, Mostafa Kahla, Ruoxi Jia, Guo-Jun Qi
    * Abstract: Model inversion (MI) attacks are aimed at reconstructing training data from model parameters. Such attacks have triggered increasing concerns about privacy, especially given the growing number of online model repositories. However, existing MI attacks against deep neural networks (DNNs) have a large room for performance improvement. We present a novel inversion-specific GAN that can better distill knowledge useful for performing attacks on private models from public data. In particular, we train the discriminator to differentiate not only the real and fake samples but the soft-labels provided by the target model. Moreover, unlike previous work that directly searches for a single data point to represent a target class, we propose to model a private data distribution for each target class. Our experiments show that the combination of these techniques can significantly boost the success rate of the state-of-the-art MI attacks by 150%, and generalize better to a variety of datasets and models. Our code is available at https://github.com/SCccc21/Knowledge-Enriched-DMI.
count=1
* TeachText: CrossModal Generalized Distillation for Text-Video Retrieval
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Croitoru_TeachText_CrossModal_Generalized_Distillation_for_Text-Video_Retrieval_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Croitoru_TeachText_CrossModal_Generalized_Distillation_for_Text-Video_Retrieval_ICCV_2021_paper.pdf)]
    * Title: TeachText: CrossModal Generalized Distillation for Text-Video Retrieval
    * Year: `2021`
    * Authors: Ioana Croitoru, Simion-Vlad Bogolin, Marius Leordeanu, Hailin Jin, Andrew Zisserman, Samuel Albanie, Yang Liu
    * Abstract: In recent years, considerable progress on the task of text-video retrieval has been achieved by leveraging large-scale pretraining on visual and audio datasets to construct powerful video encoders. By contrast, despite the natural symmetry, the design of effective algorithms for exploiting large-scale language pretraining remains under-explored. In this work, we are the first to investigate the design of such algorithms and propose a novel generalized distillation method,TeachText, which leverages complementary cues from multiple text encoders to provide an enhanced supervisory signal to the retrieval model. Moreover, we extend our method to video side modalities and show that we can effectively reduce the number of used modalities at test time without compromising performance. Our approach advances the state of the art on several video retrieval benchmarks by a significant margin and adds no computational overhead at test time. Last but not least, we show an effective application of our method for eliminating noise from retrieval datasets. Code and data can be found at https://www.robots.ox.ac.uk/ vgg/research/teachtext/.
count=1
* 3D-FRONT: 3D Furnished Rooms With layOuts and semaNTics
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Fu_3D-FRONT_3D_Furnished_Rooms_With_layOuts_and_semaNTics_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Fu_3D-FRONT_3D_Furnished_Rooms_With_layOuts_and_semaNTics_ICCV_2021_paper.pdf)]
    * Title: 3D-FRONT: 3D Furnished Rooms With layOuts and semaNTics
    * Year: `2021`
    * Authors: Huan Fu, Bowen Cai, Lin Gao, Ling-Xiao Zhang, Jiaming Wang, Cao Li, Qixun Zeng, Chengyue Sun, Rongfei Jia, Binqiang Zhao, Hao Zhang
    * Abstract: We introduce 3D-FRONT (3D Furnished Rooms with layOuts and semaNTics), a new, large-scale, and compre- hensive repository of synthetic indoor scenes highlighted by professionally designed layouts and a large number of rooms populated by high-quality textured 3D models with style compatibility. From layout semantics down to texture details of individual objects, our dataset is freely available to the academic community and beyond. Currently, 3D- FRONT contains 6,813 CAD houses, where 18,968 rooms diversely furnished by 3D objects, far surpassing all publicly available scene datasets. The 13,151 furniture objects all come with high-quality textures. While the floorplans and layout designs (i.e., furniture arrangements) are directly sourced from professional creations, the interior de- signs in terms of furniture styles, color, and textures have been carefully curated based on a recommender system we develop to attain consistent styles as expert designs. Furthermore, we release Trescope, a light-weight rendering tool, to support benchmark rendering of 2D images and annotations from 3D-FRONT. We demonstrate two applications, interior scene synthesis and texture synthesis, that are especially tailored to the strengths of our new dataset.
count=1
* Confidence Calibration for Domain Generalization Under Covariate Shift
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Gong_Confidence_Calibration_for_Domain_Generalization_Under_Covariate_Shift_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Gong_Confidence_Calibration_for_Domain_Generalization_Under_Covariate_Shift_ICCV_2021_paper.pdf)]
    * Title: Confidence Calibration for Domain Generalization Under Covariate Shift
    * Year: `2021`
    * Authors: Yunye Gong, Xiao Lin, Yi Yao, Thomas G. Dietterich, Ajay Divakaran, Melinda Gervasio
    * Abstract: Existing calibration algorithms address the problem of covariate shift via unsupervised domain adaptation. However, these methods suffer from the following limitations: 1) they require unlabeled data from the target domain, which may not be available at the stage of calibration in real-world applications and 2) their performance depends heavily on the disparity between the distributions of the source and target domains. To address these two limitations, we present novel calibration solutions via domain generalization. Our core idea is to leverage multiple calibration domains to reduce the effective distribution disparity between the target and calibration domains for improved calibration transfer without needing any data from the target domain. We provide theoretical justification and empirical experimental results to demonstrate the effectiveness of our proposed algorithms. Compared against state-of-the-art calibration methods designed for domain adaptation, we observe a decrease of 8.86 percentage points in expected calibration error or, equivalently, an increase of 35 percentage points in improvement ratio for multi-class classification on the Office-Home dataset.
count=1
* EigenGAN: Layer-Wise Eigen-Learning for GANs
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/He_EigenGAN_Layer-Wise_Eigen-Learning_for_GANs_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/He_EigenGAN_Layer-Wise_Eigen-Learning_for_GANs_ICCV_2021_paper.pdf)]
    * Title: EigenGAN: Layer-Wise Eigen-Learning for GANs
    * Year: `2021`
    * Authors: Zhenliang He, Meina Kan, Shiguang Shan
    * Abstract: Recent studies on Generative Adversarial Network (GAN) reveal that different layers of a generative CNN hold different semantics of the synthesized images. However, few GAN models have explicit dimensions to control the semantic attributes represented in a specific layer. This paper proposes EigenGAN which is able to unsupervisedly mine interpretable and controllable dimensions from different generator layers. Specifically, EigenGAN embeds one linear subspace with orthogonal basis into each generator layer. Via generative adversarial training to learn a target distribution, these layer-wise subspaces automatically discover a set of "eigen-dimensions" at each layer corresponding to a set of semantic attributes or interpretable variations. By traversing the coefficient of a specific eigen-dimension, the generator can produce samples with continuous changes corresponding to a specific semantic attribute. Taking the human face for example, EigenGAN can discover controllable dimensions for high-level concepts such as pose and gender in the subspace of deep layers, as well as low-level concepts such as hue and color in the subspace of shallow layers. Moreover, in the linear case, we theoretically prove that our algorithm derives the principal components as PCA does. Codes can be found in https://github.com/LynnHo/EigenGAN-Tensorflow.
count=1
* Inferring High-Resolution Traffic Accident Risk Maps Based on Satellite Imagery and GPS Trajectories
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/He_Inferring_High-Resolution_Traffic_Accident_Risk_Maps_Based_on_Satellite_Imagery_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/He_Inferring_High-Resolution_Traffic_Accident_Risk_Maps_Based_on_Satellite_Imagery_ICCV_2021_paper.pdf)]
    * Title: Inferring High-Resolution Traffic Accident Risk Maps Based on Satellite Imagery and GPS Trajectories
    * Year: `2021`
    * Authors: Songtao He, Mohammad Amin Sadeghi, Sanjay Chawla, Mohammad Alizadeh, Hari Balakrishnan, Samuel Madden
    * Abstract: Traffic accidents cost about 3% of the world's GDP and are the leading cause of death in children and young adults. Accident risk maps are useful tools to monitor and mitigate accident risk. We present a technique to generate high-resolution (5 meters) accident risk maps. At this high resolution, accidents are sparse and risk estimation is limited by bias-variance trade-off. Prior accident risk maps either estimate low-resolution maps that are of low utility (high bias), or they use frequency-based estimation techniques that inaccurately predict where accidents actually happen (high variance). To improve this trade-off, we use an end-to-end deep architecture that can input satellite imagery, GPS trajectories, road maps and the history of accidents. Our evaluation on four metropolitan areas in the US with a total area of 7,488 km2 shows that our technique outperforms prior work in terms of resolution and accuracy.
count=1
* Diagonal Attention and Style-Based GAN for Content-Style Disentanglement in Image Generation and Translation
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Kwon_Diagonal_Attention_and_Style-Based_GAN_for_Content-Style_Disentanglement_in_Image_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Kwon_Diagonal_Attention_and_Style-Based_GAN_for_Content-Style_Disentanglement_in_Image_ICCV_2021_paper.pdf)]
    * Title: Diagonal Attention and Style-Based GAN for Content-Style Disentanglement in Image Generation and Translation
    * Year: `2021`
    * Authors: Gihyun Kwon, Jong Chul Ye
    * Abstract: One of the important research topics in image generative models is to disentangle the spatial contents and styles for their separate control. Although StyleGAN can generate content feature vectors from random noises, the resulting spatial content control is primarily intended for minor spatial variations, and the disentanglement of global content and styles is by no means complete. Inspired by a mathematical understanding of normalization and attention, here we present a novel hierarchical adaptive Diagonal spatial ATtention (DAT) layers to separately manipulate the spatial contents from styles in a hierarchical manner. Using DAT and AdaIN, our method enables coarse-to-fine level disentanglement of spatial contents and styles. In addition, our generator can be easily integrated into the GAN inversion framework so that the content and style of translated images from multi-domain image translation tasks can be flexibly controlled. By using various datasets, we confirm that the proposed method not only outperforms the existing models in disentanglement scores, but also provides more flexible control over spatial features in the generated images.
count=1
* DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence From Box Supervision
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Lan_DiscoBox_Weakly_Supervised_Instance_Segmentation_and_Semantic_Correspondence_From_Box_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Lan_DiscoBox_Weakly_Supervised_Instance_Segmentation_and_Semantic_Correspondence_From_Box_ICCV_2021_paper.pdf)]
    * Title: DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence From Box Supervision
    * Year: `2021`
    * Authors: Shiyi Lan, Zhiding Yu, Christopher Choy, Subhashree Radhakrishnan, Guilin Liu, Yuke Zhu, Larry S. Davis, Anima Anandkumar
    * Abstract: We introduce DiscoBox, a novel framework that jointly learns instance segmentation and semantic correspondence using bounding box supervision. Specifically, we propose a self-ensembling framework where instance segmentation and semantic correspondence are jointly guided by a structured teacher in addition to the bounding box supervision. The teacher is a structured energy model incorporating a pairwise potential and a cross-image potential to model the pairwise pixel relationships both within and across the boxes. Minimizing the teacher energy simultaneously yields refined object masks and dense correspondences between intra-class objects, which are taken as pseudo-labels to supervise the task network and provide positive/negative correspondence pairs for dense contrastive learning. We show a symbiotic relationship where the two tasks mutually benefit from each other. Our best model achieves 37.9% AP on COCO instance segmentation, surpassing prior weakly supervised methods and is competitive to supervised methods. We also obtain state of the art weakly supervised results on PASCAL VOC12 and PF-PASCAL with real-time inference.
count=1
* MultiSports: A Multi-Person Video Dataset of Spatio-Temporally Localized Sports Actions
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Li_MultiSports_A_Multi-Person_Video_Dataset_of_Spatio-Temporally_Localized_Sports_Actions_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_MultiSports_A_Multi-Person_Video_Dataset_of_Spatio-Temporally_Localized_Sports_Actions_ICCV_2021_paper.pdf)]
    * Title: MultiSports: A Multi-Person Video Dataset of Spatio-Temporally Localized Sports Actions
    * Year: `2021`
    * Authors: Yixuan Li, Lei Chen, Runyu He, Zhenzhi Wang, Gangshan Wu, Limin Wang
    * Abstract: Spatio-temporal action detection is an important and challenging problem in video understanding. The existing action detection benchmarks are limited in aspects of small numbers of instances in a trimmed video or low-level atomic actions. This paper aims to present a new multi-person dataset of spatio-temporal localized sports actions, coined as MultiSports. We first analyze the important ingredients of constructing a realistic and challenging dataset for spatio-temporal action detection by proposing three criteria: (1) multi-person scenes and motion dependent identification, (2) with well-defined boundaries, (3) relatively fine-grained classes of high complexity. Based on these guidelines, we build the dataset of MultiSports v1.0 by selecting 4 sports classes, collecting 3200 video clips, and annotating 37701 action instances with 902k bounding boxes. Our datasets are characterized with important properties of high diversity, dense annotation, and high quality. Our MultiSports, with its realistic setting and detailed annotations, exposes the intrinsic challenges of spatio-temporal action detection. To benchmark this, we adapt several baseline methods to our dataset and give an in-depth analysis on the action detection results in our dataset. We hope our MultiSports can serve as a standard benchmark for spatio-temporal action detection in the future. Our dataset website is at https://deeperaction.github.io/multisports/.
count=1
* SCOUTER: Slot Attention-Based Classifier for Explainable Image Recognition
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Li_SCOUTER_Slot_Attention-Based_Classifier_for_Explainable_Image_Recognition_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_SCOUTER_Slot_Attention-Based_Classifier_for_Explainable_Image_Recognition_ICCV_2021_paper.pdf)]
    * Title: SCOUTER: Slot Attention-Based Classifier for Explainable Image Recognition
    * Year: `2021`
    * Authors: Liangzhi Li, Bowen Wang, Manisha Verma, Yuta Nakashima, Ryo Kawasaki, Hajime Nagahara
    * Abstract: Explainable artificial intelligence has been gaining attention in the past few years. However, most existing methods are based on gradients or intermediate features, which are not directly involved in the decision-making process of the classifier. In this paper, we propose a slot attention-based classifier called SCOUTER for transparent yet accurate classification. Two major differences from other attention-based methods include: (a) SCOUTER's explanation is involved in the final confidence for each category, offering more intuitive interpretation, and (b) all the categories have their corresponding positive or negative explanation, which tells "why the image is of a certain category" or "why the image is not of a certain category." We design a new loss tailored for SCOUTER that controls the model's behavior to switch between positive and negative explanations, as well as the size of explanatory regions. Experimental results show that SCOUTER can give better visual explanations in terms of various metrics while keeping good accuracy on small and medium-sized datasets.
count=1
* Homogeneous Architecture Augmentation for Neural Predictor
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Homogeneous_Architecture_Augmentation_for_Neural_Predictor_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Homogeneous_Architecture_Augmentation_for_Neural_Predictor_ICCV_2021_paper.pdf)]
    * Title: Homogeneous Architecture Augmentation for Neural Predictor
    * Year: `2021`
    * Authors: Yuqiao Liu, Yehui Tang, Yanan Sun
    * Abstract: Neural Architecture Search (NAS) can automatically design well-performed architectures of Deep Neural Networks (DNNs) for the tasks at hand. However, one bottleneck of NAS is the prohibitively computational cost largely due to the expensive performance evaluation. The neural predictors can directly estimate the performance without any training of the DNNs to be evaluated, thus have drawn increasing attention from researchers. Despite their popularity, they also suffer a severe limitation: the shortage of annotated DNN architectures for effectively training the neural predictors. In this paper, we proposed Homogeneous Architecture Augmentation for Neural Predictor (HAAP) of DNN architectures to address the issue aforementioned. Specifically, a homogeneous architecture augmentation algorithm is proposed in HAAP to generate sufficient training data taking the use of homogeneous representation. Furthermore, the one-hot encoding strategy is introduced into HAAP to make the representation of DNN architectures more effective. The experiments have been conducted on both NAS-Benchmark-101 and NAS-Bench-201 dataset. The experimental results demonstrate that the proposed HAAP algorithm outperforms the state of the arts compared, yet with much less training data. In addition, the ablation studies on both benchmark datasets have also shown the universality of the homogeneous architecture augmentation. Our code has been made available at https://github.com/lyq998/HAAP.
count=1
* Beyond Trivial Counterfactual Explanations With Diverse Valuable Explanations
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Rodriguez_Beyond_Trivial_Counterfactual_Explanations_With_Diverse_Valuable_Explanations_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Rodriguez_Beyond_Trivial_Counterfactual_Explanations_With_Diverse_Valuable_Explanations_ICCV_2021_paper.pdf)]
    * Title: Beyond Trivial Counterfactual Explanations With Diverse Valuable Explanations
    * Year: `2021`
    * Authors: Pau Rodríguez, Massimo Caccia, Alexandre Lacoste, Lee Zamparo, Issam Laradji, Laurent Charlin, David Vazquez
    * Abstract: Explainability for machine learning models has gained considerable attention within the research community given the importance of deploying more reliable machine-learning systems. In computer vision applications, generative counterfactual methods indicate how to perturb a model's input to change its prediction, providing details about the model's decision-making. Current methods tend to generate trivial counterfactuals about a model's decisions, as they often suggest to exaggerate or remove the presence of the attribute being classified. For the machine learning practitioner, these types of counterfactuals offer little value, since they provide no new information about undesired model or data biases. In this work, we identify the problem of trivial counterfactual generation and we propose DiVE to alleviate it. DiVE learns a perturbation in a disentangled latent space that is constrained using a diversity-enforcing loss to uncover multiple valuable explanations about the model's prediction. Further, we introduce a mechanism to prevent the model from producing trivial explanations. Experiments on CelebA and Synbols demonstrate that our model improves the success rate of producing high-quality valuable explanations when compared to previous state-of-the-art methods.
count=1
* Fast and Efficient DNN Deployment via Deep Gaussian Transfer Learning
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Sun_Fast_and_Efficient_DNN_Deployment_via_Deep_Gaussian_Transfer_Learning_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Sun_Fast_and_Efficient_DNN_Deployment_via_Deep_Gaussian_Transfer_Learning_ICCV_2021_paper.pdf)]
    * Title: Fast and Efficient DNN Deployment via Deep Gaussian Transfer Learning
    * Year: `2021`
    * Authors: Qi Sun, Chen Bai, Tinghuan Chen, Hao Geng, Xinyun Zhang, Yang Bai, Bei Yu
    * Abstract: Deep neural networks (DNNs) have been widely used recently while their hardware deployment optimizations are very time-consuming and the historical deployment knowledge is not utilized efficiently. In this paper, to accelerate the optimization process and find better deployment configurations, we propose a novel transfer learning method based on deep Gaussian processes (DGPs). Firstly, a deep Gaussian process (DGP) model is built on the historical data to learn empirical knowledge. Secondly, to transfer knowledge to a new task, a tuning set is sampled for the new task under the guidance of the DGP model. Then DGP is tuned according to the tuning set via maximum-a-posteriori (MAP) estimation to accommodate for the new task and finally used to guide the deployments of the task. The experiments show that our method achieves the best inference latencies of convolutions while accelerating the optimization process significantly, compared with previous arts.
count=1
* Instance-Wise Hard Negative Example Generation for Contrastive Learning in Unpaired Image-to-Image Translation
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Instance-Wise_Hard_Negative_Example_Generation_for_Contrastive_Learning_in_Unpaired_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Instance-Wise_Hard_Negative_Example_Generation_for_Contrastive_Learning_in_Unpaired_ICCV_2021_paper.pdf)]
    * Title: Instance-Wise Hard Negative Example Generation for Contrastive Learning in Unpaired Image-to-Image Translation
    * Year: `2021`
    * Authors: Weilun Wang, Wengang Zhou, Jianmin Bao, Dong Chen, Houqiang Li
    * Abstract: Contrastive learning shows great potential in unpaired image-to-image translation, but sometimes the translated results are in poor quality and the contents are not preserved consistently. In this paper, we uncover that the negative examples play a critical role in the performance of contrastive learning for image translation. The negative examples in previous methods are randomly sampled from the patches of different positions in the source image, which are not effective to push the positive examples close to the query examples. To address this issue, we present instance-wise hard Negative Example Generation for Contrastive learning in Unpaired image-to-image Translation (NEGCUT). Specifically, we train a generator to produce negative examples online. The generator is novel from two perspectives: 1) it is instance-wise which means that the generated examples are based on the input image, and 2) it can generate hard negative examples since it is trained with an adversarial loss. With the generator, the performance of unpaired image-to-image translation is significantly improved. Experiments on three benchmark datasets demonstrate that the proposed NEGCUT framework achieves state-of-the-art performance compared to previous methods.
count=1
* Procrustean Training for Imbalanced Deep Learning
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Ye_Procrustean_Training_for_Imbalanced_Deep_Learning_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Ye_Procrustean_Training_for_Imbalanced_Deep_Learning_ICCV_2021_paper.pdf)]
    * Title: Procrustean Training for Imbalanced Deep Learning
    * Year: `2021`
    * Authors: Han-Jia Ye, De-Chuan Zhan, Wei-Lun Chao
    * Abstract: Neural networks trained with class-imbalanced data are known to perform poorly on minor classes of scarce training data. Several recent works attribute this to over-fitting to minor classes. In this paper, we provide a novel explanation of this issue. We found that a neural network tends to first under-fit the minor classes by classifying most of their data into the major classes in early training epochs. To correct these wrong predictions, the neural network then must focus on pushing features of minor class data across the decision boundaries between major and minor classes, leading to much larger gradients for features of minor classes. We argue that such an under-fitting phase over-emphasizes the competition between major and minor classes, hinders the neural network from learning the discriminative knowledge that can be generalized to test data, and eventually results in over-fitting. To address this issue, we propose a novel learning strategy to equalize the training progress across classes. We mix features of the major class data with those of other data in a mini-batch, intentionally weakening their features to prevent a neural network from fitting them first. We show that this strategy can largely balance the training accuracy and feature gradients across classes, effectively mitigating the under-fitting then over-fitting problem for minor class data. On several benchmark datasets, our approach achieves the state-of-the-art accuracy, especially for the challenging step-imbalanced cases.
count=1
* Consistency-Sensitivity Guided Ensemble Black-Box Adversarial Attacks in Low-Dimensional Spaces
    [[abs-ICCV](https://openaccess.thecvf.com/content/ICCV2021/html/Yuan_Consistency-Sensitivity_Guided_Ensemble_Black-Box_Adversarial_Attacks_in_Low-Dimensional_Spaces_ICCV_2021_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Yuan_Consistency-Sensitivity_Guided_Ensemble_Black-Box_Adversarial_Attacks_in_Low-Dimensional_Spaces_ICCV_2021_paper.pdf)]
    * Title: Consistency-Sensitivity Guided Ensemble Black-Box Adversarial Attacks in Low-Dimensional Spaces
    * Year: `2021`
    * Authors: Jianhe Yuan, Zhihai He
    * Abstract: Black-box attacks aim to generate adversarial noise tofail the victim deep neural network in the black box. Thecentral task in black-box attack method design is to estimateand characterize the victim model in the high-dimensionalmodel space based on feedback results of queries submittedto the victim network. The central performance goal is tominimize the number of queries needed for successful at-tack. Existing attack methods directly search and refine theadversarial noise in an extremely high-dimensional space,requiring hundreds or even thousands queries to the victimnetwork. To address this challenge, we propose to explore aconsistency and sensitivity guided ensemble attack (CSEA)method in a low-dimensional space. Specifically, we esti-mate the victim model in the black box using a learned lin-ear composition of an ensemble of surrogate models withdiversified network structures. Using random block maskson the input image, these surrogate models jointly constructand submit randomized and sparsified queries to the victimmodel. Based on these query results and guided by a con-sistency constraint, the surrogate models can be trained us-ing a very small number of queries such that their learnedcomposition is able to accurately approximate the victimmodel in the high-dimensional space. The randomized andsparsified queries also provide important information for usto construct an attack sensitivity map for the input image,with which the adversarial attack can be locally refined tofurther increase its success rate. Our extensive experimen-tal results demonstrate that our proposed approach signifi-cantly reduces the number of queries to the victim networkwhile maintaining very high success rates, outperformingexisting black-box attack methods by large margins.
count=1
* Presence-Only Geographical Priors for Fine-Grained Image Classification
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Aodha_Presence-Only_Geographical_Priors_for_Fine-Grained_Image_Classification_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Aodha_Presence-Only_Geographical_Priors_for_Fine-Grained_Image_Classification_ICCV_2019_paper.pdf)]
    * Title: Presence-Only Geographical Priors for Fine-Grained Image Classification
    * Year: `2019`
    * Authors: Oisin Mac Aodha,  Elijah Cole,  Pietro Perona
    * Abstract: Appearance information alone is often not sufficient to accurately differentiate between fine-grained visual categories. Human experts make use of additional cues such as where, and when, a given image was taken in order to inform their final decision. This contextual information is readily available in many online image collections but has been underutilized by existing image classifiers that focus solely on making predictions based on the image contents. We propose an efficient spatio-temporal prior, that when conditioned on a geographical location and time, estimates the probability that a given object category occurs at that location. Our prior is trained from presence-only observation data and jointly models object categories, their spatio-temporal distributions, and photographer biases. Experiments performed on multiple challenging image classification datasets show that combining our prior with the predictions from image classifiers results in a large improvement in final classification performance.
count=1
* Expert Sample Consensus Applied to Camera Re-Localization
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Brachmann_Expert_Sample_Consensus_Applied_to_Camera_Re-Localization_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Brachmann_Expert_Sample_Consensus_Applied_to_Camera_Re-Localization_ICCV_2019_paper.pdf)]
    * Title: Expert Sample Consensus Applied to Camera Re-Localization
    * Year: `2019`
    * Authors: Eric Brachmann,  Carsten Rother
    * Abstract: Fitting model parameters to a set of noisy data points is a common problem in computer vision. In this work, we fit the 6D camera pose to a set of noisy correspondences between the 2D input image and a known 3D environment. We estimate these correspondences from the image using a neural network. Since the correspondences often contain outliers, we utilize a robust estimator such as Random Sample Consensus (RANSAC) or Differentiable RANSAC (DSAC) to fit the pose parameters. When the problem domain, e.g. the space of all 2D-3D correspondences, is large or ambiguous, a single network does not cover the domain well. Mixture of Experts (MoE) is a popular strategy to divide a problem domain among an ensemble of specialized networks, so called experts, where a gating network decides which expert is responsible for a given input. In this work, we introduce Expert Sample Consensus (ESAC), which integrates DSAC in a MoE. Our main technical contribution is an efficient method to train ESAC jointly and end-to-end. We demonstrate experimentally that ESAC handles two real-world problems better than competing methods, i.e. scalability and ambiguity. We apply ESAC to fitting simple geometric models to synthetic images, and to camera re-localization for difficult, real datasets.
count=1
* Attention-Based Autism Spectrum Disorder Screening With Privileged Modality
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Chen_Attention-Based_Autism_Spectrum_Disorder_Screening_With_Privileged_Modality_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Attention-Based_Autism_Spectrum_Disorder_Screening_With_Privileged_Modality_ICCV_2019_paper.pdf)]
    * Title: Attention-Based Autism Spectrum Disorder Screening With Privileged Modality
    * Year: `2019`
    * Authors: Shi Chen,  Qi Zhao
    * Abstract: This paper presents a novel framework for automatic and quantitative screening of autism spectrum disorder (ASD). It is motivated to address two issues in the current clinical settings: 1) short of clinical resources with the prevalence of ASD (1.7% in the United States), and 2) subjectivity of ASD screening. This work differentiates itself with three unique features: first, it proposes an ASD screening with privileged modality framework that integrates information from two behavioral modalities during training and improves the performance on each single modality at testing. The proposed framework does not require overlap in subjects between the modalities. Second, it develops the first computational model to classify people with ASD using a photo-taking task where subjects freely explore their environment in a more ecological setting. Photo-taking reveals attentional preference of subjects, differentiating people with ASD from healthy people, and is also easy to implement in real-world clinical settings without requiring advanced diagnostic instruments. Third, this study for the first time takes advantage of the temporal information in eye movements while viewing images, encoding more detailed behavioral differences between ASD people and healthy controls. Experiments show that our ASD screening models can achieve superior performance, outperforming the previous state-of-the-art methods by a considerable margin. Moreover, our framework using diverse modalities demonstrates performance improvement on both the photo-taking and image-viewing tasks, providing a general paradigm that takes in multiple sources of behavioral data for a more accurate ASD screening. The framework is also applicable to various scenarios where one-to-one pairwise relationship is difficult to obtain across different modalities.
count=1
* DeCaFA: Deep Convolutional Cascade for Face Alignment in the Wild
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Dapogny_DeCaFA_Deep_Convolutional_Cascade_for_Face_Alignment_in_the_Wild_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Dapogny_DeCaFA_Deep_Convolutional_Cascade_for_Face_Alignment_in_the_Wild_ICCV_2019_paper.pdf)]
    * Title: DeCaFA: Deep Convolutional Cascade for Face Alignment in the Wild
    * Year: `2019`
    * Authors: Arnaud Dapogny,  Kevin Bailly,  Matthieu Cord
    * Abstract: Face Alignment is an active computer vision domain, that consists in localizing a number of facial landmarks that vary across datasets. State-of-the-art face alignment methods either consist in end-to-end regression, or in refining the shape in a cascaded manner, starting from an initial guess. In this paper, we introduce an end-to-end deep convolutional cascade (DeCaFA) architecture for face alignment. Face Alignment is an active computer vision domain, that consists in localizing a number of facial landmarks that vary across datasets. State-of-the-art face alignment methods either consist in end-to-end regression, or in refining the shape in a cascaded manner, starting from an initial guess. In this paper, we introduce DeCaFA, an end-to-end deep convolutional cascade architecture for face alignment. DeCaFA uses fully-convolutional stages to keep full spatial resolution throughout the cascade. Between each cascade stage, DeCaFA uses multiple chained transfer layers with spatial softmax to produce landmark-wise attention maps for each of several landmark alignment tasks. Weighted intermediate supervision, as well as efficient feature fusion between the stages allow to learn to progressively refine the attention maps in an end-to-end manner. We show experimentally that DeCaFA significantly outperforms existing approaches on 300W, CelebA and WFLW databases. In addition, we show that DeCaFA can learn fine alignment with reasonable accuracy from very few images using coarsely annotated data.
count=1
* Understanding Deep Networks via Extremal Perturbations and Smooth Masks
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Fong_Understanding_Deep_Networks_via_Extremal_Perturbations_and_Smooth_Masks_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Fong_Understanding_Deep_Networks_via_Extremal_Perturbations_and_Smooth_Masks_ICCV_2019_paper.pdf)]
    * Title: Understanding Deep Networks via Extremal Perturbations and Smooth Masks
    * Year: `2019`
    * Authors: Ruth Fong,  Mandela Patrick,  Andrea Vedaldi
    * Abstract: Attribution is the problem of finding which parts of an image are the most responsible for the output of a deep neural network. An important family of attribution methods is based on measuring the effect of perturbations applied to the input image, either via exhaustive search or by finding representative perturbations via optimization. In this paper, we discuss some of the shortcomings of existing approaches to perturbation analysis and address them by introducing the concept of extremal perturbations, which are theoretically grounded and interpretable. We also introduce a number of technical innovations to compute these extremal perturbations, including a new area constraint and a parametric family of smooth perturbations, which allow us to remove all tunable weighing factors from the optimization problem. We analyze the effect of perturbations as a function of their area, demonstrating excellent sensitivity to the spatial properties of the network under stimulation. We also extend perturbation analysis to the intermediate layers of a deep neural network. This application allows us to show how compactly an image can be represented (in terms of the number of channels it requires). We also demonstrate that the consistency with which images of a given class rely on the same intermediate channel correlates well with class accuracy.
count=1
* Accelerate Learning of Deep Hashing With Gradient Attention
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Huang_Accelerate_Learning_of_Deep_Hashing_With_Gradient_Attention_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Accelerate_Learning_of_Deep_Hashing_With_Gradient_Attention_ICCV_2019_paper.pdf)]
    * Title: Accelerate Learning of Deep Hashing With Gradient Attention
    * Year: `2019`
    * Authors: Long-Kai Huang,  Jianda Chen,  Sinno Jialin Pan
    * Abstract: Recent years have witnessed the success of learning to hash in fast large-scale image retrieval. As deep learning has shown its superior performance on many computer vision applications, recent designs of learning-based hashing models have been moving from shallow ones to deep architectures. However, based on our analysis, we find that gradient descent based algorithms used in deep hashing models would potentially cause hash codes of a pair of training instances to be updated towards the directions of each other simultaneously during optimization. In the worst case, the paired hash codes switch their directions after update, and consequently, their corresponding distance in the Hamming space remain unchanged. This makes the overall learning process highly inefficient. To address this issue, we propose a new deep hashing model integrated with a novel gradient attention mechanism. Extensive experimental results on three benchmark datasets show that our proposed algorithm is able to accelerate the learning process and obtain competitive retrieval performance compared with state-of-the-art deep hashing models.
count=1
* Instance-Level Future Motion Estimation in a Single Image Based on Ordinal Regression
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Kim_Instance-Level_Future_Motion_Estimation_in_a_Single_Image_Based_on_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Kim_Instance-Level_Future_Motion_Estimation_in_a_Single_Image_Based_on_ICCV_2019_paper.pdf)]
    * Title: Instance-Level Future Motion Estimation in a Single Image Based on Ordinal Regression
    * Year: `2019`
    * Authors: Kyung-Rae Kim,  Whan Choi,  Yeong Jun Koh,  Seong-Gyun Jeong,  Chang-Su Kim
    * Abstract: A novel algorithm to estimate instance-level future motion in a single image is proposed in this paper. We first represent the future motion of an instance with its direction, speed, and action classes. Then, we develop a deep neural network that exploits different levels of semantic information to perform the future motion estimation. For effective future motion classification, we adopt ordinal regression. Especially, we develop the cyclic ordinal regression scheme using binary classifiers. Experiments demonstrate that the proposed algorithm provides reliable performance and thus can be used effectively for vision applications, including single and multi object tracking. Furthermore, we release the future motion (FM) dataset, collected from diverse sources and annotated manually, as a benchmark for single-image future motion estimation.
count=1
* Fair Loss: Margin-Aware Reinforcement Learning for Deep Face Recognition
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Liu_Fair_Loss_Margin-Aware_Reinforcement_Learning_for_Deep_Face_Recognition_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Fair_Loss_Margin-Aware_Reinforcement_Learning_for_Deep_Face_Recognition_ICCV_2019_paper.pdf)]
    * Title: Fair Loss: Margin-Aware Reinforcement Learning for Deep Face Recognition
    * Year: `2019`
    * Authors: Bingyu Liu,  Weihong Deng,  Yaoyao Zhong,  Mei Wang,  Jiani Hu,  Xunqiang Tao,  Yaohai Huang
    * Abstract: Recently, large-margin softmax loss methods, such as angular softmax loss (SphereFace), large margin cosine loss (CosFace), and additive angular margin loss (ArcFace), have demonstrated impressive performance on deep face recognition. These methods incorporate a fixed additive margin to all the classes, ignoring the class imbalance problem. However, imbalanced problem widely exists in various real-world face datasets, in which samples from some classes are in a higher number than others. We argue that the number of a class would influence its demand for the additive margin. In this paper, we introduce a new margin-aware reinforcement learning based loss function, namely fair loss, in which each class will learn an appropriate adaptive margin by Deep Q-learning. Specifically, we train an agent to learn a margin adaptive strategy for each class, and make the additive margins for different classes more reasonable. Our method has better performance than present large-margin loss functions on three benchmarks, Labeled Face in the Wild (LFW), Youtube Faces (YTF) and MegaFace, which demonstrates that our method could learn better face representation on imbalanced face datasets.
count=1
* Distillation-Based Training for Multi-Exit Architectures
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Phuong_Distillation-Based_Training_for_Multi-Exit_Architectures_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Phuong_Distillation-Based_Training_for_Multi-Exit_Architectures_ICCV_2019_paper.pdf)]
    * Title: Distillation-Based Training for Multi-Exit Architectures
    * Year: `2019`
    * Authors: Mary Phuong,  Christoph H. Lampert
    * Abstract: Multi-exit architectures, in which a stack of processing layers is interleaved with early output layers, allow the processing of a test example to stop early and thus save computation time and/or energy. In this work, we propose a new training procedure for multi-exit architectures based on the principle of knowledge distillation. The method encourages early exits to mimic later, more accurate exits, by matching their probability outputs. Experiments on CIFAR100 and ImageNet show that distillation-based training significantly improves the accuracy of early exits while maintaining state-of-the-art accuracy for late ones. The method is particularly beneficial when training data is limited and also allows a straight-forward extension to semi-supervised learning, i.e. make use also of unlabeled data at training time. Moreover, it takes only a few lines to implement and imposes almost no computational overhead at training time, and none at all at test time.
count=1
* Discriminative Feature Transformation for Occluded Pedestrian Detection
    [[abs-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/html/Zhou_Discriminative_Feature_Transformation_for_Occluded_Pedestrian_Detection_ICCV_2019_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_Discriminative_Feature_Transformation_for_Occluded_Pedestrian_Detection_ICCV_2019_paper.pdf)]
    * Title: Discriminative Feature Transformation for Occluded Pedestrian Detection
    * Year: `2019`
    * Authors: Chunluan Zhou,  Ming Yang,  Junsong Yuan
    * Abstract: Despite promising performance achieved by deep con- volutional neural networks for non-occluded pedestrian de- tection, it remains a great challenge to detect partially oc- cluded pedestrians. Compared with non-occluded pedes- trian examples, it is generally more difficult to distinguish occluded pedestrian examples from background in featue space due to the missing of occluded parts. In this paper, we propose a discriminative feature transformation which en- forces feature separability of pedestrian and non-pedestrian examples to handle occlusions for pedestrian detection. Specifically, in feature space it makes pedestrian exam- ples approach the centroid of easily classified non-occluded pedestrian examples and pushes non-pedestrian examples close to the centroid of easily classified non-pedestrian ex- amples. Such a feature transformation partially compen- sates the missing contribution of occluded parts in feature space, therefore improving the performance for occluded pedestrian detection. We implement our approach in the Fast R-CNN framework by adding one transformation net- work branch. We validate the proposed approach on two widely used pedestrian detection datasets: Caltech and CityPersons. Experimental results show that our approach achieves promising performance for both non-occluded and occluded pedestrian detection.
count=1
* Low Compute and Fully Parallel Computer Vision With HashMatch
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Fanello_Low_Compute_and_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Fanello_Low_Compute_and_ICCV_2017_paper.pdf)]
    * Title: Low Compute and Fully Parallel Computer Vision With HashMatch
    * Year: `2017`
    * Authors: Sean Ryan Fanello, Julien Valentin, Adarsh Kowdle, Christoph Rhemann, Vladimir Tankovich, Carlo Ciliberto, Philip Davidson, Shahram Izadi
    * Abstract: Numerous computer vision problems such as stereo depth estimation, object-class segmentation and foreground/background segmentation can be formulated as per-pixel image labeling tasks. Given one or many images as input, the desired output of these methods is usually a spatially smooth assignment of labels. The large amount of such computer vision problems has lead to significant research efforts, with the state of art moving from CRF-based approaches to deep CNNs and more recently, hybrids of the two. Although these approaches have significantly advanced the state of the art, the vast majority has solely focused on improving quantitative results and are not designed for low-compute scenarios. In this paper, we present a new general framework for a variety of computer vision labeling tasks, called HashMatch. Our approach is designed to be both fully parallel, i.e. each pixel is independently processed, and low-compute, with a model complexity an order of magnitude less than existing CNN and CRF-based approaches. We evaluate HashMatch extensively on several problems such as disparity estimation, image retrieval, feature approximation and background subtraction, for which HashMatch achieves high computational efficiency while producing high quality results.
count=1
* SSD-6D: Making RGB-Based 3D Detection and 6D Pose Estimation Great Again
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Kehl_SSD-6D_Making_RGB-Based_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Kehl_SSD-6D_Making_RGB-Based_ICCV_2017_paper.pdf)]
    * Title: SSD-6D: Making RGB-Based 3D Detection and 6D Pose Estimation Great Again
    * Year: `2017`
    * Authors: Wadim Kehl, Fabian Manhardt, Federico Tombari, Slobodan Ilic, Nassir Navab
    * Abstract: We present a novel method for detecting 3D model instances and estimating their 6D poses from RGB data in a single shot. To this end, we extend the popular SSD paradigm to cover the full 6D pose space and train on synthetic model data only. Our approach competes or surpasses current state-of-the-art methods that leverage RGB-D data on multiple challenging datasets. Furthermore, our method produces these results at around 10Hz, which is many times faster than the related methods. For the sake of reproducibility, we make our trained networks and detection code publicly available.
count=1
* A Simple yet Effective Baseline for 3D Human Pose Estimation
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Martinez_A_Simple_yet_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Martinez_A_Simple_yet_ICCV_2017_paper.pdf)]
    * Title: A Simple yet Effective Baseline for 3D Human Pose Estimation
    * Year: `2017`
    * Authors: Julieta Martinez, Rayat Hossain, Javier Romero, James J. Little
    * Abstract: Following the success of deep convolutional networks, state-of-the-art methods for 3d human pose estimation have focused on deep end-to-end systems that predict 3d joint locations given raw image pixels. Despite their excellent performance, it is often not easy to understand whether their remaining error stems from a limited 2d pose (visual) understanding, or from a failure to map 2d poses into 3-dimensional positions. With the goal of understanding these sources of error, we set out to build a system that given 2d joint locations predicts 3d positions. Much to our surprise, we have found that, with current technology, "lifting" ground truth 2d joint locations to 3d space is a task that can be solved with a remarkably low error rate: a relatively simple deep feed-forward network outperforms the best reported result by about 30% on Human3.6M, the largest publicly available 3d pose estimation benchmark. Furthermore, training our system on the output of an off-the-shelf state-of-the-art 2d detector (i.e., using images as input) yields state of the art results -- this includes an array of systems that have been trained end-to-end specifically for this task. Our results indicate that a large portion of the error of modern deep 3d pose estimation systems stems from their visual analysis, and suggests directions to further advance the state of the art in 3d human pose estimation.
count=1
* BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects Without Using Depth
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Rad_BB8_A_Scalable_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Rad_BB8_A_Scalable_ICCV_2017_paper.pdf)]
    * Title: BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects Without Using Depth
    * Year: `2017`
    * Authors: Mahdi Rad, Vincent Lepetit
    * Abstract: We introduce a novel method for 3D object detection and pose estimation from color images only. We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background. By contrast with recent patch-based methods, we rely on a "holistic" approach: We apply to the detected objects a Convolutional Neural Network (CNN) trained to predict their 3D poses in the form of 2D projections of the corners of their 3D bounding boxes. This, however, is not sufficient for handling objects from the recent T-LESS dataset: These objects exhibit an axis of rotational symmetry, and the similarity of two images of such an object under two different poses makes training the CNN challenging. We solve this problem by restricting the range of poses used for training, and by introducing a classifier to identify the range of a pose at run-time before estimating it. We also use an optional additional step that refines the predicted poses. We improve the state-of-the-art on the LINEMOD dataset from 73.7% to 89.3% of correctly registered RGB frames. We are also the first to report results on the Occlusion dataset using color images only. We obtain 54% of frames passing the Pose 6D criterion on average on several sequences of the T-LESS dataset, compared to the 67% of the state-of-the-art on the same sequences which uses both color and depth. The full approach is also scalable, as a single network can be trained for multiple objects simultaneously.
count=1
* Deep Determinantal Point Process for Large-Scale Multi-Label Classification
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Xie_Deep_Determinantal_Point_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Xie_Deep_Determinantal_Point_ICCV_2017_paper.pdf)]
    * Title: Deep Determinantal Point Process for Large-Scale Multi-Label Classification
    * Year: `2017`
    * Authors: Pengtao Xie, Ruslan Salakhutdinov, Luntian Mou, Eric P. Xing
    * Abstract: We study large-scale multi-label classification (MLC) on two recently released datasets: Youtube-8M and Open Images that contain millions of data instances and thousands of classes. The unprecedented problem scale poses great challenges for MLC. First, finding out the correct label subset out of exponentially many choices incurs substantial ambiguity and uncertainty. Second, the large data-size and class-size entail considerable computational cost. To address the first challenge, we investigate two strategies: capturing label-correlations from the training data and incorporating label co-occurrence relations obtained from external knowledge, which effectively eliminate semantically inconsistent labels and provide contextual clues to differentiate visually ambiguous labels. Specifically, we propose a Deep Determinantal Point Process (DDPP) model which seamlessly integrates a DPP with deep neural networks (DNNs) and supports end-to-end multi-label learning and deep representation learning. The DPP is able to capture label-correlations of any order with a polynomial computational cost, while the DNNs learn hierarchical features of images/videos and capture the dependency between input data and labels. To incorporate external knowledge about label co-occurrence relations, we impose a relational regularization over the kernel matrix in DDPP. To address the second challenge, we study an efficient low-rank kernel learning algorithm based on inducing point methods. Experiments on the two datasets demonstrate the efficacy and efficiency of the proposed methods.
count=1
* Supplementary Meta-Learning: Towards a Dynamic Model for Deep Neural Networks
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Supplementary_Meta-Learning_Towards_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Supplementary_Meta-Learning_Towards_ICCV_2017_paper.pdf)]
    * Title: Supplementary Meta-Learning: Towards a Dynamic Model for Deep Neural Networks
    * Year: `2017`
    * Authors: Feihu Zhang, Benjamin W. Wah
    * Abstract: Data diversity in terms of types, styles, as well as radiometric, exposure and texture conditions widely exists in training and test data of vision applications. However, learning in traditional neural networks (NNs) only tries to find a model with fixed parameters that optimize the average behavior over all inputs, without using data-specific properties. In this paper, we develop a meta-level NN (MLNN) model that learns meta-knowledge on data-specific properties of images during learning and that dynamically adapts its weights during application according to the properties of the images input. MLNN consists of two parts: the dynamic supplementary NN (SNN) that learns meta-information on each type of inputs, and the fixed base-level NN (BLNN) that incorporates the meta-information from SNN into its weights at run time to realize the generalization for each type of inputs. We verify our approach using over ten network architectures under various application scenarios and loss functions. In low-level vision applications on image super-resolution and denoising, MLNN has 0.1 0.3 dB improvements on PSNR, whereas for high-level image classification, MLNN has accuracy improvement of 0.4 0.6% for Cifar10 and 1.2 2.1% for ImageNet when compared to convolutional NNs (CNNs). Improvements are more pronounced as the scale or diversity of data is increased.
count=1
* Truncating Wide Networks Using Binary Tree Architectures
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Truncating_Wide_Networks_ICCV_2017_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Truncating_Wide_Networks_ICCV_2017_paper.pdf)]
    * Title: Truncating Wide Networks Using Binary Tree Architectures
    * Year: `2017`
    * Authors: Yan Zhang, Mete Ozay, Shuohao Li, Takayuki Okatani
    * Abstract: In this paper, we propose a binary tree architecture to truncate architecture of wide networks by reducing the width of the networks. More precisely, in the proposed architecture, the width is incrementally reduced from lower layers to higher layers in order to increase the expressive capacity of networks with a less increase on parameter size. Also, in order to ease the gradient vanishing problem, features obtained at different layers are concatenated to form the output of our architecture. By employing the proposed architecture on a baseline wide network, we can construct and train a new network with same depth but considerably less number of parameters. In our experimental analyses, we observe that the proposed architecture enables us to obtain better parameter size and accuracy trade-off compared to baseline networks using various benchmark image classification datasets. The results show that our model can decrease the classification error of a baseline from 20.43% to 19.22% on Cifar-100 using only 28% of parameters that the baseline has.
count=1
* Adaptive Hashing for Fast Similarity Search
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Cakir_Adaptive_Hashing_for_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Cakir_Adaptive_Hashing_for_ICCV_2015_paper.pdf)]
    * Title: Adaptive Hashing for Fast Similarity Search
    * Year: `2015`
    * Authors: Fatih Cakir, Stan Sclaroff
    * Abstract: With the staggering growth in image and video datasets, algorithms that provide fast similarity search and compact storage are crucial. Hashing methods that map the data into Hamming space have shown promise; however, many of these methods employ a batch-learning strategy in which the computational cost and memory requirements may become intractable and infeasible with larger and larger datasets. To overcome these challenges, we propose an online learning algorithm based on stochastic gradient descent in which the hash functions are updated iteratively with streaming data. In experiments with three image retrieval benchmarks, our online algorithm attains retrieval accuracy that is comparable to competing state-of-the-art batch-learning solutions, while our formulation is orders of magnitude faster and being online it is adaptable to the variations of the data. Moreover, our formulation yields improved retrieval performance over a recently reported online hashing technique, Online Kernel Hashing.
count=1
* A Novel Representation of Parts for Accurate 3D Object Detection and Tracking in Monocular Images
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Crivellaro_A_Novel_Representation_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Crivellaro_A_Novel_Representation_ICCV_2015_paper.pdf)]
    * Title: A Novel Representation of Parts for Accurate 3D Object Detection and Tracking in Monocular Images
    * Year: `2015`
    * Authors: Alberto Crivellaro, Mahdi Rad, Yannick Verdie, Kwang Moo Yi, Pascal Fua, Vincent Lepetit
    * Abstract: We present a method that estimates in real-time and under challenging conditions the 3D pose of a known object. Our method relies only on grayscale images since depth cameras fail on metallic objects; it can handle poorly textured objects, and cluttered, changing environments; the pose it predicts degrades gracefully in presence of large occlusions. As a result, by contrast with the state-of-the-art, our method is suitable for practical Augmented Reality applications even in industrial environments. To be robust to occlusions, we first learn to detect some parts of the target object. Our key idea is to then predict the 3D pose of each part in the form of the 2D projections of a few control points. The advantages of this representation is three-fold: We can predict the 3D pose of the object even when only one part is visible; when several parts are visible, we can combine them easily to compute a better pose of the object; the 3D pose we obtain is usually very accurate, even when only few parts are visible.
count=1
* Person Re-Identification With Discriminatively Trained Viewpoint Invariant Dictionaries
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Karanam_Person_Re-Identification_With_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Karanam_Person_Re-Identification_With_ICCV_2015_paper.pdf)]
    * Title: Person Re-Identification With Discriminatively Trained Viewpoint Invariant Dictionaries
    * Year: `2015`
    * Authors: Srikrishna Karanam, Yang Li, Richard J. Radke
    * Abstract: This paper introduces a new approach to address the person re-identification problem in cameras with non-overlapping fields of view. Unlike previous approaches that learn Mahalanobis-like distance metrics in some transformed feature space, we propose to learn a dictionary that is capable of discriminatively and sparsely encoding features representing different people. Our approach directly addresses two key challenges in person re-identification: viewpoint variations and discriminability. First, to tackle viewpoint and associated appearance changes, we learn a single dictionary to represent both gallery and probe images in the training phase. We then discriminatively train the dictionary by enforcing explicit constraints on the associated sparse representations of the feature vectors. In the testing phase, we re-identify a probe image by simply determining the gallery image that has the closest sparse representation to that of the probe image in the Euclidean sense. Extensive performance evaluations on three publicly available multi-shot re-identification datasets demonstrate the advantages of our algorithm over several state-of-the-art dictionary learning, temporal sequence matching, and spatial appearance and metric learning based techniques.
count=1
* SOWP: Spatially Ordered and Weighted Patch Descriptor for Visual Tracking
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Kim_SOWP_Spatially_Ordered_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Kim_SOWP_Spatially_Ordered_ICCV_2015_paper.pdf)]
    * Title: SOWP: Spatially Ordered and Weighted Patch Descriptor for Visual Tracking
    * Year: `2015`
    * Authors: Han-Ul Kim, Dae-Youn Lee, Jae-Young Sim, Chang-Su Kim
    * Abstract: A simple yet effective object descriptor for visual tracking is proposed in this paper. We first decompose the bounding box of a target object into multiple patches, which are described by color and gradient histograms. Then, we concatenate the features of the spatially ordered patches to represent the object appearance. Moreover, to alleviate the impacts of background information possibly included in the bounding box, we determine patch weights using random walk with restart (RWR) simulations. The patch weights represent the importance of each patch in the description of foreground information, and are used to construct an object descriptor, called spatially ordered and weighted patch (SOWP) descriptor. We incorporate the proposed SOWP descriptor into the structured output tracking framework. Experimental results demonstrate that the proposed algorithm yields significantly better performance than the state-of-the-art trackers on a recent benchmark dataset, and also excels in another recent benchmark dataset.
count=1
* Fast and Accurate Head Pose Estimation via Random Projection Forests
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Lee_Fast_and_Accurate_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Lee_Fast_and_Accurate_ICCV_2015_paper.pdf)]
    * Title: Fast and Accurate Head Pose Estimation via Random Projection Forests
    * Year: `2015`
    * Authors: Donghoon Lee, Ming-Hsuan Yang, Songhwai Oh
    * Abstract: In this paper, we consider the problem of estimating the gaze direction of a person from a low-resolution image. Under this condition, reliably extracting facial features is very difficult. We propose a novel head pose estimation algorithm based on compressive sensing. Head image patches are mapped to a large feature space using the proposed extensive, yet efficient filter bank. The filter bank is designed to generate sparse responses of color and gradient information, which can be compressed using random projection, and classified by a random forest. Extensive experiments on challenging datasets show that the proposed algorithm performs favorably against the state-of-the-art methods on head pose estimation in low-resolution images degraded by noise, occlusion, and blurring.
count=1
* A Multiscale Variable-Grouping Framework for MRF Energy Minimization
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Meir_A_Multiscale_Variable-Grouping_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Meir_A_Multiscale_Variable-Grouping_ICCV_2015_paper.pdf)]
    * Title: A Multiscale Variable-Grouping Framework for MRF Energy Minimization
    * Year: `2015`
    * Authors: Omer Meir, Meirav Galun, Stav Yagev, Ronen Basri, Irad Yavneh
    * Abstract: We present a multiscale approach for minimizing the energy associated with Markov Random Fields (MRFs) with energy functions that include arbitrary pairwise potentials. The MRF is represented on a hierarchy of successively coarser scales, where the problem on each scale is itself an MRF with suitably defined potentials. These representations are used to construct an efficient multiscale algorithm that seeks a minimal-energy solution to the original problem. The algorithm is iterative and features a bidirectional crosstalk between fine and coarse representations. We use consistency criteria to guarantee that the energy is nonincreasing throughout the iterative process. The algorithm is evaluated on real-world datasets, achieving competitive performance in relatively short run-times.
count=1
* Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Plummer_Flickr30k_Entities_Collecting_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Plummer_Flickr30k_Entities_Collecting_ICCV_2015_paper.pdf)]
    * Title: Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
    * Year: `2015`
    * Authors: Bryan A. Plummer, Liwei Wang, Chris M. Cervantes, Juan C. Caicedo, Julia Hockenmaier, Svetlana Lazebnik
    * Abstract: The Flickr30k dataset has become a standard benchmark for sentence-based image description. This paper presents Flickr30k Entities, which augments the 158k captions from Flickr30k with 244k coreference chains linking mentions of the same entities in images, as well as 276k manually annotated bounding boxes corresponding to each entity. Such annotation is essential for continued progress in automatic image description and grounded language understanding. We present experiments demonstrating the usefulness of our annotations for text-to-image reference resolution, or the task of localizing textual entity mentions in an image, and for bidirectional image-sentence retrieval. These experiments confirm that we can further improve the accuracy of state-of-the-art retrieval methods by training with explicit region-to-phrase correspondence, but at the same time, they show that accurately inferring this correspondence given an image and a caption remains really challenging.
count=1
* Improving Ferns Ensembles by Sparsifying and Quantising Posterior Probabilities
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Rodriguez_Improving_Ferns_Ensembles_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Rodriguez_Improving_Ferns_Ensembles_ICCV_2015_paper.pdf)]
    * Title: Improving Ferns Ensembles by Sparsifying and Quantising Posterior Probabilities
    * Year: `2015`
    * Authors: Antonio L. Rodriguez, Vitor Sequeira
    * Abstract: Ferns ensembles offer an accurate and efficient multiclass non-linear classification, commonly at the expense of consuming a large amount of memory. We introduce a two-fold contribution that produces large reductions in their memory consumption. First, an efficient L0 regularised cost optimisation finds a sparse representation of the posterior probabilities in the ensemble by discarding elements with zero contribution to valid responses in the training samples. As a by-product this can produce a prediction accuracy gain that, if required, can be traded for further reductions in memory size and prediction time. Secondly, posterior probabilities are quantised and stored in a memory-friendly sparse data structure. We reported a minimum of 75% memory reduction for different types of classification problems using generative and discriminative ferns ensembles, without increasing prediction time or classification error. For image patch recognition our proposal produced a 90% memory reduction, and improved in several percentage points the prediction accuracy.
count=1
* Naive Bayes Super-Resolution Forest
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Salvador_Naive_Bayes_Super-Resolution_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Salvador_Naive_Bayes_Super-Resolution_ICCV_2015_paper.pdf)]
    * Title: Naive Bayes Super-Resolution Forest
    * Year: `2015`
    * Authors: Jordi Salvador, Eduardo Perez-Pellitero
    * Abstract: This paper presents a fast, high-performance method for super resolution with external learning. The first contribution leading to the excellent performance is a bimodal tree for clustering, which successfully exploits the antipodal invariance of the coarse-to-high-res mapping of natural image patches and provides scalability to finer partitions of the underlying coarse patch space. During training an ensemble of such bimodal trees is computed, providing different linearizations of the mapping. The second and main contribution is a fast inference algorithm, which selects the most suitable mapping function within the tree ensemble for each patch by adopting a Local Naive Bayes formulation. The experimental validation shows promising scalability properties that reflect the suitability of the proposed model, which may also be generalized to other tasks. The resulting method is beyond one order of magnitude faster and performs objectively and subjectively better than the current state of the art.
count=1
* Learning Binary Codes for Maximum Inner Product Search
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Shen_Learning_Binary_Codes_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Shen_Learning_Binary_Codes_ICCV_2015_paper.pdf)]
    * Title: Learning Binary Codes for Maximum Inner Product Search
    * Year: `2015`
    * Authors: Fumin Shen, Wei Liu, Shaoting Zhang, Yang Yang, Heng Tao Shen
    * Abstract: Binary coding or hashing techniques are recognized to accomplish efficient near neighbor search, and have thus attracted broad interests in the recent vision and learning studies. However, such studies have rarely been dedicated to Maximum Inner Product Search (MIPS), which plays a critical role in various vision applications. In this paper, we investigate learning binary codes to exclusively handle the MIPS problem. Inspired by the latest advance in asymmetric hashing schemes, we propose an asymmetric binary code learning framework based on inner product fitting. Specifically, two sets of coding functions are learned such that the inner products between their generated binary codes can reveal the inner products between original data vectors. We also propose an alternative simpler objective which maximizes the correlations between the inner products of the produced binary codes and raw data vectors. In both objectives, the binary codes and coding functions are simultaneously learned without continuous relaxations, which is the key to achieving high-quality binary codes. We evaluate the proposed method, dubbed Asymmetric Inner-product Binary Coding (AIBC), relying on the two objectives on several large-scale image datasets. Both of them are superior to the state-of-the-art binary coding and hashing methods in performing MIPS tasks.
count=1
* Depth-Based Hand Pose Estimation: Data, Methods, and Challenges
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/Supancic_Depth-Based_Hand_Pose_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/Supancic_Depth-Based_Hand_Pose_ICCV_2015_paper.pdf)]
    * Title: Depth-Based Hand Pose Estimation: Data, Methods, and Challenges
    * Year: `2015`
    * Authors: James S. Supancic III, Gregory Rogez, Yi Yang, Jamie Shotton, Deva Ramanan
    * Abstract: Hand pose estimation has matured rapidly in recent years. The introduction of commodity depth sensors and a multitude of practical applications have spurred new advances. We provide an extensive analysis of the state-of-the-art, focusing on hand pose estimation from a single depth frame. To do so, we have implemented a considerable number of systems, and will release all software and evaluation code. We summarize important conclusions here: (1) Pose estimation appears roughly solved for scenes with isolated hands. However, methods still struggle to analyze cluttered scenes where hands may be interacting with nearby objects and surfaces. To spur further progress we introduce a challenging new dataset with diverse, cluttered scenes. (2) Many methods evaluate themselves with disparate criteria, making comparisons difficult. We define a consistent evaluation criteria, rigorously motivated by human experiments. (3) We introduce a simple nearest-neighbor baseline that outperforms most existing systems. This implies that most systems do not generalize beyond their training sets. This also reinforces the under-appreciated point that training data is as important as the model itself. We conclude with directions for future progress.
count=1
* Illumination Robust Color Naming via Label Propagation
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2015/html/liu_Illumination_Robust_Color_ICCV_2015_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2015/papers/liu_Illumination_Robust_Color_ICCV_2015_paper.pdf)]
    * Title: Illumination Robust Color Naming via Label Propagation
    * Year: `2015`
    * Authors: Yuanliu liu, Zejian Yuan, Badong Chen, Jianru Xue, Nanning Zheng
    * Abstract: Color composition is an important property for many computer vision tasks like image retrieval and object classification. In this paper we address the problem of inferring the color composition of the intrinsic reflectance of objects, where the shadows and highlights may change the observed color dramatically. We achieve this through color label propagation without recovering the intrinsic reflectance beforehand. Specifically, the color labels are propagated between regions sharing the same reflectance, and the direction of propagation is promoted to be from regions under full illumination and normal view angles to abnormal regions. We detect shadowed and highlighted regions as well as pairs of regions that have similar reflectance. A joint inference process is adopted to trim the inconsistent identities and connections. For evaluation we collect three datasets of images under noticeable highlights and shadows. Experimental results show that our model can effectively describe the color composition of real-world images.
count=1
* Randomized Ensemble Tracking
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Bai_Randomized_Ensemble_Tracking_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Bai_Randomized_Ensemble_Tracking_2013_ICCV_paper.pdf)]
    * Title: Randomized Ensemble Tracking
    * Year: `2013`
    * Authors: Qinxun Bai, Zheng Wu, Stan Sclaroff, Margrit Betke, Camille Monnier
    * Abstract: We propose a randomized ensemble algorithm to model the time-varying appearance of an object for visual tracking. In contrast with previous online methods for updating classifier ensembles in tracking-by-detection, the weight vector that combines weak classifiers is treated as a random variable and the posterior distribution for the weight vector is estimated in a Bayesian manner. In essence, the weight vector is treated as a distribution that reflects the confidence among the weak classifiers used to construct and adapt the classifier ensemble. The resulting formulation models the time-varying discriminative ability among weak classifiers so that the ensembled strong classifier can adapt to the varying appearance, backgrounds, and occlusions. The formulation is tested in a tracking-by-detection implementation. Experiments on 28 challenging benchmark videos demonstrate that the proposed method can achieve results comparable to and often better than those of stateof-the-art approaches.
count=1
* Restoring an Image Taken through a Window Covered with Dirt or Rain
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Eigen_Restoring_an_Image_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Eigen_Restoring_an_Image_2013_ICCV_paper.pdf)]
    * Title: Restoring an Image Taken through a Window Covered with Dirt or Rain
    * Year: `2013`
    * Authors: David Eigen, Dilip Krishnan, Rob Fergus
    * Abstract: Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside a vehicle, or outdoor security cameras mounted inside a protective enclosure. At capture time, defocus can be used to remove the artifacts, but this relies on achieving a shallow depth-of-field and placement of the camera close to the window. Instead, we present a post-capture image processing solution that can remove localized rain and dirt artifacts from a single image. We collect a dataset of clean/corrupted image pairs which are then used to train a specialized form of convolutional neural network. This learns how to map corrupted image patches to clean ones, implicitly capturing the characteristic appearance of dirt and water droplets in natural images. Our models demonstrate effective removal of dirt and rain in outdoor test conditions.
count=1
* Real-World Normal Map Capture for Nearly Flat Reflective Surfaces
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Jacquet_Real-World_Normal_Map_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Jacquet_Real-World_Normal_Map_2013_ICCV_paper.pdf)]
    * Title: Real-World Normal Map Capture for Nearly Flat Reflective Surfaces
    * Year: `2013`
    * Authors: Bastien Jacquet, Christian Hane, Kevin Koser, Marc Pollefeys
    * Abstract: Although specular objects have gained interest in recent years, virtually no approaches exist for markerless reconstruction of reflective scenes in the wild. In this work, we present a practical approach to capturing normal maps in real-world scenes using video only. We focus on nearly planar surfaces such as windows, facades from glass or metal, or frames, screens and other indoor objects and show how normal maps of these can be obtained without the use of an artificial calibration object. Rather, we track the reflections of real-world straight lines, while moving with a hand-held or vehicle-mounted camera in front of the object. In contrast to error-prone local edge tracking, we obtain the reflections by a robust, global segmentation technique of an ortho-rectified 3D video cube that also naturally allows efficient user interaction. Then, at each point of the reflective surface, the resulting 2D-curve to 3D-line correspondence provides a novel quadratic constraint on the local surface normal. This allows to globally solve for the shape by integrability and smoothness constraints and easily supports the usage of multiple lines. We demonstrate the technique on several objects and facades.
count=1
* Attribute Pivots for Guiding Relevance Feedback in Image Search
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Kovashka_Attribute_Pivots_for_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Kovashka_Attribute_Pivots_for_2013_ICCV_paper.pdf)]
    * Title: Attribute Pivots for Guiding Relevance Feedback in Image Search
    * Year: `2013`
    * Authors: Adriana Kovashka, Kristen Grauman
    * Abstract: In interactive image search, a user iteratively refines his results by giving feedback on exemplar images. Active selection methods aim to elicit useful feedback, but traditional approaches suffer from expensive selection criteria and cannot predict informativeness reliably due to the imprecision of relevance feedback. To address these drawbacks, we propose to actively select "pivot" exemplars for which feedback in the form of a visual comparison will most reduce the system's uncertainty. For example, the system might ask, "Is your target image more or less crowded than this image?" Our approach relies on a series of binary search trees in relative attribute space, together with a selection function that predicts the information gain were the user to compare his envisioned target to the next node deeper in a given attribute's tree. It makes interactive search more efficient than existing strategies--both in terms of the system's selection time as well as the user's feedback effort.
count=1
* Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Levinkov_Sequential_Bayesian_Model_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Levinkov_Sequential_Bayesian_Model_2013_ICCV_paper.pdf)]
    * Title: Sequential Bayesian Model Update under Structured Scene Prior for Semantic Road Scenes Labeling
    * Year: `2013`
    * Authors: Evgeny Levinkov, Mario Fritz
    * Abstract: Semantic road labeling is a key component of systems that aim at assisted or even autonomous driving. Considering that such systems continuously operate in the realworld, unforeseen conditions not represented in any conceivable training procedure are likely to occur on a regular basis. In order to equip systems with the ability to cope with such situations, we would like to enable adaptation to such new situations and conditions at runtime. Existing adaptive methods for image labeling either require labeled data from the new condition or even operate globally on a complete test set. None of this is a desirable mode of operation for a system as described above where new images arrive sequentially and conditions may vary. We study the effect of changing test conditions on scene labeling methods based on a new diverse street scene dataset. We propose a novel approach that can operate in such conditions and is based on a sequential Bayesian model update in order to robustly integrate the arriving images into the adapting procedure.
count=1
* Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection
    [[abs-ICCV](https://openaccess.thecvf.com/content_iccv_2013/html/Wu_Learning_Near-Optimal_Cost-Sensitive_2013_ICCV_paper.html)]
    [[pdf-ICCV](https://openaccess.thecvf.com/content_iccv_2013/papers/Wu_Learning_Near-Optimal_Cost-Sensitive_2013_ICCV_paper.pdf)]
    * Title: Learning Near-Optimal Cost-Sensitive Decision Policy for Object Detection
    * Year: `2013`
    * Authors: Tianfu Wu, Song-Chun Zhu
    * Abstract: Many object detectors, such as AdaBoost, SVM and deformable part-based models (DPM), compute additive scoring functions at a large number of windows scanned over image pyramid, thus computational efficiency is an important consideration beside accuracy performance. In this paper, we present a framework of learning cost-sensitive decision policy which is a sequence of two-sided thresholds to execute early rejection or early acceptance based on the accumulative scores at each step. A decision policy is said to be optimal if it minimizes an empirical global risk function that sums over the loss of false negatives (FN) and false positives (FP), and the cost of computation. While the risk function is very complex due to high-order connections among the two-sided thresholds, we find its upper bound can be optimized by dynamic programming (DP) efficiently and thus say the learned policy is near-optimal. Given the loss of FN and FP and the cost in three numbers, our method can produce a policy on-the-fly for Adaboost, SVM and DPM. In experiments, we show that our decision policy outperforms state-of-the-art cascade methods significantly in terms of speed with similar accuracy performance.
count=1
* Scalable Membership Inference Attacks via Quantile Regression
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/01328d0767830e73a612f9073e9ff15f-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/01328d0767830e73a612f9073e9ff15f-Paper-Conference.pdf)]
    * Title: Scalable Membership Inference Attacks via Quantile Regression
    * Year: `2023`
    * Authors: Martin Bertran, Shuai Tang, Aaron Roth, Michael Kearns, Jamie H. Morgenstern, Steven Z. Wu
    * Abstract: Membership inference attacks are designed to determine, using black box access to trained models, whether a particular example was used in training or not. Membership inference can be formalized as a hypothesis testing problem. The most effective existing attacks estimate the distribution of some test statistic (usually the model's confidence on the true label) on points that were (and were not) used in training by training many \emph{shadow models}---i.e. models of the same architecture as the model being attacked, trained on a random subsample of data. While effective, these attacks are extremely computationally expensive, especially when the model under attack is large. \footnotetext[0]{Martin and Shuai are the lead authors, and other authors are ordered alphabetically. {maberlop,shuat}@amazon.com}We introduce a new class of attacks based on performing quantile regression on the distribution of confidence scores induced by the model under attack on points that are not used in training. We show that our method is competitive with state-of-the-art shadow model attacks, while requiring substantially less compute because our attack requires training only a single model. Moreover, unlike shadow model attacks, our proposed attack does not require any knowledge of the architecture of the model under attack and is therefore truly ``black-box". We show the efficacy of this approach in an extensive series of experiments on various datasets and model architectures. Our code is available at \href{https://github.com/amazon-science/quantile-mia}{github.com/amazon-science/quantile-mia.}
count=1
* AllSim: Simulating and Benchmarking Resource Allocation Policies in Multi-User Systems
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/0296e17ec30fc36007edaaa2f96b5f17-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/0296e17ec30fc36007edaaa2f96b5f17-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: AllSim: Simulating and Benchmarking Resource Allocation Policies in Multi-User Systems
    * Year: `2023`
    * Authors: Jeroen Berrevoets, Daniel Jarrett, Alex Chan, Mihaela van der Schaar
    * Abstract: Numerous real-world systems, ranging from healthcare to energy grids, involve users competing for finite and potentially scarce resources. Designing policies for resource allocation in such real-world systems is challenging for many reasons, including the changing nature of user types and their (possibly urgent) need for resources. Researchers have developed numerous machine learning solutions for determining resource allocation policies in these challenging settings. However, a key limitation has been the absence of good methods and test-beds for benchmarking these policies; almost all resource allocation policies are benchmarked in environments which are either completely synthetic or do not allow any deviation from historical data. In this paper we introduce AllSim, which is a benchmarking environment for realistically simulating the impact and utility of policies for resource allocation in systems in which users compete for such scarce resources. Building such a benchmarking environment is challenging because it needs to successfully take into account the entire collective of potential users and the impact a resource allocation policy has on all the other users in the system. AllSim's benchmarking environment is modular (each component being parameterized individually), learnable (informed by historical data), and customizable (adaptable to changing conditions). These, when interacting with an allocation policy, produce a dataset of simulated outcomes for evaluation and comparison of such policies. We believe AllSim is an essential step towards a more systematic evaluation of policies for scarce resource allocation compared to current approaches for benchmarking such methods.
count=1
* $\mathcal{M}^4$: A Unified XAI Benchmark for Faithfulness Evaluation of Feature Attribution Methods across Metrics, Modalities and Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/05957c194f4c77ac9d91e1374d2def6b-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/05957c194f4c77ac9d91e1374d2def6b-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: $\mathcal{M}^4$: A Unified XAI Benchmark for Faithfulness Evaluation of Feature Attribution Methods across Metrics, Modalities and Models
    * Year: `2023`
    * Authors: Xuhong Li, Mengnan Du, Jiamin Chen, Yekun Chai, Himabindu Lakkaraju, Haoyi Xiong
    * Abstract: While Explainable Artificial Intelligence (XAI) techniques have been widely studied to explain predictions made by deep neural networks, the way to evaluate the faithfulness of explanation results remains challenging, due to the heterogeneity of explanations for various models and the lack of ground-truth explanations. This paper introduces an XAI benchmark named $\mathcal{M}^4$, which allows evaluating various input feature attribution methods using the same set of faithfulness metrics across multiple data modalities (images and texts) and network structures (ResNets, MobileNets, Transformers). A taxonomy for the metrics has been proposed as well. We first categorize commonly used XAI evaluation metrics into three groups based on the ground truth they require. We then implement classic and state-of-the-art feature attribution methods using InterpretDL and conduct extensive experiments to compare methods and gain insights. Extensive experiments have been conducted to provide holistic evaluations as benchmark baselines. Several interesting observations are noticed for designing attribution algorithms. The implementation of state-of-the-art explanation methods and evaluation metrics of $\mathcal{M}^4$ is publicly available at \url{https://github.com/PaddlePaddle/InterpretDL}.
count=1
* Information Maximization Perspective of Orthogonal Matching Pursuit with Applications to Explainable AI
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/08eac13583b310ec55d755f99c549be3-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/08eac13583b310ec55d755f99c549be3-Paper-Conference.pdf)]
    * Title: Information Maximization Perspective of Orthogonal Matching Pursuit with Applications to Explainable AI
    * Year: `2023`
    * Authors: Aditya Chattopadhyay, Ryan Pilgrim, Rene Vidal
    * Abstract: Information Pursuit (IP) is a classical active testing algorithm for predicting an output by sequentially and greedily querying the input in order of information gain. However, IP is computationally intensive since it involves estimating mutual information in high-dimensional spaces. This paper explores Orthogonal Matching Pursuit (OMP) as an alternative to IP for greedily selecting the queries. OMP is a classical signal processing algorithm for sequentially encoding a signal in terms of dictionary atoms chosen in order of correlation gain. In each iteration, OMP selects the atom that is most correlated with the signal residual (the signal minus its reconstruction thus far). Our first contribution is to establish a fundamental connection between IP and OMP, where we prove that IP with random projections of dictionary atoms as queries ``almost'' reduces to OMP, with the difference being that IP selects atoms in order of normalized correlation gain. We call this version IP-OMP and present simulations indicating that this difference does not have any appreciable effect on the sparse code recovery rate of IP-OMP compared to that of OMP for random Gaussian dictionaries. Inspired by this connection, our second contribution is to explore the utility of IP-OMP for generating explainable predictions, an area in which IP has recently gained traction. More specifically, we propose a simple explainable AI algorithm which encodes an image as a sparse combination of semantically meaningful dictionary atoms that are defined as text embeddings of interpretable concepts. The final prediction is made using the weights of this sparse combination, which serve as an explanation. Empirically, our proposed algorithm is not only competitive with existing explainability methods but also computationally less expensive.
count=1
* Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/096b1019463f34eb241e87cfce8dfe16-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/096b1019463f34eb241e87cfce8dfe16-Paper-Conference.pdf)]
    * Title: Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples
    * Year: `2023`
    * Authors: Hao Sun, Alihan Hüyük, Daniel Jarrett, Mihaela van der Schaar
    * Abstract: Learning controllers with offline data in decision-making systems is an essential area of research due to its potential to reduce the risk of applications in real-world systems. However, in responsibility-sensitive settings such as healthcare, decision accountability is of paramount importance, yet has not been adequately addressed by the literature.This paper introduces the Accountable Offline Controller (AOC) that employs the offline dataset as the Decision Corpus and performs accountable control based on a tailored selection of examples, referred to as the Corpus Subset. AOC operates effectively in low-data scenarios, can be extended to the strictly offline imitation setting, and displays qualities of both conservation and adaptability.We assess AOC's performance in both simulated and real-world healthcare scenarios, emphasizing its capability to manage offline control tasks with high levels of performance while maintaining accountability.
count=1
* Characterizing the Impacts of Semi-supervised Learning for Weak Supervision
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/0d6270381e018b3d83eb9be7d0b06036-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/0d6270381e018b3d83eb9be7d0b06036-Paper-Conference.pdf)]
    * Title: Characterizing the Impacts of Semi-supervised Learning for Weak Supervision
    * Year: `2023`
    * Authors: Jeffrey Li, Jieyu Zhang, Ludwig Schmidt, Alexander J. Ratner
    * Abstract: Labeling training data is a critical and expensive step in producing high accuracy ML models, whether training from scratch or fine-tuning. To make labeling more efficient, two major approaches are programmatic weak supervision (WS) and semi-supervised learning (SSL). More recent works have either explicitly or implicitly used techniques at their intersection, but in various complex and ad hoc ways. In this work, we define a simple, modular design space to study the use of SSL techniques for WS more systematically. Surprisingly, we find that fairly simple methods from our design space match the performance of more complex state-of-the-art methods, averaging a 3 p.p. increase in accuracy/F1-score across 8 standard WS benchmarks. Further, we provide practical guidance on when different components are worth their added complexity and training costs. Contrary to current understanding, we find using SSL is not necessary to obtain the best performance on most WS benchmarks but is more effective when: (1) end models are smaller, and (2) WS provides labels for only a small portion of training examples.
count=1
* Counterfactually Fair Representation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/2828ee0c871f78a98ed2a198a166a439-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/2828ee0c871f78a98ed2a198a166a439-Paper-Conference.pdf)]
    * Title: Counterfactually Fair Representation
    * Year: `2023`
    * Authors: Zhiqun Zuo, Mahdi Khalili, Xueru Zhang
    * Abstract: The use of machine learning models in high-stake applications (e.g., healthcare, lending, college admission) has raised growing concerns due to potential biases against protected social groups. Various fairness notions and methods have been proposed to mitigate such biases. In this work, we focus on Counterfactual Fairness (CF), a fairness notion that is dependent on an underlying causal graph and first proposed by Kusner $\textit{et al.}$; it requires that the outcome an individual perceives is the same in the real world as it would be in a "counterfactual" world, in which the individual belongs to another social group. Learning fair models satisfying CF can be challenging. It was shown in (Kusner $\textit{et al.}$) that a sufficient condition for satisfying CF is to $\textbf{not}$ use features that are descendants of sensitive attributes in the causal graph. This implies a simple method that learns CF models only using non-descendants of sensitive attributes while eliminating all descendants. Although several subsequent works proposed methods that use all features for training CF models, there is no theoretical guarantee that they can satisfy CF. In contrast, this work proposes a new algorithm that trains models using all the available features. We theoretically and empirically show that models trained with this method can satisfy CF.
count=1
* WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit Courts
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/29c80c549ed67ddd7259559c1bb07c1b-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/29c80c549ed67ddd7259559c1bb07c1b-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit Courts
    * Year: `2023`
    * Authors: Elliott Ash, Naman Goel, Nianyun Li, Claudia Marangon, Peiyao Sun
    * Abstract: Machine learning based decision-support tools in criminal justice systems are subjects of intense discussions and academic research. There are important open questions about the utility and fairness of such tools. Academic researchers often rely on a few small datasets that are not sufficient to empirically study various real-world aspects of these questions. In this paper, we contribute WCLD, a curated large dataset of 1.5 million criminal cases from circuit courts in the U.S. state of Wisconsin. We used reliable public data from 1970 to 2020 to curate attributes like prior criminal counts and recidivism outcomes. The dataset contains large number of samples from five racial groups, in addition to information like sex and age (at judgment and first offense). Other attributes in this dataset include neighborhood characteristics obtained from census data, detailed types of offense, charge severity, case decisions, sentence lengths, year of filing etc. We also provide pseudo-identifiers for judge, county and zipcode. The dataset will not only enable researchers to more rigorously study algorithmic fairness in the context of criminal justice, but also relate algorithmic challenges with various systemic issues. We also discuss in detail the process of constructing the dataset and provide a datasheet. The WCLD dataset is available at https://clezdata.github.io/wcld/.
count=1
* Joint Training of Deep Ensembles Fails Due to Learner Collusion
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/2bde8fef08f7ebe42b584266cbcfc909-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/2bde8fef08f7ebe42b584266cbcfc909-Paper-Conference.pdf)]
    * Title: Joint Training of Deep Ensembles Fails Due to Learner Collusion
    * Year: `2023`
    * Authors: Alan Jeffares, Tennison Liu, Jonathan Crabbé, Mihaela van der Schaar
    * Abstract: Ensembles of machine learning models have been well established as a powerful method of improving performance over a single model. Traditionally, ensembling algorithms train their base learners independently or sequentially with the goal of optimizing their joint performance. In the case of deep ensembles of neural networks, we are provided with the opportunity to directly optimize the true objective: the joint performance of the ensemble as a whole. Surprisingly, however, directly minimizing the loss of the ensemble appears to rarely be applied in practice. Instead, most previous research trains individual models independently with ensembling performed post hoc. In this work, we show that this is for good reason - joint optimization of ensemble loss results in degenerate behavior. We approach this problem by decomposing the ensemble objective into the strength of the base learners and the diversity between them. We discover that joint optimization results in a phenomenon in which base learners collude to artificially inflate their apparent diversity. This pseudo-diversity fails to generalize beyond the training data, causing a larger generalization gap. We proceed to comprehensively demonstrate the practical implications of this effect on a range of standard machine learning tasks and architectures by smoothly interpolating between independent training and joint optimization.
count=1
* Two-Stage Predict+Optimize for MILPs with Unknown Parameters in Constraints
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/2e14be0332c04c76742710e417cedb2a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/2e14be0332c04c76742710e417cedb2a-Paper-Conference.pdf)]
    * Title: Two-Stage Predict+Optimize for MILPs with Unknown Parameters in Constraints
    * Year: `2023`
    * Authors: Xinyi Hu, Jasper Lee, Jimmy Lee
    * Abstract: Consider the setting of constrained optimization, with some parameters unknown at solving time and requiring prediction from relevant features. Predict+Optimize is a recent framework for end-to-end training supervised learning models for such predictions, incorporating information about the optimization problem in the training process in order to yield better predictions in terms of the quality of the predicted solution under the true parameters. Almost all prior works have focused on the special case where the unknowns appear only in the optimization objective and not the constraints. Hu et al. proposed the first adaptation of Predict+Optimize to handle unknowns appearing in constraints, but the framework has somewhat ad-hoc elements, and they provided a training algorithm only for covering and packing linear programs. In this work, we give a new simpler and more powerful framework called Two-Stage Predict+Optimize, which we believe should be the canonical framework for the Predict+Optimize setting. We also give a training algorithm usable for all mixed integer linear programs, vastly generalizing the applicability of the framework. Experimental results demonstrate the superior prediction performance of our training framework over all classical and state-of-the-art methods.
count=1
* Human-Aligned Calibration for AI-Assisted Decision Making
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/2f1d1196426ba84f47d115cac3dcb9d8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/2f1d1196426ba84f47d115cac3dcb9d8-Paper-Conference.pdf)]
    * Title: Human-Aligned Calibration for AI-Assisted Decision Making
    * Year: `2023`
    * Authors: Nina Corvelo Benz, Manuel Rodriguez
    * Abstract: Whenever a binary classifier is used to provide decision support, it typically provides both a label prediction and a confidence value. Then, the decision maker is supposed to use the confidence value to calibrate how much to trust the prediction. In this context, it has been often argued that the confidence value should correspond to a well calibrated estimate of the probability that the predicted label matches the ground truth label. However, multiple lines of empirical evidence suggest that decision makers have difficulties at developing a good sense on when to trust a prediction using these confidence values. In this paper, our goal is first to understand why and then investigate how to construct more useful confidence values. We first argue that, for a broad class of utility functions, there exists data distributions for which a rational decision maker is, in general, unlikely to discover the optimal decision policy using the above confidence values—an optimal decision maker would need to sometimes place more (less) trust on predictions with lower (higher) confidence values. However, we then show that, if the confidence values satisfy a natural alignment property with respect to the decision maker’s confidence on her own predictions, there always exists an optimal decision policy under which the level of trust the decision maker would need to place on predictions is monotone on the confidence values, facilitating its discoverability. Further, we show that multicalibration with respect to the decision maker’s confidence on her own prediction is a sufficient condition for alignment. Experiments on a real AI-assisted decision making scenario where a classifier provides decision support to human decision makers validate our theoretical results and suggest that alignment may lead to better decisions.
count=1
* Easy Learning from Label Proportions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3085fd61063840fdb2e6eafac58589f8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3085fd61063840fdb2e6eafac58589f8-Paper-Conference.pdf)]
    * Title: Easy Learning from Label Proportions
    * Year: `2023`
    * Authors: Róbert Busa-Fekete, Heejin Choi, Travis Dick, Claudio Gentile, Andres Munoz Medina
    * Abstract: We consider the problem of Learning from Label Proportions (LLP), a weakly supervised classification setup where instances are grouped into i.i.d. “bags”, and only the frequency of class labels at each bag is available. Albeit, the objective of the learner is to achieve low task loss at an individual instance level. Here we propose EASYLLP, a flexible and simple-to-implement debiasing approach based on aggregate labels, which operates on arbitrary loss functions. Our technique allows us to accurately estimate the expected loss of an arbitrary model at an individual level. We elucidate the differences between our method and standard methods based on label proportion matching, in terms of applicability and optimality conditions. We showcase the flexibility of our approach compared to alternatives by applying our method to popular learning frameworks, like Empirical Risk Minimization (ERM) and Stochastic Gradient Descent (SGD) with provable guarantees on instance level performance. Finally, we validate our theoretical results on multiple datasets, empirically illustrating the conditions under which our algorithm is expected to perform better or worse than previous LLP approaches
count=1
* When are ensembles really effective?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/30b6fa308e62ed52180c31ae3ba6bb0a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/30b6fa308e62ed52180c31ae3ba6bb0a-Paper-Conference.pdf)]
    * Title: When are ensembles really effective?
    * Year: `2023`
    * Authors: Ryan Theisen, Hyunsuk Kim, Yaoqing Yang, Liam Hodgkinson, Michael W. Mahoney
    * Abstract: Ensembling has a long history in statistical data analysis, with many impactful applications. However, in many modern machine learning settings, the benefits of ensembling are less ubiquitous and less obvious. We study, both theoretically and empirically, the fundamental question of when ensembling yields significant performance improvements in classification tasks. Theoretically, we prove new results relating the \emph{ensemble improvement rate} (a measure of how much ensembling decreases the error rate versus a single model, on a relative scale) to the \emph{disagreement-error ratio}. We show that ensembling improves performance significantly whenever the disagreement rate is large relative to the average error rate; and that, conversely, one classifier is often enough whenever the disagreement rate is low relative to the average error rate. On the way to proving these results, we derive, under a mild condition called \emph{competence}, improved upper and lower bounds on the average test error rate of the majority vote classifier.To complement this theory, we study ensembling empirically in a variety of settings, verifying the predictions made by our theory, and identifying practical scenarios where ensembling does and does not result in large performance improvements. Perhaps most notably, we demonstrate a distinct difference in behavior between interpolating models (popular in current practice) and non-interpolating models (such as tree-based methods, where ensembling is popular), demonstrating that ensembling helps considerably more in the latter case than in the former.
count=1
* Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3322a9a72a1707de14badd5e552ff466-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3322a9a72a1707de14badd5e552ff466-Paper-Conference.pdf)]
    * Title: Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations
    * Year: `2023`
    * Authors: Hammaad Adam, Fan Yin, Huibin Hu, Neil Tenenholtz, Lorin Crawford, Lester Mackey, Allison Koenecke
    * Abstract: Randomized experiments often need to be stopped prematurely due to the treatment having an unintended harmful effect. Existing methods that determine when to stop an experiment early are typically applied to the data in aggregate and do not account for treatment effect heterogeneity. In this paper, we study the early stopping of experiments for harm on heterogeneous populations. We first establish that current methods often fail to stop experiments when the treatment harms a minority group of participants. We then use causal machine learning to develop CLASH, the first broadly-applicable method for heterogeneous early stopping. We demonstrate CLASH's performance on simulated and real data and show that it yields effective early stopping for both clinical trials and A/B tests.
count=1
* Expert load matters: operating networks at high accuracy and low manual effort
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/348346383eb58ed19def02e233c408d6-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/348346383eb58ed19def02e233c408d6-Paper-Conference.pdf)]
    * Title: Expert load matters: operating networks at high accuracy and low manual effort
    * Year: `2023`
    * Authors: Sara Sangalli, Ertunc Erdil, Ender Konukoglu
    * Abstract: In human-AI collaboration systems for critical applications, in order to ensure minimal error, users should set an operating point based on model confidence to determine when the decision should be delegated to human experts. Samples for which model confidence is lower than the operating point would be manually analysed by experts to avoid mistakes.Such systems can become truly useful only if they consider two aspects: models should be confident only for samples for which they are accurate, and the number of samples delegated to experts should be minimized.The latter aspect is especially crucial for applications where available expert time is limited and expensive, such as healthcare. The trade-off between the model accuracy and the number of samples delegated to experts can be represented by a curve that is similar to an ROC curve, which we refer to as confidence operating characteristic (COC) curve. In this paper, we argue that deep neural networks should be trained by taking into account both accuracy and expert load and, to that end, propose a new complementary loss function for classification that maximizes the area under this COC curve.This promotes simultaneously the increase in network accuracy and the reduction in number of samples delegated to humans.We perform experiments on multiple computer vision and medical image datasets for classification.Our results demonstrate that the proposed loss improves classification accuracy and delegates less number of decisions to experts, achieves better out-of-distribution samples detection and on par calibration performance compared to existing loss functions.
count=1
* INSPECT: A Multimodal Dataset for Patient Outcome Prediction of Pulmonary Embolisms
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/39736af1b9d87a1fddad9f84a6bcf64c-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/39736af1b9d87a1fddad9f84a6bcf64c-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: INSPECT: A Multimodal Dataset for Patient Outcome Prediction of Pulmonary Embolisms
    * Year: `2023`
    * Authors: Shih-Cheng Huang, Zepeng Huo, Ethan Steinberg, Chia-Chun Chiang, Curtis Langlotz, Matthew Lungren, Serena Yeung, Nigam Shah, Jason Fries
    * Abstract: Synthesizing information from various data sources plays a crucial role in the practice of modern medicine. Current applications of artificial intelligence in medicine often focus on single-modality data due to a lack of publicly available, multimodal medical datasets. To address this limitation, we introduce INSPECT, which contains de-identified longitudinal records from a large cohort of pulmonary embolism (PE) patients, along with ground truth labels for multiple outcomes. INSPECT contains data from 19,402 patients, including CT images, sections of radiology reports, and structured electronic health record (EHR) data (including demographics, diagnoses, procedures, and vitals). Using our provided dataset, we develop and release a benchmark for evaluating several baseline modeling approaches on a variety of important PE related tasks. We evaluate image-only, EHR-only, and fused models. Trained models and the de-identified dataset are made available for non-commercial use under a data use agreement. To the best our knowledge, INSPECT is the largest multimodal dataset for enabling reproducible research on strategies for integrating 3D medical imaging and EHR data.
count=1
* Fully Dynamic $k$-Clustering in $\tilde O(k)$ Update Time
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3b7ba46201bf15e5c3935272afae50db-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3b7ba46201bf15e5c3935272afae50db-Paper-Conference.pdf)]
    * Title: Fully Dynamic $k$-Clustering in $\tilde O(k)$ Update Time
    * Year: `2023`
    * Authors: Sayan Bhattacharya, Martín Costa, Silvio Lattanzi, Nikos Parotsidis
    * Abstract: We present a $O(1)$-approximate fully dynamic algorithm for the $k$-median and $k$-means problems on metric spaces with amortized update time $\tilde O(k)$ and worst-case query time $\tilde O(k^2)$. We complement our theoretical analysis with the first in-depth experimental study for the dynamic $k$-median problem on general metrics, focusing on comparing our dynamic algorithm to the current state-of-the-art by Henzinger and Kale [ESA'20]. Finally, we also provide a lower bound for dynamic $k$-median which shows that any $O(1)$-approximate algorithm with $\tilde O(\text{poly}(k))$ query time must have $\tilde \Omega(k)$ amortized update time, even in the incremental setting.
count=1
* Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3c646b713f5de2cf1ab1939d49a4036d-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3c646b713f5de2cf1ab1939d49a4036d-Paper-Conference.pdf)]
    * Title: Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning
    * Year: `2023`
    * Authors: Yu Wang, Zhun Zhong, Pengchong Qiao, Xuxin Cheng, Xiawu Zheng, Chang Liu, Nicu Sebe, Rongrong Ji, Jie Chen
    * Abstract: Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. Previous works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.Specifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.
count=1
* Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3c6696d70d364337cf98dcb7c652a770-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3c6696d70d364337cf98dcb7c652a770-Paper-Conference.pdf)]
    * Title: Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models
    * Year: `2023`
    * Authors: Julien Siems, Konstantin Ditschuneit, Winfried Ripken, Alma Lindborg, Maximilian Schambach, Johannes Otterbach, Martin Genzel
    * Abstract: Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity — i.e., (possibly non-linear) dependencies between the features — has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular data. Our experiments show that concurvity in GAMs can be reduced without significantly compromising prediction quality, improving interpretability and reducing variance in the feature importances.
count=1
* Mutual Information Regularized Offline Reinforcement Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3c6bd2021c10462c5164638d22f3d5d8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3c6bd2021c10462c5164638d22f3d5d8-Paper-Conference.pdf)]
    * Title: Mutual Information Regularized Offline Reinforcement Learning
    * Year: `2023`
    * Authors: Xiao Ma, Bingyi Kang, Zhongwen Xu, Min Lin, Shuicheng Yan
    * Abstract: The major challenge of offline RL is the distribution shift that appears when out-of-distribution actions are queried, which makes the policy improvement direction biased by extrapolation errors. Most existing methods address this problem by penalizing the policy or value for deviating from the behavior policy during policy improvement or evaluation. In this work, we propose a novel MISA framework to approach offline RL from the perspective of Mutual Information between States and Actions in the dataset by directly constraining the policy improvement direction. MISA constructs lower bounds of mutual information parameterized by the policy and Q-values. We show that optimizing this lower bound is equivalent to maximizing the likelihood of a one-step improved policy on the offline dataset. Hence, we constrain the policy improvement direction to lie in the data manifold. The resulting algorithm simultaneously augments the policy evaluation and improvement by adding mutual information regularizations. MISA is a general framework that unifies conservative Q-learning (CQL) and behavior regularization methods (e.g., TD3+BC) as special cases. We introduce 3 different variants of MISA, and empirically demonstrate that tighter mutual information lower bound gives better offline RL performance. In addition, our extensive experiments show MISA significantly outperforms a wide range of baselines on various tasks of the D4RL benchmark, e.g., achieving 742.9 total points on gym-locomotion tasks. Our code is attached and will be released upon publication.
count=1
* Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3d17b7f7d52c83ab6e97e2dc0bda2e71-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3d17b7f7d52c83ab6e97e2dc0bda2e71-Paper-Conference.pdf)]
    * Title: Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions
    * Year: `2023`
    * Authors: Abhineet Agarwal, Anish Agarwal, Suhas Vijaykumar
    * Abstract: We consider a setting where there are $N$ heterogeneous units and $p$ interventions. Our goal is to learn unit-specific potential outcomes for any combination of these $p$ interventions, i.e., $N \times 2^p$ causal parameters. Choosing a combination of interventions is a problem that naturally arises in a variety of applications such as factorial design experiments and recommendation engines (e.g., showing a set of movies that maximizes engagement for a given user). Running $N \times 2^p$ experiments to estimate the various parameters is likely expensive and/or infeasible as $N$ and $p$ grow. Further, with observational data there is likely confounding, i.e., whether or not a unit is seen under a combination is correlated with its potential outcome under that combination. We study this problem under a novel model that imposes latent structure across both units and combinations of interventions. Specifically, we assume latent similarity in potential outcomes across units (i.e., the matrix of potential outcomes is approximately rank $r$) and regularity in how combinations of interventions interact (i.e., the coefficients in the Fourier expansion of the potential outcomes is approximately $s$ sparse). We establish identification for all $N \times 2^p$ parameters despite unobserved confounding. We propose an estimation procedure, Synthetic Combinations, and establish finite-sample consistency under precise conditions on the observation pattern. We show that Synthetic Combinations is able to consistently estimate unit-specific potential outcomes given a total of $\text{poly}(r) \times \left( N + s^2p\right)$ observations. In comparison, previous methods that do not exploit structure across both units and combinations have poorer sample complexity scaling as $\min(N \times s^2p, \ \ r \times (N + 2^p))$.
count=1
* Locally Invariant Explanations: Towards Stable and Unidirectional Explanations through Local Invariant Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3df874367ce2c43891aab1ab23ae6959-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3df874367ce2c43891aab1ab23ae6959-Paper-Conference.pdf)]
    * Title: Locally Invariant Explanations: Towards Stable and Unidirectional Explanations through Local Invariant Learning
    * Year: `2023`
    * Authors: Amit Dhurandhar, Karthikeyan Natesan Ramamurthy, Kartik Ahuja, Vijay Arya
    * Abstract: Locally interpretable model agnostic explanations (LIME) method is one of the most popular methods used to explain black-box models at a per example level. Although many variants have been proposed, few provide a simple way to produce high fidelity explanations that are also stable and intuitive. In this work, we provide a novel perspective by proposing a model agnostic local explanation method inspired by the invariant risk minimization (IRM) principle -- originally proposed for (global) out-of-distribution generalization -- to provide such high fidelity explanations that are also stable and unidirectional across nearby examples. Our method is based on a game theoretic formulation where we theoretically show that our approach has a strong tendency to eliminate features where the gradient of the black-box function abruptly changes sign in the locality of the example we want to explain, while in other cases it is more careful and will choose a more conservative (feature) attribution, a behavior which can be highly desirable for recourse. Empirically, we show on tabular, image and text data that the quality of our explanations with neighborhoods formed using random perturbations are much better than LIME and in some cases even comparable to other methods that use realistic neighbors sampled from the data manifold. This is desirable given that learning a manifold to either create realistic neighbors or to project explanations is typically expensive or may even be impossible. Moreover, our algorithm is simple and efficient to train, and can ascertain stable input features for local decisions of a black-box without access to side information such as a (partial) causal graph as has been seen in some recent works.
count=1
* Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3f1a5e8bfcc3005724d246abe454c1e5-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3f1a5e8bfcc3005724d246abe454c1e5-Paper-Conference.pdf)]
    * Title: Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks
    * Year: `2023`
    * Authors: Steven Adriaensen, Herilalaina Rakotoarison, Samuel Müller, Frank Hutter
    * Abstract: Learning curve extrapolation aims to predict model performance in later epochs of training, based on the performance in earlier epochs.In this work, we argue that, while the inherent uncertainty in the extrapolation of learning curves warrants a Bayesian approach, existing methods are (i) overly restrictive, and/or (ii) computationally expensive. We describe the first application of prior-data fitted neural networks (PFNs) in this context. A PFN is a transformer, pre-trained on data generated from a prior, to perform approximate Bayesian inference in a single forward pass. We propose LC-PFN, a PFN trained to extrapolate 10 million artificial right-censored learning curves generated from a parametric prior proposed in prior art using MCMC. We demonstrate that LC-PFN can approximate the posterior predictive distribution more accurately than MCMC, while being over 10 000 times faster. We also show that the same LC-PFN achieves competitive performance extrapolating a total of 20 000 real learning curves from four learning curve benchmarks (LCBench, NAS-Bench-201, Taskset, and PD1) that stem from training a wide range of model architectures (MLPs, CNNs, RNNs, and Transformers) on 53 different datasets with varying input modalities (tabular, image, text, and protein data). Finally, we investigate its potential in the context of model selection and find that a simple LC-PFN based predictive early stopping criterion obtains 2 - 6x speed-ups on 45 of these datasets, at virtually no overhead.
count=1
* The Contextual Lasso: Sparse Linear Models via Deep Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/3f226824426a4d6ae3d3efad8883fc53-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/3f226824426a4d6ae3d3efad8883fc53-Paper-Conference.pdf)]
    * Title: The Contextual Lasso: Sparse Linear Models via Deep Neural Networks
    * Year: `2023`
    * Authors: Ryan Thompson, Amir Dezfouli, Robert Kohn
    * Abstract: Sparse linear models are one of several core tools for interpretable machine learning, a field of emerging importance as predictive models permeate decision-making in many domains. Unfortunately, sparse linear models are far less flexible as functions of their input features than black-box models like deep neural networks. With this capability gap in mind, we study a not-uncommon situation where the input features dichotomize into two groups: explanatory features, which are candidates for inclusion as variables in an interpretable model, and contextual features, which select from the candidate variables and determine their effects. This dichotomy leads us to the contextual lasso, a new statistical estimator that fits a sparse linear model to the explanatory features such that the sparsity pattern and coefficients vary as a function of the contextual features. The fitting process learns this function nonparametrically via a deep neural network. To attain sparse coefficients, we train the network with a novel lasso regularizer in the form of a projection layer that maps the network's output onto the space of $\ell_1$-constrained linear models. An extensive suite of experiments on real and synthetic data suggests that the learned models, which remain highly transparent, can be sparser than the regular lasso without sacrificing the predictive power of a standard deep neural network.
count=1
* Sample based Explanations via Generalized Representers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/49cf35ff2298c10452db99d08036805b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/49cf35ff2298c10452db99d08036805b-Paper-Conference.pdf)]
    * Title: Sample based Explanations via Generalized Representers
    * Year: `2023`
    * Authors: Che-Ping Tsai, Chih-Kuan Yeh, Pradeep Ravikumar
    * Abstract: We propose a general class of sample based explanations of machine learning models, which we term generalized representers. To measure the effect of a training sample on a model's test prediction, generalized representers use two components: a global sample importance that quantifies the importance of the training point to the model and is invariant to test samples, and a local sample importance that measures similarity between the training sample and the test point with a kernel. A key contribution of the paper is to show that generalized representers are the only class of sample based explanations satisfying a natural set of axiomatic properties. We discuss approaches to extract global importances given a kernel, and also natural choices of kernels given modern non-linear models. As we show, many popular existing sample based explanations could be cast as generalized representers with particular choices of kernels and approaches to extract global importances. Additionally, we conduct empirical comparisons of different generalized representers on two image classification datasets.
count=1
* Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/4ef594af0d9a519db8fb292452c461fa-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/4ef594af0d9a519db8fb292452c461fa-Paper-Conference.pdf)]
    * Title: Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation
    * Year: `2023`
    * Authors: Sébastien Lachapelle, Divyat Mahajan, Ioannis Mitliagkas, Simon Lacoste-Julien
    * Abstract: We tackle the problems of latent variables identification and "out-of-support'' image generation in representation learning. We show that both are possible for a class of decoders that we call additive, which are reminiscent of decoders used for object-centric representation learning (OCRL) and well suited for images that can be decomposed as a sum of object-specific images. We provide conditions under which exactly solving the reconstruction problem using an additive decoder is guaranteed to identify the blocks of latent variables up to permutation and block-wise invertible transformations. This guarantee relies only on very weak assumptions about the distribution of the latent factors, which might present statistical dependencies and have an almost arbitrarily shaped support. Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods. We also show theoretically that additive decoders can generate novel images by recombining observed factors of variations in novel ways, an ability we refer to as Cartesian-product extrapolation. We show empirically that additivity is crucial for both identifiability and extrapolation on simulated data.
count=1
* LANCE: Stress-testing Visual Models by Generating Language-guided Counterfactual Images
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/4f3820576130a8f796ddbf204c841487-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/4f3820576130a8f796ddbf204c841487-Paper-Conference.pdf)]
    * Title: LANCE: Stress-testing Visual Models by Generating Language-guided Counterfactual Images
    * Year: `2023`
    * Authors: Viraj Prabhu, Sriram Yenamandra, Prithvijit Chattopadhyay, Judy Hoffman
    * Abstract: We propose an automated algorithm to stress-test a trained visual model by generating language-guided counterfactual test images (LANCE). Our method leverages recent progress in large language modeling and text-based image editing to augment an IID test set with a suite of diverse, realistic, and challenging test images without altering model weights. We benchmark the performance of a diverse set of pre-trained models on our generated data and observe significant and consistent performance drops. We further analyze model sensitivity across different types of edits, and demonstrate its applicability at surfacing previously unknown class-level model biases in ImageNet. Code is available at https://github.com/virajprabhu/lance.
count=1
* Calibration by Distribution Matching: Trainable Kernel Calibration Metrics
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/52493d82db00e73abb2858a5a5f28717-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/52493d82db00e73abb2858a5a5f28717-Paper-Conference.pdf)]
    * Title: Calibration by Distribution Matching: Trainable Kernel Calibration Metrics
    * Year: `2023`
    * Authors: Charlie Marx, Sofian Zalouk, Stefano Ermon
    * Abstract: Calibration ensures that probabilistic forecasts meaningfully capture uncertainty by requiring that predicted probabilities align with empirical frequencies. However, many existing calibration methods are specialized for post-hoc recalibration, which can worsen the sharpness of forecasts. Drawing on the insight that calibration can be viewed as a distribution matching task, we introduce kernel-based calibration metrics that unify and generalize popular forms of calibration for both classification and regression. These metrics admit differentiable sample estimates, making it easy to incorporate a calibration objective into empirical risk minimization. Furthermore, we provide intuitive mechanisms to tailor calibration metrics to a decision task, and enforce accurate loss estimation and no regret decisions. Our empirical evaluation demonstrates that employing these metrics as regularizers enhances calibration, sharpness, and decision-making across a range of regression and classification tasks, outperforming methods relying solely on post-hoc recalibration.
count=1
* EMBERSim: A Large-Scale Databank for Boosting Similarity Search in Malware Analysis
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/54bf430f5d3090502ea021941e9cb18e-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/54bf430f5d3090502ea021941e9cb18e-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: EMBERSim: A Large-Scale Databank for Boosting Similarity Search in Malware Analysis
    * Year: `2023`
    * Authors: Dragos Georgian Corlatescu, Alexandru Dinu, Mihaela Petruta Gaman, Paul Sumedrea
    * Abstract: In recent years there has been a shift from heuristics based malware detection towards machine learning, which proves to be more robust in the current heavily adversarial threat landscape. While we acknowledge machine learning to be better equipped to mine for patterns in the increasingly high amounts of similar-looking files, we also note a remarkable scarcity of the data available for similarity targeted research. Moreover, we observe that the focus in the few related works falls on quantifying similarity in malware, often overlooking the clean data. This one-sided quantification is especially dangerous in the context of detection bypass. We propose to address the deficiencies in the space of similarity research on binary files, starting from EMBER — one of the largest malware classification datasets. We enhance EMBER with similarity information as well as malware class tags, to enable further research in the similarity space. Our contribution is threefold: (1) we publish EMBERSim, an augmented version of EMBER, that includes similarity informed tags; (2) we enrich EMBERSim with automatically determined malware class tags using the open-source tool AVClass on VirusTotal data and (3) we describe and share the implementation for our class scoring technique and leaf similarity method.
count=1
* Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/55a49718689fdecef31b6a2386df6fe1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/55a49718689fdecef31b6a2386df6fe1-Paper-Conference.pdf)]
    * Title: Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions
    * Year: `2023`
    * Authors: Hao Wang, Luxi He, Rui Gao, Flavio Calmon
    * Abstract: Machine learning (ML) models can underperform on certain population groups due to choices made during model development and bias inherent in the data. We categorize sources of discrimination in the ML pipeline into two classes: aleatoric discrimination, which is inherent in the data distribution, and epistemic discrimination, which is due to decisions made during model development. We quantify aleatoric discrimination by determining the performance limits of a model under fairness constraints, assuming perfect knowledge of the data distribution. We demonstrate how to characterize aleatoric discrimination by applying Blackwell's results on comparing statistical experiments. We then quantify epistemic discrimination as the gap between a model's accuracy when fairness constraints are applied and the limit posed by aleatoric discrimination. We apply this approach to benchmark existing fairness interventions and investigate fairness risks in data with missing values. Our results indicate that state-of-the-art fairness interventions are effective at removing epistemic discrimination on standard (overused) tabular datasets. However, when data has missing values, there is still significant room for improvement in handling aleatoric discrimination.
count=1
* Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/574f145eac328cc4aaf9358e27120eb5-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/574f145eac328cc4aaf9358e27120eb5-Paper-Conference.pdf)]
    * Title: Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information
    * Year: `2023`
    * Authors: Arman Zharmagambetov, Brandon Amos, Aaron Ferber, Taoan Huang, Bistra Dilkina, Yuandong Tian
    * Abstract: Recent works in learning-integrated optimization have shown promise in settings where the optimization problem is only partially observed or where general-purpose optimizers perform poorly without expert tuning. By learning an optimizer $\mathbf{g}$ to tackle these challenging problems with $f$ as the objective, the optimization process can be substantially accelerated by leveraging past experience. The optimizer can be trained with supervision from known optimal solutions or implicitly by optimizing the compound function $f\circ \mathbf{g}$. The implicit approach may not require optimal solutions as labels and is capable of handling problem uncertainty; however, it is slow to train and deploy due to frequent calls to optimizer $\mathbf{g}$ during both training and testing. The training is further challenged by sparse gradients of $\mathbf{g}$, especially for combinatorial solvers. To address these challenges, we propose using a smooth and learnable **Landscape Surrogate** $\mathcal{M}$ as a replacement for $f\circ \mathbf{g}$. This surrogate, learnable by neural networks, can be computed faster than the solver $\mathbf{g}$, provides dense and smooth gradients during training, can generalize to unseen optimization problems, and is efficiently learned via alternating optimization. We test our approach on both synthetic problems, including shortest path and multidimensional knapsack, and real-world problems such as portfolio optimization, achieving comparable or superior objective values compared to state-of-the-art baselines while reducing the number of calls to $\mathbf{g}$. Notably, our approach outperforms existing methods for computationally expensive high-dimensional problems.
count=1
* Comparing Apples to Oranges: Learning Similarity Functions for Data Produced by Different Distributions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/59056767478c7df64e6250eadfeb0a04-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/59056767478c7df64e6250eadfeb0a04-Paper-Conference.pdf)]
    * Title: Comparing Apples to Oranges: Learning Similarity Functions for Data Produced by Different Distributions
    * Year: `2023`
    * Authors: Leonidas Tsepenekas, Ivan Brugere, Freddy Lecue, Daniele Magazzeni
    * Abstract: Similarity functions measure how comparable pairs of elements are, and play a key role in a wide variety of applications, e.g., notions of Individual Fairness abiding by the seminal paradigm of Dwork et al., as well as Clustering problems. However, access to an accurate similarity function should not always be considered guaranteed, and this point was even raised by Dwork et al. For instance, it is reasonable to assume that when the elements to be compared are produced by different distributions, or in other words belong to different ``demographic'' groups, knowledge of their true similarity might be very difficult to obtain. In this work, we present an efficient sampling framework that learns these across-groups similarity functions, using only a limited amount of experts' feedback. We show analytical results with rigorous theoretical bounds, and empirically validate our algorithms via a large suite of experiments.
count=1
* Realistic Synthetic Financial Transactions for Anti-Money Laundering Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/5f38404edff6f3f642d6fa5892479c42-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/5f38404edff6f3f642d6fa5892479c42-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Realistic Synthetic Financial Transactions for Anti-Money Laundering Models
    * Year: `2023`
    * Authors: Erik Altman, Jovan Blanuša, Luc von Niederhäusern, Beni Egressy, Andreea Anghel, Kubilay Atasu
    * Abstract: With the widespread digitization of finance and the increasing popularity of cryptocurrencies, the sophistication of fraud schemes devised by cybercriminals is growing. Money laundering -- the movement of illicit funds to conceal their origins -- can cross bank and national boundaries, producing complex transaction patterns. The UN estimates 2-5\% of global GDP or \$0.8 - \$2.0 trillion dollars are laundered globally each year. Unfortunately, real data to train machine learning models to detect laundering is generally not available, and previous synthetic data generators have had significant shortcomings. A realistic, standardized, publicly-available benchmark is needed for comparing models and for the advancement of the area.To this end, this paper contributes a synthetic financial transaction dataset generator and a set of synthetically generated AML (Anti-Money Laundering) datasets. We have calibrated this agent-based generator to match real transactions as closely as possible and made the datasets public. We describe the generator in detail and demonstrate how the datasets generated can help compare different machine learning models in terms of their AML abilities. In a key way, using synthetic data in these comparisons can be even better than using real data: the ground truth labels are complete, whilst many laundering transactions in real data are never detected.
count=1
* DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/63cb9921eecf51bfad27a99b2c53dd6d-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/63cb9921eecf51bfad27a99b2c53dd6d-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models
    * Year: `2023`
    * Authors: Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, Sang Truong, Simran Arora, Mantas Mazeika, Dan Hendrycks, Zinan Lin, Yu Cheng, Sanmi Koyejo, Dawn Song, Bo Li
    * Abstract: Generative Pre-trained Transformer (GPT) models have exhibited exciting progress in capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applications to healthcare and finance – where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives – including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT models can be easily misled to generate toxic and biased outputs and leak private information in both training data and conversation history. We also find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more vulnerable given jailbreaking system or user prompts, potentially due to the reason that GPT-4 follows the (misleading) instructions more precisely. Our work illustrates a comprehensive trustworthiness evaluation of GPT models and sheds light on the trustworthiness gaps. Our benchmark is publicly available at https://decodingtrust.github.io/.
count=1
* Mitigating Source Bias for Fairer Weak Supervision
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/6a5181cfe76f67b37a7e1bb19837abdf-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/6a5181cfe76f67b37a7e1bb19837abdf-Paper-Conference.pdf)]
    * Title: Mitigating Source Bias for Fairer Weak Supervision
    * Year: `2023`
    * Authors: Changho Shin, Sonia Cromp, Dyah Adila, Frederic Sala
    * Abstract: Weak supervision enables efficient development of training sets by reducing the need for ground truth labels. However, the techniques that make weak supervision attractive---such as integrating any source of signal to estimate unknown labels---also entail the danger that the produced pseudolabels are highly biased. Surprisingly, given everyday use and the potential for increased bias, weak supervision has not been studied from the point of view of fairness. We begin such a study, starting with the observation that even when a fair model can be built from a dataset with access to ground-truth labels, the corresponding dataset labeled via weak supervision can be arbitrarily unfair. To address this, we propose and empirically validate a model for source unfairness in weak supervision, then introduce a simple counterfactual fairness-based technique that can mitigate these biases. Theoretically, we show that it is possible for our approach to simultaneously improve both accuracy and fairness---in contrast to standard fairness approaches that suffer from tradeoffs. Empirically, we show that our technique improves accuracy on weak supervision baselines by as much as 32\% while reducing demographic parity gap by 82.5\%. A simple extension of our method aimed at maximizing performance produces state-of-the-art performance in five out of ten datasets in the WRENCH benchmark.
count=1
* Discriminative Calibration: Check Bayesian Computation from Simulations and Flexible Classifier
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/7103cd82de95a7b30983fcf74ba499ac-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/7103cd82de95a7b30983fcf74ba499ac-Paper-Conference.pdf)]
    * Title: Discriminative Calibration: Check Bayesian Computation from Simulations and Flexible Classifier
    * Year: `2023`
    * Authors: Yuling Yao, Justin Domke
    * Abstract: To check the accuracy of Bayesian computations, it is common to use rank-based simulation-based calibration (SBC). However, SBC has drawbacks: The test statistic is somewhat ad-hoc, interactions are difficult to examine, multiple testing is a challenge, and the resulting p-value is not a divergence metric. We propose to replace the marginal rank test with a flexible classification approach that learns test statistics from data. This measure typically has a higher statistical power than the SBC test and returns an interpretable divergence measure of miscalibration, computed from classification accuracy. This approach can be used with different data generating processes to address simulation-based inference or traditional inference methods like Markov chain Monte Carlo or variational inference. We illustrate an automated implementation using neural networks and statistically-inspired features, and validate the method with numerical and real data experiments.
count=1
* GLIME: General, Stable and Local LIME Explanation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/71ed042903ed67c7f6355e5dd0539eec-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/71ed042903ed67c7f6355e5dd0539eec-Paper-Conference.pdf)]
    * Title: GLIME: General, Stable and Local LIME Explanation
    * Year: `2023`
    * Authors: Zeren Tan, Yang Tian, Jian Li
    * Abstract: As black-box machine learning models become more complex and are applied in high-stakes settings, the need for providing explanations for their predictions becomes crucial. Although Local Interpretable Model-agnostic Explanations (LIME) \cite{ribeiro2016should} is a widely adopted method for understanding model behavior, it suffers from instability with respect to random seeds \cite{zafar2019dlime, shankaranarayana2019alime, bansal2020sam} and exhibits low local fidelity (i.e., how the explanation explains model's local behaviors) \cite{rahnama2019study, laugel2018defining}. Our study demonstrates that this instability is caused by small sample weights, resulting in the dominance of regularization and slow convergence. Additionally, LIME's sampling approach is non-local and biased towards the reference, leading to diminished local fidelity and instability to references. To address these challenges, we propose \textsc{Glime}, an enhanced framework that extends LIME and unifies several previous methods. Within the \textsc{Glime} framework, we derive an equivalent formulation of LIME that achieves significantly faster convergence and improved stability. By employing a local and unbiased sampling distribution, \textsc{Glime} generates explanations with higher local fidelity compared to LIME, while being independent of the reference choice. Moreover, \textsc{Glime} offers users the flexibility to choose sampling distribution based on their specific scenarios.
count=1
* The Learnability of In-Context Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/73950f0eb4ac0925dc71ba2406893320-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/73950f0eb4ac0925dc71ba2406893320-Paper-Conference.pdf)]
    * Title: The Learnability of In-Context Learning
    * Year: `2023`
    * Authors: Noam Wies, Yoav Levine, Amnon Shashua
    * Abstract: In-context learning is a surprising and important phenomenon that emerged when modern language models were scaled to billions of learned parameters. Without modifying a large language model's weights, it can be tuned to perform various downstream natural language tasks simply by including concatenated training examples of these tasks in its input. Though disruptive for many practical applications of large language models, this emergent learning paradigm is not well understood from a theoretical perspective. In this paper, we propose a first-of-its-kind PAC based framework for in-context learnability, and use it to provide the first finite sample complexity results for the in-context learning setup. Our framework includes an initial pretraining phase, which fits a function to the pretraining distribution, and then a second in-context learning phase, which keeps this function constant and concatenates training examples of the downstream task in its input. We use our framework in order to prove that, under mild assumptions, when the pretraining distribution is a mixture of latent tasks (a model often considered for natural language pretraining), these tasks can be efficiently learned via in-context learning, even though the model's weights are unchanged and the input significantly diverges from the pretraining distribution. Our theoretical analysis reveals that in this setting, in-context learning is more about identifying the task than about learning it, a result which is in line with a series of recent empirical findings. We hope that the in-context learnability framework presented in this paper will facilitate future progress towards a deeper understanding of this important new learning paradigm.
count=1
* H3T: Efficient Integration of Memory Optimization and Parallelism for Large-scale Transformer Training
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/7886b89aced4d37dd25a6f32854bf3f9-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/7886b89aced4d37dd25a6f32854bf3f9-Paper-Conference.pdf)]
    * Title: H3T: Efficient Integration of Memory Optimization and Parallelism for Large-scale Transformer Training
    * Year: `2023`
    * Authors: Yuzhong Wang, Xu Han, Weilin Zhao, Guoyang Zeng, Zhiyuan Liu, Maosong Sun
    * Abstract: In recent years, big models based on Transformers have achieved state-of-the-art performance on many artificial intelligence (AI) tasks.Despite the success of these Transformer-based models, their huge parameter size poses a serious challenge to their training, both from the storage and computation perspectives.To this end, memory optimization (e.g., rematerialization and offloading) and parallelism (e.g., data parallelism and model parallelism) are widely explored to make training Transformers more efficient.In this paper, we propose a framework to automatically find an efficient integration of memory optimization and parallelism for High-Throughput Transformer Training (named H3T), which is rarely considered by existing efforts for training big Transformer-based models.Specifically, we design search algorithms to combine appropriate memory optimization strategies and parallelism schemes to achieve a balance between memory overhead and training efficiency.We implement H3T based on an open-source toolkit BMTrain and then use H3T to train the Transformers of different sizes to evaluate the efficiency of H3T.The experimental results show that H3T outperforms the most popular deep learning (DL) toolkit Megatron-DeepSpeed by $1.2\times \sim 4.3\times$ training speed while reducing $34.6\% \sim 80.5\%$ of memory overhead.Moreover, H3T can use only 64 NVIDIA A100 GPUs to train GPT-3-175B, which is very difficult for existing DL toolkits. The source code is available at https://github.com/OpenBMB/BMTrain/tree/h3t.
count=1
* Fast Partitioned Learned Bloom Filter
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/7b2e844c52349134268e819a9b56b9e8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/7b2e844c52349134268e819a9b56b9e8-Paper-Conference.pdf)]
    * Title: Fast Partitioned Learned Bloom Filter
    * Year: `2023`
    * Authors: Atsuki Sato, Yusuke Matsui
    * Abstract: A Bloom filter is a memory-efficient data structure for approximate membership queries used in numerous fields of computer science.Recently, learned Bloom filters that achieve better memory efficiency using machine learning models have attracted attention.One such filter, the partitioned learned Bloom filter (PLBF), achieves excellent memory efficiency.However, PLBF requires a $\mathcal{O}(N^3k)$ time complexity to construct the data structure, where $N$ and $k$ are the hyperparameters of PLBF.One can improve memory efficiency by increasing $N$, but the construction time becomes extremely long.Thus, we propose two methods that can reduce the construction time while maintaining the memory efficiency of PLBF.First, we propose fast PLBF, which can construct the same data structure as PLBF with a smaller time complexity $\mathcal{O}(N^2k)$.Second, we propose fast PLBF++, which can construct the data structure with even smaller time complexity $\mathcal{O}(Nk\log N + Nk^2)$.Fast PLBF++ does not necessarily construct the same data structure as PLBF.Still, it is almost as memory efficient as PLBF, and it is proved that fast PLBF++ has the same data structure as PLBF when the distribution satisfies a certain constraint.Our experimental results from real-world datasets show that (i) fast PLBF and fast PLBF++ can construct the data structure up to 233 and 761 times faster than PLBF, (ii) fast PLBF can achieve the same memory efficiency as PLBF, and (iii) fast PLBF++ can achieve almost the same memory efficiency as PLBF.The codes are available at [this https URL](https://github.com/atsukisato/FastPLBF).
count=1
* This Looks Like Those: Illuminating Prototypical Concepts Using Multiple Visualizations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/7b76eea0c3683e440c3d362620f578cd-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/7b76eea0c3683e440c3d362620f578cd-Paper-Conference.pdf)]
    * Title: This Looks Like Those: Illuminating Prototypical Concepts Using Multiple Visualizations
    * Year: `2023`
    * Authors: Chiyu Ma, Brandon Zhao, Chaofan Chen, Cynthia Rudin
    * Abstract: We present ProtoConcepts, a method for interpretable image classification combining deep learning and case-based reasoning using prototypical parts. Existing work in prototype-based image classification uses a "this looks like that'' reasoning process, which dissects a test image by finding prototypical parts and combining evidence from these prototypes to make a final classification. However, all of the existing prototypical part-based image classifiers provide only one-to-one comparisons, where a single training image patch serves as a prototype to compare with a part of our test image. With these single-image comparisons, it can often be difficult to identify the underlying concept being compared (e.g., "is it comparing the color or the shape?''). Our proposed method modifies the architecture of prototype-based networks to instead learn prototypical concepts which are visualized using multiple image patches. Having multiple visualizations of the same prototype allows us to more easily identify the concept captured by that prototype (e.g., "the test image and the related training patches are all the same shade of blue''), and allows our model to create richer, more interpretable visual explanations. Our experiments show that our ``this looks like those'' reasoning process can be applied as a modification to a wide range of existing prototypical image classification networks while achieving comparable accuracy on benchmark datasets.
count=1
* Swap Agnostic Learning, or Characterizing Omniprediction via Multicalibration
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/7d693203215325902ff9dbdd067a50ac-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/7d693203215325902ff9dbdd067a50ac-Paper-Conference.pdf)]
    * Title: Swap Agnostic Learning, or Characterizing Omniprediction via Multicalibration
    * Year: `2023`
    * Authors: Parikshit Gopalan, Michael Kim, Omer Reingold
    * Abstract: We introduce and study the notion of Swap Agnostic Learning.The problem can be phrased as a game between a *predictor* and an *adversary*: first, the predictor selects a hypothesis $h$; then, the adversary plays in response, and for each level set of the predictor, selects a loss-minimizing hypothesis $c_v \in \mathcal{C}$; the predictor wins if $h$ competes with the adaptive adversary's loss.Despite the strength of the adversary, our main result demonstrates the feasibility Swap Agnostic Learning for any convex loss.Somewhat surprisingly, the result follows by proving an *equivalence* between Swap Agnostic Learning and swap variants of the recent notions Omniprediction (ITCS'22) and Multicalibration (ICML'18).Beyond this equivalence, we establish further connections to the literature on Outcome Indistinguishability (STOC'20, ITCS'23), revealing a unified notion of OI that captures all existing notions of omniprediction and multicalibration.
count=1
* Large Language Models of Code Fail at Completing Code with Potential Bugs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/819cebb05f993840e8a52d7564c5c282-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/819cebb05f993840e8a52d7564c5c282-Paper-Conference.pdf)]
    * Title: Large Language Models of Code Fail at Completing Code with Potential Bugs
    * Year: `2023`
    * Authors: Tuan Dinh, Jinman Zhao, Samson Tan, Renato Negrinho, Leonard Lausen, Sheng Zha, George Karypis
    * Abstract: Large language models of code (Code-LLMs) have recently brought tremendous advances to code completion, a fundamental feature of programming assistance and code intelligence. However, most existing works ignore the possible presence of bugs in the code context for generation, which are inevitable in software development. Therefore, we introduce and study the buggy-code completion problem, inspired by the realistic scenario of real-time code suggestion where the code context contains potential bugs – anti-patterns that can become bugs in the completed program. To systematically study the task, we introduce two datasets: one with synthetic bugs derived from semantics-altering operator changes (buggy-HumanEval) and one with realistic bugs derived from user submissions to coding problems (buggy-FixEval). We find that the presence of potential bugs significantly degrades the generation performance of the high-performing Code-LLMs. For instance, the passing rates of CODEGEN-2B-MONO on test cases of buggy-HumanEval drop more than 50% given a single potential bug in the context. Finally, we investigate several post-hoc methods for mitigating the adverse effect of potential bugs and find that there remains a large gap in post-mitigation performance.
count=1
* Error Discovery By Clustering Influence Embeddings
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/8278a2e5f9db8489cd908d20c43f1f87-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/8278a2e5f9db8489cd908d20c43f1f87-Paper-Conference.pdf)]
    * Title: Error Discovery By Clustering Influence Embeddings
    * Year: `2023`
    * Authors: Fulton Wang, Julius Adebayo, Sarah Tan, Diego Garcia-Olano, Narine Kokhlikyan
    * Abstract: We present a method for identifying groups of test examples---slices---on which a model under-performs, a task now known as slice discovery. We formalize coherence---a requirement that erroneous predictions, within a slice, should be wrong for the same reason---as a key property that any slice discovery method should satisfy. We then use influence functions to derive a new slice discovery method, InfEmbed, which satisfies coherence by returning slices whose examples are influenced similarly by the training data. InfEmbed is simple, and consists of applying K-Means clustering to a novel representation we deem influence embeddings. We show InfEmbed outperforms current state-of-the-art methods on 2 benchmarks, and is effective for model debugging across several case studies.
count=1
* Active Learning-Based Species Range Estimation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/82eec786fdfbbfa53450c5feb7d1ac92-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/82eec786fdfbbfa53450c5feb7d1ac92-Paper-Conference.pdf)]
    * Title: Active Learning-Based Species Range Estimation
    * Year: `2023`
    * Authors: Christian Lange, Elijah Cole, Grant Van Horn, Oisin Mac Aodha
    * Abstract: We propose a new active learning approach for efficiently estimating the geographic range of a species from a limited number of on the ground observations. We model the range of an unmapped species of interest as the weighted combination of estimated ranges obtained from a set of different species. We show that it is possible to generate this candidate set of ranges by using models that have been trained on large weakly supervised community collected observation data. From this, we develop a new active querying approach that sequentially selects geographic locations to visit that best reduce our uncertainty over an unmapped species’ range. We conduct a detailed evaluation of our approach and compare it to existing active learning methods using an evaluation dataset containing expert-derived ranges for one thousand species. Our results demonstrate that our method outperforms alternative active learning methods and approaches the performance of end-to-end trained models, even when only using a fraction of the data. This highlights the utility of active learning via transfer learned spatial representations for species range estimation. It also emphasizes the value of leveraging emerging large-scale crowdsourced datasets, not only for modeling a species' range, but also for actively discovering them.
count=1
* An Inductive Bias for Tabular Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/8671b6dffc08b4fcf5b8ce26799b2bef-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/8671b6dffc08b4fcf5b8ce26799b2bef-Paper-Conference.pdf)]
    * Title: An Inductive Bias for Tabular Deep Learning
    * Year: `2023`
    * Authors: Ege Beyazit, Jonathan Kozaczuk, Bo Li, Vanessa Wallace, Bilal Fadlallah
    * Abstract: Deep learning methods have achieved state-of-the-art performance in most modeling tasks involving images, text and audio, however, they typically underperform tree-based methods on tabular data. In this paper, we hypothesize that a significant contributor to this performance gap is the interaction between irregular target functions resulting from the heterogeneous nature of tabular feature spaces, and the well-known tendency of neural networks to learn smooth functions. Utilizing tools from spectral analysis, we show that functions described by tabular datasets often have high irregularity, and that they can be smoothed by transformations such as scaling and ranking in order to improve performance. However, because these transformations tend to lose information or negatively impact the loss landscape during optimization, they need to be rigorously fine-tuned for each feature to achieve performance gains. To address these problems, we propose introducing frequency reduction as an inductive bias. We realize this bias as a neural network layer that promotes learning low-frequency representations of the input features, allowing the network to operate in a space where the target function is more regular. Our proposed method introduces less computational complexity than a fully connected layer, while significantly improving neural network performance, and speeding up its convergence on 14 tabular datasets.
count=1
* Constant Approximation for Individual Preference Stable Clustering
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/881259965dacb9f42967aae84a157283-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/881259965dacb9f42967aae84a157283-Paper-Conference.pdf)]
    * Title: Constant Approximation for Individual Preference Stable Clustering
    * Year: `2023`
    * Authors: Anders Aamand, Justin Chen, Allen Liu, Sandeep Silwal, Pattara Sukprasert, Ali Vakilian, Fred Zhang
    * Abstract: Individual preference (IP) stability, introduced by Ahmadi et al. (ICML 2022), is a natural clustering objective inspired by stability and fairness constraints. A clustering is $\alpha$-IP stable if the average distance of every data point to its own cluster is at most $\alpha$ times the average distance to any other cluster. Unfortunately, determining if a dataset admits a $1$-IP stable clustering is NP-Hard. Moreover, before this work, it was unknown if an $o(n)$-IP stable clustering always exists, as the prior state of the art only guaranteed an $O(n)$-IP stable clustering. We close this gap in understanding and show that an $O(1)$-IP stable clustering always exists for general metrics, and we give an efficient algorithm which outputs such a clustering. We also introduce generalizations of IP stability beyond average distance and give efficient near optimal algorithms in the cases where we consider the maximum and minimum distances within and between clusters.
count=1
* Discriminative Feature Attributions: Bridging Post Hoc Explainability and Inherent Interpretability
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/89beb2a345269f3f9afe48cee35403aa-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/89beb2a345269f3f9afe48cee35403aa-Paper-Conference.pdf)]
    * Title: Discriminative Feature Attributions: Bridging Post Hoc Explainability and Inherent Interpretability
    * Year: `2023`
    * Authors: Usha Bhalla, Suraj Srinivas, Himabindu Lakkaraju
    * Abstract: With the increased deployment of machine learning models in various real-world applications, researchers and practitioners alike have emphasized the need for explanations of model behaviour. To this end, two broad strategies have been outlined in prior literature to explain models. Post hoc explanation methods explain the behaviour of complex black-box models by identifying features critical to model predictions; however, prior work has shown that these explanations may not be faithful, in that they incorrectly attribute high importance to features that are unimportant or non-discriminative for the underlying task. Inherently interpretable models, on the other hand, circumvent these issues by explicitly encoding explanations into model architecture, meaning their explanations are naturally faithful, but they often exhibit poor predictive performance due to their limited expressive power. In this work, we identify a key reason for the lack of faithfulness of feature attributions: the lack of robustness of the underlying black-box models, especially the erasure of unimportant distractor features in the input. To address this issue, we propose Distractor Erasure Tuning (DiET), a method that adapts black-box models to be robust to distractor erasure, thus providing discriminative and faithful attributions. This strategy naturally combines the ease-of-use of post hoc explanations with the faithfulness of inherently interpretable models. We perform extensive experiments on semi-synthetic and real-world datasets, and show that DiET produces models that (1) closely approximate the original black-box models they are intended to explain, and (2) yield explanations that match approximate ground truths available by construction.
count=1
* Disentanglement via Latent Quantization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/8e63972d4d9d81b31459d787466ce271-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/8e63972d4d9d81b31459d787466ce271-Paper-Conference.pdf)]
    * Title: Disentanglement via Latent Quantization
    * Year: `2023`
    * Authors: Kyle Hsu, William Dorrell, James Whittington, Jiajun Wu, Chelsea Finn
    * Abstract: In disentangled representation learning, a model is asked to tease apart a dataset's underlying sources of variation and represent them independently of one another. Since the model is provided with no ground truth information about these sources, inductive biases take a paramount role in enabling disentanglement. In this work, we construct an inductive bias towards encoding to and decoding from an organized latent space. Concretely, we do this by (i) quantizing the latent space into discrete code vectors with a separate learnable scalar codebook per dimension and (ii) applying strong model regularization via an unusually high weight decay. Intuitively, the latent space design forces the encoder to combinatorially construct codes from a small number of distinct scalar values, which in turn enables the decoder to assign a consistent meaning to each value. Regularization then serves to drive the model towards this parsimonious strategy. We demonstrate the broad applicability of this approach by adding it to both basic data-reconstructing (vanilla autoencoder) and latent-reconstructing (InfoGAN) generative models. For reliable evaluation, we also propose InfoMEC, a new set of metrics for disentanglement that is cohesively grounded in information theory and fixes well-established shortcomings in previous metrics. Together with regularization, latent quantization dramatically improves the modularity and explicitness of learned representations on a representative suite of benchmark datasets. In particular, our quantized-latent autoencoder (QLAE) consistently outperforms strong methods from prior work in these key disentanglement properties without compromising data reconstruction.
count=1
* Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A Comprehensive Benchmark for Evaluating Foundation Models in Emergency Medicine
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/8f61049e8fe5b9ed714860b951066f1e-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/8f61049e8fe5b9ed714860b951066f1e-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A Comprehensive Benchmark for Evaluating Foundation Models in Emergency Medicine
    * Year: `2023`
    * Authors: Emma Chen, Aman Kansal, Julie Chen, Boyang Tom Jin, Julia Reisler, David E. Kim, Pranav Rajpurkar
    * Abstract: We propose the Multimodal Clinical Benchmark for Emergency Care (MC-BEC), a comprehensive benchmark for evaluating foundation models in Emergency Medicine using a dataset of 100K+ continuously monitored Emergency Department visits from 2020-2022. MC-BEC focuses on clinically relevant prediction tasks at timescales from minutes to days, including predicting patient decompensation, disposition, and emergency department (ED) revisit, and includes a standardized evaluation framework with train-test splits and evaluation metrics. The multimodal dataset includes a wide range of detailed clinical data, including triage information, prior diagnoses and medications, continuously measured vital signs, electrocardiogram and photoplethysmograph waveforms, orders placed and medications administered throughout the visit, free-text reports of imaging studies, and information on ED diagnosis, disposition, and subsequent revisits. We provide performance baselines for each prediction task to enable the evaluation of multimodal, multitask models. We believe that MC-BEC will encourage researchers to develop more effective, generalizable, and accessible foundation models for multimodal clinical data.
count=1
* CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/920f2dced7d32ab2ba2f1970bc306af6-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/920f2dced7d32ab2ba2f1970bc306af6-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion
    * Year: `2023`
    * Authors: Yangruibo Ding, Zijian Wang, Wasi Ahmad, Hantian Ding, Ming Tan, Nihal Jain, Murali Krishna Ramanathan, Ramesh Nallapati, Parminder Bhatia, Dan Roth, Bing Xiang
    * Abstract: Code completion models have made significant progress in recent years, yet current popular evaluation datasets, such as HumanEval and MBPP, predominantly focus on code completion tasks within a single file. This over-simplified setting falls short of representing the real-world software development scenario where repositories span multiple files with numerous cross-file dependencies, and accessing and understanding cross-file context is often required to complete the code correctly. To fill in this gap, we propose CrossCodeEval, a diverse and multilingual code completion benchmark that necessitates an in-depth cross-file contextual understanding to complete the code accurately. CrossCodeEval is built on a diverse set of real-world, open-sourced, permissively-licensed repositories in four popular programming languages: Python, Java, TypeScript, and C#. To create examples that strictly require cross-file context for accurate completion, we propose a straightforward yet efficient static-analysis-based approach to pinpoint the use of cross-file context within the current file. Extensive experiments on state-of-the-art code language models like CodeGen and StarCoder demonstrate that CrossCodeEval is extremely challenging when the relevant cross-file context is absent, and we see clear improvements when adding these context into the prompt. However, despite such improvements, the pinnacle of performance remains notably unattained even with the highest-performing model, indicating that CrossCodeEval is also capable of assessing model's capability in leveraging extensive context to make better code completion. Finally, we benchmarked various methods in retrieving cross-file context, and show that CrossCodeEval can also be used to measure the capability of code retrievers.
count=1
* Online robust non-stationary estimation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/9e15d892c63903ecc278e0dd05536951-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/9e15d892c63903ecc278e0dd05536951-Paper-Conference.pdf)]
    * Title: Online robust non-stationary estimation
    * Year: `2023`
    * Authors: Abishek Sankararaman, Balakrishnan Narayanaswamy
    * Abstract: The real-time estimation of time-varying parameters from high-dimensional, heavy-tailed and corrupted data-streams is a common sub-routine in systems ranging from those for network monitoring and anomaly detection to those for traffic scheduling in data-centers. For estimation tasks that can be cast as minimizing a strongly convex loss function, we prove that an appropriately tuned version of the {\ttfamily clipped Stochastic Gradient Descent} (SGD) is simultaneously {\em(i)} adaptive to drift, {\em (ii)} robust to heavy-tailed inliers and arbitrary corruptions, {\em(iii)} requires no distributional knowledge and {\em (iv)} can be implemented in an online streaming fashion. All prior estimation algorithms have only been proven to posses a subset of these practical desiderata. A observation we make is that, neither the $\mathcal{O}\left(\frac{1}{t}\right)$ learning rate for {\ttfamily clipped SGD} known to be optimal for strongly convex loss functions of a \emph{stationary} data-stream, nor the $\mathcal{O}(1)$ learning rate known to be optimal for being adaptive to drift in a \emph{noiseless} environment can be used. Instead, a learning rate of $T^{-\alpha}$ for $ \alpha < 1$ where $T$ is the stream-length is needed to balance adaptivity to potential drift and to combat noise. We develop a new inductive argument and combine it with a martingale concentration result to derive high-probability under \emph{any learning rate} on data-streams exhibiting \emph{arbitrary distribution shift} - a proof strategy that may be of independent interest. Further, using the classical doubling-trick, we relax the knowledge of the stream length $T$. Ours is the first online estimation algorithm that is provably robust to heavy-tails, corruptions and distribution shift simultaneously. We complement our theoretical results empirically on synthetic and real data.
count=1
* Diverse Community Data for Benchmarking Data Privacy Algorithms
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/a15032f8199511ced4d7a8e2bbb487a5-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/a15032f8199511ced4d7a8e2bbb487a5-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Diverse Community Data for Benchmarking Data Privacy Algorithms
    * Year: `2023`
    * Authors: Aniruddha Sen, Christine Task, Dhruv Kapur, Gary Howarth, Karan Bhagat
    * Abstract: The Collaborative Research Cycle (CRC) is a National Institute of Standards and Technology (NIST) benchmarking program intended to strengthen understanding of tabular data deidentification technologies. Deidentification algorithms are vulnerable to the same bias and privacy issues that impact other data analytics and machine learning applications, and it can even amplify those issues by contaminating downstream applications. This paper summarizes four CRC contributions: theoretical work on the relationship between diverse populations and challenges for equitable deidentification; public benchmark data focused on diverse populations and challenging features; a comprehensive open source suite of evaluation metrology for deidentified datasets; and an archive of more than 450 deidentified data samples from a broad range of techniques. The initial set of evaluation results demonstrate the value of the CRC tools for investigations in this field.
count=1
* A Logic for Expressing Log-Precision Transformers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/a48e5877c7bf86a513950ab23b360498-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/a48e5877c7bf86a513950ab23b360498-Paper-Conference.pdf)]
    * Title: A Logic for Expressing Log-Precision Transformers
    * Year: `2023`
    * Authors: William Merrill, Ashish Sabharwal
    * Abstract: One way to interpret the reasoning power of transformer-based language models is to describe the types of logical rules they can resolve over some input text. Recently, Chiang et al. (2023) showed that finite-precision transformer classifiers can be equivalently expressed in a generalization of first-order logic. However, finite-precision transformers are a weak transformer variant because, as we show, a single head can only attend to a constant number of tokens and, in particular, cannot represent uniform attention. Since attending broadly is a core capability for transformers, we ask whether a minimally more expressive model that can attend universally can also be characterized in logic. To this end, we analyze transformers whose forward pass is computed in $\log n$ precision on contexts of length $n$. We prove any log-precision transformer classifier can be equivalently expressed as a first-order logic sentence that, in addition to standard universal and existential quantifiers, may also contain majority-vote quantifiers. This is the tightest known upper bound and first logical characterization of log-precision transformers.
count=1
* Benchmarking Distribution Shift in Tabular Data with TableShift
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/a76a757ed479a1e6a5f8134bea492f83-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/a76a757ed479a1e6a5f8134bea492f83-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Benchmarking Distribution Shift in Tabular Data with TableShift
    * Year: `2023`
    * Authors: Josh Gardner, Zoran Popovic, Ludwig Schmidt
    * Abstract: Robustness to distribution shift has become a growing concern for text and image models as they transition from research subjects to deployment in the real world. However, high-quality benchmarks for distribution shift in tabular machine learning tasks are still lacking despite the widespread real-world use of tabular data and differences in the models used for tabular data in comparison to text and images. As a consequence, the robustness of tabular models to distribution shift is poorly understood. To address this issue, we introduce TableShift, a distribution shift benchmark for tabular data. TableShift contains 15 binary classification tasks in total, each with an associated shift, and includes a diverse set of data sources, prediction targets, and distribution shifts. The benchmark covers domains including finance, education, public policy, healthcare, and civic participation, and is accessible using only a few lines of Python code via the TableShift API. We conduct a large-scale study comparing several state-of-the-art tabular data models alongside robust learning and domain generalization methods on the benchmark tasks. Our study demonstrates (1) a linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy; (2) domain robustness methods can reduce shift gaps but at the cost of reduced ID accuracy; (3) a strong relationship between shift gap (difference between ID and OOD performance) and shifts in the label distribution. The benchmark data, Python package, model implementations, and more information about TableShift are available at https://github.com/mlfoundations/tableshift and https://tableshift.org .
count=1
* Oracle Complexity of Single-Loop Switching Subgradient Methods for Non-Smooth Weakly Convex Functional Constrained Optimization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/c132c02176577c4319a878f6417a331a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/c132c02176577c4319a878f6417a331a-Paper-Conference.pdf)]
    * Title: Oracle Complexity of Single-Loop Switching Subgradient Methods for Non-Smooth Weakly Convex Functional Constrained Optimization
    * Year: `2023`
    * Authors: Yankun Huang, Qihang Lin
    * Abstract: We consider a non-convex constrained optimization problem, where the objective function is weakly convex and the constraint function is either convex or weakly convex. To solve this problem, we consider the classical switching subgradient method, which is an intuitive and easily implementable first-order method whose oracle complexity was only known for convex problems. This paper provides the first analysis on the oracle complexity of the switching subgradient method for finding a nearly stationary point of non-convex problems. Our results are derived separately for convex and weakly convex constraints. Compared to existing approaches, especially the double-loop methods, the switching gradient method can be applied to non-smooth problems and achieves the same complexity using only a single loop, which saves the effort on tuning the number of inner iterations.
count=1
* The Bayesian Stability Zoo
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/c2586b71fd150fb56952e253a9c551cc-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/c2586b71fd150fb56952e253a9c551cc-Paper-Conference.pdf)]
    * Title: The Bayesian Stability Zoo
    * Year: `2023`
    * Authors: Shay Moran, Hilla Schefler, Jonathan Shafer
    * Abstract: We show that many definitions of stability found in the learning theory literature are equivalent to one another. We distinguish between two families of definitions of stability: distribution-dependent and distribution-independent Bayesian stability. Within each family, we establish equivalences between various definitions, encompassing approximate differential privacy, pure differential privacy, replicability, global stability, perfect generalization, TV stability, mutual information stability, KL-divergence stability, and Rényi-divergence stability. Along the way, we prove boosting results that enable the amplification of the stability of a learning rule. This work is a step towards a more systematic taxonomy of stability notions in learning theory, which can promote clarity and an improved understanding of an array of stability concepts that have emerged in recent years.
count=1
* StateMask: Explaining Deep Reinforcement Learning through State Mask
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/c4bf73386022473a652a18941e9ea6f8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/c4bf73386022473a652a18941e9ea6f8-Paper-Conference.pdf)]
    * Title: StateMask: Explaining Deep Reinforcement Learning through State Mask
    * Year: `2023`
    * Authors: Zelei Cheng, Xian Wu, Jiahao Yu, Wenhai Sun, Wenbo Guo, Xinyu Xing
    * Abstract: Despite the promising performance of deep reinforcement learning (DRL) agents in many challenging scenarios, the black-box nature of these agents greatly limits their applications in critical domains. Prior research has proposed several explanation techniques to understand the deep learning-based policies in RL. Most existing methods explain why an agent takes individual actions rather than pinpointing the critical steps to its final reward. To fill this gap, we propose StateMask, a novel method to identify the states most critical to the agent's final reward. The high-level idea of StateMask is to learn a mask net that blinds a target agent and forces it to take random actions at some steps without compromising the agent's performance. Through careful design, we can theoretically ensure that the masked agent performs similarly to the original agent. We evaluate StateMask in various popular RL environments and show its superiority over existing explainers in explanation fidelity. We also show that StateMask has better utilities, such as launching adversarial attacks and patching policy errors.
count=1
* Certified Minimax Unlearning with Generalization Rates and Deletion Capacity
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/c69465280855cfe25d566e359da140c1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/c69465280855cfe25d566e359da140c1-Paper-Conference.pdf)]
    * Title: Certified Minimax Unlearning with Generalization Rates and Deletion Capacity
    * Year: `2023`
    * Authors: Jiaqi Liu, Jian Lou, Zhan Qin, Kui Ren
    * Abstract: We study the problem of $(\epsilon,\delta)$-certified machine unlearning for minimax models. Most of the existing works focus on unlearning from standard statistical learning models that have a single variable and their unlearning steps hinge on the direct Hessian-based conventional Newton update. We develop a new $(\epsilon,\delta)$-certified machine unlearning algorithm for minimax models. It proposes a minimax unlearning step consisting of a total Hessian-based complete Newton update and the Gaussian mechanism borrowed from differential privacy. To obtain the unlearning certification, our method injects calibrated Gaussian noises by carefully analyzing the ''sensitivity'' of the minimax unlearning step (i.e., the closeness between the minimax unlearning variables and the retraining-from-scratch variables). We derive the generalization rates in terms of population strong and weak primal-dual risk for three different cases of loss functions, i.e., (strongly-)convex-(strongly-)concave losses. We also provide the deletion capacity to guarantee that a desired population risk can be maintained as long as the number of deleted samples does not exceed the derived amount. With training samples $n$ and model dimension $d$, it yields the order $\mathcal O(n/d^{1/4})$, which shows a strict gap over the baseline method of differentially private minimax learning that has $\mathcal O(n/d^{1/2})$. In addition, our rates of generalization and deletion capacity match the state-of-the-art rates derived previously for standard statistical learning models.
count=1
* Learning Rate Free Sampling in Constrained Domains
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/cdee6c3eaa2adc285f11da7711a75c12-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/cdee6c3eaa2adc285f11da7711a75c12-Paper-Conference.pdf)]
    * Title: Learning Rate Free Sampling in Constrained Domains
    * Year: `2023`
    * Authors: Louis Sharrock, Lester Mackey, Christopher Nemeth
    * Abstract: We introduce a suite of new particle-based algorithms for sampling in constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.
count=1
* Feature Selection in the Contrastive Analysis Setting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/d083980ec9f874025550136b776a96a9-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/d083980ec9f874025550136b776a96a9-Paper-Conference.pdf)]
    * Title: Feature Selection in the Contrastive Analysis Setting
    * Year: `2023`
    * Authors: Ethan Weinberger, Ian Covert, Su-In Lee
    * Abstract: Contrastive analysis (CA) refers to the exploration of variations uniquely enriched in a target dataset as compared to a corresponding background dataset generated from sources of variation that are irrelevant to a given task. For example, a biomedical data analyst may wish to find a small set of genes to use as a proxy for variations in genomic data only present among patients with a given disease (target) as opposed to healthy control subjects (background). However, as of yet the problem of feature selection in the CA setting has received little attention from the machine learning community. In this work we present contrastive feature selection (CFS),a method for performing feature selection in the CA setting. We motivate our approach with a novel information-theoretic analysis of representation learning in the CA setting, and we empirically validate CFS on a semi-synthetic dataset and four real-world biomedical datasets. We find that our method consistently outperforms previously proposed state-of-the-art supervised and fully unsupervised feature selection methods not designed for the CA setting. An open-source implementation of our method is available at https://github.com/suinleelab/CFS.
count=1
* EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/d42db1f74df54cb992b3956eb7f15a6f-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/d42db1f74df54cb992b3956eb7f15a6f-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models
    * Year: `2023`
    * Authors: Michael Wornow, Rahul Thapa, Ethan Steinberg, Jason Fries, Nigam Shah
    * Abstract: While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets. The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits. We help address these challenges through three contributions. First, we publish a new dataset, EHRSHOT, which contains de-identified structured data from the electronic health records (EHRs) of 6,739 patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients. Second, we publish the weights of CLMBR-T-base, a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients. We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBERT) only work with unstructured text and cannot process the rich, structured data within an EHR. We provide an end-to-end pipeline for the community to validate and build upon its performance. Third, we define 15 few-shot clinical prediction tasks, enabling evaluation of foundation models on benefits such as sample efficiency and task adaptation. Our model and dataset are available via a research data use agreement from here: https://stanfordaimi.azurewebsites.net/. Code to reproduce our results is available here: https://github.com/som-shahlab/ehrshot-benchmark.
count=1
* Beyond Myopia: Learning from Positive and Unlabeled Data through Holistic Predictive Trends
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/d5c0f9585592bad5251133813893a6c0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/d5c0f9585592bad5251133813893a6c0-Paper-Conference.pdf)]
    * Title: Beyond Myopia: Learning from Positive and Unlabeled Data through Holistic Predictive Trends
    * Year: `2023`
    * Authors: Wang Xinrui, Wenhai Wan, Chuanxing Geng, Shao-Yuan Li, Songcan Chen
    * Abstract: Learning binary classifiers from positive and unlabeled data (PUL) is vital in many real-world applications, especially when verifying negative examples is difficult. Despite the impressive empirical performance of recent PUL methods, challenges like accumulated errors and increased estimation bias persist due to the absence of negative labels. In this paper, we unveil an intriguing yet long-overlooked observation in PUL: \textit{resampling the positive data in each training iteration to ensure a balanced distribution between positive and unlabeled examples results in strong early-stage performance. Furthermore, predictive trends for positive and negative classes display distinctly different patterns.} Specifically, the scores (output probability) of unlabeled negative examples consistently decrease, while those of unlabeled positive examples show largely chaotic trends. Instead of focusing on classification within individual time frames, we innovatively adopt a holistic approach, interpreting the scores of each example as a temporal point process (TPP). This reformulates the core problem of PUL as recognizing trends in these scores. We then propose a novel TPP-inspired measure for trend detection and prove its asymptotic unbiasedness in predicting changes. Notably, our method accomplishes PUL without requiring additional parameter tuning or prior assumptions, offering an alternative perspective for tackling this problem. Extensive experiments verify the superiority of our method, particularly in a highly imbalanced real-world setting, where it achieves improvements of up to $11.3\%$ in key metrics.
count=1
* Bootstrapped Training of Score-Conditioned Generator for Offline Design of Biological Sequences
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/d601a9b708cacfad167f6c6c45647a18-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/d601a9b708cacfad167f6c6c45647a18-Paper-Conference.pdf)]
    * Title: Bootstrapped Training of Score-Conditioned Generator for Offline Design of Biological Sequences
    * Year: `2023`
    * Authors: Minsu Kim, Federico Berto, Sungsoo Ahn, Jinkyoo Park
    * Abstract: We study the problem of optimizing biological sequences, e.g., proteins, DNA, and RNA, to maximize a black-box score function that is only evaluated in an offline dataset. We propose a novel solution, bootstrapped training of score-conditioned generator (BootGen) algorithm. Our algorithm repeats a two-stage process. In the first stage, our algorithm trains the biological sequence generator with rank-based weights to enhance the accuracy of sequence generation based on high scores. The subsequent stage involves bootstrapping, which augments the training dataset with self-generated data labeled by a proxy score function. Our key idea is to align the score-based generation with a proxy score function, which distills the knowledge of the proxy score function to the generator. After training, we aggregate samples from multiple bootstrapped generators and proxies to produce a diverse design. Extensive experiments show that our method outperforms competitive baselines on biological sequential design tasks. We provide reproducible source code: https://github.com/kaist-silab/bootgen.
count=1
* Proximity-Informed Calibration for Deep Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/d826f5aadb26db488b8686097ceea2d1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/d826f5aadb26db488b8686097ceea2d1-Paper-Conference.pdf)]
    * Title: Proximity-Informed Calibration for Deep Neural Networks
    * Year: `2023`
    * Authors: Miao Xiong, Ailin Deng, Pang Wei W. Koh, Jiaying Wu, Shen Li, Jianqing Xu, Bryan Hooi
    * Abstract: Confidence calibration is central to providing accurate and interpretable uncertainty estimates, especially under safety-critical scenarios. However, we find that existing calibration algorithms often overlook the issue of proximity bias, a phenomenon where models tend to be more overconfident in low proximity data (i.e., data lying in the sparse region of the data distribution) compared to high proximity samples, and thus suffer from inconsistent miscalibration across different proximity samples. We examine the problem over $504$ pretrained ImageNet models and observe that: 1) Proximity bias exists across a wide variety of model architectures and sizes; 2) Transformer-based models are relatively more susceptible to proximity bias than CNN-based models; 3) Proximity bias persists even after performing popular calibration algorithms like temperature scaling; 4) Models tend to overfit more heavily on low proximity samples than on high proximity samples. Motivated by the empirical findings, we propose ProCal, a plug-and-play algorithm with a theoretical guarantee to adjust sample confidence based on proximity. To further quantify the effectiveness of calibration algorithms in mitigating proximity bias, we introduce proximity-informed expected calibration error (PIECE) with theoretical analysis. We show that ProCal is effective in addressing proximity bias and improving calibration on balanced, long-tail, and distribution-shift settings under four metrics over various model architectures. We believe our findings on proximity bias will guide the development of fairer and better-calibrated} models, contributing to the broader pursuit of trustworthy AI.
count=1
* Individual Arbitrariness and Group Fairness
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/d891d240b5784656a0356bf4b00f5cdd-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/d891d240b5784656a0356bf4b00f5cdd-Paper-Conference.pdf)]
    * Title: Individual Arbitrariness and Group Fairness
    * Year: `2023`
    * Authors: Carol Long, Hsiang Hsu, Wael Alghamdi, Flavio Calmon
    * Abstract: Machine learning tasks may admit multiple competing models that achieve similar performance yet produce conflicting outputs for individual samples---a phenomenon known as predictive multiplicity. We demonstrate that fairness interventions in machine learning optimized solely for group fairness and accuracy can exacerbate predictive multiplicity. Consequently, state-of-the-art fairness interventions can mask high predictive multiplicity behind favorable group fairness and accuracy metrics. We argue that a third axis of ``arbitrariness'' should be considered when deploying models to aid decision-making in applications of individual-level impact.To address this challenge, we propose an ensemble algorithm applicable to any fairness intervention that provably ensures more consistent predictions.
count=1
* Minimum-Risk Recalibration of Classifiers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/dbd6b295535e44f2b8ec0c3f1da7c509-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/dbd6b295535e44f2b8ec0c3f1da7c509-Paper-Conference.pdf)]
    * Title: Minimum-Risk Recalibration of Classifiers
    * Year: `2023`
    * Authors: Zeyu Sun, Dogyoon Song, Alfred Hero
    * Abstract: Recalibrating probabilistic classifiers is vital for enhancing the reliability and accuracy of predictive models. Despite the development of numerous recalibration algorithms, there is still a lack of a comprehensive theory that integrates calibration and sharpness (which is essential for maintaining predictive power). In this paper, we introduce the concept of minimum-risk recalibration within the framework of mean-squared-error (MSE) decomposition, offering a principled approach for evaluating and recalibrating probabilistic classifiers. Using this framework, we analyze the uniform-mass binning (UMB) recalibration method and establish a finite-sample risk upper bound of order $\tilde{O}(B/n + 1/B^2)$ where $B$ is the number of bins and $n$ is the sample size. By balancing calibration and sharpness, we further determine that the optimal number of bins for UMB scales with $n^{1/3}$, resulting in a risk bound of approximately $O(n^{-2/3})$. Additionally, we tackle the challenge of label shift by proposing a two-stage approach that adjusts the recalibration function using limited labeled data from the target domain. Our results show that transferring a calibrated classifier requires significantly fewer target samples compared to recalibrating from scratch. We validate our theoretical findings through numerical simulations, which confirm the tightness of the proposed bounds, the optimal number of bins, and the effectiveness of label shift adaptation.
count=1
* Towards a fuller understanding of neurons with Clustered Compositional Explanations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/debd0ae2083160397a22a4a8831c7230-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/debd0ae2083160397a22a4a8831c7230-Paper-Conference.pdf)]
    * Title: Towards a fuller understanding of neurons with Clustered Compositional Explanations
    * Year: `2023`
    * Authors: Biagio La Rosa, Leilani Gilpin, Roberto Capobianco
    * Abstract: Compositional Explanations is a method for identifying logical formulas of concepts that approximate the neurons' behavior. However, these explanations are linked to the small spectrum of neuron activations (i.e., the highest ones) used to check the alignment, thus lacking completeness. In this paper, we propose a generalization, called Clustered Compositional Explanations, that combines Compositional Explanations with clustering and a novel search heuristic to approximate a broader spectrum of the neuron behavior. We define and address the problems connected to the application of these methods to multiple ranges of activations, analyze the insights retrievable by using our algorithm, and propose desiderata qualities that can be used to study the explanations returned by different algorithms.
count=1
* TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/ded1a89e2b3b925444ada973af66336e-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/ded1a89e2b3b925444ada973af66336e-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs
    * Year: `2023`
    * Authors: Mangpo Phothilimthana, Sami Abu-El-Haija, Kaidi Cao, Bahare Fatemi, Michael Burrows, Charith Mendis, Bryan Perozzi
    * Abstract: Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10–20\% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TpuGraphs, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the dataset are collected from open-source machine learning programs, featuring popular model architectures (e.g., ResNet, EfficientNet, Mask R-CNN, and Transformer). TpuGraphs provides 25x more graphs than the largest graph property prediction dataset (with comparable graph sizes), and 770x larger graphs on average compared to existing performance prediction datasets on machine learning programs. This graph-level prediction task on large graphs introduces new challenges in learning, ranging from scalability, training efficiency, to model quality.
count=1
* Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/dfc310e81992d2e4cedc09ac47eff13e-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/dfc310e81992d2e4cedc09ac47eff13e-Paper-Conference.pdf)]
    * Title: Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective
    * Year: `2023`
    * Authors: Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang
    * Abstract: Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the expressivity of LLMs with CoT in solving fundamental mathematical and decision-making problems. By using circuit complexity theory, we first give impossibility results showing that bounded-depth Transformers are unable to directly produce correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of constant size suffice to solve both tasks by generating CoT derivations using a commonly used math language format. Moreover, we show LLMs with CoT can handle a general class of decision-making problems known as Dynamic Programming, thus justifying their power in tackling complex real-world tasks. Finally, an extensive set of experiments show that, while Transformers always fail to directly predict the answers, they can consistently learn to generate correct solutions step-by-step given sufficient CoT demonstrations.
count=1
* Creating a Public Repository for Joining Private Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/e19560e93418dd0d6498bd3b2de856cd-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/e19560e93418dd0d6498bd3b2de856cd-Paper-Conference.pdf)]
    * Title: Creating a Public Repository for Joining Private Data
    * Year: `2023`
    * Authors: James Cook, Milind Shyani, Nina Mishra
    * Abstract: How can one publish a dataset with sensitive attributes in a way that both preserves privacy and enables joins with other datasets on those same sensitive attributes? This problem arises in many contexts, e.g., a hospital and an airline may want to jointly determine whether people who take long-haul flights are more likely to catch respiratory infections. If they join their data by a common keyed user identifier such as email address, they can determine the answer, though it breaks privacy. This paper shows how the hospital can generate a private sketch and how the airline can privately join with the hospital's sketch by email address. The proposed solution satisfies pure differential privacy and gives approximate answers to linear queries and optimization problems over those joins. Whereas prior work such as secure function evaluation requires sender/receiver interaction, a distinguishing characteristic of the proposed approach is that it is non-interactive. Consequently, the sketch can be published to a repository for any organization to join with, facilitating data discovery. The accuracy of the method is demonstrated through both theoretical analysis and extensive empirical evidence.
count=1
* AirDelhi: Fine-Grained Spatio-Temporal Particulate Matter Dataset From Delhi For ML based Modeling
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/ee799aff607fcf39c01df6391e96f92c-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/ee799aff607fcf39c01df6391e96f92c-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: AirDelhi: Fine-Grained Spatio-Temporal Particulate Matter Dataset From Delhi For ML based Modeling
    * Year: `2023`
    * Authors: Sachin Chauhan, Zeel Bharatkumar Patel, Sayan Ranu, Rijurekha Sen, Nipun Batra
    * Abstract: Air pollution poses serious health concerns in developing countries, such as India, necessitating large-scale measurement for correlation analysis, policy recommendations, and informed decision-making. However, fine-grained data collection is costly. Specifically, static sensors for pollution measurement cost several thousand dollars per unit, leading to inadequate deployment and coverage. To complement the existing sparse static sensor network, we propose a mobile sensor network utilizing lower-cost PM2.5 sensors mounted on public buses in the Delhi-NCR region of India. Through this exercise, we introduce a novel dataset AirDelhi comprising PM2.5 and PM10 measurements. This dataset is made publicly available, at https://www.cse.iitd.ac.in/pollutiondata, serving as a valuable resource for machine learning (ML) researchers and environmentalists. We present three key contributions with the release of this dataset. Firstly, through in-depth statistical analysis, we demonstrate that the released dataset significantly differs from existing pollution datasets, highlighting its uniqueness and potential for new insights. Secondly, the dataset quality been validated against existing expensive sensors. Thirdly, we conduct a benchmarking exercise (https://github.com/sachin-iitd/DelhiPMDatasetBenchmark), evaluating state-of-the-art methods for interpolation, feature imputation, and forecasting on this dataset, which is the largest publicly available PM dataset to date. The results of the benchmarking exercise underscore the substantial disparities in accuracy between the proposed dataset and other publicly available datasets. This finding highlights the complexity and richness of our dataset, emphasizing its value for advancing research in the field of air pollution.
count=1
* Predicting a Protein's Stability under a Million Mutations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/f03cb785864596fa5901f1359d23fd81-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/f03cb785864596fa5901f1359d23fd81-Paper-Conference.pdf)]
    * Title: Predicting a Protein's Stability under a Million Mutations
    * Year: `2023`
    * Authors: Jeffrey Ouyang-Zhang, Daniel Diaz, Adam Klivans, Philipp Kraehenbuehl
    * Abstract: Stabilizing proteins is a foundational step in protein engineering. However, the evolutionary pressure of all extant proteins makes identifying the scarce number of mutations that will improve thermodynamic stability challenging. Deep learning has recently emerged as a powerful tool for identifying promising mutations.Existing approaches, however, are computationally expensive, as the number of model inferences scales with the number of mutations queried. Our main contribution is a simple, parallel decoding algorithm.Mutate Everything is capable of predicting the effect of all single and double mutations in one forward pass. It is even versatile enough to predict higher-order mutations with minimal computational overhead.We build Mutate Everything on top of ESM2 and AlphaFold, neither of which were trained to predict thermodynamic stability.We trained on the Mega-Scale cDNA proteolysis dataset and achieved state-of-the-art performance on single and higher-order mutations on S669, ProTherm, and ProteinGym datasets.Our code is available at https://github.com/jozhang97/MutateEverything.
count=1
* Computational Complexity of Learning Neural Networks: Smoothness and Degeneracy
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/f0552f14388d95b19740dee809f5cad1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/f0552f14388d95b19740dee809f5cad1-Paper-Conference.pdf)]
    * Title: Computational Complexity of Learning Neural Networks: Smoothness and Degeneracy
    * Year: `2023`
    * Authors: Amit Daniely, Nati Srebro, Gal Vardi
    * Abstract: Understanding when neural networks can be learned efficientlyis a fundamental question in learning theory.Existing hardness results suggest that assumptions on both the input distribution and the network's weights are necessary for obtaining efficient algorithms. Moreover, it was previously shown that depth-$2$ networks can be efficiently learned under the assumptions that the input distribution is Gaussian, and the weight matrix is non-degenerate. In this work, we study whether such assumptions may suffice for learning deeper networks and prove negative results. We show that learning depth-$3$ ReLU networks under the Gaussian input distribution is hard even in the smoothed-analysis framework, where a random noise is added to the network's parameters. It implies that learning depth-$3$ ReLU networks under the Gaussian distribution is hard even if the weight matrices are non-degenerate. Moreover, we consider depth-$2$ networks, and show hardness of learning in the smoothed-analysis framework, where both the network parameters and the input distribution are smoothed. Our hardness results are under a well-studied assumption on the existence of local pseudorandom generators.
count=1
* How to Turn Your Knowledge Graph Embeddings into Generative Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/f4b768188be63b8d2680a46934fd295a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/f4b768188be63b8d2680a46934fd295a-Paper-Conference.pdf)]
    * Title: How to Turn Your Knowledge Graph Embeddings into Generative Models
    * Year: `2023`
    * Authors: Lorenzo Loconte, Nicola Di Mauro, Robert Peharz, Antonio Vergari
    * Abstract: Some of the most successful knowledge graph embedding (KGE) models for link prediction – CP, RESCAL, TuckER, ComplEx – can be interpreted as energy-based models. Under this perspective they are not amenable for exact maximum-likelihood estimation (MLE), sampling and struggle to integrate logical constraints. This work re-interprets the score functions of these KGEs as circuits – constrained computational graphs allowing efficient marginalisation. Then, we design two recipes to obtain efficient generative circuit models by either restricting their activations to be non-negative or squaring their outputs. Our interpretation comes with little or no loss of performance for link prediction, while the circuits framework unlocks exact learning by MLE, efficient sampling of new triples, and guarantee that logical constraints are satisfied by design. Furthermore, our models scale more gracefully than the original KGEs on graphs with millions of entities.
count=1
* MedSat: A Public Health Dataset for England Featuring Medical Prescriptions and Satellite Imagery
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/f4fdf676c3b21f20f8c391d929188386-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/f4fdf676c3b21f20f8c391d929188386-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: MedSat: A Public Health Dataset for England Featuring Medical Prescriptions and Satellite Imagery
    * Year: `2023`
    * Authors: Sanja Scepanovic, Ivica Obadic, Sagar Joglekar, Laura GIUSTARINI, Cristiano Nattero, Daniele Quercia, Xiaoxiang Zhu
    * Abstract: As extreme weather events become more frequent, understanding their impact on human health becomes increasingly crucial. However, the utilization of Earth Observation to effectively analyze the environmental context in relation to health remains limited. This limitation is primarily due to the lack of fine-grained spatial and temporal data in public and population health studies, hindering a comprehensive understanding of health outcomes. Additionally, obtaining appropriate environmental indices across different geographical levels and timeframes poses a challenge. For the years 2019 (pre-COVID) and 2020 (COVID), we collected spatio-temporal indicators for all Lower Layer Super Output Areas in England. These indicators included: i) 111 sociodemographic features linked to health in existing literature, ii) 43 environmental point features (e.g., greenery and air pollution levels), iii) 4 seasonal composite satellite images each with 11 bands, and iv) prescription prevalence associated with five medical conditions (depression, anxiety, diabetes, hypertension, and asthma), opioids and total prescriptions. We combined these indicators into a single MedSat dataset, the availability of which presents an opportunity for the machine learning community to develop new techniques specific to public health. These techniques would address challenges such as handling large and complex data volumes, performing effective feature engineering on environmental and sociodemographic factors, capturing spatial and temporal dependencies in the models, addressing imbalanced data distributions, developing novel computer vision methods for health modeling based on satellite imagery, ensuring model explainability, and achieving generalization beyond the specific geographical region.
count=1
* Online POMDP Planning with Anytime Deterministic Guarantees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/fc6bd0eef19459655d5b097af783661d-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2023/file/fc6bd0eef19459655d5b097af783661d-Paper-Conference.pdf)]
    * Title: Online POMDP Planning with Anytime Deterministic Guarantees
    * Year: `2023`
    * Authors: Moran Barenboim, Vadim Indelman
    * Abstract: Autonomous agents operating in real-world scenarios frequently encounter uncertainty and make decisions based on incomplete information. Planning under uncertainty can be mathematically formalized using partially observable Markov decision processes (POMDPs). However, finding an optimal plan for POMDPs can be computationally expensive and is feasible only for small tasks. In recent years, approximate algorithms, such as tree search and sample-based methodologies, have emerged as state-of-the-art POMDP solvers for larger problems. Despite their effectiveness, these algorithms offer only probabilistic and often asymptotic guarantees toward the optimal solution due to their dependence on sampling. To address these limitations, we derive a deterministic relationship between a simplified solution that iseasier to obtain and the theoretically optimal one. First, we derive bounds for selecting a subset of the observations to branch from while computing a complete belief at each posterior node. Then, since a complete belief update may be computationally demanding, we extend the bounds to support reduction of both the state and the observation spaces. We demonstrate how our guarantees can be integrated with existing state-of-the-art solvers that sample a subset of states and observations. As a result, the returned solution holds deterministic bounds relative to the optimal policy. Lastly, we substantiate our findings with supporting experimental results.
count=1
* Diffusion Visual Counterfactual Explanations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/025f7165a452e7d0b57f1397fed3b0fd-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/025f7165a452e7d0b57f1397fed3b0fd-Paper-Conference.pdf)]
    * Title: Diffusion Visual Counterfactual Explanations
    * Year: `2022`
    * Authors: Maximilian Augustin, Valentyn Boreiko, Francesco Croce, Matthias Hein
    * Abstract: Visual Counterfactual Explanations (VCEs) are an important tool to understand the decisions of an image classifier. They are “small” but “realistic” semantic changes of the image changing the classifier decision. Current approaches for the generation of VCEs are restricted to adversarially robust models and often contain non-realistic artefacts, or are limited to image classification problems with few classes. In this paper, we overcome this by generating Diffusion Visual Counterfactual Explanations (DVCEs) for arbitrary ImageNet classifiers via a diffusion process. Two modifications to the diffusion process are key for our DVCEs: first, an adaptive parameterization, whose hyperparameters generalize across images and models, together with distance regularization and late start of the diffusion process, allow us to generate images with minimal semantic changes to the original ones but different classification. Second, our cone regularization via an adversarially robust model ensures that the diffusion process does not converge to trivial non-semantic changes, but instead produces realistic images of the target class which achieve high confidence by the classifier.
count=1
* Algorithms and Hardness for Learning Linear Thresholds from Label Proportions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/08a9e28c96d016dd63903ab51cd085b0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/08a9e28c96d016dd63903ab51cd085b0-Paper-Conference.pdf)]
    * Title: Algorithms and Hardness for Learning Linear Thresholds from Label Proportions
    * Year: `2022`
    * Authors: Rishi Saket
    * Abstract: We study the learnability of linear threshold functions (LTFs) in the learning from label proportions (LLP) framework. In this, the feature-vector classifier is learnt from bags of feature-vectors and their corresponding observed label proportions which are satisfied by (i.e., consistent with) some unknown LTF. This problem has been investigated in recent work (Saket21) which gave an algorithm to produce an LTF that satisfies at least $(2/5)$-fraction of a satisfiable collection of bags, each of size $\leq 2$, by solving and rounding a natural SDP relaxation. However, this SDP relaxation is specific to at most $2$-sized bags and does not apply to bags of larger size. In this work we provide a fairly non-trivial SDP relaxation of a non-quadratic formulation for bags of size $3$. We analyze its rounding procedure using novel matrix decomposition techniques to obtain an algorithm which outputs an LTF satisfying at least $(1/12)$-fraction of the bags of size $\leq 3$. We also apply our techniques to bags of size $q \geq 4$ to provide a $\Omega\left(1/q\right)$-approximation guarantee for a weaker notion of satisfiability. We include comparative experiments on simulated data demonstrating the applicability of our algorithmic techniques. From the complexity side we provide a hardness reduction to produce instances with bags of any constant size $q$. Our reduction proves the NP-hardness of satisfying more than $({1}/{q}) + o(1)$ fraction of a satisfiable collection of such bags using as hypothesis any function of constantly many LTFs, showing thereby that the problem is harder to approximate as the bag size $q$ increases. Using a strengthened analysis, for $q=2$ we obtain a $({4}/{9}) +o(1)$ hardness factor for this problem, improving upon the $({1}/{2}) + o(1)$ factor shown by Saket21.
count=1
* AdaFocal: Calibration-aware Adaptive Focal Loss
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/0a692a24dbc744fca340b9ba33bc6522-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/0a692a24dbc744fca340b9ba33bc6522-Paper-Conference.pdf)]
    * Title: AdaFocal: Calibration-aware Adaptive Focal Loss
    * Year: `2022`
    * Authors: Arindam Ghosh, Thomas Schaaf, Matthew Gormley
    * Abstract: Much recent work has been devoted to the problem of ensuring that a neural network's confidence scores match the true probability of being correct, i.e. the calibration problem. Of note, it was found that training with focal loss leads to better calibration than cross-entropy while achieving similar level of accuracy \cite{mukhoti2020}. This success stems from focal loss regularizing the entropy of the model's prediction (controlled by the parameter $\gamma$), thereby reining in the model's overconfidence. Further improvement is expected if $\gamma$ is selected independently for each training sample (Sample-Dependent Focal Loss (FLSD-53) \cite{mukhoti2020}). However, FLSD-53 is based on heuristics and does not generalize well. In this paper, we propose a calibration-aware adaptive focal loss called AdaFocal that utilizes the calibration properties of focal (and inverse-focal) loss and adaptively modifies $\gamma_t$ for different groups of samples based on $\gamma_{t-1}$ from the previous step and the knowledge of model's under/over-confidence on the validation set. We evaluate AdaFocal on various image recognition and one NLP task, covering a wide variety of network architectures, to confirm the improvement in calibration while achieving similar levels of accuracy. Additionally, we show that models trained with AdaFocal achieve a significant boost in out-of-distribution detection.
count=1
* Use-Case-Grounded Simulations for Explanation Evaluation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/0b9536e186a77feff516893a5f393f7a-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/0b9536e186a77feff516893a5f393f7a-Paper-Conference.pdf)]
    * Title: Use-Case-Grounded Simulations for Explanation Evaluation
    * Year: `2022`
    * Authors: Valerie Chen, Nari Johnson, Nicholay Topin, Gregory Plumb, Ameet Talwalkar
    * Abstract: A growing body of research runs human subject evaluations to study whether providing users with explanations of machine learning models can help them with practical real-world use cases. However, running user studies is challenging and costly, and consequently each study typically only evaluates a limited number of different settings, e.g., studies often only evaluate a few arbitrarily selected model explanation methods. To address these challenges and aid user study design, we introduce Simulated Evaluations (SimEvals). SimEvals involve training algorithmic agents that take as input the information content (such as model explanations) that would be presented to the user, to predict answers to the use case of interest. The algorithmic agent's test set accuracy provides a measure of the predictiveness of the information content for the downstream use case. We run a comprehensive evaluation on three real-world use cases (forward simulation, model debugging, and counterfactual reasoning) to demonstrate that SimEvals can effectively identify which explanation methods will help humans for each use case. These results provide evidence that \simevals{} can be used to efficiently screen an important set of user study design decisions, e.g., selecting which explanations should be presented to the user, before running a potentially costly user study.
count=1
* On the Epistemic Limits of Personalized Prediction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/0cfc9404f89400c5ed897035e0d3748c-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/0cfc9404f89400c5ed897035e0d3748c-Paper-Conference.pdf)]
    * Title: On the Epistemic Limits of Personalized Prediction
    * Year: `2022`
    * Authors: Lucas Monteiro Paes, Carol Long, Berk Ustun, Flavio Calmon
    * Abstract: Machine learning models are often personalized by using group attributes that encode personal characteristics (e.g., sex, age group, HIV status). In such settings, individuals expect to receive more accurate predictions in return for disclosing group attributes to the personalized model. We study when we can tell that a personalized model upholds this principle for every group who provides personal data. We introduce a metric called the benefit of personalization (BoP) to measure the smallest gain in accuracy that any group expects to receive from a personalized model. We describe how the BoP can be used to carry out basic routines to audit a personalized model, including: (i) hypothesis tests to check that a personalized model improves performance for every group; (ii) estimation procedures to bound the minimum gain in personalization. We characterize the reliability of these routines in a finite-sample regime and present minimax bounds on both the probability of error for BoP hypothesis tests and the mean-squared error of BoP estimates. Our results show that we can only claim that personalization improves performance for each group who provides data when we explicitly limit the number of group attributes used by a personalized model. In particular, we show that it is impossible to reliably verify that a personalized classifier with $k \geq 19$ binary group attributes will benefit every group who provides personal data using a dataset of $n = 8\times10^9$ samples -- one for each person in the world.
count=1
* VF-PS: How to Select Important Participants in Vertical Federated Learning, Efficiently and Securely?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/0e1a2388cd2f78069f4d048d935cb218-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/0e1a2388cd2f78069f4d048d935cb218-Paper-Conference.pdf)]
    * Title: VF-PS: How to Select Important Participants in Vertical Federated Learning, Efficiently and Securely?
    * Year: `2022`
    * Authors: Jiawei Jiang, Lukas Burkhalter, Fangcheng Fu, Bolin Ding, Bo Du, Anwar Hithnawi, Bo Li, Ce Zhang
    * Abstract: Vertical Federated Learning (VFL), that trains federated models over vertically partitioned data, has emerged as an important learning paradigm. However, existing VFL methods are facing two challenges: (1) scalability when # participants grows to even modest scale and (2) diminishing return w.r.t. # participants: not all participants are equally important and many will not introduce quality improvement in a large consortium. Inspired by these two challenges, in this paper, we ask: How can we select l out of m participants, where l ≪ m, that are most important?We call this problem Vertically Federated Participant Selection, and model it with a principled mutual information-based view. Our first technical contribution is VF-MINE—a Vertically Federated Mutual INformation Estimator—that uses one of the most celebrated algorithms in database theory—Fagin’s algorithm as a building block. Our second contribution is to further optimize VF-MINE to enable VF-PS, a group testing-based participant selection framework. We empirically show that vertically federated participation selection can be orders of magnitude faster than training a full-fledged VFL model, while being able to identify the most important subset of participants that often lead to a VFL model of similar quality.
count=1
* What You See is What You Get: Principled Deep Learning via Distributional Generalization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/0f4bbaaaf1e167f79134dd4cf11e3ed4-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/0f4bbaaaf1e167f79134dd4cf11e3ed4-Paper-Conference.pdf)]
    * Title: What You See is What You Get: Principled Deep Learning via Distributional Generalization
    * Year: `2022`
    * Authors: Bogdan Kulynych, Yao-Yuan Yang, Yaodong Yu, Jarosław Błasiok, Preetum Nakkiran
    * Abstract: Having similar behavior at training time and test time—what we call a “What You See Is What You Get” (WYSIWYG) property—is desirable in machine learning. Models trained with standard stochastic gradient descent (SGD), however, do not necessarily have this property, as their complex behaviors such as robustness or subgroup performance can differ drastically between training and test time. In contrast, we show that Differentially-Private (DP) training provably ensures the high-level WYSIWYG property, which we quantify using a notion of distributional generalization. Applying this connection, we introduce new conceptual tools for designing deep-learning methods by reducing generalization concerns to optimization ones: to mitigate unwanted behavior at test time, it is provably sufficient to mitigate this behavior on the training data. By applying this novel design principle, which bypasses “pathologies” of SGD, we construct simple algorithms that are competitive with SOTA in several distributional-robustness applications, significantly improve the privacy vs. disparate impact trade-off of DP-SGD, and mitigate robust overfitting in adversarial training. Finally, we also improve on theoretical bounds relating DP, stability, and distributional generalization.
count=1
* A Reduction to Binary Approach for Debiasing Multiclass Datasets
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/10eaa0aae94b34308e9b3fa7b677cbe1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/10eaa0aae94b34308e9b3fa7b677cbe1-Paper-Conference.pdf)]
    * Title: A Reduction to Binary Approach for Debiasing Multiclass Datasets
    * Year: `2022`
    * Authors: Ibrahim M. Alabdulmohsin, Jessica Schrouff, Sanmi Koyejo
    * Abstract: We propose a novel reduction-to-binary (R2B) approach that enforces demographic parity for multiclass classification with non-binary sensitive attributes via a reduction to a sequence of binary debiasing tasks. We prove that R2B satisfies optimality and bias guarantees and demonstrate empirically that it can lead to an improvement over two baselines: (1) treating multiclass problems as multi-label by debiasing labels independently and (2) transforming the features instead of the labels. Surprisingly, we also demonstrate that independent label debiasing yields competitive results in most (but not all) settings. We validate these conclusions on synthetic and real-world datasets from social science, computer vision, and healthcare.
count=1
* Improved Coresets for Euclidean $k$-Means
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/120c9ab5c58ba0fa9dd3a22ace1de245-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/120c9ab5c58ba0fa9dd3a22ace1de245-Paper-Conference.pdf)]
    * Title: Improved Coresets for Euclidean $k$-Means
    * Year: `2022`
    * Authors: Vincent Cohen-Addad, Kasper Green Larsen, David Saulpic, Chris Schwiegelshohn, Omar Ali Sheikh-Omar
    * Abstract: Given a set of $n$ points in $d$ dimensions, the Euclidean $k$-means problem (resp. Euclidean $k$-median) consists of finding $k$ centers such that the sum of squared distances (resp. sum of distances) from every point to its closest center is minimized. The arguably most popular way of dealing with this problem in the big data setting is to first compress the data by computing a weighted subset known as a coreset and then run any algorithm on this subset. The guarantee of the coreset is that for any candidate solution, the ratio between coreset cost and the cost of the original instance is less than a $(1\pm \varepsilon)$ factor. The current state of the art coreset size is $\tilde O(\min(k^{2} \cdot \varepsilon^{-2},k\cdot \varepsilon^{-4}))$ for Euclidean $k$-means and $\tilde O(\min(k^{2} \cdot \varepsilon^{-2},k\cdot \varepsilon^{-3}))$ for Euclidean $k$-median. The best known lower bound for both problems is $\Omega(k\varepsilon^{-2})$. In this paper, we improve these bounds to $\tilde O(\min(k^{3/2} \cdot \varepsilon^{-2},k\cdot \varepsilon^{-4}))$ for Euclidean $k$-means and $\tilde O(\min(k^{4/3} \cdot \varepsilon^{-2},k\cdot \varepsilon^{-3}))$ for Euclidean $k$-median. In particular, ours is the first provable bound that breaks through the $k^2$ barrier while retaining an optimal dependency on $\varepsilon$.
count=1
* Understanding Programmatic Weak Supervision via Source-aware Influence Function
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/1343edb2739a61a6e20bd8764e814b50-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/1343edb2739a61a6e20bd8764e814b50-Paper-Conference.pdf)]
    * Title: Understanding Programmatic Weak Supervision via Source-aware Influence Function
    * Year: `2022`
    * Authors: Jieyu Zhang, Haonan Wang, Cheng-Yu Hsieh, Alexander J. Ratner
    * Abstract: Programmatic Weak Supervision (PWS) aggregates the source votes of multiple weak supervision sources into probabilistic training labels, which are in turn used to train an end model. With its increasing popularity, it is critical to have some tool for users to understand the influence of each component (\eg, the source vote or training data) in the pipeline and interpret the end model behavior. To achieve this, we build on Influence Function (IF) and propose source-aware IF, which leverages the generation process of the probabilistic labels to decompose the end model's training objective and then calculate the influence associated with each (data, source, class) tuple. These primitive influence score can then be used to estimate the influence of individual component of PWS, such as source vote, supervision source, and training data. On datasets of diverse domains, we demonstrate multiple use cases: (1) interpreting incorrect predictions from multiple angles that reveals insights for debugging the PWS pipeline, (2) identifying mislabeling of sources with a gain of 9\%-37\% over baselines, and (3) improving the end model's generalization performance by removing harmful components in the training objective (13\%-24\% better than ordinary IF).
count=1
* TransTab: Learning Transferable Tabular Transformers Across Tables
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/1377f76686d56439a2bd7a91859972f5-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/1377f76686d56439a2bd7a91859972f5-Paper-Conference.pdf)]
    * Title: TransTab: Learning Transferable Tabular Transformers Across Tables
    * Year: `2022`
    * Authors: Zifeng Wang, Jimeng Sun
    * Abstract: Tabular data (or tables) are the most widely used data format in machine learning (ML). However, ML models often assume the table structure keeps fixed in training and testing. Before ML modeling, heavy data cleaning is required to merge disparate tables with different columns. This preprocessing often incurs significant data waste (e.g., removing unmatched columns and samples). How to learn ML models from multiple tables with partially overlapping columns? How to incrementally update ML models as more columns become available over time? Can we leverage model pretraining on multiple distinct tables? How to train an ML model which can predict on an unseen table? To answer all those questions, we propose to relax fixed table structures by introducing a Transferable Tabular Transformer (TransTab) for tables. The goal of TransTab is to convert each sample (a row in the table) to a generalizable embedding vector, and then apply stacked transformers for feature encoding. One methodology insight is combining column description and table cells as the raw input to a gated transformer model. The other insight is to introduce supervised and self-supervised pretraining to improve model performance. We compare TransTab with multiple baseline methods on diverse benchmark datasets and five oncology clinical trial datasets. Overall, TransTab ranks 1.00, 1.00, 1.78 out of 12 methods in supervised learning, incremental feature learning, and transfer learning scenarios, respectively; and the proposed pretraining leads to 2.3\% AUC lift on average over the supervised learning.
count=1
* DivBO: Diversity-aware CASH for Ensemble Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/13b2f88be223cd2b4d6be67b56e02fa8-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/13b2f88be223cd2b4d6be67b56e02fa8-Paper-Conference.pdf)]
    * Title: DivBO: Diversity-aware CASH for Ensemble Learning
    * Year: `2022`
    * Authors: Yu Shen, Yupeng Lu, Yang Li, Yaofeng Tu, Wentao Zhang, Bin CUI
    * Abstract: The Combined Algorithm Selection and Hyperparameters optimization (CASH) problem is one of the fundamental problems in Automated Machine Learning (AutoML). Motivated by the success of ensemble learning, recent AutoML systems build post-hoc ensembles to output the final predictions instead of using the best single learner. However, while most CASH methods focus on searching for a single learner with the best performance, they neglect the diversity among base learners (i.e., they may suggest similar configurations to previously evaluated ones), which is also a crucial consideration when building an ensemble. To tackle this issue and further enhance the ensemble performance, we propose DivBO, a diversity-aware framework to inject explicit search of diversity into the CASH problems. In the framework, we propose to use a diversity surrogate to predict the pair-wise diversity of two unseen configurations. Furthermore, we introduce a temporary pool and a weighted acquisition function to guide the search of both performance and diversity based on Bayesian optimization. Empirical results on 15 public datasets show that DivBO achieves the best average ranks (1.82 and 1.73) on both validation and test errors among 10 compared methods, including post-hoc designs in recent AutoML systems and state-of-the-art baselines for ensemble learning on CASH problems.
count=1
* Consistent Interpolating Ensembles via the Manifold-Hilbert Kernel
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/16371a9d5fed65d6d78ca3a7fa6e598c-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/16371a9d5fed65d6d78ca3a7fa6e598c-Paper-Conference.pdf)]
    * Title: Consistent Interpolating Ensembles via the Manifold-Hilbert Kernel
    * Year: `2022`
    * Authors: Yutong Wang, Clay Scott
    * Abstract: Recent research in the theory of overparametrized learning has sought to establish generalization guarantees in the interpolating regime. Such results have been established for a few common classes of methods, but so far not for ensemble methods. We devise an ensemble classification method that simultaneously interpolates the training data, and is consistent for a broad class of data distributions. To this end, we define the manifold-Hilbert kernel for data distributed on a Riemannian manifold. We prove that kernel smoothing regression using the manifold-Hilbert kernel is weakly consistent in the setting of Devroye et al. 1998. For the sphere, we show that the manifold-Hilbert kernel can be realized as a weighted random partition kernel, which arises as an infinite ensemble of partition-based classifiers.
count=1
* Debiased Causal Tree: Heterogeneous Treatment Effects Estimation with Unmeasured Confounding
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/2526d439030a3af95fc647dd20e9d049-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/2526d439030a3af95fc647dd20e9d049-Paper-Conference.pdf)]
    * Title: Debiased Causal Tree: Heterogeneous Treatment Effects Estimation with Unmeasured Confounding
    * Year: `2022`
    * Authors: Caizhi Tang, Huiyuan Wang, Xinyu Li, Qing Cui, Ya-Lin Zhang, Feng Zhu, Longfei Li, Jun Zhou, Linbo Jiang
    * Abstract: Unmeasured confounding poses a significant threat to the validity of causal inference. Despite that various ad hoc methods are developed to remove confounding effects, they are subject to certain fairly strong assumptions. In this work, we consider the estimation of conditional causal effects in the presence of unmeasured confounding using observational data and historical controls. Under an interpretable transportability condition, we prove the partial identifiability of conditional average treatment effect on the treated group (CATT). For tree-based models, a new notion, \emph{confounding entropy}, is proposed to measure the discrepancy introduced by unobserved confounders between the conditional outcome distribution of the treated and control groups. The confounding entropy generalizes conventional confounding bias, and can be estimated effectively using historical controls. We develop a new method, debiased causal tree, whose splitting rule is to minimize the empirical risk regularized by the confounding entropy. Notably, our method integrates current observational data (for empirical risk) and their historical controls (for confounding entropy) harmoniously. We highlight that, debiased causal tree can not only estimate CATT well in the presence of unmeasured confounding, but also is a robust estimator of conditional average treatment effect (CATE) against the imbalance of the treated and control populations when all confounders are observed. An extension of combining multiple debiased causal trees to further reduce biases by gradient boosting is considered. The computational feasibility and statistical power of our method are evidenced by simulations and a study of a credit card balance dataset.
count=1
* FairVFL: A Fair Vertical Federated Learning Framework with Contrastive Adversarial Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/333a7697dbb67f09249337f81c27d749-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/333a7697dbb67f09249337f81c27d749-Paper-Conference.pdf)]
    * Title: FairVFL: A Fair Vertical Federated Learning Framework with Contrastive Adversarial Learning
    * Year: `2022`
    * Authors: Tao Qi, Fangzhao Wu, Chuhan Wu, Lingjuan Lyu, Tong Xu, Hao Liao, Zhongliang Yang, Yongfeng Huang, Xing Xie
    * Abstract: Vertical federated learning (VFL) is a privacy-preserving machine learning paradigm that can learn models from features distributed on different platforms in a privacy-preserving way. Since in real-world applications the data may contain bias on fairness-sensitive features (e.g., gender), VFL models may inherit bias from training data and become unfair for some user groups. However, existing fair machine learning methods usually rely on the centralized storage of fairness-sensitive features to achieve model fairness, which are usually inapplicable in federated scenarios. In this paper, we propose a fair vertical federated learning framework (FairVFL), which can improve the fairness of VFL models. The core idea of FairVFL is to learn unified and fair representations of samples based on the decentralized feature fields in a privacy-preserving way. Specifically, each platform with fairness-insensitive features first learns local data representations from local features. Then, these local representations are uploaded to a server and aggregated into a unified representation for the target task. In order to learn a fair unified representation, we send it to each platform storing fairness-sensitive features and apply adversarial learning to remove bias from the unified representation inherited from the biased data. Moreover, for protecting user privacy, we further propose a contrastive adversarial learning method to remove private information from the unified representation in server before sending it to the platforms keeping fairness-sensitive features. Experiments on three real-world datasets validate that our method can effectively improve model fairness with user privacy well-protected.
count=1
* A Consistent and Differentiable Lp Canonical Calibration Error Estimator
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/33d6e648ee4fb24acec3a4bbcd4f001e-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/33d6e648ee4fb24acec3a4bbcd4f001e-Paper-Conference.pdf)]
    * Title: A Consistent and Differentiable Lp Canonical Calibration Error Estimator
    * Year: `2022`
    * Authors: Teodora Popordanoska, Raphael Sayer, Matthew Blaschko
    * Abstract: Calibrated probabilistic classifiers are models whose predicted probabilities can directly be interpreted as uncertainty estimates. It has been shown recently that deep neural networks are poorly calibrated and tend to output overconfident predictions. As a remedy, we propose a low-bias, trainable calibration error estimator based on Dirichlet kernel density estimates, which asymptotically converges to the true $L_p$ calibration error. This novel estimator enables us to tackle the strongest notion of multiclass calibration, called canonical (or distribution) calibration, while other common calibration methods are tractable only for top-label and marginal calibration. The computational complexity of our estimator is $\mathcal{O}(n^2)$, the convergence rate is $\mathcal{O}(n^{-1/2})$, and it is unbiased up to $\mathcal{O}(n^{-2})$, achieved by a geometric series debiasing scheme. In practice, this means that the estimator can be applied to small subsets of data, enabling efficient estimation and mini-batch updates. The proposed method has a natural choice of kernel, and can be used to generate consistent estimates of other quantities based on conditional expectation, such as the sharpness of a probabilistic classifier. Empirical results validate the correctness of our estimator, and demonstrate its utility in canonical calibration error estimation and calibration error regularized risk minimization.
count=1
* Better Uncertainty Calibration via Proper Scores for Classification and Beyond
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/3915a87ddac8e8c2f23dbabbcee6eec9-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/3915a87ddac8e8c2f23dbabbcee6eec9-Paper-Conference.pdf)]
    * Title: Better Uncertainty Calibration via Proper Scores for Classification and Beyond
    * Year: `2022`
    * Authors: Sebastian Gruber, Florian Buettner
    * Abstract: With model trustworthiness being crucial for sensitive real-world applications, practitioners are putting more and more focus on improving the uncertainty calibration of deep neural networks.Calibration errors are designed to quantify the reliability of probabilistic predictions but their estimators are usually biased and inconsistent.In this work, we introduce the framework of \textit{proper calibration errors}, which relates every calibration error to a proper score and provides a respective upper bound with optimal estimation properties.This relationship can be used to reliably quantify the model calibration improvement.We theoretically and empirically demonstrate the shortcomings of commonly used estimators compared to our approach.Due to the wide applicability of proper scores, this gives a natural extension of recalibration beyond classification.
count=1
* Simulation-guided Beam Search for Neural Combinatorial Optimization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/39b9b60f0d149eabd1fff2d7c7d5afc4-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/39b9b60f0d149eabd1fff2d7c7d5afc4-Paper-Conference.pdf)]
    * Title: Simulation-guided Beam Search for Neural Combinatorial Optimization
    * Year: `2022`
    * Authors: Jinho Choo, Yeong-Dae Kwon, Jihoon Kim, Jeongwoo Jae, André Hottung, Kevin Tierney, Youngjune Gwon
    * Abstract: Neural approaches for combinatorial optimization (CO) equip a learning mechanism to discover powerful heuristics for solving complex real-world problems. While neural approaches capable of high-quality solutions in a single shot are emerging, state-of-the-art approaches are often unable to take full advantage of the solving time available to them. In contrast, hand-crafted heuristics perform highly effective search well and exploit the computation time given to them, but contain heuristics that are difficult to adapt to a dataset being solved. With the goal of providing a powerful search procedure to neural CO approaches, we propose simulation-guided beam search (SGBS), which examines candidate solutions within a fixed-width tree search that both a neural net-learned policy and a simulation (rollout) identify as promising. We further hybridize SGBS with efficient active search (EAS), where SGBS enhances the quality of solutions backpropagated in EAS, and EAS improves the quality of the policy used in SGBS. We evaluate our methods on well-known CO benchmarks and show that SGBS significantly improves the quality of the solutions found under reasonable runtime assumptions.
count=1
* End-to-end Symbolic Regression with Transformers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/42eb37cdbefd7abae0835f4b67548c39-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/42eb37cdbefd7abae0835f4b67548c39-Paper-Conference.pdf)]
    * Title: End-to-end Symbolic Regression with Transformers
    * Year: `2022`
    * Authors: Pierre-alexandre Kamienny, Stéphane d'Ascoli, Guillaume Lample, Francois Charton
    * Abstract: Symbolic regression, the task of predicting the mathematical expression of a function from the observation of its values, is a difficult task which usually involves a two-step procedure: predicting the "skeleton" of the expression up to the choice of numerical constants, then fitting the constants by optimizing a non-convex loss function. The dominant approach is genetic programming, which evolves candidates by iterating this subroutine a large number of times. Neural networks have recently been tasked to predict the correct skeleton in a single try, but remain much less powerful.In this paper, we challenge this two-step procedure, and task a Transformer to directly predict the full mathematical expression, constants included. One can subsequently refine the predicted constants by feeding them to the non-convex optimizer as an informed initialization. We present ablations to show that this end-to-end approach yields better results, sometimes even without the refinement step. We evaluate our model on problems from the SRBench benchmark and show that our model approaches the performance of state-of-the-art genetic programming with several orders of magnitude faster inference.
count=1
* EcoFormer: Energy-Saving Attention with Linear Complexity
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/4310ae054ce265e56d8ea897971149b5-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/4310ae054ce265e56d8ea897971149b5-Paper-Conference.pdf)]
    * Title: EcoFormer: Energy-Saving Attention with Linear Complexity
    * Year: `2022`
    * Authors: Jing Liu, Zizheng Pan, Haoyu He, Jianfei Cai, Bohan Zhuang
    * Abstract: Transformer is a transformative framework for deep learning which models sequential data and has achieved remarkable performance on a wide range of tasks, but with high computational and energy cost. To improve its efficiency, a popular choice is to compress the models via binarization which constrains the floating-point values into binary ones to save resource consumption owing to cheap bitwise operations significantly. However, existing binarization methods only aim at minimizing the information loss for the input distribution statistically, while ignoring the pairwise similarity modeling at the core of the attention mechanism. To this end, we propose a new binarization paradigm customized to high-dimensional softmax attention via kernelized hashing, called EcoFormer, to map the original queries and keys into low-dimensional binary codes in Hamming space. The kernelized hash functions are learned to match the ground-truth similarity relations extracted from the attention map in a self-supervised way. Based on the equivalence between the inner product of binary codes and the Hamming distance as well as the associative property of matrix multiplication, we can approximate the attention in linear complexity by expressing it as a dot-product of binary codes. Moreover, the compact binary representations of queries and keys in EcoFormer enable us to replace most of the expensive multiply-accumulate operations in attention with simple accumulations to save considerable on-chip energy footprint on edge devices. Extensive experiments on both vision and language tasks show that EcoFormer consistently achieves comparable performance with standard attentions while consuming much fewer resources. For example, based on PVTv2-B0 and ImageNet-1K, EcoFormer achieves a 73% reduction in on-chip energy footprint with only a slight performance drop of 0.33% compared to the standard attention. Code is available at https://github.com/ziplab/EcoFormer.
count=1
* Learning Tractable Probabilistic Models from Inconsistent Local Estimates
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/437d9bde2999f6e3e854e09f250261a5-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/437d9bde2999f6e3e854e09f250261a5-Paper-Conference.pdf)]
    * Title: Learning Tractable Probabilistic Models from Inconsistent Local Estimates
    * Year: `2022`
    * Authors: Shasha Jin, Vasundhara Komaragiri, Tahrima Rahman, Vibhav Gogate
    * Abstract: Tractable probabilistic models such as cutset networks which admit exact linear time posterior marginal inference are often preferred in practice over intractable models such as Bayesian and Markov networks. This is because although tractable models, when learned from data, are slightly inferior to the intractable ones in terms of goodness-of-fit measures such as log-likelihood, they do not use approximate inference at prediction time and as a result exhibit superior predictive performance. In this paper, we consider the problem of improving a tractable model using a large number of local probability estimates, each defined over a small subset of variables that are either available from experts or via an external process. Given a model learned from fully-observed, but small amount of possibly noisy data, the key idea in our approach is to update the parameters of the model via a gradient descent procedure that seeks to minimize a convex combination of two quantities: one that enforces closeness via KL divergence to the local estimates and another that enforces closeness to the given model. We show that although the gradients are NP-hard to compute on arbitrary graphical models, they can be efficiently computed over tractable models. We show via experiments that our approach yields tractable models that are significantly superior to the ones learned from small amount of possibly noisy data, even when the local estimates are inconsistent.
count=1
* Split-kl and PAC-Bayes-split-kl Inequalities for Ternary Random Variables
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/49ffa271264808cf500ea528ed8ec9b3-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/49ffa271264808cf500ea528ed8ec9b3-Paper-Conference.pdf)]
    * Title: Split-kl and PAC-Bayes-split-kl Inequalities for Ternary Random Variables
    * Year: `2022`
    * Authors: Yi-Shan Wu, Yevgeny Seldin
    * Abstract: We present a new concentration of measure inequality for sums of independent bounded random variables, which we name a split-kl inequality. The inequality combines the combinatorial power of the kl inequality with ability to exploit low variance. While for Bernoulli random variables the kl inequality is tighter than the Empirical Bernstein, for random variables taking values inside a bounded interval and having low variance the Empirical Bernstein inequality is tighter than the kl. The proposed split-kl inequality yields the best of both worlds. We discuss an application of the split-kl inequality to bounding excess losses. We also derive a PAC-Bayes-split-kl inequality and use a synthetic example and several UCI datasets to compare it with the PAC-Bayes-kl, PAC-Bayes Empirical Bernstein, PAC-Bayes Unexpected Bernstein, and PAC-Bayes Empirical Bennett inequalities.
count=1
* Learning Long-Term Crop Management Strategies with CyclesGym
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/4a22ceafe2dd6e0d32df1f7c0a69ab68-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/4a22ceafe2dd6e0d32df1f7c0a69ab68-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Learning Long-Term Crop Management Strategies with CyclesGym
    * Year: `2022`
    * Authors: Matteo Turchetta, Luca Corinzia, Scott Sussex, Amanda Burton, Juan Herrera, Ioannis Athanasiadis, Joachim M Buhmann, Andreas Krause
    * Abstract: To improve the sustainability and resilience of modern food systems, designing improved crop management strategies is crucial. The increasing abundance of data on agricultural systems suggests that future strategies could benefit from adapting to environmental conditions, but how to design these adaptive policies poses a new frontier. A natural technique for learning policies in these kinds of sequential decision-making problems is reinforcement learning (RL). To obtain the large number of samples required to learn effective RL policies, existing work has used mechanistic crop growth models (CGMs) as simulators. These solutions focus on single-year, single-crop simulations for learning strategies for a single agricultural management practice. However, to learn sustainable long-term policies we must be able to train in multi-year environments, with multiple crops, and consider a wider array of management techniques. We introduce CYCLESGYM, an RL environment based on the multi-year, multi-crop CGM Cycles. CYCLESGYM allows for long-term planning in agroecosystems, provides modular state space and reward constructors and weather generators, and allows for complex actions. For RL researchers, this is a novel benchmark to investigate issues arising in real-world applications. For agronomists, we demonstrate the potential of RL as a powerful optimization tool for agricultural systems management in multi-year case studies on nitrogen (N) fertilization and crop planning scenarios.
count=1
* Benchmarking Heterogeneous Treatment Effect Models through the Lens of Interpretability
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/4fd7b4ed13f78b9ba7afcd9d01615896-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/4fd7b4ed13f78b9ba7afcd9d01615896-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: Benchmarking Heterogeneous Treatment Effect Models through the Lens of Interpretability
    * Year: `2022`
    * Authors: Jonathan Crabbé, Alicia Curth, Ioana Bica, Mihaela van der Schaar
    * Abstract: Estimating personalized effects of treatments is a complex, yet pervasive problem. To tackle it, recent developments in the machine learning (ML) literature on heterogeneous treatment effect estimation gave rise to many sophisticated, but opaque, tools: due to their flexibility, modularity and ability to learn constrained representations, neural networks in particular have become central to this literature. Unfortunately, the assets of such black boxes come at a cost: models typically involve countless nontrivial operations, making it difficult to understand what they have learned. Yet, understanding these models can be crucial -- in a medical context, for example, discovered knowledge on treatment effect heterogeneity could inform treatment prescription in clinical practice. In this work, we therefore use post-hoc feature importance methods to identify features that influence the model's predictions. This allows us to evaluate treatment effect estimators along a new and important dimension that has been overlooked in previous work: We construct a benchmarking environment to empirically investigate the ability of personalized treatment effect models to identify predictive covariates -- covariates that determine differential responses to treatment. Our benchmarking environment then enables us to provide new insight into the strengths and weaknesses of different types of treatment effects models as we modulate different challenges specific to treatment effect estimation -- e.g. the ratio of prognostic to predictive information, the possible nonlinearity of potential outcomes and the presence and type of confounding.
count=1
* Domain Generalization without Excess Empirical Risk
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/57568e093cbe0a222de0334b36e83cf5-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/57568e093cbe0a222de0334b36e83cf5-Paper-Conference.pdf)]
    * Title: Domain Generalization without Excess Empirical Risk
    * Year: `2022`
    * Authors: Ozan Sener, Vladlen Koltun
    * Abstract: Given data from diverse sets of distinct distributions, domain generalization aims to learn models that generalize to unseen distributions. A common approach is designing a data-driven surrogate penalty to capture generalization and minimize the empirical risk jointly with the penalty. We argue that a significant failure mode of this recipe is an excess risk due to an erroneous penalty or hardness in joint optimization. We present an approach that eliminates this problem. Instead of jointly minimizing empirical risk with the penalty, we minimize the penalty under the constraint of optimality of the empirical risk. This change guarantees that the domain generalization penalty cannot impair optimization of the empirical risk, \ie, in-distribution performance. To solve the proposed optimization problem, we demonstrate an exciting connection to rate-distortion theory and utilize its tools to design an efficient method. Our approach can be applied to any penalty-based domain generalization method, and we demonstrate its effectiveness by applying it to three examplar methods from the literature, showing significant improvements.
count=1
* Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Query Attacks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/5fa29a2f163ce2020769eca8956e2d77-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/5fa29a2f163ce2020769eca8956e2d77-Paper-Conference.pdf)]
    * Title: Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Query Attacks
    * Year: `2022`
    * Authors: Sizhe Chen, Zhehao Huang, Qinghua Tao, Yingwen Wu, Cihang Xie, Xiaolin Huang
    * Abstract: The score-based query attacks (SQAs) pose practical threats to deep neural networks by crafting adversarial perturbations within dozens of queries, only using the model's output scores. Nonetheless, we note that if the loss trend of the outputs is slightly perturbed, SQAs could be easily misled and thereby become much less effective. Following this idea, we propose a novel defense, namely Adversarial Attack on Attackers (AAA), to confound SQAs towards incorrect attack directions by slightly modifying the output logits. In this way, (1) SQAs are prevented regardless of the model's worst-case robustness; (2) the original model predictions are hardly changed, i.e., no degradation on clean accuracy; (3) the calibration of confidence scores can be improved simultaneously. Extensive experiments are provided to verify the above advantages. For example, by setting $\ell_\infty=8/255$ on CIFAR-10, our proposed AAA helps WideResNet-28 secure 80.59% accuracy under Square attack (2500 queries), while the best prior defense (i.e., adversarial training) only attains 67.44%. Since AAA attacks SQA's general greedy strategy, such advantages of AAA over 8 defenses can be consistently observed on 8 CIFAR-10/ImageNet models under 6 SQAs, using different attack targets, bounds, norms, losses, and strategies. Moreover, AAA calibrates better without hurting the accuracy. Our code is available at https://github.com/Sizhe-Chen/AAA.
count=1
* Private and Communication-Efficient Algorithms for Entropy Estimation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/62e5721247075dd097023d077d8e22f7-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/62e5721247075dd097023d077d8e22f7-Paper-Conference.pdf)]
    * Title: Private and Communication-Efficient Algorithms for Entropy Estimation
    * Year: `2022`
    * Authors: Gecia Bravo-Hermsdorff, Róbert Busa-Fekete, Mohammad Ghavamzadeh, Andres Munoz Medina, Umar Syed
    * Abstract: Modern statistical estimation is often performed in a distributed setting where each sample belongs to single user who shares their data with a central server. Users are typically concerned with preserving the privacy of their sample, and also with minimizing the amount of data they must transmit to the server. We give improved private and communication-efficient algorithms for estimating several popular measures of the entropy of a distribution. All of our algorithms have constant communication cost and satisfy local differential privacy. For a joint distribution on many variables whose conditional independence graph is a tree, we describe algorithms for estimating Shannon entropy that require a number of samples that is linear in the number of variables, compared to the quadratic sample complexity of prior work. We also describe an algorithm for estimating Gini entropy whose sample complexity has no dependence on the support size of the distribution and can be implemented using a single round of concurrent communication between the users and the server, while the previously best-known algorithm has high communication cost and requires the server to facilitate interaction between the users. Finally, we describe an algorithm for estimating collision entropy that matches the space and sample complexity of the best known algorithm but generalizes it to the private and communication-efficient setting.
count=1
* Efficient Meta Reinforcement Learning for Preference-based Fast Adaptation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/63b2b056f48653b7cff0d8d233c96a4d-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/63b2b056f48653b7cff0d8d233c96a4d-Paper-Conference.pdf)]
    * Title: Efficient Meta Reinforcement Learning for Preference-based Fast Adaptation
    * Year: `2022`
    * Authors: Zhizhou Ren, Anji Liu, Yitao Liang, Jian Peng, Jianzhu Ma
    * Abstract: Learning new task-specific skills from a few trials is a fundamental challenge for artificial intelligence. Meta reinforcement learning (meta-RL) tackles this problem by learning transferable policies that support few-shot adaptation to unseen tasks. Despite recent advances in meta-RL, most existing methods require the access to the environmental reward function of new tasks to infer the task objective, which is not realistic in many practical applications. To bridge this gap, we study the problem of few-shot adaptation in the context of human-in-the-loop reinforcement learning. We develop a meta-RL algorithm that enables fast policy adaptation with preference-based feedback. The agent can adapt to new tasks by querying human's preference between behavior trajectories instead of using per-step numeric rewards. By extending techniques from information theory, our approach can design query sequences to maximize the information gain from human interactions while tolerating the inherent error of non-expert human oracle. In experiments, we extensively evaluate our method, Adaptation with Noisy OracLE (ANOLE), on a variety of meta-RL benchmark tasks and demonstrate substantial improvement over baseline algorithms in terms of both feedback efficiency and error tolerance.
count=1
* VeriDark: A Large-Scale Benchmark for Authorship Verification on the Dark Web
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/64008fa30cba9b4d1ab1bd3bd3d57d61-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/64008fa30cba9b4d1ab1bd3bd3d57d61-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: VeriDark: A Large-Scale Benchmark for Authorship Verification on the Dark Web
    * Year: `2022`
    * Authors: Andrei Manolache, Florin Brad, Antonio Barbalau, Radu Tudor Ionescu, Marius Popescu
    * Abstract: The Dark Web represents a hotbed for illicit activity, where users communicate on different market forums in order to exchange goods and services. Law enforcement agencies benefit from forensic tools that perform authorship analysis, in order to identify and profile users based on their textual content. However, authorship analysis has been traditionally studied using corpora featuring literary texts such as fragments from novels or fan fiction, which may not be suitable in a cybercrime context. Moreover, the few works that employ authorship analysis tools for cybercrime prevention usually employ ad-hoc experimental setups and datasets. To address these issues, we release VeriDark: a benchmark comprised of three large scale authorship verification datasets and one authorship identification dataset obtained from user activity from either Dark Web related Reddit communities or popular illicit Dark Web market forums. We evaluate competitive NLP baselines on the three datasets and perform an analysis of the predictions to better understand the limitations of such approaches. We make the datasets and baselines publicly available at https://github.com/bit-ml/VeriDark .
count=1
* Learning Enhanced Representation for Tabular Data via Neighborhood Propagation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/67e79c8e9b11f068a7cafd79505175c0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/67e79c8e9b11f068a7cafd79505175c0-Paper-Conference.pdf)]
    * Title: Learning Enhanced Representation for Tabular Data via Neighborhood Propagation
    * Year: `2022`
    * Authors: Kounianhua Du, Weinan Zhang, Ruiwen Zhou, Yangkun Wang, Xilong Zhao, Jiarui Jin, Quan Gan, Zheng Zhang, David P Wipf
    * Abstract: Prediction over tabular data is an essential and fundamental problem in many important downstream tasks. However, existing methods either take a data instance of the table independently as input or do not fully utilize the multi-row features and labels to directly change and enhance the target data representations. In this paper, we propose to 1) construct a hypergraph from relevant data instance retrieval to model the cross-row and cross-column patterns of those instances, and 2) perform message Propagation to Enhance the target data instance representation for Tabular prediction tasks. Specifically, our specially-designed message propagation step benefits from 1) the fusion of label and features during propagation, and 2) locality-aware multiplicative high-order interaction between features. Experiments on two important tabular prediction tasks validate the superiority of the proposed PET model against other baselines. Additionally, we demonstrate the effectiveness of the model components and the feature enhancement ability of PET via various ablation studies and visualizations. The code is available at https://github.com/KounianhuaDu/PET.
count=1
* Wasserstein Logistic Regression with Mixed Features
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/6a13cffb5ec4128324f64a186785215b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/6a13cffb5ec4128324f64a186785215b-Paper-Conference.pdf)]
    * Title: Wasserstein Logistic Regression with Mixed Features
    * Year: `2022`
    * Authors: Aras Selvi, Mohammad Reza Belbasi, Martin Haugh, Wolfram Wiesemann
    * Abstract: Recent work has leveraged the popular distributionally robust optimization paradigm to combat overfitting in classical logistic regression. While the resulting classification scheme displays a promising performance in numerical experiments, it is inherently limited to numerical features. In this paper, we show that distributionally robust logistic regression with mixed (\emph{i.e.}, numerical and categorical) features, despite amounting to an optimization problem of exponential size, admits a polynomial-time solution scheme. We subsequently develop a practically efficient cutting plane approach that solves the problem as a sequence of polynomial-time solvable exponential conic programs. Our method retains many of the desirable theoretical features of previous works, but---in contrast to the literature---it does not admit an equivalent representation as a regularized logistic regression, that is, it represents a genuinely novel variant of the logistic regression problem. We show that our method outperforms both the unregularized and the regularized logistic regression on categorical as well as mixed-feature benchmark instances.
count=1
* Learning to Generate Inversion-Resistant Model Explanations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/70d638f3177d2f0bbdd9f400b43f0683-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/70d638f3177d2f0bbdd9f400b43f0683-Paper-Conference.pdf)]
    * Title: Learning to Generate Inversion-Resistant Model Explanations
    * Year: `2022`
    * Authors: Hoyong Jeong, Suyoung Lee, Sung Ju Hwang, Sooel Son
    * Abstract: The wide adoption of deep neural networks (DNNs) in mission-critical applications has spurred the need for interpretable models that provide explanations of the model's decisions. Unfortunately, previous studies have demonstrated that model explanations facilitate information leakage, rendering DNN models vulnerable to model inversion attacks. These attacks enable the adversary to reconstruct original images based on model explanations, thus leaking privacy-sensitive features. To this end, we present Generative Noise Injector for Model Explanations (GNIME), a novel defense framework that perturbs model explanations to minimize the risk of model inversion attacks while preserving the interpretabilities of the generated explanations. Specifically, we formulate the defense training as a two-player minimax game between the inversion attack network on the one hand, which aims to invert model explanations, and the noise generator network on the other, which aims to inject perturbations to tamper with model inversion attacks. We demonstrate that GNIME significantly decreases the information leakage in model explanations, decreasing transferable classification accuracy in facial recognition models by up to 84.8% while preserving the original functionality of model explanations.
count=1
* Modeling the Machine Learning Multiverse
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/750337e1301941f81ae31a90e0a1c181-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/750337e1301941f81ae31a90e0a1c181-Paper-Conference.pdf)]
    * Title: Modeling the Machine Learning Multiverse
    * Year: `2022`
    * Authors: Samuel J. Bell, Onno Kampman, Jesse Dodge, Neil Lawrence
    * Abstract: Amid mounting concern about the reliability and credibility of machine learning research, we present a principled framework for making robust and generalizable claims: the multiverse analysis. Our framework builds upon the multiverse analysis introduced in response to psychology's own reproducibility crisis. To efficiently explore high-dimensional and often continuous ML search spaces, we model the multiverse with a Gaussian Process surrogate and apply Bayesian experimental design. Our framework is designed to facilitate drawing robust scientific conclusions about model performance, and thus our approach focuses on exploration rather than conventional optimization. In the first of two case studies, we investigate disputed claims about the relative merit of adaptive optimizers. Second, we synthesize conflicting research on the effect of learning rate on the large batch training generalization gap. For the machine learning community, the multiverse analysis is a simple and effective technique for identifying robust claims, for increasing transparency, and a step toward improved reproducibility.
count=1
* Unsupervised Learning under Latent Label Shift
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/771e09dd204ea339da0d8114c48afd21-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/771e09dd204ea339da0d8114c48afd21-Paper-Conference.pdf)]
    * Title: Unsupervised Learning under Latent Label Shift
    * Year: `2022`
    * Authors: Manley Roberts, Pranav Mani, Saurabh Garg, Zachary Lipton
    * Abstract: What sorts of structure might enable a learner to discover classes from unlabeled data? Traditional approaches rely on feature-space similarity and heroic assumptions on the data. In this paper, we introduce unsupervised learning under Latent Label Shift (LLS), where the label marginals $p_d(y)$ shift but the class conditionals $p(x|y)$ do not. This work instantiates a new principle for identifying classes: elements that shift together group together. For finite input spaces, we establish an isomorphism between LLS and topic modeling: inputs correspond to words, domains to documents, and labels to topics. Addressing continuous data, we prove that when each label's support contains a separable region, analogous to an anchor word, oracle access to $p(d|x)$ suffices to identify $p_d(y)$ and $p_d(y|x)$ up to permutation. Thus motivated, we introduce a practical algorithm that leverages domain-discriminative models as follows: (i) push examples through domain discriminator $p(d|x)$; (ii) discretize the data by clustering examples in $p(d|x)$ space; (iii) perform non-negative matrix factorization on the discrete data; (iv) combine the recovered $p(y|d)$ with the discriminator outputs $p(d|x)$ to compute $p_d(y|x) \; \forall d$. With semisynthetic experiments, we show that our algorithm can leverage domain information to improve upon competitiveunsupervised classification methods. We reveal a failure mode of standard unsupervised classification methods when data-space similarity does not indicate true groupings, and show empirically that our method better handles this case. Our results establish a deep connection between distribution shift and topic modeling, opening promising lines for future work.
count=1
* ELIAS: End-to-End Learning to Index and Search in Large Output Spaces
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/7d4f98f916494121aca3da02e36a4d18-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/7d4f98f916494121aca3da02e36a4d18-Paper-Conference.pdf)]
    * Title: ELIAS: End-to-End Learning to Index and Search in Large Output Spaces
    * Year: `2022`
    * Authors: Nilesh Gupta, Patrick Chen, Hsiang-Fu Yu, Cho-Jui Hsieh, Inderjit Dhillon
    * Abstract: Extreme multi-label classification (XMC) is a popular framework for solving many real-world problems that require accurate prediction from a very large number of potential output choices. A popular approach for dealing with the large label space is to arrange the labels into a shallow tree-based index and then learn an ML model to efficiently search this index via beam search. Existing methods initialize the tree index by clustering the label space into a few mutually exclusive clusters based on pre-defined features and keep it fixed throughout the training procedure. This approach results in a sub-optimal indexing structure over the label space and limits the search performance to the quality of choices made during the initialization of the index. In this paper, we propose a novel method ELIAS which relaxes the tree-based index to a specialized weighted graph-based index which is learned end-to-end with the final task objective. More specifically, ELIAS models the discrete cluster-to-label assignments in the existing tree-based index as soft learnable parameters that are learned jointly with the rest of the ML model. ELIAS achieves state-of-the-art performance on several large-scale extreme classification benchmarks with millions of labels. In particular, ELIAS can be up to 2.5% better at precision@$1$ and up to 4% better at recall@$100$ than existing XMC methods. A PyTorch implementation of ELIAS along with other resources is available at https://github.com/nilesh2797/ELIAS.
count=1
* Continuous MDP Homomorphisms and Homomorphic Policy Gradient
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/7f44f98e5e70dea605d0c5baca231c58-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/7f44f98e5e70dea605d0c5baca231c58-Paper-Conference.pdf)]
    * Title: Continuous MDP Homomorphisms and Homomorphic Policy Gradient
    * Year: `2022`
    * Authors: Sahand Rezaei-Shoshtari, Rosie Zhao, Prakash Panangaden, David Meger, Doina Precup
    * Abstract: Abstraction has been widely studied as a way to improve the efficiency and generalization of reinforcement learning algorithms. In this paper, we study abstraction in the continuous-control setting. We extend the definition of MDP homomorphisms to encompass continuous actions in continuous state spaces. We derive a policy gradient theorem on the abstract MDP, which allows us to leverage approximate symmetries of the environment for policy optimization. Based on this theorem, we propose an actor-critic algorithm that is able to learn the policy and the MDP homomorphism map simultaneously, using the lax bisimulation metric. We demonstrate the effectiveness of our method on benchmark tasks in the DeepMind Control Suite. Our method's ability to utilize MDP homomorphisms for representation learning leads to improved performance when learning from pixel observations.
count=1
* A Coupled Design of Exploiting Record Similarity for Practical Vertical Federated Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/84b744165a0597360caad96b06e69313-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/84b744165a0597360caad96b06e69313-Paper-Conference.pdf)]
    * Title: A Coupled Design of Exploiting Record Similarity for Practical Vertical Federated Learning
    * Year: `2022`
    * Authors: Zhaomin Wu, Qinbin Li, Bingsheng He
    * Abstract: Federated learning is a learning paradigm to enable collaborative learning across different parties without revealing raw data. Notably, vertical federated learning (VFL), where parties share the same set of samples but only hold partial features, has a wide range of real-world applications. However, most existing studies in VFL disregard the "record linkage'' process. They design algorithms either assuming the data from different parties can be exactly linked or simply linking each record with its most similar neighboring record. These approaches may fail to capture the key features from other less similar records. Moreover, such improper linkage cannot be corrected by training since existing approaches provide no feedback on linkage during training. In this paper, we design a novel coupled training paradigm, FedSim, that integrates one-to-many linkage into the training process. Besides enabling VFL in many real-world applications with fuzzy identifiers, FedSim also achieves better performance in traditional VFL tasks. Moreover, we theoretically analyze the additional privacy risk incurred by sharing similarities. Our experiments on eight datasets with various similarity metrics show that FedSim outperforms other state-of-the-art baselines. The codes of FedSim are available at https://github.com/Xtra-Computing/FedSim.
count=1
* Hidden Progress in Deep Learning: SGD Learns Parities Near the Computational Limit
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/884baf65392170763b27c914087bde01-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/884baf65392170763b27c914087bde01-Paper-Conference.pdf)]
    * Title: Hidden Progress in Deep Learning: SGD Learns Parities Near the Computational Limit
    * Year: `2022`
    * Authors: Boaz Barak, Benjamin Edelman, Surbhi Goel, Sham Kakade, Eran Malach, Cyril Zhang
    * Abstract: There is mounting evidence of emergent phenomena in the capabilities of deep learning methods as we scale up datasets, model sizes, and training times. While there are some accounts of how these resources modulate statistical capacity, far less is known about their effect on the computational problem of model training. This work conducts such an exploration through the lens of learning a $k$-sparse parity of $n$ bits, a canonical discrete search problem which is statistically easy but computationally hard. Empirically, we find that a variety of neural networks successfully learn sparse parities, with discontinuous phase transitions in the training curves. On small instances, learning abruptly occurs at approximately $n^{O(k)}$ iterations; this nearly matches SQ lower bounds, despite the apparent lack of a sparse prior. Our theoretical analysis shows that these observations are not explained by a Langevin-like mechanism, whereby SGD "stumbles in the dark" until it finds the hidden set of features (a natural algorithm which also runs in $n^{O(k)}$ time). Instead, we show that SGD gradually amplifies the sparse solution via a Fourier gap in the population gradient, making continual progress that is invisible to loss and error metrics.
count=1
* C2FAR: Coarse-to-Fine Autoregressive Networks for Precise Probabilistic Forecasting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/899511e37a8e01e1bd6f6f1d377cc250-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/899511e37a8e01e1bd6f6f1d377cc250-Paper-Conference.pdf)]
    * Title: C2FAR: Coarse-to-Fine Autoregressive Networks for Precise Probabilistic Forecasting
    * Year: `2022`
    * Authors: Shane Bergsma, Tim Zeyl, Javad Rahimipour Anaraki, Lei Guo
    * Abstract: We present coarse-to-fine autoregressive networks (C2FAR), a method for modeling the probability distribution of univariate, numeric random variables. C2FAR generates a hierarchical, coarse-to-fine discretization of a variable autoregressively; progressively finer intervals of support are generated from a sequence of binned distributions, where each distribution is conditioned on previously-generated coarser intervals. Unlike prior (flat) binned distributions, C2FAR can represent values with exponentially higher precision, for only a linear increase in complexity. We use C2FAR for probabilistic forecasting via a recurrent neural network, thus modeling time series autoregressively in both space and time. C2FAR is the first method to simultaneously handle discrete and continuous series of arbitrary scale and distribution shape. This flexibility enables a variety of time series use cases, including anomaly detection, interpolation, and compression. C2FAR achieves improvements over the state-of-the-art on several benchmark forecasting datasets.
count=1
* Training Uncertainty-Aware Classifiers with Conformalized Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/8c96b559340daa7bb29f56ccfbbc9c2f-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/8c96b559340daa7bb29f56ccfbbc9c2f-Paper-Conference.pdf)]
    * Title: Training Uncertainty-Aware Classifiers with Conformalized Deep Learning
    * Year: `2022`
    * Authors: Bat-Sheva Einbinder, Yaniv Romano, Matteo Sesia, Yanfei Zhou
    * Abstract: Deep neural networks are powerful tools to detect hidden patterns in data and leverage them to make predictions, but they are not designed to understand uncertainty and estimate reliable probabilities. In particular, they tend to be overconfident. We begin to address this problem in the context of multi-class classification by developing a novel training algorithm producing models with more dependable uncertainty estimates, without sacrificing predictive power. The idea is to mitigate overconfidence by minimizing a loss function, inspired by advances in conformal inference, that quantifies model uncertainty by carefully leveraging hold-out data. Experiments with synthetic and real data demonstrate this method can lead to smaller conformal prediction sets with higher conditional coverage, after exact calibration with hold-out data, compared to state-of-the-art alternatives.
count=1
* Domain Adaptation under Open Set Label Shift
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/8d5f526a31d3731a30eb58d5874cf5b1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/8d5f526a31d3731a30eb58d5874cf5b1-Paper-Conference.pdf)]
    * Title: Domain Adaptation under Open Set Label Shift
    * Year: `2022`
    * Authors: Saurabh Garg, Sivaraman Balakrishnan, Zachary Lipton
    * Abstract: We introduce the problem of domain adaptation under Open Set Label Shift (OSLS), where the label distribution can change arbitrarily and a new class may arrive during deployment, but the class-conditional distributions $p(x|y)$ are domain-invariant. OSLS subsumes domain adaptation under label shift and Positive-Unlabeled (PU) learning. The learner's goals here are two-fold: (a) estimate the target label distribution, including the novel class; and (b) learn a target classifier. First, we establish the necessary and sufficient for identifying these quantities. Second, motivated by advances in label shift and PU learning, we propose practical methods for both tasks that leverage black-box predictors. Unlike typical Open Set Domain Adaptation (OSDA) problems, which tend to be ill-posed and amenable only to heuristics, OSLS offers a well-posed problem amenable to more principled machinery. Experiments across numerous semi-synthetic benchmarks on vision, language, and medical datasets demonstrate that our methods consistently outperform OSDA baselines, achieving $10$--$25\%$ improvements in target domain accuracy. Finally, we analyze the proposed methods, establishing finite-sample convergence to the true label marginal and convergence to optimal classifier for linear models in a Gaussian setup. Code is available at https://github.com/acmi-lab/Open-Set-Label-Shift.
count=1
* Towards Understanding the Mixture-of-Experts Layer in Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/91edff07232fb1b55a505a9e9f6c0ff3-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/91edff07232fb1b55a505a9e9f6c0ff3-Paper-Conference.pdf)]
    * Title: Towards Understanding the Mixture-of-Experts Layer in Deep Learning
    * Year: `2022`
    * Authors: Zixiang Chen, Yihe Deng, Yue Wu, Quanquan Gu, Yuanzhi Li
    * Abstract: The Mixture-of-Experts (MoE) layer, a sparsely-activated model controlled by a router, has achieved great success in deep learning. However, the understanding of such architecture remains elusive. In this paper, we formally study how the MoE layer improves the performance of neural network learning and why the mixture model will not collapse into a single model. Our empirical results suggest that the cluster structure of the underlying problem and the non-linearity of the expert are pivotal to the success of MoE. This motivates us to consider a challenging classification problem with intrinsic cluster structures. Theoretically, we proved that this problem is hard to solve by a single expert such as a two-layer convolutional neural network (CNN). Yet with the MoE layer with each expert being a two-layer CNN, the problem can be solved successfully. In particular, our theory shows that the router can learn the cluster-center features, which helps divide the input complex problem into simpler classification sub-problems that individual experts can conquer. To our knowledge, this is the first theoretical result toward formally understanding the mechanism of the MoE layer for deep learning.
count=1
* Efficient and Stable Fully Dynamic Facility Location
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/943d6dca1884955e645d8997ae2fa938-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/943d6dca1884955e645d8997ae2fa938-Paper-Conference.pdf)]
    * Title: Efficient and Stable Fully Dynamic Facility Location
    * Year: `2022`
    * Authors: Sayan Bhattacharya, Silvio Lattanzi, Nikos Parotsidis
    * Abstract: We consider the classic facility location problem in fully dynamic data streams, where elements can be both inserted and deleted. In this problem, one is interested in maintaining a stable and high quality solution throughout the data stream while using only little time per update (insertion or deletion). We study the problem and provide the first algorithm that at the same time maintains a constant approximation and incurs polylogarithmic amortized recourse per update. We complement our theoretical results with an experimental analysis showing the practical efficiency of our method.
count=1
* Data-IQ: Characterizing subgroups with heterogeneous outcomes in tabular data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/95b6e2ff961580e03c0a662a63a71812-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/95b6e2ff961580e03c0a662a63a71812-Paper-Conference.pdf)]
    * Title: Data-IQ: Characterizing subgroups with heterogeneous outcomes in tabular data
    * Year: `2022`
    * Authors: Nabeel Seedat, Jonathan Crabbé, Ioana Bica, Mihaela van der Schaar
    * Abstract: High model performance, on average, can hide that models may systematically underperform on subgroups of the data. We consider the tabular setting, which surfaces the unique issue of outcome heterogeneity - this is prevalent in areas such as healthcare, where patients with similar features can have different outcomes, thus making reliable predictions challenging. To tackle this, we propose Data-IQ, a framework to systematically stratify examples into subgroups with respect to their outcomes. We do this by analyzing the behavior of individual examples during training, based on their predictive confidence and, importantly, the aleatoric (data) uncertainty. Capturing the aleatoric uncertainty permits a principled characterization and then subsequent stratification of data examples into three distinct subgroups (Easy, Ambiguous, Hard). We experimentally demonstrate the benefits of Data-IQ on four real-world medical datasets. We show that Data-IQ's characterization of examples is most robust to variation across similarly performant (yet different models), compared to baselines. Since Data-IQ can be used with any ML model (including neural networks, gradient boosting etc.), this property ensures consistency of data characterization, while allowing flexible model selection. Taking this a step further, we demonstrate that the subgroups enable us to construct new approaches to both feature acquisition and dataset selection. Furthermore, we highlight how the subgroups can inform reliable model usage, noting the significant impact of the Ambiguous subgroup on model generalization.
count=1
* Active Learning Polynomial Threshold Functions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/99015a2974664cb9db56844d0f27b5a9-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/99015a2974664cb9db56844d0f27b5a9-Paper-Conference.pdf)]
    * Title: Active Learning Polynomial Threshold Functions
    * Year: `2022`
    * Authors: Omri Ben-Eliezer, Max Hopkins, Chutong Yang, Hantao Yu
    * Abstract: We initiate the study of active learning polynomial threshold functions (PTFs). While traditional lower bounds imply that even univariate quadratics cannot be non-trivially actively learned, we show that allowing the learner basic access to the derivatives of the underlying classifier circumvents this issue and leads to a computationally efficient algorithm for active learning degree-$d$ univariate PTFs in $\tilde{O}(d^3\log(1/\varepsilon\delta))$ queries. We extend this result to the batch active setting, providing a smooth transition between query complexity and rounds of adaptivity, and also provide near-optimal algorithms for active learning PTFs in several average case settings. Finally, we prove that access to derivatives is insufficient for active learning multivariate PTFs, even those of just two variables.
count=1
* Benign Overfitting in Two-layer Convolutional Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/a12c999be280372b157294e72a4bbc8b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/a12c999be280372b157294e72a4bbc8b-Paper-Conference.pdf)]
    * Title: Benign Overfitting in Two-layer Convolutional Neural Networks
    * Year: `2022`
    * Authors: Yuan Cao, Zixiang Chen, Misha Belkin, Quanquan Gu
    * Abstract: Modern neural networks often have great expressive power and can be trained to overfit the training data, while still achieving a good test performance. This phenomenon is referred to as “benign overfitting”. Recently, there emerges a line of works studying “benign overfitting” from the theoretical perspective. However, they are limited to linear models or kernel/random feature models, and there is still a lack of theoretical understanding about when and how benign overfitting occurs in neural networks. In this paper, we study the benign overfitting phenomenon in training a two-layer convolutional neural network (CNN). We show that when the signal-to-noise ratio satisfies a certain condition, a two-layer CNN trained by gradient descent can achieve arbitrarily small training and test loss. On the other hand, when this condition does not hold, overfitting becomes harmful and the obtained CNN can only achieve a constant level test loss. These together demonstrate a sharp phase transition between benign overfitting and harmful overfitting, driven by the signal-to-noise ratio. To the best of our knowledge, this is the first work that precisely characterizes the conditions under which benign overfitting can occur in training convolutional neural networks.
count=1
* Branch &amp; Learn for Recursively and Iteratively Solvable Problems in Predict+Optimize
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/a59a11e8580a7ac850cb792f6179c7a0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/a59a11e8580a7ac850cb792f6179c7a0-Paper-Conference.pdf)]
    * Title: Branch &amp; Learn for Recursively and Iteratively Solvable Problems in Predict+Optimize
    * Year: `2022`
    * Authors: Xinyi Hu, Jasper Lee, Jimmy Lee, Allen Z. Zhong
    * Abstract: This paper proposes Branch & Learn, a framework for Predict+Optimize to tackle optimization problems containing parameters that are unknown at the time of solving. Given an optimization problem solvable by a recursive algorithm satisfying simple conditions, we show how a corresponding learning algorithm can be constructed directly and methodically from the recursive algorithm. Our framework applies also to iterative algorithms by viewing them as a degenerate form of recursion. Extensive experimentation shows better performance for our proposal over classical and state of the art approaches.
count=1
* Toward Understanding Privileged Features Distillation in Learning-to-Rank
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/aa31dc84098add7dd2ffdd20646f2043-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/aa31dc84098add7dd2ffdd20646f2043-Paper-Conference.pdf)]
    * Title: Toward Understanding Privileged Features Distillation in Learning-to-Rank
    * Year: `2022`
    * Authors: Shuo Yang, Sujay Sanghavi, Holakou Rahmanian, Jan Bakus, Vishwanathan S. V. N.
    * Abstract: In learning-to-rank problems, a \textit{privileged feature} is one that is available during model training, but not available at test time. Such features naturally arise in merchandised recommendation systems; for instance, "user clicked this item" as a feature is predictive of "user purchased this item" in the offline data, but is clearly not available during online serving. Another source of privileged features is those that are too expensive to compute online but feasible to be added offline. \textit{Privileged features distillation} (PFD) refers to a natural idea: train a "teacher" model using all features (including privileged ones) and then use it to train a "student" model that does not use the privileged features. In this paper, we first study PFD empirically on three public ranking datasets and an industrial-scale ranking problem derived from Amazon's logs. We show that PFD outperforms several baselines (no-distillation, pretraining-finetuning, self-distillation, and generalized distillation) on all these datasets. Next, we analyze why and when PFD performs well via both empirical ablation studies and theoretical analysis for linear models. Both investigations uncover an interesting non-monotone behavior: as the predictive power of a privileged feature increases, the performance of the resulting student model initially increases but then decreases. We show the reason for the later decreasing performance is that a very predictive privileged teacher produces predictions with high variance, which lead to high variance student estimates and inferior testing performance.
count=1
* Robust Calibration with Multi-domain Temperature Scaling
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/b054fadf1ccd80b37d465f6082629934-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/b054fadf1ccd80b37d465f6082629934-Paper-Conference.pdf)]
    * Title: Robust Calibration with Multi-domain Temperature Scaling
    * Year: `2022`
    * Authors: Yaodong Yu, Stephen Bates, Yi Ma, Michael Jordan
    * Abstract: Uncertainty quantification is essential for the reliable deployment of machine learning models to high-stakes application domains. Uncertainty quantification is all the more challenging when training distribution and test distribution are different, even if the distribution shifts are mild. Despite the ubiquity of distribution shifts in real-world applications, existing uncertainty quantification approaches mainly study the in-distribution setting where the train and test distributions are the same. In this paper, we develop a systematic calibration model to handle distribution shifts by leveraging data from multiple domains. Our proposed method---multi-domain temperature scaling---uses the heterogeneity in the domains to improve calibration robustness under distribution shift. Through experiments on three benchmark data sets, we find our proposed method outperforms existing methods as measured on both in-distribution and out-of-distribution test sets.
count=1
* Synthetic Model Combination: An Instance-wise Approach to Unsupervised Ensemble Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/b24426d44bfbef35e24812c996752ceb-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/b24426d44bfbef35e24812c996752ceb-Paper-Conference.pdf)]
    * Title: Synthetic Model Combination: An Instance-wise Approach to Unsupervised Ensemble Learning
    * Year: `2022`
    * Authors: Alex Chan, Mihaela van der Schaar
    * Abstract: Consider making a prediction over new test data without any opportunity to learn from a training set of labelled data - instead given access to a set of expert models and their predictions alongside some limited information about the dataset used to train them. In scenarios from finance to the medical sciences, and even consumer practice, stakeholders have developed models on private data they either cannot, or do not want to, share. Given the value and legislation surrounding personal information, it is not surprising that only the models, and not the data, will be released - the pertinent question becoming: how best to use these models? Previous work has focused on global model selection or ensembling, with the result of a single final model across the feature space. Machine learning models perform notoriously poorly on data outside their training domain however, and so we argue that when ensembling models the weightings for individual instances must reflect their respective domains - in other words models that are more likely to have seen information on that instance should have more attention paid to them. We introduce a method for such an instance-wise ensembling of models, including a novel representation learning step for handling sparse high-dimensional domains. Finally, we demonstrate the need and generalisability of our method on classical machine learning tasks as well as highlighting a real world use case in the pharmacological setting of vancomycin precision dosing.
count=1
* ToDD: Topological Compound Fingerprinting in Computer-Aided Drug Discovery
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/b31f6d65f2584b3c4347148db36fe07f-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/b31f6d65f2584b3c4347148db36fe07f-Paper-Conference.pdf)]
    * Title: ToDD: Topological Compound Fingerprinting in Computer-Aided Drug Discovery
    * Year: `2022`
    * Authors: Andaç Demir, Baris Coskunuzer, Yulia Gel, Ignacio Segovia-Dominguez, Yuzhou Chen, Bulent Kiziltan
    * Abstract: In computer-aided drug discovery (CADD), virtual screening (VS) is used for comparing a library of compounds against known active ligands to identify the drug candidates that are most likely to bind to a molecular target. Most VS methods to date have focused on using canonical compound representations (e.g., SMILES strings, Morgan fingerprints) or generating alternative fingerprints of the compounds by training progressively more complex variational autoencoders (VAEs) and graph neural networks (GNNs). Although VAEs and GNNs led to significant improvements in VS performance, these methods suffer from reduced performance when scaling to large virtual compound datasets. The performance of these methods has shown only incremental improvements in the past few years. To address this problem, we developed a novel method using multiparameter persistence (MP) homology that produces topological fingerprints of the compounds as multidimensional vectors. Our primary contribution is framing the VS process as a new topology-based graph ranking problem by partitioning a compound into chemical substructures informed by the periodic properties of its atoms and extracting their persistent homology features at multiple resolution levels. We show that the margin loss fine-tuning of pretrained Triplet networks attains highly competitive results in differentiating between compounds in the embedding space and ranking their likelihood of becoming effective drug candidates. We further establish theoretical guarantees for the stability properties of our proposed MP signatures, and demonstrate that our models, enhanced by the MP signatures, outperform state-of-the-art methods on benchmark datasets by a wide and highly statistically significant margin (e.g., 93\% gain for Cleves-Jain and 54\% gain for DUD-E Diverse dataset).
count=1
* Pitfalls of Epistemic Uncertainty Quantification through Loss Minimisation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/bc1d640f841f752c689aae20b31198c1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/bc1d640f841f752c689aae20b31198c1-Paper-Conference.pdf)]
    * Title: Pitfalls of Epistemic Uncertainty Quantification through Loss Minimisation
    * Year: `2022`
    * Authors: Viktor Bengs, Eyke Hüllermeier, Willem Waegeman
    * Abstract: Uncertainty quantification has received increasing attention in machine learning in the recent past. In particular, a distinction between aleatoric and epistemic uncertainty has been found useful in this regard. The latter refers to the learner's (lack of) knowledge and appears to be especially difficult to measure and quantify. In this paper, we analyse a recent proposal based on the idea of a second-order learner, which yields predictions in the form of distributions over probability distributions. While standard (first-order) learners can be trained to predict accurate probabilities, namely by minimising suitable loss functions on sample data, we show that loss minimisation does not work for second-order predictors: The loss functions proposed for inducing such predictors do not incentivise the learner to represent its epistemic uncertainty in a faithful way.
count=1
* Optimizing Data Collection for Machine Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/c1449acc2e64050d79c2830964f8515f-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/c1449acc2e64050d79c2830964f8515f-Paper-Conference.pdf)]
    * Title: Optimizing Data Collection for Machine Learning
    * Year: `2022`
    * Authors: Rafid Mahmood, James Lucas, Jose M. Alvarez, Sanja Fidler, Marc Law
    * Abstract: Modern deep learning systems require huge data sets to achieve impressive performance, but there is little guidance on how much or what kind of data to collect. Over-collecting data incurs unnecessary present costs, while under-collecting may incur future costs and delay workflows. We propose a new paradigm for modeling the data collection workflow as a formal optimal data collection problem that allows designers to specify performance targets, collection costs, a time horizon, and penalties for failing to meet the targets. Additionally, this formulation generalizes to tasks requiring multiple data sources, such as labeled and unlabeled data used in semi-supervised learning. To solve our problem, we develop Learn-Optimize-Collect (LOC), which minimizes expected future collection costs. Finally, we numerically compare our framework to the conventional baseline of estimating data requirements by extrapolating from neural scaling laws. We significantly reduce the risks of failing to meet desired performance targets on several classification, segmentation, and detection tasks, while maintaining low total collection costs.
count=1
* Off-Policy Evaluation with Deficient Support Using Side Information
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/c32be49c09eec3aad1f2bb587543e7f6-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/c32be49c09eec3aad1f2bb587543e7f6-Paper-Conference.pdf)]
    * Title: Off-Policy Evaluation with Deficient Support Using Side Information
    * Year: `2022`
    * Authors: Nicolò Felicioni, Maurizio Ferrari Dacrema, Marcello Restelli, Paolo Cremonesi
    * Abstract: The Off-Policy Evaluation (OPE) problem consists in evaluating the performance of new policies from the data collected by another one. OPE is crucial when evaluating a new policy online is too expensive or risky. Many of the state-of-the-art OPE estimators are based on the Inverse Propensity Scoring (IPS) technique, which provides an unbiased estimator when the full support assumption holds, i.e., when the logging policy assigns a non-zero probability to each action. However, there are several scenarios where this assumption does not hold in practice, i.e., there is deficient support, and the IPS estimator is biased in the general case.In this paper, we consider two alternative estimators for the deficient support OPE problem. We first show how to adapt an estimator that was originally proposed for a different domain to the deficient support setting.Then, we propose another estimator, which is a novel contribution of this paper.These estimators exploit additional information about the actions, which we call side information, in order to make reliable estimates on the unsupported actions. Under alternative assumptions that do not require full support, we show that the considered estimators are unbiased.We also provide a theoretical analysis of the concentration when relaxing all the assumptions. Finally, we provide an experimental evaluation showing how the considered estimators are better suited for the deficient support setting compared to the baselines.
count=1
* Text Classification with Born's Rule
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/c88d0c9bea6230b518ce71268c8e49e0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/c88d0c9bea6230b518ce71268c8e49e0-Paper-Conference.pdf)]
    * Title: Text Classification with Born's Rule
    * Year: `2022`
    * Authors: Emanuele Guidotti, Alfio Ferrara
    * Abstract: This paper presents a text classification algorithm inspired by the notion of superposition of states in quantum physics. By regarding text as a superposition of words, we derive the wave function of a document and we compute the transition probability of the document to a target class according to Born's rule. Two complementary implementations are presented. In the first one, wave functions are calculated explicitly. The second implementation embeds the classifier in a neural network architecture. Through analysis of three benchmark datasets, we illustrate several aspects of the proposed method, such as classification performance, explainability, and computational efficiency. These ideas are also applicable to non-textual data.
count=1
* Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/cf7a83a5342befd11d3d65beba1be5b0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/cf7a83a5342befd11d3d65beba1be5b0-Paper-Conference.pdf)]
    * Title: Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks
    * Year: `2022`
    * Authors: Indradyumna Roy, Soumen Chakrabarti, Abir De
    * Abstract: The graph retrieval problem is to search in a large corpus of graphs for ones that are most similar to a query graph. A common consideration for scoring similarity is the maximum common subgraph (MCS) between the query and corpus graphs, usually counting the number of common edges (i.e., MCES). In some applications, it is also desirable that the common subgraph be connected, i.e., the maximum common connected subgraph (MCCS). Finding exact MCES and MCCS is intractable, but may be unnecessary if ranking corpus graphs by relevance is the goal. We design fast and trainable neural functions that approximate MCES and MCCS well. Late interaction methods compute dense representations for the query and corpus graph separately, and compare these representations using simple similarity functions at the last stage, leading to highly scalable systems. Early interaction methods combine information from both graphs right from the input stages, are usually considerably more accurate, but slower. We propose both late and early interaction neural MCES and MCCS formulations. They are both based on a continuous relaxation of a node alignment matrix between query and corpus nodes. For MCCS, we propose a novel differentiable network for estimating the size of the largest connected common subgraph. Extensive experiments with seven data sets show that our proposals are superior among late interaction models in terms of both accuracy and speed. Our early interaction models provide accuracy competitive with the state of the art, at substantially greater speeds.
count=1
* On Efficient Online Imitation Learning via Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/d0d5dd7bd2ee9f095e50084c2ba3a716-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/d0d5dd7bd2ee9f095e50084c2ba3a716-Paper-Conference.pdf)]
    * Title: On Efficient Online Imitation Learning via Classification
    * Year: `2022`
    * Authors: Yichen Li, Chicheng Zhang
    * Abstract: Imitation learning (IL) is a general learning paradigm for sequential decision-making problems. Interactive imitation learning, where learners can interactively query for expert annotations, has been shown to achieve provably superior sample efficiency guarantees compared with its offline counterpart or reinforcement learning. In this work, we study classification-based online imitation learning (abbrev. COIL) and the fundamental feasibility to design oracle-efficient regret-minimization algorithms in this setting, with a focus on the general non-realizable case. We make the following contributions: (1) we show that in the COIL problem, any proper online learning algorithm cannot guarantee a sublinear regret in general; (2) we propose Logger, an improper online learning algorithmic framework, that reduces COIL to online linear optimization, by utilizing a new definition of mixed policy class; (3) we design two oracle-efficient algorithms within the Logger framework that enjoy different sample and interaction round complexity tradeoffs, and show their improvements over behavior cloning; (4) we show that under standard complexity-theoretic assumptions, efficient dynamic regret minimization is infeasible in the Logger framework.
count=1
* On the Discrimination Risk of Mean Aggregation Feature Imputation in Graphs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/d4c2f25bf0c33065b7d4fb9be2a9add1-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/d4c2f25bf0c33065b7d4fb9be2a9add1-Paper-Conference.pdf)]
    * Title: On the Discrimination Risk of Mean Aggregation Feature Imputation in Graphs
    * Year: `2022`
    * Authors: Arjun Subramonian, Kai-Wei Chang, Yizhou Sun
    * Abstract: In human networks, nodes belonging to a marginalized group often have a disproportionate rate of unknown or missing features. This, in conjunction with graph structure and known feature biases, can cause graph feature imputation algorithms to predict values for unknown features that make the marginalized group's feature values more distinct from the the dominant group's feature values than they are in reality. We call this distinction the discrimination risk. We prove that a higher discrimination risk can amplify the unfairness of a machine learning model applied to the imputed data. We then formalize a general graph feature imputation framework called mean aggregation imputation and theoretically and empirically characterize graphs in which applying this framework can yield feature values with a high discrimination risk. We propose a simple algorithm to ensure mean aggregation-imputed features provably have a low discrimination risk, while minimally sacrificing reconstruction error (with respect to the imputation objective). We evaluate the fairness and accuracy of our solution on synthetic and real-world credit networks.
count=1
* Deep Ensembles Work, But Are They Necessary?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/da18c47118a2d09926346f33bebde9f4-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/da18c47118a2d09926346f33bebde9f4-Paper-Conference.pdf)]
    * Title: Deep Ensembles Work, But Are They Necessary?
    * Year: `2022`
    * Authors: Taiga Abe, Estefany Kelly Buchanan, Geoff Pleiss, Richard Zemel, John P. Cunningham
    * Abstract: Ensembling neural networks is an effective way to increase accuracy, and can often match the performance of individual larger models. This observation poses a natural question: given the choice between a deep ensemble and a single neural network with similar accuracy, is one preferable over the other? Recent work suggests that deep ensembles may offer distinct benefits beyond predictive power: namely, uncertainty quantification and robustness to dataset shift. In this work, we demonstrate limitations to these purported benefits, and show that a single (but larger) neural network can replicate these qualities. First, we show that ensemble diversity, by any metric, does not meaningfully contribute to an ensemble's ability to detect out-of-distribution (OOD) data, but is instead highly correlated with the relative improvement of a single larger model. Second, we show that the OOD performance afforded by ensembles is strongly determined by their in-distribution (InD) performance, and - in this sense - is not indicative of any "effective robustness." While deep ensembles are a practical way to achieve improvements to predictive power, uncertainty quantification, and robustness, our results show that these improvements can be replicated by a (larger) single model.
count=1
* Structural Analysis of Branch-and-Cut and the Learnability of Gomory Mixed Integer Cuts
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/db2cbf43a349bc866111e791b58c7bf4-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/db2cbf43a349bc866111e791b58c7bf4-Paper-Conference.pdf)]
    * Title: Structural Analysis of Branch-and-Cut and the Learnability of Gomory Mixed Integer Cuts
    * Year: `2022`
    * Authors: Maria-Florina F. Balcan, Siddharth Prasad, Tuomas Sandholm, Ellen Vitercik
    * Abstract: The incorporation of cutting planes within the branch-and-bound algorithm, known as branch-and-cut, forms the backbone of modern integer programming solvers. These solvers are the foremost method for solving discrete optimization problems and thus have a vast array of applications in machine learning, operations research, and many other fields. Choosing cutting planes effectively is a major research topic in the theory and practice of integer programming. We conduct a novel structural analysis of branch-and-cut that pins down how every step of the algorithm is affected by changes in the parameters defining the cutting planes added to the input integer program. Our main application of this analysis is to derive sample complexity guarantees for using machine learning to determine which cutting planes to apply during branch-and-cut. These guarantees apply to infinite families of cutting planes, such as the family of Gomory mixed integer cuts, which are responsible for the main breakthrough speedups of integer programming solvers. We exploit geometric and combinatorial structure of branch-and-cut in our analysis, which provides a key missing piece for the recent generalization theory of branch-and-cut.
count=1
* Fairness Reprogramming
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/de08b3ee7c0043a76ee4a44fe68e90bc-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/de08b3ee7c0043a76ee4a44fe68e90bc-Paper-Conference.pdf)]
    * Title: Fairness Reprogramming
    * Year: `2022`
    * Authors: Guanhua Zhang, Yihua Zhang, Yang Zhang, Wenqi Fan, Qing Li, Sijia Liu, Shiyu Chang
    * Abstract: Despite a surge of recent advances in promoting machine Learning (ML) fairness, the existing mainstream approaches mostly require training or finetuning the entire weights of the neural network to meet the fairness criteria. However, this is often infeasible in practice for those large-scale trained models due to large computational and storage costs, low data efficiency, and model privacy issues. In this paper, we propose a new generic fairness learning paradigm, called FairReprogram, which incorporates the model reprogramming technique. Specifically, FairReprogram considers the case where models can not be changed and appends to the input a set of perturbations, called the fairness trigger, which is tuned towards the fairness criteria under a min-max formulation. We further introduce an information-theoretic framework that explains why and under what conditions fairness goals can be achieved using the fairness trigger. We show both theoretically and empirically that the fairness trigger can effectively obscure demographic biases in the output prediction of fixed ML models by providing false demographic information that hinders the model from utilizing the correct demographic information to make the prediction. Extensive experiments on both NLP and CV datasets demonstrate that our method can achieve better fairness improvements than retraining-based methods with far less data dependency under two widely-used fairness criteria. Codes are available at https://github.com/UCSB-NLP-Chang/Fairness-Reprogramming.git.
count=1
* WeightedSHAP: analyzing and improving Shapley based feature attributions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/de1739eba209c682a90ec3669229ab2d-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/de1739eba209c682a90ec3669229ab2d-Paper-Conference.pdf)]
    * Title: WeightedSHAP: analyzing and improving Shapley based feature attributions
    * Year: `2022`
    * Authors: Yongchan Kwon, James Y. Zou
    * Abstract: Shapley value is a popular approach for measuring the influence of individual features. While Shapley feature attribution is built upon desiderata from game theory, some of its constraints may be less natural in certain machine learning settings, leading to unintuitive model interpretation. In particular, the Shapley value uses the same weight for all marginal contributions---i.e. it gives the same importance when a large number of other features are given versus when a small number of other features are given. This property can be problematic if larger feature sets are more or less informative than smaller feature sets. Our work performs a rigorous analysis of the potential limitations of Shapley feature attribution. We identify simple settings where the Shapley value is mathematically suboptimal by assigning larger attributions for less influential features. Motivated by this observation, we propose WeightedSHAP, which generalizes the Shapley value and learns which marginal contributions to focus directly from data. On several real-world datasets, we demonstrate that the influential features identified by WeightedSHAP are better able to recapitulate the model's predictions compared to the features identified by the Shapley value.
count=1
* MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for Handwriting Verification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/eca896a8cf6363c9573a701c8c5c9cc5-Abstract-Datasets_and_Benchmarks.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/eca896a8cf6363c9573a701c8c5c9cc5-Paper-Datasets_and_Benchmarks.pdf)]
    * Title: MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for Handwriting Verification
    * Year: `2022`
    * Authors: Peirong Zhang, Jiajia Jiang, Yuliang Liu, Lianwen Jin
    * Abstract: Although online handwriting verification has made great progress recently, the verification performances are still far behind the real usage owing to the small scale of the datasets as well as the limited biometric mediums. Therefore, this paper proposes a new handwriting verification benchmark dataset named Multimodal Signature and Digit String (MSDS), which consists of two subsets: MSDS-ChS (Chinese Signatures) and MSDS-TDS (Token Digit Strings), contributed by 402 users, with 20 genuine samples and 20 skilled forgeries per user per subset. MSDS-ChS consists of handwritten Chinese signatures, which, to the best of our knowledge, is the largest publicly available Chinese signature dataset for handwriting verification, at least eight times larger than existing online datasets. Meanwhile, MSDS-TDS consists of handwritten Token Digit Strings, i.e, the actual phone numbers of users, which have not been explored yet. Extensive experiments with different baselines are respectively conducted for MSDS-ChS and MSDS-TDS. Surprisingly, verification performances of state-of-the-art methods on MSDS-TDS are generally better than those on MSDS-ChS, which indicates that the handwritten Token Digit String could be a more effective biometric than handwritten Chinese signature. This is a promising discovery that could inspire us to explore new biometric traits. The MSDS dataset is available at https://github.com/HCIILAB/MSDS.
count=1
* Predicting Label Distribution from Multi-label Ranking
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/efc549c2d22edf2f244b7013387c6251-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/efc549c2d22edf2f244b7013387c6251-Paper-Conference.pdf)]
    * Title: Predicting Label Distribution from Multi-label Ranking
    * Year: `2022`
    * Authors: Yunan Lu, Xiuyi Jia
    * Abstract: Label distribution can provide richer information about label polysemy than logical labels in multi-label learning. There are currently two strategies including LDL (label distribution learning) and LE (label enhancement) to predict label distributions. LDL requires experts to annotate instances with label distributions and learn a predictive mapping on such a training set. LE requires experts to annotate instances with logical labels and generates label distributions from them. However, LDL requires costly annotation, and the performance of the LE is unstable. In this paper, we study the problem of predicting label distribution from multi-label ranking which is a compromise w.r.t. annotation cost but has good guarantees for performance. On the one hand, we theoretically investigate the relation between multi-label ranking and label distribution. We define the notion of EAE (expected approximation error) to quantify the quality of an annotation, give the bounds of EAE for multi-label ranking, and derive the optimal range of label distribution corresponding to a particular multi-label ranking. On the other hand, we propose a framework of label distribution predicting from multi-label ranking via conditional Dirichlet mixtures. This framework integrates the processes of recovering and learning label distributions end-to-end and allows us to easily encode our knowledge about current tasks by a scoring function. Finally, we implement extensive experiments to validate our proposal.
count=1
* PDSketch: Integrated Domain Programming, Learning, and Planning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/efe36e55d80a94d1726f660b8d237a0f-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/efe36e55d80a94d1726f660b8d237a0f-Paper-Conference.pdf)]
    * Title: PDSketch: Integrated Domain Programming, Learning, and Planning
    * Year: `2022`
    * Authors: Jiayuan Mao, Tomás Lozano-Pérez, Josh Tenenbaum, Leslie Kaelbling
    * Abstract: This paper studies a model learning and online planning approach towards building flexible and general robots. Specifically, we investigate how to exploit the locality and sparsity structures in the underlying environmental transition model to improve model generalization, data-efficiency, and runtime-efficiency. We present a new domain definition language, named PDSketch. It allows users to flexibly define high-level structures in the transition models, such as object and feature dependencies, in a way similar to how programmers use TensorFlow or PyTorch to specify kernel sizes and hidden dimensions of a convolutional neural network. The details of the transition model will be filled in by trainable neural networks. Based on the defined structures and learned parameters, PDSketch automatically generates domain-independent planning heuristics without additional training. The derived heuristics accelerate the performance-time planning for novel goals.
count=1
* Sampling in Constrained Domains with Orthogonal-Space Variational Gradient Descent
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/f092c84221d73387a6a5dd7517c500a5-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/f092c84221d73387a6a5dd7517c500a5-Paper-Conference.pdf)]
    * Title: Sampling in Constrained Domains with Orthogonal-Space Variational Gradient Descent
    * Year: `2022`
    * Authors: Ruqi Zhang, Qiang Liu, Xin Tong
    * Abstract: Sampling methods, as important inference and learning techniques, are typically designed for unconstrained domains. However, constraints are ubiquitous in machine learning problems, such as those on safety, fairness, robustness, and many other properties that must be satisfied to apply sampling results in real-life applications. Enforcing these constraints often leads to implicitly-defined manifolds, making efficient sampling with constraints very challenging. In this paper, we propose a new variational framework with a designed orthogonal-space gradient flow (O-Gradient) for sampling on a manifold $\mathcal{G}_0$ defined by general equality constraints. O-Gradient decomposes the gradient into two parts: one decreases the distance to $\mathcal{G}_0$ and the other decreases the KL divergence in the orthogonal space. While most existing manifold sampling methods require initialization on $\mathcal{G}_0$, O-Gradient does not require such prior knowledge. We prove that O-Gradient converges to the target constrained distribution with rate $\widetilde{O}(1/\text{the number of iterations})$ under mild conditions. Our proof relies on a new Stein characterization of conditional measure which could be of independent interest. We implement O-Gradient through both Langevin dynamics and Stein variational gradient descent and demonstrate its effectiveness in various experiments, including Bayesian deep neural networks.
count=1
* ClimbQ: Class Imbalanced Quantization Enabling Robustness on Efficient Inferences
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/f0b1515be276f6ba82b4f2b25e50bef0-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/f0b1515be276f6ba82b4f2b25e50bef0-Paper-Conference.pdf)]
    * Title: ClimbQ: Class Imbalanced Quantization Enabling Robustness on Efficient Inferences
    * Year: `2022`
    * Authors: Ting-An Chen, De-Nian Yang, Ming-syan Chen
    * Abstract: Quantization compresses models to low bits for efficient inferences which has received increasing attentions. However, existing approaches focused on balanced datasets, while imbalanced data is pervasive in the real world. Therefore, in this study, we investigate the realistic problem, quantization on class-imbalanced data. We observe from the analytical results that quantizing imbalanced data tends to obtain a large error due to the differences between separate class distributions, which leads to a significant accuracy loss. To address this issue, we propose a novel quantization framework, Class Imbalanced Quantization (ClimbQ) that focuses on diminishing the inter-class heterogeneity for quantization error reduction. ClimbQ first scales the variance of each class distribution and then projects data through the new distributions to the same space for quantization. To guarantee the homogeneity of class variances after the ClimbQ process, we examine the quantized features and derive that the homogeneity satisfies when data size for each class is restricted (bounded). Accordingly, we design a Homogeneous Variance Loss (HomoVar Loss) which reweights the data losses of each class based on the bounded data sizes to satisfy the homogeneity of class variances. Extensive experiments on class-imbalanced and benchmark balanced datasets reveal that ClimbQ outperforms the state-of-the-art quantization techniques, especially on highly imbalanced data.
count=1
* PhysGNN: A Physics--Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image--Guided Neurosurgery
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/f200119a40846e508954abcd61f5f3fd-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/f200119a40846e508954abcd61f5f3fd-Paper-Conference.pdf)]
    * Title: PhysGNN: A Physics--Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image--Guided Neurosurgery
    * Year: `2022`
    * Authors: Yasmin Salehi, Dennis Giannacopoulos
    * Abstract: Correctly capturing intraoperative brain shift in image-guided neurosurgical procedures is a critical task for aligning preoperative data with intraoperative geometry for ensuring accurate surgical navigation. While the finite element method (FEM) is a proven technique to effectively approximate soft tissue deformation through biomechanical formulations, their degree of success boils down to a trade-off between accuracy and speed. To circumvent this problem, the most recent works in this domain have proposed leveraging data-driven models obtained by training various machine learning algorithms---e.g., random forests, artificial neural networks (ANNs)---with the results of finite element analysis (FEA) to speed up tissue deformation approximations by prediction. These methods, however, do not account for the structure of the finite element (FE) mesh during training that provides information on node connectivities as well as the distance between them, which can aid with approximating tissue deformation based on the proximity of force load points with the rest of the mesh nodes. Therefore, this work proposes a novel framework, PhysGNN, a data-driven model that approximates the solution of the FEM by leveraging graph neural networks (GNNs), which are capable of accounting for the mesh structural information and inductive learning over unstructured grids and complex topological structures. Empirically, we demonstrate that the proposed architecture, PhysGNN, promises accurate and fast soft tissue deformation approximations, and is competitive with the state-of-the-art (SOTA) algorithms while promising enhanced computational feasibility, therefore suitable for neurosurgical settings.
count=1
* Coreset for Line-Sets Clustering
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/f2ce95887c34393af4eb240d60017860-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/f2ce95887c34393af4eb240d60017860-Paper-Conference.pdf)]
    * Title: Coreset for Line-Sets Clustering
    * Year: `2022`
    * Authors: Sagi Lotan, Ernesto Evgeniy Sanches Shayda, Dan Feldman
    * Abstract: The input to the {line-sets $k$-median} problem is an integer $k \geq 1$, and a set $\mathcal{L} = \{L_1,\dots,L_n\}$that contains $n$ sets of lines in $\mathbb{R}^d$. The goal is to compute a set $C$ of $k$ centers (points in $\mathbb{R}^d$) that minimizes the sum $\sum_{L \in \mathcal{L}}\min_{\ell\in L, c\in C}\mathrm{dist}(\ell,c)$ of Euclidean distances from each set to its closest center, where $\mathrm{dist}(\ell,c):=\min_{x\in \ell}\norm{x-c}_2$.An \emph{$\varepsilon$-coreset} for this problem is a weighted subset of sets in $\mathcal{L}$ that approximates this sum up to $1 \pm \varepsilon$ multiplicative factor, for every set $C$ of $k$ centers. We prove that \emph{every} such input set $\set{L}$ has a small $\varepsilon$-coreset, and provide the first coreset construction for this problem and its variants. The coreset consists of $O(\log^2n)$ weighted line-sets from $\set{L}$, and is constructed in $O(n\log n)$ time for every fixed $d, k\geq 1$ and $\varepsilon \in (0,1)$. The main technique is based on a novel reduction to a ``fair clustering'' of colored points to colored centers. We then provide a coreset for this coloring problem, which may be of independent interest. Open source code and experiments are also provided.
count=1
* Asymptotically Unbiased Instance-wise Regularized Partial AUC Optimization: Theory and Algorithm
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/fc9f83d9925e6885e8f1ae1e17b3c44b-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/fc9f83d9925e6885e8f1ae1e17b3c44b-Paper-Conference.pdf)]
    * Title: Asymptotically Unbiased Instance-wise Regularized Partial AUC Optimization: Theory and Algorithm
    * Year: `2022`
    * Authors: HuiYang Shao, Qianqian Xu, Zhiyong Yang, Shilong Bao, Qingming Huang
    * Abstract: The Partial Area Under the ROC Curve (PAUC), typically including One-way Partial AUC (OPAUC) and Two-way Partial AUC (TPAUC), measures the average performance of a binary classifier within a specific false positive rate and/or true positive rate interval, which is a widely adopted measure when decision constraints must be considered. Consequently, PAUC optimization has naturally attracted increasing attention in the machine learning community within the last few years. Nonetheless, most of the existing methods could only optimize PAUC approximately, leading to inevitable biases that are not controllable. Fortunately, a recent work presents an unbiased formulation of the PAUC optimization problem via distributional robust optimization. However, it is based on the pair-wise formulation of AUC, which suffers from the limited scalability w.r.t. sample size and a slow convergence rate, especially for TPAUC. To address this issue, we present a simpler reformulation of the problem in an asymptotically unbiased and instance-wise manner. For both OPAUC and TPAUC, we come to a nonconvex strongly concave min-max regularized problem of instance-wise functions. On top of this, we employ an efficient solver that enjoys a linear per-iteration computational complexity w.r.t. the sample size and a time-complexity of $O(\epsilon^{-1/3})$ to reach a $\epsilon$ stationary point. Furthermore, we find that the min-max reformulation also facilitates the theoretical analysis of generalization error as a byproduct. Compared with the existing results, we present new error bounds that are much easier to prove and could deal with hypotheses with real-valued outputs. Finally, extensive experiments on several benchmark datasets demonstrate the effectiveness of our method.
count=1
* Beyond Adult and COMPAS: Fair Multi-Class Prediction via Information Projection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/fd5013ea0c3f96931dec77174eaf9d80-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/fd5013ea0c3f96931dec77174eaf9d80-Paper-Conference.pdf)]
    * Title: Beyond Adult and COMPAS: Fair Multi-Class Prediction via Information Projection
    * Year: `2022`
    * Authors: Wael Alghamdi, Hsiang Hsu, Haewon Jeong, Hao Wang, Peter Michalak, Shahab Asoodeh, Flavio Calmon
    * Abstract: We consider the problem of producing fair probabilistic classifiers for multi-class classification tasks. We formulate this problem in terms of ``projecting'' a pre-trained (and potentially unfair) classifier onto the set of models that satisfy target group-fairness requirements. The new, projected model is given by post-processing the outputs of the pre-trained classifier by a multiplicative factor. We provide a parallelizable, iterative algorithm for computing the projected classifier and derive both sample complexity and convergence guarantees. Comprehensive numerical comparisons with state-of-the-art benchmarks demonstrate that our approach maintains competitive performance in terms of accuracy-fairness trade-off curves, while achieving favorable runtime on large datasets. We also evaluate our method at scale on an open dataset with multiple classes, multiple intersectional groups, and over 1M samples.
count=1
* Explicable Policy Search
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/hash/fdff3c4130c24c40c88aa41eb52d2a27-Abstract-Conference.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2022/file/fdff3c4130c24c40c88aa41eb52d2a27-Paper-Conference.pdf)]
    * Title: Explicable Policy Search
    * Year: `2022`
    * Authors: Ze Gong, Yu (&amp;quot;Tony&amp;quot;) Zhang
    * Abstract: Human teammates often form conscious and subconscious expectations of each other during interaction. Teaming success is contingent on whether such expectations can be met. Similarly, for an intelligent agent to operate beside a human, it must consider the human’s expectation of its behavior. Disregarding such expectations can lead to the loss of trust and degraded team performance. A key challenge here is that the human’s expectation may not align with the agent’s optimal behavior, e.g., due to the human’s partial or inaccurate understanding of the task domain. Prior work on explicable planning described the ability of agents to respect their human teammate’s expectations by trading off task performance for more expected or “explicable” behaviors. In this paper, we introduce Explicable Policy Search (EPS) to significantly extend such an ability to stochastic domains in a reinforcement learning (RL) setting with continuous state and action spaces. Furthermore, in contrast to the traditional RL methods, EPS must at the same time infer the human’s hidden expectations. Such inferences require information about the human’s belief about the domain dynamics and her reward model but directly querying them is impractical. We demonstrate that such information can be necessarily and sufficiently encoded by a surrogate reward function for EPS, which can be learned based on the human’s feedback on the agent’s behavior. The surrogate reward function is then used to reshape the agent’s reward function, which is shown to be equivalent to searching for an explicable policy. We evaluate EPS in a set of navigation domains with synthetic human models and in an autonomous driving domain with a user study. The results suggest that our method can generate explicable behaviors that reconcile task performance with human expectations intelligently and has real-world relevance in human-agent teaming domains.
count=1
* Counterfactual Explanations Can Be Manipulated
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/009c434cab57de48a31f6b669e7ba266-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/009c434cab57de48a31f6b669e7ba266-Paper.pdf)]
    * Title: Counterfactual Explanations Can Be Manipulated
    * Year: `2021`
    * Authors: Dylan Slack, Anna Hilgard, Himabindu Lakkaraju, Sameer Singh
    * Abstract: Counterfactual explanations are emerging as an attractive option for providing recourse to individuals adversely impacted by algorithmic decisions. As they are deployed in critical applications (e.g. law enforcement, financial lending), it becomes important to ensure that we clearly understand the vulnerabilties of these methods and find ways to address them. However, there is little understanding of the vulnerabilities and shortcomings of counterfactual explanations. In this work, we introduce the first framework that describes the vulnerabilities of counterfactual explanations and shows how they can be manipulated. More specifically, we show counterfactual explanations may converge to drastically different counterfactuals under a small perturbation indicating they are not robust. Leveraging this insight, we introduce a novel objective to train seemingly fair models where counterfactual explanations find much lower cost recourse under a slight perturbation. We describe how these models can unfairly provide low-cost recourse for specific subgroups in the data while appearing fair to auditors. We perform experiments on loan and violent crime prediction data sets where certain subgroups achieve up to 20x lower cost recourse under the perturbation. These results raise concerns regarding the dependability of current counterfactual explanation techniques, which we hope will inspire investigations in robust counterfactual explanations.
count=1
* Sample Selection for Fair and Robust Training
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/07563a3fe3bbe7e3ba84431ad9d055af-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/07563a3fe3bbe7e3ba84431ad9d055af-Paper.pdf)]
    * Title: Sample Selection for Fair and Robust Training
    * Year: `2021`
    * Authors: Yuji Roh, Kangwook Lee, Steven Whang, Changho Suh
    * Abstract: Fairness and robustness are critical elements of Trustworthy AI that need to be addressed together. Fairness is about learning an unbiased model while robustness is about learning from corrupted data, and it is known that addressing only one of them may have an adverse affect on the other. In this work, we propose a sample selection-based algorithm for fair and robust training. To this end, we formulate a combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. Observing that solving this optimization problem is strongly NP-hard, we propose a greedy algorithm that is efficient and effective in practice. Experiments show that our method obtains fairness and robustness that are better than or comparable to the state-of-the-art technique, both on synthetic and benchmark real datasets. Moreover, unlike other fair and robust training baselines, our algorithm can be used by only modifying the sampling step in batch selection without changing the training algorithm or leveraging additional clean data.
count=1
* Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/080acdcce72c06873a773c4311c2e464-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/080acdcce72c06873a773c4311c2e464-Paper.pdf)]
    * Title: Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee
    * Year: `2021`
    * Authors: Xiaofeng Fan, Yining Ma, Zhongxiang Dai, Wei Jing, Cheston Tan, Bryan Kian Hsiang Low
    * Abstract: The growing literature of Federated Learning (FL) has recently inspired Federated Reinforcement Learning (FRL) to encourage multiple agents to federatively build a better decision-making policy without sharing raw trajectories. Despite its promising applications, existing works on FRL fail to I) provide theoretical analysis on its convergence, and II) account for random system failures and adversarial attacks. Towards this end, we propose the first FRL framework the convergence of which is guaranteed and tolerant to less than half of the participating agents being random system failures or adversarial attackers. We prove that the sample efficiency of the proposed framework is guaranteed to improve with the number of agents and is able to account for such potential failures or attacks. All theoretical results are empirically verified on various RL benchmark tasks.
count=1
* Improving Conditional Coverage via Orthogonal Quantile Regression
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/1006ff12c465532f8c574aeaa4461b16-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/1006ff12c465532f8c574aeaa4461b16-Paper.pdf)]
    * Title: Improving Conditional Coverage via Orthogonal Quantile Regression
    * Year: `2021`
    * Authors: Shai Feldman, Stephen Bates, Yaniv Romano
    * Abstract: We develop a method to generate prediction intervals that have a user-specified coverage level across all regions of feature-space, a property called conditional coverage. A typical approach to this task is to estimate the conditional quantiles with quantile regression---it is well-known that this leads to correct coverage in the large-sample limit, although it may not be accurate in finite samples. We find in experiments that traditional quantile regression can have poor conditional coverage. To remedy this, we modify the loss function to promote independence between the size of the intervals and the indicator of a miscoverage event. For the true conditional quantiles, these two quantities are independent (orthogonal), so the modified loss function continues to be valid. Moreover, we empirically show that the modified loss function leads to improved conditional coverage, as evaluated by several metrics. We also introduce two new metrics that check conditional coverage by looking at the strength of the dependence between the interval size and the indicator of miscoverage.
count=1
* On Calibration and Out-of-Domain Generalization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/118bd558033a1016fcc82560c65cca5f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/118bd558033a1016fcc82560c65cca5f-Paper.pdf)]
    * Title: On Calibration and Out-of-Domain Generalization
    * Year: `2021`
    * Authors: Yoav Wald, Amir Feder, Daniel Greenfeld, Uri Shalit
    * Abstract: Out-of-domain (OOD) generalization is a significant challenge for machine learning models. Many techniques have been proposed to overcome this challenge, often focused on learning models with certain invariance properties. In this work, we draw a link between OOD performance and model calibration, arguing that calibration across multiple domains can be viewed as a special case of an invariant representation leading to better OOD generalization. Specifically, we show that under certain conditions, models which achieve \emph{multi-domain calibration} are provably free of spurious correlations. This leads us to propose multi-domain calibration as a measurable and trainable surrogate for the OOD performance of a classifier. We therefore introduce methods that are easy to apply and allow practitioners to improve multi-domain calibration by training or modifying an existing model, leading to better performance on unseen domains. Using four datasets from the recently proposed WILDS OOD benchmark, as well as the Colored MNIST, we demonstrate that training or tuning models so they are calibrated across multiple domains leads to significantly improved performance on unseen test domains. We believe this intriguing connection between calibration and OOD generalization is promising from both a practical and theoretical point of view.
count=1
* Self-Interpretable Model with Transformation Equivariant Interpretation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/1387a00f03b4b423e63127b08c261bdc-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/1387a00f03b4b423e63127b08c261bdc-Paper.pdf)]
    * Title: Self-Interpretable Model with Transformation Equivariant Interpretation
    * Year: `2021`
    * Authors: Yipei Wang, Xiaoqian Wang
    * Abstract: With the proliferation of machine learning applications in the real world, the demand for explaining machine learning predictions continues to grow especially in high-stakes fields. Recent studies have found that interpretation methods can be sensitive and unreliable, where the interpretations can be disturbed by perturbations or transformations of input data. To address this issue, we propose to learn robust interpretation through transformation equivariant regularization in a self-interpretable model. The resulting model is capable of capturing valid interpretation that is equivariant to geometric transformations. Moreover, since our model is self-interpretable, it enables faithful interpretations that reflect the true predictive mechanism. Unlike existing self-interpretable models, which usually sacrifice expressive power for the sake of interpretation quality, our model preserves the high expressive capability comparable to the state-of-the-art deep learning models in complex tasks, while providing visualizable and faithful high-quality interpretation. We compare with various related methods and validate the interpretation quality and consistency of our model.
count=1
* On Model Calibration for Long-Tailed Object Detection and Instance Segmentation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/14ad095ecc1c3e1b87f3c522836e9158-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/14ad095ecc1c3e1b87f3c522836e9158-Paper.pdf)]
    * Title: On Model Calibration for Long-Tailed Object Detection and Instance Segmentation
    * Year: `2021`
    * Authors: Tai-Yu Pan, Cheng Zhang, Yandong Li, Hexiang Hu, Dong Xuan, Soravit Changpinyo, Boqing Gong, Wei-Lun Chao
    * Abstract: Vanilla models for object detection and instance segmentation suffer from the heavy bias toward detecting frequent objects in the long-tailed setting. Existing methods address this issue mostly during training, e.g., by re-sampling or re-weighting. In this paper, we investigate a largely overlooked approach --- post-processing calibration of confidence scores. We propose NorCal, Normalized Calibration for long-tailed object detection and instance segmentation, a simple and straightforward recipe that reweighs the predicted scores of each class by its training sample size. We show that separately handling the background class and normalizing the scores over classes for each proposal are keys to achieving superior performance. On the LVIS dataset, NorCal can effectively improve nearly all the baseline models not only on rare classes but also on common and frequent classes. Finally, we conduct extensive analysis and ablation studies to offer insights into various modeling choices and mechanisms of our approach. Our code is publicly available at https://github.com/tydpan/NorCal.
count=1
* Control Variates for Slate Off-Policy Evaluation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/1e0b802d5c0e1e8434a771ba7ff2c301-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/1e0b802d5c0e1e8434a771ba7ff2c301-Paper.pdf)]
    * Title: Control Variates for Slate Off-Policy Evaluation
    * Year: `2021`
    * Authors: Nikos Vlassis, Ashok Chandrashekar, Fernando Amat, Nathan Kallus
    * Abstract: We study the problem of off-policy evaluation from batched contextual bandit data with multidimensional actions, often termed slates. The problem is common to recommender systems and user-interface optimization, and it is particularly challenging because of the combinatorially-sized action space. Swaminathan et al. (2017) have proposed the pseudoinverse (PI) estimator under the assumption that the conditional mean rewards are additive in actions. Using control variates, we consider a large class of unbiased estimators that includes as specific cases the PI estimator and (asymptotically) its self-normalized variant. By optimizing over this class, we obtain new estimators with risk improvement guarantees over both the PI and the self-normalized PI estimators. Experiments with real-world recommender data as well as synthetic data validate these improvements in practice.
count=1
* Speedy Performance Estimation for Neural Architecture Search
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/2130eb640e0a272898a51da41363542d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/2130eb640e0a272898a51da41363542d-Paper.pdf)]
    * Title: Speedy Performance Estimation for Neural Architecture Search
    * Year: `2021`
    * Authors: Robin Ru, Clare Lyle, Lisa Schut, Miroslav Fil, Mark van der Wilk, Yarin Gal
    * Abstract: Reliable yet efficient evaluation of generalisation performance of a proposed architecture is crucial to the success of neural architecture search (NAS). Traditional approaches face a variety of limitations: training each architecture to completion is prohibitively expensive, early stopped validation accuracy may correlate poorly with fully trained performance, and model-based estimators require large training sets. We instead propose to estimate the final test performance based on a simple measure of training speed. Our estimator is theoretically motivated by the connection between generalisation and training speed, and is also inspired by the reformulation of a PAC-Bayes bound under the Bayesian setting. Our model-free estimator is simple, efficient, and cheap to implement, and does not require hyperparameter-tuning or surrogate training before deployment. We demonstrate on various NAS search spaces that our estimator consistently outperforms other alternatives in achieving better correlation with the true test performance rankings. We further show that our estimator can be easily incorporated into both query-based and one-shot NAS methods to improve the speed or quality of the search.
count=1
* Understanding Partial Multi-Label Learning via Mutual Information
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/217c0e01c1828e7279051f1b6675745d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/217c0e01c1828e7279051f1b6675745d-Paper.pdf)]
    * Title: Understanding Partial Multi-Label Learning via Mutual Information
    * Year: `2021`
    * Authors: Xiuwen Gong, Dong Yuan, Wei Bao
    * Abstract: To deal with ambiguities in partial multilabel learning (PML), state-of-the-art methods perform disambiguation by identifying ground-truth labels directly. However, there is an essential question:“Can the ground-truth labels be identified precisely?". If yes, “How can the ground-truth labels be found?". This paper provides affirmative answers to these questions. Instead of adopting hand-made heuristic strategy, we propose a novel Mutual Information Label Identification for Partial Multilabel Learning (MILI-PML), which is derived from a clear probabilistic formulation and could be easily interpreted theoretically from the mutual information perspective, as well as naturally incorporates the feature/label relevancy considerations. Extensive experiments on synthetic and real-world datasets clearly demonstrate the superiorities of the proposed MILI-PML.
count=1
* Invertible Tabular GANs: Killing Two Birds with One Stone for Tabular Data Synthesis
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/22456f4b545572855c766df5eefc9832-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/22456f4b545572855c766df5eefc9832-Paper.pdf)]
    * Title: Invertible Tabular GANs: Killing Two Birds with One Stone for Tabular Data Synthesis
    * Year: `2021`
    * Authors: JAEHOON LEE, Jihyeon Hyeong, Jinsung Jeon, Noseong Park, Jihoon Cho
    * Abstract: Tabular data synthesis has received wide attention in the literature. This is because available data is often limited, incomplete, or cannot be obtained easily, and data privacy is becoming increasingly important. In this work, we present a generalized GAN framework for tabular synthesis, which combines the adversarial training of GANs and the negative log-density regularization of invertible neural networks. The proposed framework can be used for two distinctive objectives. First, we can further improve the synthesis quality, by decreasing the negative log-density of real records in the process of adversarial training. On the other hand, by increasing the negative log-density of real records, realistic fake records can be synthesized in a way that they are not too much close to real records and reduce the chance of potential information leakage. We conduct experiments with real-world datasets for classification, regression, and privacy attacks. In general, the proposed method demonstrates the best synthesis quality (in terms of task-oriented evaluation metrics, e.g., F1) when decreasing the negative log-density during the adversarial training. If increasing the negative log-density, our experimental results show that the distance between real and fake records increases, enhancing robustness against privacy attacks.
count=1
* Learning to Combine Per-Example Solutions for Neural Program Synthesis
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/30d411fdc0e6daf092a74354094359bb-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/30d411fdc0e6daf092a74354094359bb-Paper.pdf)]
    * Title: Learning to Combine Per-Example Solutions for Neural Program Synthesis
    * Year: `2021`
    * Authors: Disha Shrivastava, Hugo Larochelle, Daniel Tarlow
    * Abstract: The goal of program synthesis from examples is to find a computer program that is consistent with a given set of input-output examples. Most learning-based approaches try to find a program that satisfies all examples at once. Our work, by contrast, considers an approach that breaks the problem into two stages: (a) find programs that satisfy only one example, and (b) leverage these per-example solutions to yield a program that satisfies all examples. We introduce the Cross Aggregator neural network module based on a multi-head attention mechanism that learns to combine the cues present in these per-example solutions to synthesize a global solution. Evaluation across programs of different lengths and under two different experimental settings reveal that when given the same time budget, our technique significantly improves the success rate over PCCoder [Zohar et. al 2018] and other ablation baselines.
count=1
* A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/43c656628a4a479e108ed86f7a28a010-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/43c656628a4a479e108ed86f7a28a010-Paper.pdf)]
    * Title: A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models
    * Year: `2021`
    * Authors: Ibrahim M. Alabdulmohsin, Mario Lucic
    * Abstract: We present a scalable post-processing algorithm for debiasing trained models, including deep neural networks (DNNs), which we prove to be near-optimal by bounding its excess Bayes risk. We empirically validate its advantages on standard benchmark datasets across both classical algorithms as well as modern DNN architectures and demonstrate that it outperforms previous post-processing methods while performing on par with in-processing. In addition, we show that the proposed algorithm is particularly effective for models trained at scale where post-processing is a natural and practical choice.
count=1
* Fair Classification with Adversarial Perturbations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/44e207aecc63505eb828d442de03f2e9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/44e207aecc63505eb828d442de03f2e9-Paper.pdf)]
    * Title: Fair Classification with Adversarial Perturbations
    * Year: `2021`
    * Authors: L. Elisa Celis, Anay Mehrotra, Nisheeth Vishnoi
    * Abstract: We study fair classification in the presence of an omniscient adversary that, given an $\eta$, is allowed to choose an arbitrary $\eta$-fraction of the training samples and arbitrarily perturb their protected attributes. The motivation comes from settings in which protected attributes can be incorrect due to strategic misreporting, malicious actors, or errors in imputation; and prior approaches that make stochastic or independence assumptions on errors may not satisfy their guarantees in this adversarial setting. Our main contribution is an optimization framework to learn fair classifiers in this adversarial setting that comes with provable guarantees on accuracy and fairness. Our framework works with multiple and non-binary protected attributes, is designed for the large class of linear-fractional fairness metrics, and can also handle perturbations besides protected attributes. We prove near-tightness of our framework's guarantees for natural hypothesis classes: no algorithm can have significantly better accuracy and any algorithm with better fairness must have lower accuracy. Empirically, we evaluate the classifiers produced by our framework for statistical rate on real-world and synthetic datasets for a family of adversaries.
count=1
* Parameter-free HE-friendly Logistic Regression
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/477bdb55b231264bb53a7942fd84254d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/477bdb55b231264bb53a7942fd84254d-Paper.pdf)]
    * Title: Parameter-free HE-friendly Logistic Regression
    * Year: `2021`
    * Authors: Junyoung Byun, Woojin Lee, Jaewook Lee
    * Abstract: Privacy in machine learning has been widely recognized as an essential ethical and legal issue, because the data used for machine learning may contain sensitive information. Homomorphic encryption has recently attracted attention as a key solution to preserve privacy in machine learning applications. However, current approaches on the training of encrypted machine learning have relied heavily on hyperparameter selection, which should be avoided owing to the extreme difficulty of conducting validation on encrypted data. In this study, we propose an effective privacy-preserving logistic regression method that is free from the approximation of the sigmoid function and hyperparameter selection. In our framework, a logistic regression model can be transformed into the corresponding ridge regression for the logit function. We provide a theoretical background for our framework by suggesting a new generalization error bound on the encrypted data. Experiments on various real-world data show that our framework achieves better classification results while reducing latency by $\sim68\%$, compared to the previous models.
count=1
* Scaling Vision with Sparse Mixture of Experts
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/48237d9f2dea8c74c2a72126cf63d933-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/48237d9f2dea8c74c2a72126cf63d933-Paper.pdf)]
    * Title: Scaling Vision with Sparse Mixture of Experts
    * Year: `2021`
    * Authors: Carlos Riquelme, Joan Puigcerver, Basil Mustafa, Maxim Neumann, Rodolphe Jenatton, André Susano Pinto, Daniel Keysers, Neil Houlsby
    * Abstract: Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent scalability in Natural Language Processing. In Computer Vision, however, almost all performant networks are "dense", that is, every input is processed by every parameter. We present a Vision MoE (V-MoE), a sparse version of the Vision Transformer, that is scalable and competitive with the largest dense networks. When applied to image recognition, V-MoE matches the performance of state-of-the-art networks, while requiring as little as half of the compute at inference time. Further, we propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per-image compute. This allows V-MoE to trade-off performance and compute smoothly at test-time. Finally, we demonstrate the potential of V-MoE to scale vision models, and train a 15B parameter model that attains 90.35% on ImageNet.
count=1
* Machine Learning for Variance Reduction in Online Experiments
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/488b084119a1c7a4950f00706ec7ea16-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/488b084119a1c7a4950f00706ec7ea16-Paper.pdf)]
    * Title: Machine Learning for Variance Reduction in Online Experiments
    * Year: `2021`
    * Authors: Yongyi Guo, Dominic Coey, Mikael Konutgan, Wenting Li, Chris Schoener, Matt Goldman
    * Abstract: We consider the problem of variance reduction in randomized controlled trials, through the use of covariates correlated with the outcome but independent of the treatment. We propose a machine learning regression-adjusted treatment effect estimator, which we call MLRATE. MLRATE uses machine learning predictors of the outcome to reduce estimator variance. It employs cross-fitting to avoid overfitting biases, and we prove consistency and asymptotic normality under general conditions. MLRATE is robust to poor predictions from the machine learning step: if the predictions are uncorrelated with the outcomes, the estimator performs asymptotically no worse than the standard difference-in-means estimator, while if predictions are highly correlated with outcomes, the efficiency gains are large. In A/A tests, for a set of 48 outcome metrics commonly monitored in Facebook experiments, the estimator has over $70\%$ lower variance than the simple difference-in-means estimator, and about $19\%$ lower variance than the common univariate procedure which adjusts only for pre-experiment values of the outcome.
count=1
* Consistent Non-Parametric Methods for Maximizing Robustness
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/4bb236de7787ceedafdff83bb8ea4710-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/4bb236de7787ceedafdff83bb8ea4710-Paper.pdf)]
    * Title: Consistent Non-Parametric Methods for Maximizing Robustness
    * Year: `2021`
    * Authors: Robi Bhattacharjee, Kamalika Chaudhuri
    * Abstract: Learning classifiers that are robust to adversarial examples has received a great deal of recent attention. A major drawback of the standard robust learning framework is the imposition of an artificial robustness radius $r$ that applies to all inputs, and ignores the fact that data may be highly heterogeneous. In particular, it is plausible that robustness regions should be larger in some regions of data, and smaller in other. In this paper, we address this limitation by proposing a new limit classifier, called the neighborhood optimal classifier, that extends the Bayes optimal classifier outside its support by using the label of the closest in-support point. We then argue that this classifier maximizes the size of its robustness regions subject to the constraint of having accuracy equal to the Bayes optimal. We then present sufficient conditions under which general non-parametric methods that can be represented as weight functions converge towards this limit object, and show that both nearest neighbors and kernel classifiers (under certain assumptions) suffice.
count=1
* Novel Upper Bounds for the Constrained Most Probable Explanation Task
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/4fc7e9c4df30aafd8b7e1ab324f27712-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/4fc7e9c4df30aafd8b7e1ab324f27712-Paper.pdf)]
    * Title: Novel Upper Bounds for the Constrained Most Probable Explanation Task
    * Year: `2021`
    * Authors: Tahrima Rahman, Sara Rouhani, Vibhav Gogate
    * Abstract: We propose several schemes for upper bounding the optimal value of the constrained most probable explanation (CMPE) problem. Given a set of discrete random variables, two probabilistic graphical models defined over them and a real number $q$, this problem involves finding an assignment of values to all the variables such that the probability of the assignment is maximized according to the first model and is bounded by $q$ w.r.t. the second model. In prior work, it was shown that CMPE is a unifying problem with several applications and special cases including the nearest assignment problem, the decision preserving most probable explanation task and robust estimation. It was also shown that CMPE is NP-hard even on tractable models such as bounded treewidth networks and is hard for integer linear programming methods because it includes a dense global constraint. The main idea in our approach is to simplify the problem via Lagrange relaxation and decomposition to yield either a knapsack problem or the unconstrained most probable explanation (MPE) problem, and then solving the two problems, respectively using specialized knapsack algorithms and mini-buckets based upper bounding schemes. We evaluate our proposed scheme along several dimensions including quality of the bounds and computation time required on various benchmark graphical models and how it can be used to find heuristic, near-optimal feasible solutions in an example application pertaining to robust estimation and adversarial attacks on classifiers.
count=1
* Oracle-Efficient Regret Minimization in Factored MDPs with Unknown Structure
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/5c936263f3428a40227908d5a3847c0b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/5c936263f3428a40227908d5a3847c0b-Paper.pdf)]
    * Title: Oracle-Efficient Regret Minimization in Factored MDPs with Unknown Structure
    * Year: `2021`
    * Authors: Aviv Rosenberg, Yishay Mansour
    * Abstract: We study regret minimization in non-episodic factored Markov decision processes (FMDPs), where all existing algorithms make the strong assumption that the factored structure of the FMDP is known to the learner in advance. In this paper, we provide the first algorithm that learns the structure of the FMDP while minimizing the regret. Our algorithm is based on the optimism in face of uncertainty principle, combined with a simple statistical method for structure learning, and can be implemented efficiently given oracle-access to an FMDP planner. Moreover, we give a variant of our algorithm that remains efficient even when the oracle is limited to non-factored actions, which is the case with almost all existing approximate planners. Finally, we leverage our techniques to prove a novel lower bound for the known structure case, closing the gap to the regret bound of Chen et al. [2021].
count=1
* One Explanation is Not Enough: Structured Attention Graphs for Image Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/5e751896e527c862bf67251a474b3819-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/5e751896e527c862bf67251a474b3819-Paper.pdf)]
    * Title: One Explanation is Not Enough: Structured Attention Graphs for Image Classification
    * Year: `2021`
    * Authors: Vivswan Shitole, Fuxin Li, Minsuk Kahng, Prasad Tadepalli, Alan Fern
    * Abstract: Attention maps are popular tools for explaining the decisions of convolutional neural networks (CNNs) for image classification. Typically, for each image of interest, a single attention map is produced, which assigns weights to pixels based on their importance to the classification. We argue that a single attention map provides an incomplete understanding since there are often many other maps that explain a classification equally well. In this paper, we propose to utilize a beam search algorithm to systematically search for multiple explanations for each image. Results show that there are indeed multiple relatively localized explanations for many images. However, naively showing multiple explanations to users can be overwhelming and does not reveal their common and distinct structures. We introduce structured attention graphs (SAGs), which compactly represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier. An approach to computing a compact and representative SAG for visualization is proposed via diverse sampling. We conduct a user study comparing the use of SAGs to traditional attention maps for answering comparative counterfactual questions about image classifications. Our results show that the users are significantly more accurate when presented with SAGs compared to standard attention map baselines.
count=1
* What’s a good imputation to predict with missing values?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/5fe8fdc79ce292c39c5f209d734b7206-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/5fe8fdc79ce292c39c5f209d734b7206-Paper.pdf)]
    * Title: What’s a good imputation to predict with missing values?
    * Year: `2021`
    * Authors: Marine Le Morvan, Julie Josse, Erwan Scornet, Gael Varoquaux
    * Abstract: How to learn a good predictor on data with missing values? Most efforts focus on first imputing as well as possible and second learning on the completed data to predict the outcome. Yet, this widespread practice has no theoretical grounding. Here we show that for almost all imputation functions, an impute-then-regress procedure with a powerful learner is Bayes optimal. This result holds for all missing-values mechanisms, in contrast with the classic statistical results that require missing-at-random settings to use imputation in probabilistic modeling. Moreover, it implies that perfect conditional imputation is not needed for good prediction asymptotically. In fact, we show that on perfectly imputed data the best regression function will generally be discontinuous, which makes it hard to learn. Crafting instead the imputation so as to leave the regression function unchanged simply shifts the problem to learning discontinuous imputations. Rather, we suggest that it is easier to learn imputation and regression jointly. We propose such a procedure, adapting NeuMiss, a neural network capturing the conditional links across observed and unobserved variables whatever the missing-value pattern. Our experiments confirm that joint imputation and regression through NeuMiss is better than various two step procedures in a finite-sample regime.
count=1
* Rethinking Calibration of Deep Neural Networks: Do Not Be Afraid of Overconfidence
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/61f3a6dbc9120ea78ef75544826c814e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/61f3a6dbc9120ea78ef75544826c814e-Paper.pdf)]
    * Title: Rethinking Calibration of Deep Neural Networks: Do Not Be Afraid of Overconfidence
    * Year: `2021`
    * Authors: Deng-Bao Wang, Lei Feng, Min-Ling Zhang
    * Abstract: Capturing accurate uncertainty quantification of the prediction from deep neural networks is important in many real-world decision-making applications. A reliable predictor is expected to be accurate when it is confident about its predictions and indicate high uncertainty when it is likely to be inaccurate. However, modern neural networks have been found to be poorly calibrated, primarily in the direction of overconfidence. In recent years, there is a surge of research on model calibration by leveraging implicit or explicit regularization techniques during training, which obtain well calibration by avoiding overconfident outputs. In our study, we empirically found that despite the predictions obtained from these regularized models are better calibrated, they suffer from not being as calibratable, namely, it is harder to further calibrate their predictions with post-hoc calibration methods like temperature scaling and histogram binning. We conduct a series of empirical studies showing that overconfidence may not hurt final calibration performance if post-hoc calibration is allowed, rather, the penalty of confident outputs will compress the room of potential improvements in post-hoc calibration phase. Our experimental findings point out a new direction to improve calibration of DNNs by considering main training and post-hoc calibration as a unified framework.
count=1
* Contrastive Learning for Neural Topic Model
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/6467c327eaf8940b4dd07a08c63c5e85-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/6467c327eaf8940b4dd07a08c63c5e85-Paper.pdf)]
    * Title: Contrastive Learning for Neural Topic Model
    * Year: `2021`
    * Authors: Thong Nguyen, Anh Tuan Luu
    * Abstract: Recent empirical studies show that adversarial topic models (ATM) can successfully capture semantic patterns of the document by differentiating a document with another dissimilar sample. However, utilizing that discriminative-generative architecture has two important drawbacks: (1) the architecture does not relate similar documents, which has the same document-word distribution of salient words; (2) it restricts the ability to integrate external information, such as sentiments of the document, which has been shown to benefit the training of neural topic model. To address those issues, we revisit the adversarial topic architecture in the view point of mathematical analysis, propose a novel approach to re-formulate discriminative goal as an optimization problem, and design a novel sampling method which facilitates the integration of external variables. The reformulation encourages the model to incorporate the relations among similar samples and enforces the constraint on the similarity among dissimilar ones; while the sampling method, which is based on the internal input and reconstructed output, helps inform the model of salient words contributing to the main topic. Experimental results show that our framework outperforms other state-of-the-art neural topic models in three common benchmark datasets that belong to various domains, vocabulary sizes, and document lengths in terms of topic coherence.
count=1
* Fairness via Representation Neutralization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/64ff7983a47d331b13a81156e2f4d29d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/64ff7983a47d331b13a81156e2f4d29d-Paper.pdf)]
    * Title: Fairness via Representation Neutralization
    * Year: `2021`
    * Authors: Mengnan Du, Subhabrata Mukherjee, Guanchu Wang, Ruixiang Tang, Ahmed Awadallah, Xia Hu
    * Abstract: Existing bias mitigation methods for DNN models primarily work on learning debiased encoders. This process not only requires a lot of instance-level annotations for sensitive attributes, it also does not guarantee that all fairness sensitive information has been removed from the encoder. To address these limitations, we explore the following research question: Can we reduce the discrimination of DNN models by only debiasing the classification head, even with biased representations as inputs? To this end, we propose a new mitigation technique, namely, Representation Neutralization for Fairness (RNF) that achieves fairness by debiasing only the task-specific classification head of DNN models. To this end, we leverage samples with the same ground-truth label but different sensitive attributes, and use their neutralized representations to train the classification head of the DNN model. The key idea of RNF is to discourage the classification head from capturing spurious correlation between fairness sensitive information in encoder representations with specific class labels. To address low-resource settings with no access to sensitive attribute annotations, we leverage a bias-amplified model to generate proxy annotations for sensitive attributes. Experimental results over several benchmark datasets demonstrate our RNF framework to effectively reduce discrimination of DNN models with minimal degradation in task-specific performance.
count=1
* EDGE: Explaining Deep Reinforcement Learning Policies
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/65c89f5a9501a04c073b354f03791b1f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/65c89f5a9501a04c073b354f03791b1f-Paper.pdf)]
    * Title: EDGE: Explaining Deep Reinforcement Learning Policies
    * Year: `2021`
    * Authors: Wenbo Guo, Xian Wu, Usmann Khan, Xinyu Xing
    * Abstract: With the rapid development of deep reinforcement learning (DRL) techniques, there is an increasing need to understand and interpret DRL policies. While recent research has developed explanation methods to interpret how an agent determines its moves, they cannot capture the importance of actions/states to a game's final result. In this work, we propose a novel self-explainable model that augments a Gaussian process with a customized kernel function and an interpretable predictor. Together with the proposed model, we also develop a parameter learning procedure that leverages inducing points and variational inference to improve learning efficiency. Using our proposed model, we can predict an agent's final rewards from its game episodes and extract time step importance within episodes as strategy-level explanations for that agent. Through experiments on Atari and MuJoCo games, we verify the explanation fidelity of our method and demonstrate how to employ interpretation to understand agent behavior, discover policy vulnerabilities, remediate policy errors, and even defend against adversarial attacks.
count=1
* Chebyshev-Cantelli PAC-Bayes-Bennett Inequality for the Weighted Majority Vote
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/69386f6bb1dfed68692a24c8686939b9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf)]
    * Title: Chebyshev-Cantelli PAC-Bayes-Bennett Inequality for the Weighted Majority Vote
    * Year: `2021`
    * Authors: Yi-Shan Wu, Andres Masegosa, Stephan Lorenzen, Christian Igel, Yevgeny Seldin
    * Abstract: We present a new second-order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the Chebyshev-Cantelli inequality (a.k.a. one-sided Chebyshev’s), which is amenable to efficient minimization. The new form resolves the optimization challenge faced by prior oracle bounds based on the Chebyshev-Cantelli inequality, the C-bounds [Germain et al., 2015], and, at the same time, it improves on the oracle bound based on second order Markov’s inequality introduced by Masegosa et al. [2020]. We also derive a new concentration of measure inequality, which we name PAC-Bayes-Bennett, since it combines PAC-Bayesian bounding with Bennett’s inequality. We use it for empirical estimation of the oracle bound. The PAC-Bayes-Bennett inequality improves on the PAC-Bayes-Bernstein inequality of Seldin et al. [2012]. We provide an empirical evaluation demonstrating that the new bounds can improve on the work of Masegosa et al. [2020]. Both the parametric form of the Chebyshev-Cantelli inequality and the PAC-Bayes-Bennett inequality may be of independent interest for the study of concentration of measure in other domains.
count=1
* Better Algorithms for Individually Fair $k$-Clustering
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/6f221fcb5c504fe96789df252123770b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/6f221fcb5c504fe96789df252123770b-Paper.pdf)]
    * Title: Better Algorithms for Individually Fair $k$-Clustering
    * Year: `2021`
    * Authors: Maryam Negahbani, Deeparnab Chakrabarty
    * Abstract: We study data clustering problems with $\ell_p$-norm objectives (e.g. \textsc{$k$-Median} and \textsc{$k$-Means}) in the context of individual fairness. The dataset consists of $n$ points, and we want to find $k$ centers such that (a) the objective is minimized, while (b) respecting the individual fairness constraint that every point $v$ has a center within a distance at most $r(v)$, where $r(v)$ is $v$'s distance to its $(n/k)$th nearest point. Jung, Kannan, and Lutz [FORC 2020] introduced this concept and designed a clustering algorithm with provable (approximate) fairness and objective guarantees for the $\ell_\infty$ or \textsc{$k$-Center} objective. Mahabadi and Vakilian [ICML 2020] revisited this problem to give a local-search algorithm for all $\ell_p$-norms. Empirically, their algorithms outperform Jung et. al.'s by a large margin in terms of cost (for \textsc{$k$-Median} and \textsc{$k$-Means}), but they incur a reasonable loss in fairness. In this paper, our main contribution is to use Linear Programming (LP) techniques to obtain better algorithms for this problem, both in theory and in practice. We prove that by modifying known LP rounding techniques, one gets a worst-case guarantee on the objective which is much better than in MV20, and empirically, this objective is extremely close to the optimal. Furthermore, our theoretical fairness guarantees are comparable with MV20 in theory, and empirically, we obtain noticeably fairer solutions.Although solving the LP {\em exactly} might be prohibitive, we demonstrate that in practice, a simple sparsification technique drastically improves the run-time of our algorithm.
count=1
* Progressive Coordinate Transforms for Monocular 3D Object Detection
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/6f3ef77ac0e3619e98159e9b6febf557-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/6f3ef77ac0e3619e98159e9b6febf557-Paper.pdf)]
    * Title: Progressive Coordinate Transforms for Monocular 3D Object Detection
    * Year: `2021`
    * Authors: Li Wang, Li Zhang, Yi Zhu, Zhi Zhang, Tong He, Mu Li, Xiangyang Xue
    * Abstract: Recognizing and localizing objects in the 3D space is a crucial ability for an AI agent to perceive its surrounding environment. While significant progress has been achieved with expensive LiDAR point clouds, it poses a great challenge for 3D object detection given only a monocular image. While there exist different alternatives for tackling this problem, it is found that they are either equipped with heavy networks to fuse RGB and depth information or empirically ineffective to process millions of pseudo-LiDAR points. With in-depth examination, we realize that these limitations are rooted in inaccurate object localization. In this paper, we propose a novel and lightweight approach, dubbed {\em Progressive Coordinate Transforms} (PCT) to facilitate learning coordinate representations. Specifically, a localization boosting mechanism with confidence-aware loss is introduced to progressively refine the localization prediction. In addition, semantic image representation is also exploited to compensate for the usage of patch proposals. Despite being lightweight and simple, our strategy allows us to establish a new state-of-the-art among the monocular 3D detectors on the competitive KITTI benchmark. At the same time, our proposed PCT shows great generalization to most coordinate-based 3D detection frameworks.
count=1
* Revisiting Smoothed Online Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/70fc5f043205720a49d973d280eb83e7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/70fc5f043205720a49d973d280eb83e7-Paper.pdf)]
    * Title: Revisiting Smoothed Online Learning
    * Year: `2021`
    * Authors: Lijun Zhang, Wei Jiang, Shiyin Lu, Tianbao Yang
    * Abstract: In this paper, we revisit the problem of smoothed online learning, in which the online learner suffers both a hitting cost and a switching cost, and target two performance metrics: competitive ratio and dynamic regret with switching cost. To bound the competitive ratio, we assume the hitting cost is known to the learner in each round, and investigate the simple idea of balancing the two costs by an optimization problem. Surprisingly, we find that minimizing the hitting cost alone is $\max(1, \frac{2}{\alpha})$-competitive for $\alpha$-polyhedral functions and $1 + \frac{4}{\lambda}$-competitive for $\lambda$-quadratic growth functions, both of which improve state-of-the-art results significantly. Moreover, when the hitting cost is both convex and $\lambda$-quadratic growth, we reduce the competitive ratio to $1 + \frac{2}{\sqrt{\lambda}}$ by minimizing the weighted sum of the hitting cost and the switching cost. To bound the dynamic regret with switching cost, we follow the standard setting of online convex optimization, in which the hitting cost is convex but hidden from the learner before making predictions. We modify Ader, an existing algorithm designed for dynamic regret, slightly to take into account the switching cost when measuring the performance. The proposed algorithm, named as Smoothed Ader, attains an optimal $O(\sqrt{T(1+P_T)})$ bound for dynamic regret with switching cost, where $P_T$ is the path-length of the comparator sequence. Furthermore, if the hitting cost is accessible in the beginning of each round, we obtain a similar guarantee without the bounded gradient condition, and establish an $\Omega(\sqrt{T(1+P_T)})$ lower bound to confirm the optimality.
count=1
* Test-time Collective Prediction
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/722caafb4825ef5d8670710fa29087cf-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/722caafb4825ef5d8670710fa29087cf-Paper.pdf)]
    * Title: Test-time Collective Prediction
    * Year: `2021`
    * Authors: Celestine Mendler-Dünner, Wenshuo Guo, Stephen Bates, Michael Jordan
    * Abstract: An increasingly common setting in machine learning involves multiple parties, each with their own data, who want to jointly make predictions on future test points. Agents wish to benefit from the collective expertise of the full set of agents to make better predictions than they would individually, but may not be willing to release labeled data or model parameters. In this work, we explore a decentralized mechanism to make collective predictions at test time, that is inspired by the literature in social science on human consensus-making. Building on a query model to facilitate information exchange among agents, our approach leverages each agent’s pre-trained model without relying on external validation, model retraining, or data pooling. A theoretical analysis shows that our approach recovers inverse mean-squared-error (MSE) weighting in the large-sample limit which is known to be the optimal way to combine independent, unbiased estimators. Empirically, we demonstrate that our scheme effectively combines models with differing quality across the input space: the proposed consensus prediction achieves significant gains over classical model averaging, and even outperforms weighted averaging schemes that have access to additional validation data. Finally, we propose a decentralized Jackknife procedure as a tool to evaluate the sensitivity of the collective predictions with respect to a single agent's opinion.
count=1
* Fair Clustering Under a Bounded Cost
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/781877bda0783aac5f1cf765c128b437-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/781877bda0783aac5f1cf765c128b437-Paper.pdf)]
    * Title: Fair Clustering Under a Bounded Cost
    * Year: `2021`
    * Authors: Seyed Esmaeili, Brian Brubach, Aravind Srinivasan, John Dickerson
    * Abstract: Clustering is a fundamental unsupervised learning problem where a dataset is partitioned into clusters that consist of nearby points in a metric space. A recent variant, fair clustering, associates a color with each point representing its group membership and requires that each color has (approximately) equal representation in each cluster to satisfy group fairness. In this model, the cost of the clustering objective increases due to enforcing fairness in the algorithm. The relative increase in the cost, the ```````''price of fairness,'' can indeed be unbounded. Therefore, in this paper we propose to treat an upper bound on the clustering objective as a constraint on the clustering problem, and to maximize equality of representation subject to it. We consider two fairness objectives: the group utilitarian objective and the group egalitarian objective, as well as the group leximin objective which generalizes the group egalitarian objective. We derive fundamental lower bounds on the approximation of the utilitarian and egalitarian objectives and introduce algorithms with provable guarantees for them. For the leximin objective we introduce an effective heuristic algorithm. We further derive impossibility results for other natural fairness objectives. We conclude with experimental results on real-world datasets that demonstrate the validity of our algorithms.
count=1
* Adversarial Examples for k-Nearest Neighbor Classifiers Based on Higher-Order Voronoi Diagrams
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/82ca5dd156cc926b2992f73c2896f761-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/82ca5dd156cc926b2992f73c2896f761-Paper.pdf)]
    * Title: Adversarial Examples for k-Nearest Neighbor Classifiers Based on Higher-Order Voronoi Diagrams
    * Year: `2021`
    * Authors: Chawin Sitawarin, Evgenios Kornaropoulos, Dawn Song, David Wagner
    * Abstract: Adversarial examples are a widely studied phenomenon in machine learning models. While most of the attention has been focused on neural networks, other practical models also suffer from this issue. In this work, we propose an algorithm for evaluating the adversarial robustness of $k$-nearest neighbor classification, i.e., finding a minimum-norm adversarial example. Diverging from previous proposals, we propose the first geometric approach by performing a search that expands outwards from a given input point. On a high level, the search radius expands to the nearby higher-order Voronoi cells until we find a cell that classifies differently from the input point. To scale the algorithm to a large $k$, we introduce approximation steps that find perturbation with smaller norm, compared to the baselines, in a variety of datasets. Furthermore, we analyze the structural properties of a dataset where our approach outperforms the competition.
count=1
* Assessing Fairness in the Presence of Missing Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/85dca1d270f7f9aef00c9d372f114482-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/85dca1d270f7f9aef00c9d372f114482-Paper.pdf)]
    * Title: Assessing Fairness in the Presence of Missing Data
    * Year: `2021`
    * Authors: Yiliang Zhang, Qi Long
    * Abstract: Missing data are prevalent and present daunting challenges in real data analysis. While there is a growing body of literature on fairness in analysis of fully observed data, there has been little theoretical work on investigating fairness in analysis of incomplete data. In practice, a popular analytical approach for dealing with missing data is to use only the set of complete cases, i.e., observations with all features fully observed to train a prediction algorithm. However, depending on the missing data mechanism, the distribution of complete cases and the distribution of the complete data may be substantially different. When the goal is to develop a fair algorithm in the complete data domain where there are no missing values, an algorithm that is fair in the complete case domain may show disproportionate bias towards some marginalized groups in the complete data domain. To fill this significant gap, we study the problem of estimating fairness in the complete data domain for an arbitrary model evaluated merely using complete cases. We provide upper and lower bounds on the fairness estimation error and conduct numerical experiments to assess our theoretical results. Our work provides the first known theoretical results on fairness guarantee in analysis of incomplete data.
count=1
* Evaluating model performance under worst-case subpopulations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/908075ea2c025c335f4865f7db427062-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/908075ea2c025c335f4865f7db427062-Paper.pdf)]
    * Title: Evaluating model performance under worst-case subpopulations
    * Year: `2021`
    * Authors: Mike Li, Hongseok Namkoong, Shangzhou Xia
    * Abstract: The performance of ML models degrades when the training population is different from that seen under operation. Towards assessing distributional robustness, we study the worst-case performance of a model over all subpopulations of a given size, defined with respect to core attributes $Z$. This notion of robustness can consider arbitrary (continuous) attributes $Z$, and automatically accounts for complex intersectionality in disadvantaged groups. We develop a scalable yet principled two-stage estimation procedure that can evaluate the robustness of state-of-the-art models. We prove that our procedure enjoys several finite-sample convergence guarantees, including dimension-free convergence. Instead of overly conservative notions based on Rademacher complexities, our evaluation error depends on the dimension of $Z$ only through the out-of-sample error in estimating the performance conditional on $Z$. On real datasets, we demonstrate that our method certifies the robustness of a model and prevents deployment of unreliable models.
count=1
* Boosting with Multiple Sources
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/9103820024efb30b451d006dc4ab3370-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/9103820024efb30b451d006dc4ab3370-Paper.pdf)]
    * Title: Boosting with Multiple Sources
    * Year: `2021`
    * Authors: Corinna Cortes, Mehryar Mohri, Dmitry Storcheus, Ananda Theertha Suresh
    * Abstract: We study the problem of learning accurate ensemble predictors, in particular boosting, in the presence of multiple source domains. We show that the standard convex combination ensembles in general cannot succeed in this scenario and adopt instead a domain-weighted combination. We introduce and analyze a new boosting algorithm, MULTIBOOST, for this scenario and show that it benefits from favorable theoretical guarantees. We also report the results of several experiments with our algorithm demonstrating that it outperforms natural baselines on multi-source text-based, image-based and tabular data. We further present an extension of our algorithm to the federated learning scenario and report favorable experimental results for that setting as well. Additionally, we describe in detail an extension of our algorithm to the multi-class setting, MCMULTIBOOST, for which we also report experimental results.
count=1
* Understanding the Under-Coverage Bias in Uncertainty Estimation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/9854d7afce413aa13cd0a1d39d0bcec5-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/9854d7afce413aa13cd0a1d39d0bcec5-Paper.pdf)]
    * Title: Understanding the Under-Coverage Bias in Uncertainty Estimation
    * Year: `2021`
    * Authors: Yu Bai, Song Mei, Huan Wang, Caiming Xiong
    * Abstract: Estimating the data uncertainty in regression tasks is often done by learning a quantile function or a prediction interval of the true label conditioned on the input. It is frequently observed that quantile regression---a vanilla algorithm for learning quantiles with asymptotic guarantees---tends to *under-cover* than the desired coverage level in reality. While various fixes have been proposed, a more fundamental understanding of why this under-coverage bias happens in the first place remains elusive.In this paper, we present a rigorous theoretical study on the coverage of uncertainty estimation algorithms in learning quantiles. We prove that quantile regression suffers from an inherent under-coverage bias, in a vanilla setting where we learn a realizable linear quantile function and there is more data than parameters. More quantitatively, for $\alpha>0.5$ and small $d/n$, the $\alpha$-quantile learned by quantile regression roughly achieves coverage $\alpha - (\alpha-1/2)\cdot d/n$ regardless of the noise distribution, where $d$ is the input dimension and $n$ is the number of training data. Our theory reveals that this under-coverage bias stems from a certain high-dimensional parameter estimation error that is not implied by existing theories on quantile regression. Experiments on simulated and real data verify our theory and further illustrate the effect of various factors such as sample size and model capacity on the under-coverage bias in more practical setups.
count=1
* SubTab: Subsetting Features of Tabular Data for Self-Supervised Representation Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/9c8661befae6dbcd08304dbf4dcaf0db-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/9c8661befae6dbcd08304dbf4dcaf0db-Paper.pdf)]
    * Title: SubTab: Subsetting Features of Tabular Data for Self-Supervised Representation Learning
    * Year: `2021`
    * Authors: Talip Ucar, Ehsan Hajiramezanali, Lindsay Edwards
    * Abstract: Self-supervised learning has been shown to be very effective in learning useful representations, and yet much of the success is achieved in data types such as images, audio, and text. The success is mainly enabled by taking advantage of spatial, temporal, or semantic structure in the data through augmentation. However, such structure may not exist in tabular datasets commonly used in fields such as healthcare, making it difficult to design an effective augmentation method, and hindering a similar progress in tabular data setting. In this paper, we introduce a new framework, Subsetting features of Tabular data (SubTab), that turns the task of learning from tabular data into a multi-view representation learning problem by dividing the input features to multiple subsets. We argue that reconstructing the data from the subset of its features rather than its corrupted version in an autoencoder setting can better capture its underlying latent representation. In this framework, the joint representation can be expressed as the aggregate of latent variables of the subsets at test time, which we refer to as collaborative inference. Our experiments show that the SubTab achieves the state of the art (SOTA) performance of 98.31% on MNIST in tabular setting, on par with CNN-based SOTA models, and surpasses existing baselines on three other real-world datasets by a significant margin.
count=1
* Risk Minimization from Adaptively Collected Data: Guarantees for Supervised and Policy Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/a0ae15571eb4a97ac1c34a114f1bb179-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/a0ae15571eb4a97ac1c34a114f1bb179-Paper.pdf)]
    * Title: Risk Minimization from Adaptively Collected Data: Guarantees for Supervised and Policy Learning
    * Year: `2021`
    * Authors: Aurelien Bibaut, Nathan Kallus, Maria Dimakopoulou, Antoine Chambaz, Mark van der Laan
    * Abstract: Empirical risk minimization (ERM) is the workhorse of machine learning, whether for classification and regression or for off-policy policy learning, but its model-agnostic guarantees can fail when we use adaptively collected data, such as the result of running a contextual bandit algorithm. We study a generic importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provide first-of-their-kind generalization guarantees and fast convergence rates. Our results are based on a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, we provide fast rates that leverage the strong convexity of squared-error loss. For policy learning, we provide regret guarantees that close an open gap in the existing literature whenever exploration decays to zero, as is the case for bandit-collected data. An empirical investigation validates our theory.
count=1
* Fast Axiomatic Attribution for Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/a284df1155ec3e67286080500df36a9a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/a284df1155ec3e67286080500df36a9a-Paper.pdf)]
    * Title: Fast Axiomatic Attribution for Neural Networks
    * Year: `2021`
    * Authors: Robin Hesse, Simone Schaub-Meyer, Stefan Roth
    * Abstract: Mitigating the dependence on spurious correlations present in the training dataset is a quickly emerging and important topic of deep learning. Recent approaches include priors on the feature attribution of a deep neural network (DNN) into the training process to reduce the dependence on unwanted features. However, until now one needed to trade off high-quality attributions, satisfying desirable axioms, against the time required to compute them. This in turn either led to long training times or ineffective attribution priors. In this work, we break this trade-off by considering a special class of efficiently axiomatically attributable DNNs for which an axiomatic feature attribution can be computed with only a single forward/backward pass. We formally prove that nonnegatively homogeneous DNNs, here termed $\mathcal{X}$-DNNs, are efficiently axiomatically attributable and show that they can be effortlessly constructed from a wide range of regular DNNs by simply removing the bias term of each layer. Various experiments demonstrate the advantages of $\mathcal{X}$-DNNs, beating state-of-the-art generic attribution methods on regular DNNs for training with attribution priors.
count=1
* Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/a8fbbd3b11424ce032ba813493d95ad7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf)]
    * Title: Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient
    * Year: `2021`
    * Authors: David Applegate, Mateo Diaz, Oliver Hinder, Haihao Lu, Miles Lubin, Brendan O'Donoghue, Warren Schudy
    * Abstract: We present PDLP, a practical first-order method for linear programming (LP) that can solve to the high levels of accuracy that are expected in traditional LP applications. In addition, it can scale to very large problems because its core operation is matrix-vector multiplications. PDLP is derived by applying the primal-dual hybrid gradient (PDHG) method, popularized by Chambolle and Pock (2011), to a saddle-point formulation of LP. PDLP enhances PDHG for LP by combining several new techniques with older tricks from the literature; the enhancements include diagonal preconditioning, presolving, adaptive step sizes, and adaptive restarting. PDLP improves the state of the art for first-order methods applied to LP. We compare PDLP with SCS, an ADMM-based solver, on a set of 383 LP instances derived from MIPLIB 2017. With a target of $10^{-8}$ relative accuracy and 1 hour time limit, PDLP achieves a 6.3x reduction in the geometric mean of solve times and a 4.6x reduction in the number of instances unsolved (from 227 to 49). Furthermore, we highlight standard benchmark instances and a large-scale application (PageRank) where our open-source prototype of PDLP, written in Julia, outperforms a commercial LP solver.
count=1
* An online passive-aggressive algorithm for difference-of-squares classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/b2ea5e977c5fc1ccfa74171a9723dd61-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/b2ea5e977c5fc1ccfa74171a9723dd61-Paper.pdf)]
    * Title: An online passive-aggressive algorithm for difference-of-squares classification
    * Year: `2021`
    * Authors: Lawrence Saul
    * Abstract: We investigate a low-rank model of quadratic classification inspired by previous work on factorization machines, polynomial networks, and capsule-based architectures for visual object recognition. The model is parameterized by a pair of affine transformations, and it classifies examples by comparing the magnitudes of vectors that these transformations produce. The model is also over-parameterized in the sense that different pairs of affine transformations can describe classifiers with the same decision boundary and confidence scores. We show that such pairs arise from discrete and continuous symmetries of the model’s parameter space: in particular, the latter define symmetry groups of rotations and Lorentz transformations, and we use these group structures to devise appropriately invariant procedures for model alignment and averaging. We also leverage the form of the model’s decision boundary to derive simple margin-based updates for online learning. Here we explore a strategy of passive-aggressive learning: for each example, we compute the minimum change in parameters that is required to predict its correct label with high confidence. We derive these updates by solving a quadratically constrained quadratic program (QCQP); interestingly, this QCQP is nonconvex but tractable, and it can be solved efficiently by elementary methods. We highlight the conceptual and practical contributions of this approach. Conceptually, we show that it extends the paradigm of passive-aggressive learning to a larger family of nonlinear models for classification. Practically, we show that these models perform well on large-scale problems in online learning.
count=1
* Two steps to risk sensitivity
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/ba530cdf0a884348613f2aaa3a5ba5e8-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/ba530cdf0a884348613f2aaa3a5ba5e8-Paper.pdf)]
    * Title: Two steps to risk sensitivity
    * Year: `2021`
    * Authors: Christopher Gagne, Peter Dayan
    * Abstract: Distributional reinforcement learning (RL) – in which agents learn about all the possible long-term consequences of their actions, and not just the expected value – is of great recent interest. One of the most important affordances of a distributional view is facilitating a modern, measured, approach to risk when outcomes are not completely certain. By contrast, psychological and neuroscientific investigations into decision making under risk have utilized a variety of more venerable theoretical models such as prospect theory that lack axiomatically desirable properties such as coherence. Here, we consider a particularly relevant risk measure for modeling human and animal planning, called conditional value-at-risk (CVaR), which quantifies worst-case outcomes (e.g., vehicle accidents or predation). We first adopt a conventional distributional approach to CVaR in a sequential setting and reanalyze the choices of human decision-makers in the well-known two-step task, revealing substantial risk aversion that had been lurking under stickiness and perseveration. We then consider a further critical property of risk sensitivity, namely time consistency, showing alternatives to this form of CVaR that enjoy this desirable characteristic. We use simulations to examine settings in which the various forms differ in ways that have implications for human and animal planning and behavior.
count=1
* NAS-Bench-x11 and the Power of Learning Curves
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/be3159ad04564bfb90db9e32851ebf9c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/be3159ad04564bfb90db9e32851ebf9c-Paper.pdf)]
    * Title: NAS-Bench-x11 and the Power of Learning Curves
    * Year: `2021`
    * Authors: Shen Yan, Colin White, Yash Savani, Frank Hutter
    * Abstract: While early research in neural architecture search (NAS) required extreme computational resources, the recent releases of tabular and surrogate benchmarks have greatly increased the speed and reproducibility of NAS research. However, two of the most popular benchmarks do not provide the full training information for each architecture. As a result, on these benchmarks it is not possible to evaluate many types of multi-fidelity algorithms, such as learning curve extrapolation, that require evaluating architectures at arbitrary epochs. In this work, we present a method using singular value decomposition and noise modeling to create surrogate benchmarks, NAS-Bench-111, NAS-Bench-311, and NAS-Bench-NLP11, that output the full training information for each architecture, rather than just the final validation accuracy. We demonstrate the power of using the full training information by introducing a learning curve extrapolation framework to modify single-fidelity algorithms, showing that it leads to improvements over popular single-fidelity algorithms which claimed to be state-of-the-art upon release.
count=1
* Representer Point Selection via Local Jacobian Expansion for Post-hoc Classifier Explanation of Deep Neural Networks and Ensemble Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/c460dc0f18fc309ac07306a4a55d2fd6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/c460dc0f18fc309ac07306a4a55d2fd6-Paper.pdf)]
    * Title: Representer Point Selection via Local Jacobian Expansion for Post-hoc Classifier Explanation of Deep Neural Networks and Ensemble Models
    * Year: `2021`
    * Authors: Yi Sui, Ga Wu, Scott Sanner
    * Abstract: Explaining the influence of training data on deep neural network predictions is a critical tool for debugging models through data curation. A recent tractable and appealing approach for this task was provided via the concept of Representer Point Selection (RPS), i.e. a method the leverages the dual form of $l_2$ regularized optimization in the last layer of the neural network to identify the contribution of training points to the prediction. However, two key drawbacks of RPS are that they (i) lead to disagreement between the originally trained network and the RP regularized network modification and (ii) often yield a static ranking of training data for the same class, independent of the data being classified. Inspired by the RPS approach, we propose an alternative method based on a local Jacobian Taylor expansion (LJE) of the Jacobian.We empirically compared RPS-LJE with the original RPS-$l_2$ on image classification (with ResNet), text classification recurrent neural networks (with Bi-LSTM), and tabular classification (with XGBoost) tasks.Quantitatively, we show that RPS-LJE slightly outperforms RPS-$l_2$ and other state-of-the-art data explanation methods by up to 3\% on a data debugging task. Qualitatively, we observe that RPS-LJE provides individualized explanations for each test data point rather than the class-specific static ranking of points in the original approach. Overall, RPS-LJE represents a novel approach to RPS that provides a powerful tool for data-oriented explanation and debugging.
count=1
* Learning Semantic Representations to Verify Hardware Designs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/c5aa65949d20f6b20e1a922c13d974e7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/c5aa65949d20f6b20e1a922c13d974e7-Paper.pdf)]
    * Title: Learning Semantic Representations to Verify Hardware Designs
    * Year: `2021`
    * Authors: Shobha Vasudevan, Wenjie (Joe) Jiang, David Bieber, Rishabh Singh, hamid shojaei, C. Richard Ho, Charles Sutton
    * Abstract: Verification is a serious bottleneck in the industrial hardware design cycle, routinely requiring person-years of effort. Practical verification relies on a "best effort" process that simulates the design on test inputs. This suggests a new research question: Can this simulation data be exploited to learn a continuous representation of a hardware design that allows us to predict its functionality? As a first approach to this new problem, we introduce Design2Vec, a deep architecture that learns semantic abstractions of hardware designs. The key idea is to work at a higher level of abstraction than the gate or the bit level, namely the Register Transfer Level (RTL), which is somewhat analogous to software source code, and can be represented by a graph that incorporates control and data flow. This allows us to learn representations of RTL syntax and semantics using a graph neural network. We apply these representations to several tasks within verification, including predicting what cover points of the design will be exercised by a test, and generating new tests that will exercise desired cover points. We evaluate Design2Vec on three real-world hardware designs, including an industrial chip used in commercial data centers. Our results demonstrate that Design2Vec dramatically outperforms baseline approaches that do not incorporate the RTL semantics, scales to industrial designs, and can generate tests that exercise design points that are currently hard to cover with manually written tests by design verification experts.
count=1
* Sampling  with Trusthworthy Constraints:  A Variational Gradient Framework   
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/c61aed648da48aa3893fb3eaadd88a7f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/c61aed648da48aa3893fb3eaadd88a7f-Paper.pdf)]
    * Title: Sampling  with Trusthworthy Constraints:  A Variational Gradient Framework   
    * Year: `2021`
    * Authors: Xingchao Liu, Xin Tong, Qiang Liu
    * Abstract: Sampling-based inference and learning techniques, especially Bayesian inference, provide an essential approach to handling uncertainty in machine learning (ML). As these techniques are increasingly used in daily life, it becomes essential to safeguard the ML systems with various trustworthy-related constraints, such as fairness, safety, interpretability. Mathematically, enforcing these constraints in probabilistic inference can be cast into sampling from intractable distributions subject to general nonlinear constraints, for which practical efficient algorithms are still largely missing. In this work, we propose a family of constrained sampling algorithms which generalize Langevin Dynamics (LD) and Stein Variational Gradient Descent (SVGD) to incorporate a moment constraint specified by a general nonlinear function. By exploiting the gradient flow structure of LD and SVGD, we derive two types of algorithms for handling constraints, including a primal-dual gradient approach and the constraint controlled gradient descent approach. We investigate the continuous-time mean-field limit of these algorithms and show that they have O(1/t) convergence under mild conditions. Moreover, the LD variant converges linearly assuming that a log Sobolev like inequality holds. Various numerical experiments are conducted to demonstrate the efficiency of our algorithms in trustworthy settings.
count=1
* A Framework to Learn with Interpretation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/cbb6a3b884f4f88b3a8e3d44c636cbd8-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/cbb6a3b884f4f88b3a8e3d44c636cbd8-Paper.pdf)]
    * Title: A Framework to Learn with Interpretation
    * Year: `2021`
    * Authors: Jayneel Parekh, Pavlo Mozharovskyi, Florence d'Alché-Buc
    * Abstract: To tackle interpretability in deep learning, we present a novel framework to jointly learn a predictive model and its associated interpretation model. The interpreter provides both local and global interpretability about the predictive model in terms of human-understandable high level attribute functions, with minimal loss of accuracy. This is achieved by a dedicated architecture and well chosen regularization penalties. We seek for a small-size dictionary of high level attribute functions that take as inputs the outputs of selected hidden layers and whose outputs feed a linear classifier. We impose strong conciseness on the activation of attributes with an entropy-based criterion while enforcing fidelity to both inputs and outputs of the predictive model. A detailed pipeline to visualize the learnt features is also developed. Moreover, besides generating interpretable models by design, our approach can be specialized to provide post-hoc interpretations for a pre-trained neural network. We validate our approach against several state-of-the-art methods on multiple datasets and show its efficacy on both kinds of tasks.
count=1
* Learning with Holographic Reduced Representations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/d71dd235287466052f1630f31bde7932-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/d71dd235287466052f1630f31bde7932-Paper.pdf)]
    * Title: Learning with Holographic Reduced Representations
    * Year: `2021`
    * Authors: Ashwinkumar Ganesan, Hang Gao, Sunil Gandhi, Edward Raff, Tim Oates, James Holt, Mark McLean
    * Abstract: Holographic Reduced Representations (HRR) are a method for performing symbolic AI on top of real-valued vectors by associating each vector with an abstract concept, and providing mathematical operations to manipulate vectors as if they were classic symbolic objects. This method has seen little use outside of older symbolic AI work and cognitive science. Our goal is to revisit this approach to understand if it is viable for enabling a hybrid neural-symbolic approach to learning as a differential component of a deep learning architecture. HRRs today are not effective in a differential solution due to numerical instability, a problem we solve by introducing a projection step that forces the vectors to exist in a well behaved point in space. In doing so we improve the concept retrieval efficacy of HRRs by over $100\times$. Using multi-label classification we demonstrate how to leverage the symbolic HRR properties to develop a output layer and loss function that is able to learn effectively, and allows us to investigate some of the pros and cons of an HRR neuro-symbolic learning approach.
count=1
* Improving Compositionality of Neural Networks by Decoding Representations to Inputs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/e0308d73972d8dd5e2dd27853106386e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/e0308d73972d8dd5e2dd27853106386e-Paper.pdf)]
    * Title: Improving Compositionality of Neural Networks by Decoding Representations to Inputs
    * Year: `2021`
    * Authors: Mike Wu, Noah Goodman, Stefano Ermon
    * Abstract: In traditional software programs, it is easy to trace program logic from variables back to input, apply assertion statements to block erroneous behavior, and compose programs together. Although deep learning programs have demonstrated strong performance on novel applications, they sacrifice many of the functionalities of traditional software programs. With this as motivation, we take a modest first step towards improving deep learning programs by jointly training a generative model to constrain neural network activations to "decode" back to inputs. We call this design a Decodable Neural Network, or DecNN. Doing so enables a form of compositionality in neural networks, where one can recursively compose DecNN with itself to create an ensemble-like model with uncertainty. In our experiments, we demonstrate applications of this uncertainty to out-of-distribution detection, adversarial example detection, and calibration --- while matching standard neural networks in accuracy. We further explore this compositionality by combining DecNN with pretrained models, where we show promising results that neural networks can be regularized from using protected features.
count=1
* Improving Deep Learning Interpretability by Saliency Guided Training
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/e0cd3f16f9e883ca91c2a4c24f47b3d9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/e0cd3f16f9e883ca91c2a4c24f47b3d9-Paper.pdf)]
    * Title: Improving Deep Learning Interpretability by Saliency Guided Training
    * Year: `2021`
    * Authors: Aya Abdelsalam Ismail, Hector Corrada Bravo, Soheil Feizi
    * Abstract: Saliency methods have been widely used to highlight important input features in model predictions. Most existing methods use backpropagation on a modified gradient function to generate saliency maps. Thus, noisy gradients can result in unfaithful feature attributions. In this paper, we tackle this issue and introduce a {\it saliency guided training} procedure for neural networks to reduce noisy gradients used in predictions while retaining the predictive performance of the model. Our saliency guided training procedure iteratively masks features with small and potentially noisy gradients while maximizing the similarity of model outputs for both masked and unmasked inputs. We apply the saliency guided training procedure to various synthetic and real data sets from computer vision, natural language processing, and time series across diverse neural architectures, including Recurrent Neural Networks, Convolutional Networks, and Transformers. Through qualitative and quantitative evaluations, we show that saliency guided training procedure significantly improves model interpretability across various domains while preserving its predictive performance.
count=1
* Fair Sequential Selection Using Supervised Learning Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/ed277964a8959e72a0d987e598dfbe72-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/ed277964a8959e72a0d987e598dfbe72-Paper.pdf)]
    * Title: Fair Sequential Selection Using Supervised Learning Models
    * Year: `2021`
    * Authors: Mohammad Mahdi Khalili, Xueru Zhang, Mahed Abroshan
    * Abstract: We consider a selection problem where sequentially arrived applicants apply for a limited number of positions/jobs. At each time step, a decision maker accepts or rejects the given applicant using a pre-trained supervised learning model until all the vacant positions are filled. In this paper, we discuss whether the fairness notions (e.g., equal opportunity, statistical parity, etc.) that are commonly used in classification problems are suitable for the sequential selection problems. In particular, we show that even with a pre-trained model that satisfies the common fairness notions, the selection outcomes may still be biased against certain demographic groups. This observation implies that the fairness notions used in classification problems are not suitable for a selection problem where the applicants compete for a limited number of positions. We introduce a new fairness notion, ``Equal Selection (ES),'' suitable for sequential selection problems and propose a post-processing approach to satisfy the ES fairness notion. We also consider a setting where the applicants have privacy concerns, and the decision maker only has access to the noisy version of sensitive attributes. In this setting, we can show that the \textit{perfect} ES fairness can still be attained under certain conditions.
count=1
* How Powerful are Performance Predictors in Neural Architecture Search?
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/ef575e8837d065a1683c022d2077d342-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/ef575e8837d065a1683c022d2077d342-Paper.pdf)]
    * Title: How Powerful are Performance Predictors in Neural Architecture Search?
    * Year: `2021`
    * Authors: Colin White, Arber Zela, Robin Ru, Yang Liu, Frank Hutter
    * Abstract: Early methods in the rapidly developing field of neural architecture search (NAS) required fully training thousands of neural networks. To reduce this extreme computational cost, dozens of techniques have since been proposed to predict the final performance of neural architectures. Despite the success of such performance prediction methods, it is not well-understood how different families of techniques compare to one another, due to the lack of an agreed-upon evaluation metric and optimization for different constraints on the initialization time and query time. In this work, we give the first large-scale study of performance predictors by analyzing 31 techniques ranging from learning curve extrapolation, to weight-sharing, to supervised learning, to zero-cost proxies. We test a number of correlation- and rank-based performance measures in a variety of settings, as well as the ability of each technique to speed up predictor-based NAS frameworks. Our results act as recommendations for the best predictors to use in different settings, and we show that certain families of predictors can be combined to achieve even better predictive power, opening up promising research directions. We release our code, featuring a library of 31 performance predictors.
count=1
* Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/f1507aba9fc82ffa7cc7373c58f8a613-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/f1507aba9fc82ffa7cc7373c58f8a613-Paper.pdf)]
    * Title: Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning
    * Year: `2021`
    * Authors: Jannik Kossen, Neil Band, Clare Lyle, Aidan N. Gomez, Thomas Rainforth, Yarin Gal
    * Abstract: We challenge a common assumption underlying most supervised deep learning: that a model makes a prediction depending only on its parameters and the features of a single input. To this end, we introduce a general-purpose deep learning architecture that takes as input the entire dataset instead of processing one datapoint at a time. Our approach uses self-attention to reason about relationships between datapoints explicitly, which can be seen as realizing non-parametric models using parametric attention mechanisms. However, unlike conventional non-parametric models, we let the model learn end-to-end from the data how to make use of other datapoints for prediction. Empirically, our models solve cross-datapoint lookup and complex reasoning tasks unsolvable by traditional deep learning models. We show highly competitive results on tabular data, early results on CIFAR-10, and give insight into how the model makes use of the interactions between points.
count=1
* Automatic and Harmless  Regularization  with Constrained and Lexicographic Optimization: A Dynamic Barrier Approach
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/f7b027d45fd7484f6d0833823b98907e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/f7b027d45fd7484f6d0833823b98907e-Paper.pdf)]
    * Title: Automatic and Harmless  Regularization  with Constrained and Lexicographic Optimization: A Dynamic Barrier Approach
    * Year: `2021`
    * Authors: Chengyue Gong, Xingchao Liu, Qiang Liu
    * Abstract: Many machine learning tasks have to make a trade-off between two loss functions, typically the main data-fitness loss and an auxiliary loss. The most widely used approach is to optimize the linear combination of the objectives, which, however, requires manual tuning of the combination coefficient and is theoretically unsuitable for non-convex functions. In this work, we consider constrained optimization as a more principled approach for trading off two losses, with a special emphasis on lexicographic optimization, a degenerated limit of constrained optimization which optimizes a secondary loss inside the optimal set of the main loss. We propose a dynamic barrier gradient descent algorithm which provides a unified solution of both constrained and lexicographic optimization. We establish the convergence of the method for general non-convex functions.
count=1
* Soft Calibration Objectives for Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/f8905bd3df64ace64a68e154ba72f24c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/f8905bd3df64ace64a68e154ba72f24c-Paper.pdf)]
    * Title: Soft Calibration Objectives for Neural Networks
    * Year: `2021`
    * Authors: Archit Karandikar, Nicholas Cain, Dustin Tran, Balaji Lakshminarayanan, Jonathon Shlens, Michael C. Mozer, Becca Roelofs
    * Abstract: Optimal decision making requires that classifiers produce uncertainty estimates consistent with their empirical accuracy. However, deep neural networks are often under- or over-confident in their predictions. Consequently, methods have been developed to improve the calibration of their predictive uncertainty both during training and post-hoc. In this work, we propose differentiable losses to improve calibration based on a soft (continuous) version of the binning operation underlying popular calibration-error estimators. When incorporated into training, these soft calibration losses achieve state-of-the-art single-model ECE across multiple datasets with less than 1% decrease in accuracy. For instance, we observe an 82% reduction in ECE (70% relative to the post-hoc rescaled ECE) in exchange for a 0.7% relative decrease in accuracy relative to the cross entropy baseline on CIFAR-100.When incorporated post-training, the soft-binning-based calibration error objective improves upon temperature scaling, a popular recalibration method. Overall, experiments across losses and datasets demonstrate that using calibration-sensitive procedures yield better uncertainty estimates under dataset shift than the standard practice of using a cross entropy loss and post-hoc recalibration methods.
count=1
* Scalable and Stable Surrogates for Flexible Classifiers with Fairness Constraints
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/fc2e6a440b94f64831840137698021e1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/fc2e6a440b94f64831840137698021e1-Paper.pdf)]
    * Title: Scalable and Stable Surrogates for Flexible Classifiers with Fairness Constraints
    * Year: `2021`
    * Authors: Henry C Bendekgey, Erik Sudderth
    * Abstract: We investigate how fairness relaxations scale to flexible classifiers like deep neural networks for images and text. We analyze an easy-to-use and robust way of imposing fairness constraints when training, and through this framework prove that some prior fairness surrogates exhibit degeneracies for non-convex models. We resolve these problems via three new surrogates: an adaptive data re-weighting, and two smooth upper-bounds that are provably more robust than some previous methods. Our surrogates perform comparably to the state-of-the-art on low-dimensional fairness benchmarks, while achieving superior accuracy and stability for more complex computer vision and natural language processing tasks.
count=1
* Provable Representation Learning for Imitation with Contrastive Fourier Features
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/hash/fd00d3474e495e7b6d5f9f575b2d7ec4-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2021/file/fd00d3474e495e7b6d5f9f575b2d7ec4-Paper.pdf)]
    * Title: Provable Representation Learning for Imitation with Contrastive Fourier Features
    * Year: `2021`
    * Authors: Ofir Nachum, Mengjiao Yang
    * Abstract: In imitation learning, it is common to learn a behavior policy to match an unknown target policy via max-likelihood training on a collected set of target demonstrations. In this work, we consider using offline experience datasets -- potentially far from the target distribution -- to learn low-dimensional state representations that provably accelerate the sample-efficiency of downstream imitation learning. A central challenge in this setting is that the unknown target policy itself may not exhibit low-dimensional behavior, and so there is a potential for the representation learning objective to alias states in which the target policy acts differently. Circumventing this challenge, we derive a representation learning objective that provides an upper bound on the performance difference between the target policy and a low-dimensional policy trained with max-likelihood, and this bound is tight regardless of whether the target policy itself exhibits low-dimensional structure. Moving to the practicality of our method, we show that our objective can be implemented as contrastive learning, in which the transition dynamics are approximated by either an implicit energy-based model or, in some special cases, an implicit linear model with representations given by random Fourier features. Experiments on both tabular environments and high-dimensional Atari games provide quantitative evidence for the practical benefits of our proposed objective.
count=1
* Fairness without Demographics through Adversarially Reweighted Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/07fc15c9d169ee48573edd749d25945d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/07fc15c9d169ee48573edd749d25945d-Paper.pdf)]
    * Title: Fairness without Demographics through Adversarially Reweighted Learning
    * Year: `2020`
    * Authors: Preethi Lahoti, Alex Beutel, Jilin Chen, Kang Lee, Flavien Prost, Nithum Thain, Xuezhi Wang, Ed Chi
    * Abstract: Much of the previous machine learning (ML) fairness literature assumes that protected features such as race and sex are present in the dataset, and relies upon them to mitigate fairness concerns. However, in practice factors like privacy and regulation often preclude the collection of protected features, or their use for training or inference, severely limiting the applicability of traditional fairness research. Therefore, we ask: How can we train a ML model to improve fairness when we do not even know the protected group memberships? In this work we address this problem by proposing Adversarially Reweighted Learning (ARL). In particular, we hypothesize that non-protected features and task labels are valuable for identifying fairness issues, and can be used to co-train an adversarial reweighting approach for improving fairness. Our results show that ARL improves Rawlsian Max-Min fairness, with notable AUC improvements for worst-case protected groups in multiple datasets, outperforming state-of-the-art alternatives.
count=1
* A Combinatorial Perspective on Transfer Learning 
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/0a3b6f64f0523984e51323fe53b8c504-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/0a3b6f64f0523984e51323fe53b8c504-Paper.pdf)]
    * Title: A Combinatorial Perspective on Transfer Learning 
    * Year: `2020`
    * Authors: Jianan Wang, Eren Sezener, David Budden, Marcus Hutter, Joel Veness
    * Abstract: Human intelligence is characterized not only by the capacity to learn complex skills, but the ability to rapidly adapt and acquire new skills within an ever-changing environment. In this work we study how the learning of modular solutions can allow for effective generalization to both unseen and potentially differently distributed data. Our main postulate is that the combination of task segmentation, modular learning and memory-based ensembling can give rise to generalization on an exponentially growing number of unseen tasks. We provide a concrete instantiation of this idea using a combination of: (1) the Forget-Me-Not Process, for task segmentation and memory based ensembling; and (2) Gated Linear Networks, which in contrast to contemporary deep learning techniques use a modular and local learning mechanism. We demonstrate that this system exhibits a number of desirable continual learning properties: robustness to catastrophic forgetting, no negative transfer and increasing levels of positive transfer as more tasks are seen. We show competitive performance against both offline and online methods on standard continual learning benchmarks.
count=1
* Locally-Adaptive Nonparametric Online Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/12780ea688a71dabc284b064add459a4-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/12780ea688a71dabc284b064add459a4-Paper.pdf)]
    * Title: Locally-Adaptive Nonparametric Online Learning
    * Year: `2020`
    * Authors: Ilja Kuzborskij, Nicolò Cesa-Bianchi
    * Abstract: One of the main strengths of online algorithms is their ability to adapt to arbitrary data sequences. This is especially important in nonparametric settings, where performance is measured against rich classes of comparator functions that are able to fit complex environments. Although such hard comparators and complex environments may exhibit local regularities, efficient algorithms, which can provably take advantage of these local patterns, are hardly known. We fill this gap by introducing efficient online algorithms (based on a single versatile master algorithm) each adapting to one of the following regularities: (i) local Lipschitzness of the competitor function, (ii) local metric dimension of the instance sequence, (iii) local performance of the predictor across different regions of the instance space. Extending previous approaches, we design algorithms that dynamically grow hierarchical ε-nets on the instance space whose prunings correspond to different “locality profiles” for the problem at hand. Using a technique based on tree experts, we simultaneously and efficiently compete against all such prunings, and prove regret bounds each scaling with a quantity associated with a different type of local regularity. When competing against “simple” locality profiles, our technique delivers regret bounds that are significantly better than those proven using the previous approach. On the other hand, the time dependence of our bounds is not worse than that obtained by ignoring any local regularities.
count=1
* Margins are Insufficient for Explaining Gradient Boosting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/146f7dd4c91bc9d80cf4458ad6d6cd1b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/146f7dd4c91bc9d80cf4458ad6d6cd1b-Paper.pdf)]
    * Title: Margins are Insufficient for Explaining Gradient Boosting
    * Year: `2020`
    * Authors: Allan Grønlund, Lior Kamma, Kasper Green Larsen
    * Abstract: Boosting is one of the most successful ideas in machine learning, achieving great practical performance with little fine-tuning. The success of boosted classifiers is most often attributed to improvements in margins. The focus on margin explanations was pioneered in the seminal work by Schaphire et al. (1998) and has culminated in the $k$'th margin generalization bound by Gao and Zhou (2013), which was recently proved to be near-tight for some data distributions (Gr\o nlund et al. 2019). In this work, we first demonstrate that the $k$'th margin bound is inadequate in explaining the performance of state-of-the-art gradient boosters. We then explain the short comings of the $k$'th margin bound and prove a stronger and more refined margin-based generalization bound that indeed succeeds in explaining the performance of modern gradient boosters. Finally, we improve upon the recent generalization lower bound by Gr\o nlund et al. (2019).
count=1
* Improving Policy-Constrained Kidney Exchange via Pre-Screening
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/1bda4c789c38754f639a376716c5859f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/1bda4c789c38754f639a376716c5859f-Paper.pdf)]
    * Title: Improving Policy-Constrained Kidney Exchange via Pre-Screening
    * Year: `2020`
    * Authors: Duncan McElfresh, Michael Curry, Tuomas Sandholm, John Dickerson
    * Abstract: In barter exchanges, participants swap goods with one another without exchanging money; these exchanges are often facilitated by a central clearinghouse, with the goal of maximizing the aggregate quality (or number) of swaps. Barter exchanges are subject to many forms of uncertainty--in participant preferences, the feasibility and quality of various swaps, and so on. Our work is motivated by kidney exchange, a real-world barter market in which patients in need of a kidney transplant swap their willing living donors, in order to find a better match. Modern exchanges include 2- and 3-way swaps, making the kidney exchange clearing problem NP-hard. Planned transplants often \emph{fail} for a variety of reasons--if the donor organ is rejected by the recipient's medical team, or if the donor and recipient are found to be medically incompatible. Due to 2- and 3-way swaps, failed transplants can ``cascade'' through an exchange; one US-based exchange estimated that about $85\%$ of planned transplants failed in 2019. Many optimization-based approaches have been designed to avoid these failures; however most exchanges cannot implement these methods, due to legal and policy constraints. Instead, we consider a setting where exchanges can \emph{query} the preferences of certain donors and recipients--asking whether they would accept a particular transplant. We characterize this as a two-stage decision problem, in which the exchange program (a) queries a small number of transplants before committing to a matching, and (b) constructs a matching according to fixed policy. We show that selecting these edges is a challenging combinatorial problem, which is non-monotonic and non-submodular, in addition to being NP-hard. We propose both a greedy heuristic and a Monte Carlo tree search, which outperforms previous approaches, using experiments on both synthetic data and real kidney exchange data from the United Network for Organ Sharing.
count=1
* Robust Correction of Sampling Bias using Cumulative Distribution Functions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/24368c745de15b3d2d6279667debcba3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/24368c745de15b3d2d6279667debcba3-Paper.pdf)]
    * Title: Robust Correction of Sampling Bias using Cumulative Distribution Functions
    * Year: `2020`
    * Authors: Bijan Mazaheri, Siddharth Jain, Jehoshua Bruck
    * Abstract: Varying domains and biased datasets can lead to differences between the training and the target distributions, known as covariate shift. Current approaches for alleviating this often rely on estimating the ratio of training and target probability density functions. These techniques require parameter tuning and can be unstable across different datasets. We present a new method for handling covariate shift using the empirical cumulative distribution function estimates of the target distribution by a rigorous generalization of a recent idea proposed by Vapnik and Izmailov. Further, we show experimentally that our method is more robust in its predictions, is not reliant on parameter tuning and shows similar classification performance compared to the current state-of-the-art techniques on synthetic and real datasets.
count=1
* Classification with Valid and Adaptive Coverage
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/244edd7e85dc81602b7615cd705545f5-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/244edd7e85dc81602b7615cd705545f5-Paper.pdf)]
    * Title: Classification with Valid and Adaptive Coverage
    * Year: `2020`
    * Authors: Yaniv Romano, Matteo Sesia, Emmanuel Candes
    * Abstract: Conformal inference, cross-validation+, and the jackknife+ are hold-out methods that can be combined with virtually any machine learning algorithm to construct prediction sets with guaranteed marginal coverage. In this paper, we develop specialized versions of these techniques for categorical and unordered response labels that, in addition to providing marginal coverage, are also fully adaptive to complex data distributions, in the sense that they perform favorably in terms of approximate conditional coverage compared to alternative methods. The heart of our contribution is a novel conformity score, which we explicitly demonstrate to be powerful and intuitive for classification problems, but whose underlying principle is potentially far more general. Experiments on synthetic and real data demonstrate the practical value of our theoretical guarantees, as well as the statistical advantages of the proposed methods over the existing alternatives.
count=1
* Distribution-free binary classification: prediction sets, confidence intervals and calibration
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/26d88423fc6da243ffddf161ca712757-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/26d88423fc6da243ffddf161ca712757-Paper.pdf)]
    * Title: Distribution-free binary classification: prediction sets, confidence intervals and calibration
    * Year: `2020`
    * Authors: Chirag Gupta, Aleksandr Podkopaev, Aaditya Ramdas
    * Abstract: We study three notions of uncertainty quantification---calibration, confidence intervals and prediction sets---for binary classification in the distribution-free setting, that is without making any distributional assumptions on the data. With a focus towards calibration, we establish a 'tripod' of theorems that connect these three notions for score-based classifiers. A direct implication is that distribution-free calibration is only possible, even asymptotically, using a scoring function whose level sets partition the feature space into at most countably many sets. Parametric calibration schemes such as variants of Platt scaling do not satisfy this requirement, while nonparametric schemes based on binning do. To close the loop, we derive distribution-free confidence intervals for binned probabilities for both fixed-width and uniform-mass binning. As a consequence of our 'tripod' theorems, these confidence intervals for binned probabilities lead to distribution-free calibration. We also derive extensions to settings with streaming data and covariate shift.
count=1
* Adaptive Discretization for Model-Based Reinforcement Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/285baacbdf8fda1de94b19282acd23e2-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/285baacbdf8fda1de94b19282acd23e2-Paper.pdf)]
    * Title: Adaptive Discretization for Model-Based Reinforcement Learning
    * Year: `2020`
    * Authors: Sean Sinclair, Tianyu Wang, Gauri Jain, Siddhartha Banerjee, Christina Yu
    * Abstract: We introduce the technique of adaptive discretization to design an efficient model-based episodic reinforcement learning algorithm in large (potentially continuous) state-action spaces. Our algorithm is based on optimistic one-step value iteration extended to maintain an adaptive discretization of the space. From a theoretical perspective we provide worst-case regret bounds for our algorithm which are competitive compared to the state-of-the-art model-based algorithms. Moreover, our bounds are obtained via a modular proof technique which can potentially extend to incorporate additional structure on the problem. From an implementation standpoint, our algorithm has much lower storage and computational requirements due to maintaining a more efficient partition of the state and action spaces. We illustrate this via experiments on several canonical control problems, which shows that our algorithm empirically performs significantly better than fixed discretization in terms of both faster convergence and lower memory usage. Interestingly, we observe empirically that while fixed discretization model-based algorithms vastly outperform their model-free counterparts, the two achieve comparable performance with adaptive discretization.
count=1
* Learning discrete distributions with infinite support
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/291dbc18539ba7e19b8abb7d85aa204e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/291dbc18539ba7e19b8abb7d85aa204e-Paper.pdf)]
    * Title: Learning discrete distributions with infinite support
    * Year: `2020`
    * Authors: Doron Cohen, Aryeh Kontorovich, Geoﬀrey Wolfer
    * Abstract: We present a novel approach to estimating discrete distributions with (potentially) infinite support in the total variation metric. In a departure from the established paradigm, we make no structural assumptions whatsoever on the sampling distribution. In such a setting, distribution-free risk bounds are impossible, and the best one could hope for is a fully empirical data-dependent bound. We derive precisely such bounds, and demonstrate that these are, in a well-defined sense, the best possible. Our main discovery is that the half-norm of the empirical distribution provides tight upper and lower estimates on the empirical risk. Furthermore, this quantity decays at a nearly optimal rate as a function of the true distribution. The optimality follows from a minimax result, of possible independent interest. Additional structural results are provided, including an exact Rademacher complexity calculation and apparently a first connection between the total variation risk and the missing mass.
count=1
* How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/2c29d89cc56cdb191c60db2f0bae796b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/2c29d89cc56cdb191c60db2f0bae796b-Paper.pdf)]
    * Title: How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods
    * Year: `2020`
    * Authors: Jeya Vikranth Jeyakumar, Joseph Noor, Yu-Hsi Cheng, Luis Garcia, Mani Srivastava
    * Abstract: Explaining the inner workings of deep neural network models have received considerable attention in recent years. Researchers have attempted to provide human parseable explanations justifying why a model performed a specific classification. Although many of these toolkits are available for use, it is unclear which style of explanation is preferred by end-users, thereby demanding investigation. We performed a cross-analysis Amazon Mechanical Turk study comparing the popular state-of-the-art explanation methods to empirically determine which are better in explaining model decisions. The participants were asked to compare explanation methods across applications spanning image, text, audio, and sensory domains. Among the surveyed methods, explanation-by-example was preferred in all domains except text sentiment classification, where LIME's method of annotating input text was preferred. We highlight qualitative aspects of employing the studied explainability methods and conclude with implications for researchers and engineers that seek to incorporate explanations into user-facing deployments.
count=1
* Temporal Positive-unlabeled Learning for Biomedical Hypothesis Generation via Risk Estimation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/310614fca8fb8e5491295336298c340f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/310614fca8fb8e5491295336298c340f-Paper.pdf)]
    * Title: Temporal Positive-unlabeled Learning for Biomedical Hypothesis Generation via Risk Estimation
    * Year: `2020`
    * Authors: Uchenna Akujuobi, Jun Chen, Mohamed Elhoseiny, Michael Spranger, Xiangliang Zhang
    * Abstract: Understanding the relationships between biomedical terms like viruses, drugs, and symptoms is essential in the fight against diseases. Many attempts have been made to introduce the use of machine learning to the scientific process of hypothesis generation (HG), which refers to the discovery of meaningful implicit connections between biomedical terms. However, most existing methods fail to truly capture the temporal dynamics of scientific term relations and also assume unobserved connections to be irrelevant (i.e., in a positive-negative (PN) learning setting). To break these limits, we formulate this HG problem as future connectivity prediction task on a dynamic attributed graph via positive-unlabeled (PU) learning. Then, the key is to capture the temporal evolution of node pair (term pair) relations from just the positive and unlabeled data. We propose a variational inference model to estimate the positive prior, and incorporate it in the learning of node pair embeddings, which are then used for link prediction. Experiment results on real-world biomedical term relationship datasets and case study analyses on a COVID-19 dataset validate the effectiveness of the proposed model.
count=1
* Learning Differentiable Programs with Admissible Neural Heuristics
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/342285bb2a8cadef22f667eeb6a63732-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/342285bb2a8cadef22f667eeb6a63732-Paper.pdf)]
    * Title: Learning Differentiable Programs with Admissible Neural Heuristics
    * Year: `2020`
    * Authors: Ameesh Shah, Eric Zhan, Jennifer Sun, Abhinav Verma, Yisong Yue, Swarat Chaudhuri
    * Abstract: We study the problem of learning differentiable functions expressed as programs in a domain-specific language. Such programmatic models can offer benefits such as composability and interpretability; however, learning them requires optimizing over a combinatorial space of program "architectures". We frame this optimization problem as a search in a weighted graph whose paths encode top-down derivations of program syntax. Our key innovation is to view various classes of neural networks as continuous relaxations over the space of programs, which can then be used to complete any partial program. All the parameters of this relaxed program can be trained end-to-end, and the resulting training loss is an approximately admissible heuristic that can guide the combinatorial search. We instantiate our approach on top of the A* and Iterative Deepening Depth-First Search algorithms and use these algorithms to learn programmatic classifiers in three sequence classification tasks. Our experiments show that the algorithms outperform state-of-the-art methods for program learning, and that they discover programmatic classifiers that yield natural interpretations and achieve competitive accuracy.
count=1
* Deep Direct Likelihood Knockoffs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/350a7f5ee27d22dbe36698b10930ff96-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/350a7f5ee27d22dbe36698b10930ff96-Paper.pdf)]
    * Title: Deep Direct Likelihood Knockoffs
    * Year: `2020`
    * Authors: Mukund Sudarshan, Wesley Tansey, Rajesh Ranganath
    * Abstract: Predictive modeling often uses black box machine learning methods, such as deep neural networks, to achieve state-of-the-art performance. In scientific domains, the scientist often wishes to discover which features are actually important for making the predictions. These discoveries may lead to costly follow-up experiments and as such it is important that the error rate on discoveries is not too high. Model-X knockoffs enable important features to be discovered with control of the false discovery rate (FDR). However, knockoffs require rich generative models capable of accurately modeling the knockoff features while ensuring they obey the so-called "swap" property. We develop Deep Direct Likelihood Knockoffs (DDLK), which directly minimizes the KL divergence implied by the knockoff swap property. DDLK consists of two stages: it first maximizes the explicit likelihood of the features, then minimizes the KL divergence between the joint distribution of features and knockoffs and any swap between them. To ensure that the generated knockoffs are valid under any possible swap, DDLK uses the Gumbel-Softmax trick to optimize the knockoff generator under the worst-case swap. We find DDLK has higher power than baselines while controlling the false discovery rate on a variety of synthetic and real benchmarks including a task involving the largest COVID-19 health record dataset in the United States.
count=1
* Generative causal explanations of black-box classifiers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/3a93a609b97ec0ab0ff5539eb79ef33a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/3a93a609b97ec0ab0ff5539eb79ef33a-Paper.pdf)]
    * Title: Generative causal explanations of black-box classifiers
    * Year: `2020`
    * Authors: Matthew O'Shaughnessy, Gregory Canal, Marissa Connor, Christopher Rozell, Mark Davenport
    * Abstract: We develop a method for generating causal post-hoc explanations of black-box classifiers based on a learned low-dimensional representation of the data. The explanation is causal in the sense that changing learned latent factors produces a change in the classifier output statistics. To construct these explanations, we design a learning framework that leverages a generative model and information-theoretic measures of causal influence. Our objective function encourages both the generative model to faithfully represent the data distribution and the latent factors to have a large causal influence on the classifier output. Our method learns both global and local explanations, is compatible with any classifier that admits class probabilities and a gradient, and does not require labeled attributes or knowledge of causal structure. Using carefully controlled test cases, we provide intuition that illuminates the function of our causal objective. We then demonstrate the practical utility of our method on image recognition tasks.
count=1
* Bayesian Probabilistic Numerical Integration with Tree-Based Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/3fe94a002317b5f9259f82690aeea4cd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/3fe94a002317b5f9259f82690aeea4cd-Paper.pdf)]
    * Title: Bayesian Probabilistic Numerical Integration with Tree-Based Models
    * Year: `2020`
    * Authors: Harrison Zhu, Xing Liu, Ruya Kang, Zhichao Shen, Seth Flaxman, Francois-Xavier Briol
    * Abstract: Bayesian quadrature (BQ) is a method for solving numerical integration problems in a Bayesian manner, which allows users to quantify their uncertainty about the solution. The standard approach to BQ is based on a Gaussian process (GP) approximation of the integrand. As a result, BQ is inherently limited to cases where GP approximations can be done in an efficient manner, thus often prohibiting very high-dimensional or non-smooth target functions. This paper proposes to tackle this issue with a new Bayesian numerical integration algorithm based on Bayesian Additive Regression Trees (BART) priors, which we call BART-Int. BART priors are easy to tune and well-suited for discontinuous functions. We demonstrate that they also lend themselves naturally to a sequential design setting and that explicit convergence rates can be obtained in a variety of settings. The advantages and disadvantages of this new methodology are highlighted on a set of benchmark tests including the Genz functions, on a rare-event simulation problem and on a Bayesian survey design problem.
count=1
* Meta-learning from Tasks with Heterogeneous Attribute Spaces
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/438124b4c06f3a5caffab2c07863b617-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/438124b4c06f3a5caffab2c07863b617-Paper.pdf)]
    * Title: Meta-learning from Tasks with Heterogeneous Attribute Spaces
    * Year: `2020`
    * Authors: Tomoharu Iwata, Atsutoshi Kumagai
    * Abstract: We propose a heterogeneous meta-learning method that trains a model on tasks with various attribute spaces, such that it can solve unseen tasks whose attribute spaces are different from the training tasks given a few labeled instances. Although many meta-learning methods have been proposed, they assume that all training and target tasks share the same attribute space, and they are inapplicable when attribute sizes are different across tasks. Our model infers latent representations of each attribute and each response from a few labeled instances using an inference network. Then, responses of unlabeled instances are predicted with the inferred representations using a prediction network. The attribute and response representations enable us to make predictions based on the task-specific properties of attributes and responses even when attribute and response sizes are different across tasks. In our experiments with synthetic datasets and 59 datasets in OpenML, we demonstrate that our proposed method can predict the responses given a few labeled instances in new tasks after being trained with tasks with heterogeneous attribute spaces.
count=1
* Detecting Interactions from Neural Networks via Topological Analysis
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/473803f0f2ebd77d83ee60daaa61f381-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/473803f0f2ebd77d83ee60daaa61f381-Paper.pdf)]
    * Title: Detecting Interactions from Neural Networks via Topological Analysis
    * Year: `2020`
    * Authors: Zirui Liu, Qingquan Song, Kaixiong Zhou, Ting-Hsiang Wang, Ying Shan, Xia Hu
    * Abstract: Detecting statistical interactions between input features is a crucial and challenging task. Recent advances demonstrate that it is possible to extract learned interactions from trained neural networks. It has also been observed that, in neural networks, any interacting features must follow a strongly weighted connection to common hidden units. Motivated by the observation, in this paper, we propose to investigate the interaction detection problem from a novel topological perspective by analyzing the connectivity in neural networks. Specially, we propose a new measure for quantifying interaction strength, based upon the well-received theory of persistent homology. Based on this measure, a Persistence Interaction Dection (PID) algorithm is developed to efficiently detect interactions. Our proposed algorithm is evaluated across a number of interaction detection tasks on several synthetic and real-world datasets with different hyperparameters. Experimental results validate that the PID algorithm outperforms the state-of-the-art baselines.
count=1
* Benchmarking Deep Learning Interpretability in Time Series Predictions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/47a3893cc405396a5c30d91320572d6d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/47a3893cc405396a5c30d91320572d6d-Paper.pdf)]
    * Title: Benchmarking Deep Learning Interpretability in Time Series Predictions
    * Year: `2020`
    * Authors: Aya Abdelsalam Ismail, Mohamed Gunady, Hector Corrada Bravo, Soheil Feizi
    * Abstract: Saliency methods are used extensively to highlight the importance of input features in model predictions. These methods are mostly used in vision and language tasks, and their applications to time series data is relatively unexplored. In this paper, we set out to extensively compare the performance of various saliency-based interpretability methods across diverse neural architectures, including Recurrent Neural Network, Temporal Convolutional Networks, and Transformers in a new benchmark of synthetic time series data. We propose and report multiple metrics to empirically evaluate the performance of saliency methods for detecting feature importance over time using both precision (i.e., whether identified features contain meaningful signals) and recall (i.e., the number of features with signal identified as important). Through several experiments, we show that (i) in general, network architectures and saliency methods fail to reliably and accurately identify feature importance over time in time series data, (ii) this failure is mainly due to the conflation of time and feature domains, and (iii) the quality of saliency maps can be improved substantially by using our proposed two-step temporal saliency rescaling (TSR) approach that first calculates the importance of each time step before calculating the importance of each feature at a time step.
count=1
* Learning Certified Individually Fair Representations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/55d491cf951b1b920900684d71419282-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/55d491cf951b1b920900684d71419282-Paper.pdf)]
    * Title: Learning Certified Individually Fair Representations
    * Year: `2020`
    * Authors: Anian Ruoss, Mislav Balunovic, Marc Fischer, Martin Vechev
    * Abstract: Fair representation learning provides an effective way of enforcing fairness constraints without compromising utility for downstream users. A desirable family of such fairness constraints, each requiring similar treatment for similar individuals, is known as individual fairness. In this work, we introduce the first method that enables data consumers to obtain certificates of individual fairness for existing and new data points. The key idea is to map similar individuals to close latent representations and leverage this latent proximity to certify individual fairness. That is, our method enables the data producer to learn and certify a representation where for a data point all similar individuals are at l-infinity distance at most epsilon, thus allowing data consumers to certify individual fairness by proving epsilon-robustness of their classifier. Our experimental evaluation on five real-world datasets and several fairness constraints demonstrates the expressivity and scalability of our approach.
count=1
* Efficient Online Learning of Optimal Rankings: Dimensionality Reduction via Gradient Descent
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/5938b4d054136e5d59ada6ec9c295d7a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/5938b4d054136e5d59ada6ec9c295d7a-Paper.pdf)]
    * Title: Efficient Online Learning of Optimal Rankings: Dimensionality Reduction via Gradient Descent
    * Year: `2020`
    * Authors: Dimitris Fotakis, Thanasis Lianeas, Georgios Piliouras, Stratis Skoulakis
    * Abstract: We consider a natural model of online preference aggregation, where sets of preferred items R1, R2, ..., Rt, ..., along with a demand for kt items in each Rt, appear online. Without prior knowledge of (Rt, kt), the learner maintains a ranking \pit aiming that at least kt items from Rt appear high in \pi_t. This is a fundamental problem in preference aggregation with applications to e.g., ordering product or news items in web pages based on user scrolling and click patterns. The widely studied Generalized Min-Sum-Set-Cover (GMSSC) problem serves as a formal model for the setting above. GMSSC is NP-hard and the standard application of no-regret online learning algorithms is computationally inefficient, because they operate in the space of rankings. In this work, we show how to achieve low regret for GMSSC in polynomial-time. We employ dimensionality reduction from rankings to the space of doubly stochastic matrices, where we apply Online Gradient Descent. A key step is to show how subgradients can be computed efficiently, by solving the dual of a configuration LP. Using deterministic and randomized rounding schemes, we map doubly stochastic matrices back to rankings with a small loss in the GMSSC objective.
count=1
* Learning from Aggregate Observations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/5b0fa0e4c041548bb6289e15d865a696-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/5b0fa0e4c041548bb6289e15d865a696-Paper.pdf)]
    * Title: Learning from Aggregate Observations
    * Year: `2020`
    * Authors: Yivan Zhang, Nontawat Charoenphakdee, Zhenguo Wu, Masashi Sugiyama
    * Abstract: We study the problem of learning from aggregate observations where supervision signals are given to sets of instances instead of individual instances, while the goal is still to predict labels of unseen individuals. A well-known example is multiple instance learning (MIL). In this paper, we extend MIL beyond binary classification to other problems such as multiclass classification and regression. We present a general probabilistic framework that accommodates a variety of aggregate observations, e.g., pairwise similarity/triplet comparison for classification and mean/difference/rank observation for regression. Simple maximum likelihood solutions can be applied to various differentiable models such as deep neural networks and gradient boosting machines. Moreover, we develop the concept of consistency up to an equivalence relation to characterize our estimator and show that it has nice convergence properties under mild assumptions. Experiments on three problem settings --- classification via triplet comparison and regression via mean/rank observation indicate the effectiveness of the proposed method.
count=1
* Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Evolvability
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/5f8b73c0d4b1bf60dd7173b660b87c29-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/5f8b73c0d4b1bf60dd7173b660b87c29-Paper.pdf)]
    * Title: Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Evolvability
    * Year: `2020`
    * Authors: Sitan Chen, Frederic Koehler, Ankur Moitra, Morris Yau
    * Abstract: In this paper, we revisit the problem of distribution-independently learning halfspaces under Massart noise with rate $\eta$. Recent work resolved a long-standing problem in this model of efficiently learning to error $\eta + \epsilon$ for any $\epsilon > 0$, by giving an improper learner that partitions space into $\text{poly}(d,1/\epsilon)$ regions. Here we give a much simpler algorithm and settle a number of outstanding open questions: (1) We give the first \emph{proper} learner for Massart halfspaces that achieves $\eta + \epsilon$. (2) Based on (1), we develop a blackbox knowledge distillation procedure to convert an arbitrarily complex classifier to an equally good proper classifier. (3) By leveraging a simple but overlooked connection to \emph{evolvability}, we show any SQ algorithm requires super-polynomially many queries to achieve $\mathsf{OPT} + \epsilon$. We then zoom out to study generalized linear models and give an efficient algorithm for learning under a challenging new corruption model generalizing Massart noise. Finally we study our algorithm for learning halfspaces under Massart noise empirically and find that it exhibits some appealing fairness properties as a byproduct of its strong provable robustness guarantees.
count=1
* Learning to Play Sequential Games versus Unknown Opponents
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/65cf25ef90de99d93fa96dc49d0d8b3c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/65cf25ef90de99d93fa96dc49d0d8b3c-Paper.pdf)]
    * Title: Learning to Play Sequential Games versus Unknown Opponents
    * Year: `2020`
    * Authors: Pier Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, Andreas Krause
    * Abstract: We consider a repeated sequential game between a learner, who plays first, and an opponent who responds to the chosen action. We seek to design strategies for the learner to successfully interact with the opponent. While most previous approaches consider known opponent models, we focus on the setting in which the opponent's model is unknown. To this end, we use kernel-based regularity assumptions to capture and exploit the structure in the opponent's response. We propose a novel algorithm for the learner when playing against an adversarial sequence of opponents. The algorithm combines ideas from bilevel optimization and online learning to effectively balance between exploration (learning about the opponent's model) and exploitation (selecting highly rewarding actions for the learner). Our results include algorithm's regret guarantees that depend on the regularity of the opponent's response and scale sublinearly with the number of game rounds. Moreover, we specialize our approach to repeated Stackelberg games, and empirically demonstrate its effectiveness in a traffic routing and wildlife conservation task.
count=1
* Smoothed Analysis of Online and Differentially Private Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/685bfde03eb646c27ed565881917c71c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/685bfde03eb646c27ed565881917c71c-Paper.pdf)]
    * Title: Smoothed Analysis of Online and Differentially Private Learning
    * Year: `2020`
    * Authors: Nika Haghtalab, Tim Roughgarden, Abhishek Shetty
    * Abstract: Practical and pervasive needs for robustness and privacy in algorithms have inspired the design of online adversarial and differentially private learning algorithms. The primary quantity that characterizes learnability in these settings is the Littlestone dimension of the class of hypotheses [Ben-David et al., 2009, Alon et al., 2019]. This characterization is often interpreted as an impossibility result because classes such as linear thresholds and neural networks have infinite Littlestone dimension. In this paper, we apply the framework of smoothed analysis [Spielman and Teng, 2004], in which adversarially chosen inputs are perturbed slightly by nature. We show that fundamentally stronger regret and error guarantees are possible with smoothed adversaries than with worst-case adversaries. In particular, we obtain regret and privacy error bounds that depend only on the VC dimension and the bracketing number of a hypothesis class, and on the magnitudes of the perturbations.
count=1
* Learning with Differentiable Pertubed Optimizers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/6bb56208f672af0dd65451f869fedfd9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/6bb56208f672af0dd65451f869fedfd9-Paper.pdf)]
    * Title: Learning with Differentiable Pertubed Optimizers
    * Year: `2020`
    * Authors: Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, Francis Bach
    * Abstract: Machine learning pipelines often rely on optimizers procedures to make discrete decisions (e.g., sorting, picking closest neighbors, or shortest paths). Although these discrete decisions are easily computed in a forward manner, they break the back-propagation of computational graphs. In order to expand the scope of learning problems that can be solved in an end-to-end fashion, we propose a systematic method to transform optimizers into operations that are differentiable and never locally constant. Our approach relies on stochastically perturbed optimizers, and can be used readily within existing solvers. Their derivatives can be evaluated efficiently, and smoothness tuned via the chosen noise amplitude. We also show how this framework can be connected to a family of losses developed in structured prediction, and give theoretical guarantees for their use in learning tasks. We demonstrate experimentally the performance of our approach on various tasks.
count=1
* An Unbiased Risk Estimator for Learning with Augmented Classes
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/747c1bcceb6109a4ef936bc70cfe67de-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/747c1bcceb6109a4ef936bc70cfe67de-Paper.pdf)]
    * Title: An Unbiased Risk Estimator for Learning with Augmented Classes
    * Year: `2020`
    * Authors: Yu-Jie Zhang, Peng Zhao, Lanjihong Ma, Zhi-Hua Zhou
    * Abstract: This paper studies the problem of learning with augmented classes (LAC), where augmented classes unobserved in the training data might emerge in the testing phase. Previous studies generally attempt to discover augmented classes by exploiting geometric properties, achieving inspiring empirical performance yet lacking theoretical understandings particularly on the generalization ability. In this paper we show that, by using unlabeled training data to approximate the potential distribution of augmented classes, an unbiased risk estimator of the testing distribution can be established for the LAC problem under mild assumptions, which paves a way to develop a sound approach with theoretical guarantees. Moreover, the proposed approach can adapt to complex changing environments where augmented classes may appear and the prior of known classes may change simultaneously. Extensive experiments confirm the effectiveness of our proposed approach.
count=1
* SURF: A Simple, Universal, Robust, Fast Distribution Learning Algorithm
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/7ac52e3f2729d1b3f6d2b7e8f6467226-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/7ac52e3f2729d1b3f6d2b7e8f6467226-Paper.pdf)]
    * Title: SURF: A Simple, Universal, Robust, Fast Distribution Learning Algorithm
    * Year: `2020`
    * Authors: Yi Hao, Ayush Jain, Alon Orlitsky, Vaishakh Ravindrakumar
    * Abstract: Sample- and computationally-efficient distribution estimation is a fundamental tenet in statistics and machine learning. We present $\SURF$, an algorithm for approximating distributions by piecewise polynomials. $\SURF$ is: simple, replacing prior complex optimization techniques by straight-forward empirical probability approximation of each potential polynomial piece through simple empirical-probability interpolation, and using plain divide-and-conquer to merge the pieces; universal, as well-known polynomial-approximation results imply that it accurately approximates a large class of common distributions; robust to distribution mis-specification as for any degree $d \le 8$, it estimates any distribution to an $\ell_1$ distance $< 3$ times that of the nearest degree-$d$ piecewise polynomial, improving known factor upper bounds of 3 for single polynomials and 15 for polynomials with arbitrarily many pieces; fast, using optimal sample complexity, running in near sample-linear time, and if given sorted samples it may be parallelized to run in sub-linear time. In experiments, $\SURF$ outperforms state-of-the art algorithms.
count=1
* VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/7d97667a3e056acab9aaf653807b4a03-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/7d97667a3e056acab9aaf653807b4a03-Paper.pdf)]
    * Title: VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain
    * Year: `2020`
    * Authors: Jinsung Yoon, Yao Zhang, James Jordon, Mihaela van der Schaar
    * Abstract: Self- and semi-supervised learning frameworks have made significant progress in training machine learning models with limited labeled data in image and language domains. These methods heavily rely on the unique structure in the domain datasets (such as spatial relationships in images or semantic relationships in language). They are not adaptable to general tabular data which does not have the same explicit structure as image and language data. In this paper, we fill this gap by proposing novel self- and semi-supervised learning frameworks for tabular data, which we refer to collectively as VIME (Value Imputation and Mask Estimation). We create a novel pretext task of estimating mask vectors from corrupted tabular data in addition to the reconstruction pretext task for self-supervised learning. We also introduce a novel tabular data augmentation method for self- and semi-supervised learning frameworks. In experiments, we evaluate the proposed framework in multiple tabular datasets from various application domains, such as genomics and clinical data. VIME exceeds state-of-the-art performance in comparison to the existing baseline methods.
count=1
* Fair Performance Metric Elicitation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/7ec2442aa04c157590b2fa1a7d093a33-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/7ec2442aa04c157590b2fa1a7d093a33-Paper.pdf)]
    * Title: Fair Performance Metric Elicitation
    * Year: `2020`
    * Authors: Gaurush Hiranandani, Harikrishna Narasimhan, Sanmi Koyejo
    * Abstract: What is a fair performance metric? We consider the choice of fairness metrics through the lens of metric elicitation -- a principled framework for selecting performance metrics that best reflect implicit preferences. The use of metric elicitation enables a practitioner to tune the performance and fairness metrics to the task, context, and population at hand. Specifically, we propose a novel strategy to elicit group-fair performance metrics for multiclass classification problems with multiple sensitive groups that also includes selecting the trade-off between predictive performance and fairness violation. The proposed elicitation strategy requires only relative preference feedback and is robust to both finite sample and feedback noise.
count=1
* Probabilistic Fair Clustering
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/95f2b84de5660ddf45c8a34933a2e66f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/95f2b84de5660ddf45c8a34933a2e66f-Paper.pdf)]
    * Title: Probabilistic Fair Clustering
    * Year: `2020`
    * Authors: Seyed  Esmaeili, Brian Brubach, Leonidas Tsepenekas, John Dickerson
    * Abstract: In clustering problems, a central decision-maker is given a complete metric graph over vertices and must provide a clustering of vertices that minimizes some objective function. In fair clustering problems, vertices are endowed with a color (e.g., membership in a group), and the requirements of a valid clustering might also include the representation of colors in the solution. Prior work in fair clustering assumes complete knowledge of group membership. In this paper, we generalize this by assuming imperfect knowledge of group membership through probabilistic assignments, and present algorithms in this more general setting with approximation ratio guarantees. We also address the problem of "metric membership", where group membership has a notion of order and distance. Experiments are conducted using our proposed algorithms as well as baselines to validate our approach, and also surface nuanced concerns when group membership is not known deterministically.
count=1
* Learning from Positive and Unlabeled Data with Arbitrary Positive Shift
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/98b297950041a42470269d56260243a1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/98b297950041a42470269d56260243a1-Paper.pdf)]
    * Title: Learning from Positive and Unlabeled Data with Arbitrary Positive Shift
    * Year: `2020`
    * Authors: Zayd Hammoudeh, Daniel Lowd
    * Abstract: Positive-unlabeled (PU) learning trains a binary classifier using only positive and unlabeled data. A common simplifying assumption is that the positive data is representative of the target positive class. This assumption rarely holds in practice due to temporal drift, domain shift, and/or adversarial manipulation. This paper shows that PU learning is possible even with arbitrarily non-representative positive data given unlabeled data from the source and target distributions. Our key insight is that only the negative class's distribution need be fixed. We integrate this into two statistically consistent methods to address arbitrary positive bias - one approach combines negative-unlabeled learning with unlabeled-unlabeled learning while the other uses a novel, recursive risk estimator. Experimental results demonstrate our methods' effectiveness across numerous real-world datasets and forms of positive bias, including disjoint positive class-conditional supports. Additionally, we propose a general, simplified approach to address PU risk estimation overfitting.
count=1
* Intra Order-preserving Functions for Calibration of Multi-Class Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/9bc99c590be3511b8d53741684ef574c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/9bc99c590be3511b8d53741684ef574c-Paper.pdf)]
    * Title: Intra Order-preserving Functions for Calibration of Multi-Class Neural Networks
    * Year: `2020`
    * Authors: Amir Rahimi, Amirreza Shaban, Ching-An Cheng, Richard Hartley, Byron Boots
    * Abstract: Predicting calibrated confidence scores for multi-class deep networks is important for avoiding rare but costly mistakes. A common approach is to learn a post-hoc calibration function that transforms the output of the original network into calibrated confidence scores while maintaining the network's accuracy. However, previous post-hoc calibration techniques work only with simple calibration functions, potentially lacking sufficient representation to calibrate the complex function landscape of deep networks. In this work, we aim to learn general post-hoc calibration functions that can preserve the top-k predictions of any deep network. We call this family of functions intra order-preserving functions. We propose a new neural network architecture that represents a class of intra order-preserving functions by combining common neural network components. Additionally, we introduce order-invariant and diagonal sub-families, which can act as regularization for better generalization when the training data size is small. We show the effectiveness of the proposed method across a wide range of datasets and classifiers. Our method outperforms state-of-the-art post-hoc calibration methods, namely temperature scaling and Dirichlet calibration, in several evaluation metrics for the task.
count=1
* Neurosymbolic Transformers for Multi-Agent Communication
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/9d740bd0f36aaa312c8d504e28c42163-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/9d740bd0f36aaa312c8d504e28c42163-Paper.pdf)]
    * Title: Neurosymbolic Transformers for Multi-Agent Communication
    * Year: `2020`
    * Authors: Jeevana Priya Inala, Yichen Yang, James Paulos, Yewen Pu, Osbert Bastani, Vijay Kumar, Martin Rinard, Armando Solar-Lezama
    * Abstract: We study the problem of inferring communication structures that can solve cooperative multi-agent planning problems while minimizing the amount of communication. We quantify the amount of communication as the maximum degree of the communication graph; this metric captures settings where agents have limited bandwidth. Minimizing communication is challenging due to the combinatorial nature of both the decision space and the objective; for instance, we cannot solve this problem by training neural networks using gradient descent. We propose a novel algorithm that synthesizes a control policy that combines a programmatic communication policy used to generate the communication graph with a transformer policy network used to choose actions. Our algorithm first trains the transformer policy, which implicitly generates a "soft" communication graph; then, it synthesizes a programmatic communication policy that "hardens" this graph, forming a neurosymbolic transformer. Our experiments demonstrate how our approach can synthesize policies that generate low-degree communication graphs while maintaining near-optimal performance.
count=1
* Mutual exclusivity as a challenge for deep neural networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/a378383b89e6719e15cd1aa45478627c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/a378383b89e6719e15cd1aa45478627c-Paper.pdf)]
    * Title: Mutual exclusivity as a challenge for deep neural networks
    * Year: `2020`
    * Authors: Kanishk Gandhi, Brenden M. Lake
    * Abstract: Strong inductive biases allow children to learn in fast and adaptable ways. Children use the mutual exclusivity (ME) bias to help disambiguate how words map to referents, assuming that if an object has one label then it does not need another. In this paper, we investigate whether or not vanilla neural architectures have an ME bias, demonstrating that they lack this learning assumption. Moreover, we show that their inductive biases are poorly matched to lifelong learning formulations of classification and translation. We demonstrate that there is a compelling case for designing task-general neural networks that learn through mutual exclusivity, which remains an open challenge.
count=1
* Transfer Learning via $\ell_1$ Regularization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/a4a83056b58ff983d12c72bb17996243-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/a4a83056b58ff983d12c72bb17996243-Paper.pdf)]
    * Title: Transfer Learning via $\ell_1$ Regularization
    * Year: `2020`
    * Authors: Masaaki Takada, Hironori Fujisawa
    * Abstract: Machine learning algorithms typically require abundant data under a stationary environment. However, environments are nonstationary in many real-world applications. Critical issues lie in how to effectively adapt models under an ever-changing environment. We propose a method for transferring knowledge from a source domain to a target domain via $\ell_1$ regularization in high dimension. We incorporate $\ell_1$ regularization of differences between source and target parameters in addition to an ordinary $\ell_1$ regularization. Hence, our method yields sparsity for both the estimates themselves and changes of the estimates. The proposed method has a tight estimation error bound under a stationary environment, and the estimate remains unchanged from the source estimate under small residuals. Moreover, the estimate is consistent with the underlying function, even when the source estimate is mistaken due to nonstationarity. Empirical results demonstrate that the proposed method effectively balances stability and plasticity.
count=1
* AdaTune: Adaptive Tensor Program Compilation Made Efficient
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/a9b7ba70783b617e9998dc4dd82eb3c5-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/a9b7ba70783b617e9998dc4dd82eb3c5-Paper.pdf)]
    * Title: AdaTune: Adaptive Tensor Program Compilation Made Efficient
    * Year: `2020`
    * Authors: Menghao Li, Minjia Zhang, Chi Wang, Mingqin Li
    * Abstract: Deep learning models are computationally intense, and implementations often have to be highly optimized by experts or hardware vendors to be usable in practice. The DL compiler, together with Learning to Compile have proven to be a powerful technique for optimizing tensor programs. However, a limitation of this approach is that it still suffers from unbearably long overall optimization time. In this paper, we present a new method, called AdaTune, that significantly reduces the optimization time of tensor programs for high-performance deep learning inference. In particular, we propose an adaptive evaluation method that statistically early terminates a costly hardware measurement without losing much accuracy. We further devise a surrogate model with uncertainty quantification that allows the optimization to adapt to hardware and model heterogeneity better. Finally, we introduce a contextual optimizer that provides adaptive control of the exploration and exploitation to improve the transformation space searching effectiveness. We evaluate and compare the levels of optimization obtained by a state-of-the-art DL compiler and AdaTune. The experiment results show that AdaTune obtains up to 115% higher GFLOPS than the baseline under the same optimization time budget. Furthermore, AdaTune provides 1.3--3.9X speedup in optimization time over the state-of-the-art to reach the same optimization quality for a range of models across different hardware architectures.
count=1
* A Variational Approach for Learning from Positive and Unlabeled Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/aa0d2a804a3510442f2fd40f2100b054-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/aa0d2a804a3510442f2fd40f2100b054-Paper.pdf)]
    * Title: A Variational Approach for Learning from Positive and Unlabeled Data
    * Year: `2020`
    * Authors: Hui Chen, Fangqing Liu, Yin Wang, Liyue Zhao, Hao Wu
    * Abstract: Learning binary classiﬁers only from positive and unlabeled (PU) data is an important and challenging task in many real-world applications, including web text classiﬁcation, disease gene identiﬁcation and fraud detection, where negative samples are difﬁcult to verify experimentally. Most recent PU learning methods are developed based on the misclassiﬁcation risk of the supervised learning type, and they may suffer from inaccurate estimates of class prior probabilities. In this paper, we introduce a variational principle for PU learning that allows us to quantitatively evaluate the modeling error of the Bayesian classiﬁer directly from given data. This leads to a loss function which can be efﬁciently calculated without involving class prior estimation or any other intermediate estimation problems, and the variational learning method can then be employed to optimize the classiﬁer under general conditions. We illustrate the effectiveness of the proposed variational method on a number of benchmark examples.
count=1
* Calibrating Deep Neural Networks using Focal Loss
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/aeb7b30ef1d024a76f21a1d40e30c302-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/aeb7b30ef1d024a76f21a1d40e30c302-Paper.pdf)]
    * Title: Calibrating Deep Neural Networks using Focal Loss
    * Year: `2020`
    * Authors: Jishnu Mukhoti, Viveka Kulharia, Amartya Sanyal, Stuart Golodetz, Philip Torr, Puneet Dokania
    * Abstract: Miscalibration -- a mismatch between a model's confidence and its correctness -- of Deep Neural Networks (DNNs) makes their predictions hard to rely on. Ideally, we want networks to be accurate, calibrated and confident. We show that, as opposed to the standard cross-entropy loss, focal loss (Lin et al., 2017) allows us to learn models that are already very well calibrated. When combined with temperature scaling, whilst preserving accuracy, it yields state-of-the-art calibrated models. We provide a thorough analysis of the factors causing miscalibration, and use the insights we glean from this to justify the empirically excellent performance of focal loss. To facilitate the use of focal loss in practice, we also provide a principled approach to automatically select the hyperparameter involved in the loss function. We perform extensive experiments on a variety of computer vision and NLP datasets, and with a wide variety of network architectures, and show that our approach achieves state-of-the-art calibration without compromising on accuracy in almost all cases. Code is available at https://github.com/torrvision/focal_calibration.
count=1
* Certified Monotonic Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/b139aeda1c2914e3b579aafd3ceeb1bd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/b139aeda1c2914e3b579aafd3ceeb1bd-Paper.pdf)]
    * Title: Certified Monotonic Neural Networks
    * Year: `2020`
    * Authors: Xingchao Liu, Xing Han, Na Zhang, Qiang Liu
    * Abstract: Learning monotonic models with respect to a subset of the inputs is a desirable feature to effectively address the fairness, interpretability, and generalization issues in practice. Existing methods for learning monotonic neural networks either require specifically designed model structures to ensure monotonicity, which can be too restrictive/complicated, or enforce monotonicity by adjusting the learning process, which cannot provably guarantee the learned model is monotonic on selected features. In this work, we propose to certify the monotonicity of the general piece-wise linear neural networks by solving a mixed integer linear programming problem. This provides a new general approach for learning monotonic neural networks with arbitrary model structures. Our method allows us to train neural networks with heuristic monotonicity regularizations, and we can gradually increase the regularization magnitude until the learned network is certified monotonic. Compared to prior work, our method does not require human-designed constraints on the weight space and also yields more accurate approximation. Empirical studies on various datasets demonstrate the efficiency of our approach over the state-of-the-art methods, such as Deep Lattice Networks
count=1
* Fast and Accurate $k$-means++ via Rejection Sampling
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/babcff88f8be8c4795bd6f0f8cccca61-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/babcff88f8be8c4795bd6f0f8cccca61-Paper.pdf)]
    * Title: Fast and Accurate $k$-means++ via Rejection Sampling
    * Year: `2020`
    * Authors: Vincent Cohen-Addad, Silvio Lattanzi, Ashkan Norouzi-Fard, Christian Sohler, Ola Svensson
    * Abstract: $k$-means++ \cite{arthur2007k} is a widely used clustering algorithm that is easy to implement, has nice theoretical guarantees and strong empirical performance. Despite its wide adoption, $k$-means++ sometimes suffers from being slow on large data-sets so a natural question has been to obtain more efficient algorithms with similar guarantees. In this paper, we present such a near linear time algorithm for $k$-means++ seeding. Interestingly our algorithm obtains the same theoretical guarantees as $k$-means++ and significantly improves earlier results on fast $k$-means++ seeding. Moreover, we show empirically that our algorithm is significantly faster than $k$-means++ and obtains solutions of equivalent quality.
count=1
* Gaussian Gated Linear Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/c0356641f421b381e475776b602a5da8-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/c0356641f421b381e475776b602a5da8-Paper.pdf)]
    * Title: Gaussian Gated Linear Networks
    * Year: `2020`
    * Authors: David Budden, Adam Marblestone, Eren Sezener, Tor Lattimore, Gregory Wayne, Joel Veness
    * Abstract: We propose the Gaussian Gated Linear Network (G-GLN), an extension to the recently proposed GLN family of deep neural networks. Instead of using backpropagation to learn features, GLNs have a distributed and local credit assignment mechanism based on optimizing a convex objective. This gives rise to many desirable properties including universality, data-efficient online learning, trivial interpretability and robustness to catastrophic forgetting. We extend the GLN framework from classification to multiple regression and density modelling by generalizing geometric mixing to a product of Gaussian densities. The G-GLN achieves competitive or state-of-the-art performance on several univariate and multivariate regression benchmarks, and we demonstrate its applicability to practical tasks including online contextual bandits and density estimation via denoising.
count=1
* Interpolation Technique to Speed Up Gradients Propagation in Neural ODEs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/c24c65259d90ed4a19ab37b6fd6fe716-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/c24c65259d90ed4a19ab37b6fd6fe716-Paper.pdf)]
    * Title: Interpolation Technique to Speed Up Gradients Propagation in Neural ODEs
    * Year: `2020`
    * Authors: Talgat Daulbaev, Alexandr Katrutsa, Larisa Markeeva, Julia Gusak, Andrzej Cichocki, Ivan Oseledets
    * Abstract: We propose a simple interpolation-based method for the efficient approximation of gradients in neural ODE models. We compare it with reverse dynamic method (known in literature as “adjoint method”) to train neural ODEs on classification, density estimation and inference approximation tasks. We also propose a theoretical justification of our approach using logarithmic norm formalism. As a result, our method allows faster model training than the reverse dynamic method what was confirmed and validated by extensive numerical experiments for several standard benchmarks.
count=1
* PAC-Bayes Analysis Beyond the Usual Bounds
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/c3992e9a68c5ae12bd18488bc579b30d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/c3992e9a68c5ae12bd18488bc579b30d-Paper.pdf)]
    * Title: PAC-Bayes Analysis Beyond the Usual Bounds
    * Year: `2020`
    * Authors: Omar Rivasplata, Ilja Kuzborskij, Csaba Szepesvari, John Shawe-Taylor
    * Abstract: We focus on a stochastic learning model where the learner observes a finite set of training examples and the output of the learning process is a data-dependent distribution over a space of hypotheses. The learned data-dependent distribution is then used to make randomized predictions, and the high-level theme addressed here is guaranteeing the quality of predictions on examples that were not seen during training, i.e. generalization. In this setting the unknown quantity of interest is the expected risk of the data-dependent randomized predictor, for which upper bounds can be derived via a PAC-Bayes analysis, leading to PAC-Bayes bounds. Specifically, we present a basic PAC-Bayes inequality for stochastic kernels, from which one may derive extensions of various known PAC-Bayes bounds as well as novel bounds. We clarify the role of the requirements of fixed ‘data-free’ priors, bounded losses, and i.i.d. data. We highlight that those requirements were used to upper-bound an exponential moment term, while the basic PAC-Bayes theorem remains valid without those restrictions. We present three bounds that illustrate the use of data-dependent priors, including one for the unbounded square loss.
count=1
* Calibrated Reliable Regression using Maximum Mean Discrepancy
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/c74c4bf0dad9cbae3d80faa054b7d8ca-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/c74c4bf0dad9cbae3d80faa054b7d8ca-Paper.pdf)]
    * Title: Calibrated Reliable Regression using Maximum Mean Discrepancy
    * Year: `2020`
    * Authors: Peng Cui, Wenbo Hu, Jun Zhu
    * Abstract: Accurate quantification of uncertainty is crucial for real-world applications of machine learning. However, modern deep neural networks still produce unreliable predictive uncertainty, often yielding over-confident predictions. In this paper, we are concerned with getting well-calibrated predictions in regression tasks. We propose the calibrated regression method using the maximum mean discrepancy by minimizing the kernel embedding measure. Theoretically, the calibration error of our method asymptotically converges to zero when the sample size is large enough. Experiments on non-trivial real datasets show that our method can produce well-calibrated and sharp prediction intervals, which outperforms the related state-of-the-art methods.
count=1
* Learning outside the Black-Box: The pursuit of interpretable models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/ce758408f6ef98d7c7a7b786eca7b3a8-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/ce758408f6ef98d7c7a7b786eca7b3a8-Paper.pdf)]
    * Title: Learning outside the Black-Box: The pursuit of interpretable models
    * Year: `2020`
    * Authors: Jonathan Crabbe, Yao Zhang, William Zame, Mihaela van der Schaar
    * Abstract: Machine learning has proved its ability to produce accurate models -- but the deployment of these models outside the machine learning community has been hindered by the difficulties of interpreting these models. This paper proposes an algorithm that produces a continuous global interpretation of any given continuous black-box function. Our algorithm employs a variation of projection pursuit in which the ridge functions are chosen to be Meijer G-functions, rather than the usual polynomial splines. Because Meijer G-functions are differentiable in their parameters, we can "tune" the parameters of the representation by gradient descent; as a consequence, our algorithm is efficient. Using five familiar data sets from the UCI repository and two familiar machine learning algorithms, we demonstrate that our algorithm produces global interpretations that are both faithful (highly accurate) and parsimonious (involve a small number of terms). Our interpretations permit easy understanding of the relative importance of features and feature interactions. Our interpretation algorithm represents a leap forward from the previous state of the art.
count=1
* Efficient Nonmyopic Bayesian Optimization via One-Shot Multi-Step Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/d1d5923fc822531bbfd9d87d4760914b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/d1d5923fc822531bbfd9d87d4760914b-Paper.pdf)]
    * Title: Efficient Nonmyopic Bayesian Optimization via One-Shot Multi-Step Trees
    * Year: `2020`
    * Authors: Shali Jiang, Daniel Jiang, Maximilian Balandat, Brian Karrer, Jacob Gardner, Roman Garnett
    * Abstract: Bayesian optimization is a sequential decision making framework for optimizing expensive-to-evaluate black-box functions. Computing a full lookahead policy amounts to solving a highly intractable stochastic dynamic program. Myopic approaches, such as expected improvement, are often adopted in practice, but they ignore the long-term impact of the immediate decision. Existing nonmyopic approaches are mostly heuristic and/or computationally expensive. In this paper, we provide the first efficient implementation of general multi-step lookahead Bayesian optimization, formulated as a sequence of nested optimization problems within a multi-step scenario tree. Instead of solving these problems in a nested way, we equivalently optimize all decision variables in the full tree jointly, in a "one-shot" fashion. Combining this with an efficient method for implementing multi-step Gaussian process "fantasization," we demonstrate that multi-step expected improvement is computationally tractable and exhibits performance superior to existing methods on a wide range of benchmarks.
count=1
* Ensuring Fairness Beyond the Training Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/d6539d3b57159babf6a72e106beb45bd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/d6539d3b57159babf6a72e106beb45bd-Paper.pdf)]
    * Title: Ensuring Fairness Beyond the Training Data
    * Year: `2020`
    * Authors: Debmalya Mandal, Samuel Deng, Suman Jana, Jeannette Wing, Daniel J. Hsu
    * Abstract: We initiate the study of fair classifiers that are robust to perturbations in the training distribution. Despite recent progress, the literature on fairness has largely ignored the design of fair and robust classifiers. In this work, we develop classifiers that are fair not only with respect to the training distribution but also for a class of distributions that are weighted perturbations of the training samples. We formulate a min-max objective function whose goal is to minimize a distributionally robust training loss, and at the same time, find a classifier that is fair with respect to a class of distributions. We first reduce this problem to finding a fair classifier that is robust with respect to the class of distributions. Based on an online learning algorithm, we develop an iterative algorithm that provably converges to such a fair and robust solution. Experiments on standard machine learning fairness datasets suggest that, compared to the state-of-the-art fair classifiers, our classifier retains fairness guarantees and test accuracy for a large class of perturbations on the test set. Furthermore, our experiments show that there is an inherent trade-off between fairness robustness and accuracy of such classifiers.
count=1
* All your loss are belong to Bayes
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/d75320797f266ba9ed6dd6dc218cb1b5-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/d75320797f266ba9ed6dd6dc218cb1b5-Paper.pdf)]
    * Title: All your loss are belong to Bayes
    * Year: `2020`
    * Authors: Christian Walder, Richard Nock
    * Abstract: Loss functions are a cornerstone of machine learning and the starting point of most algorithms. Statistics and Bayesian decision theory have contributed, via properness, to elicit over the past decades a wide set of admissible losses in supervised learning, to which most popular choices belong (logistic, square, Matsushita, etc.). Rather than making a potentially biased ad hoc choice of the loss, there has recently been a boost in efforts to fit the loss to the domain at hand while training the model itself. The key approaches fit a canonical link, a function which monotonically relates the closed unit interval to R and can provide a proper loss via integration. In this paper, we rely on a broader view of proper composite losses and a recent construct from information geometry, source functions, whose fitting alleviates constraints faced by canonical links. We introduce a trick on squared Gaussian Processes to obtain a random process whose paths are compliant source functions with many desirable properties in the context of link estimation. Experimental results demonstrate substantial improvements over the state of the art.
count=1
* Optimization and Generalization Analysis of Transduction through Gradient Boosting and Application to Multi-scale Graph Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/dab49080d80c724aad5ebf158d63df41-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/dab49080d80c724aad5ebf158d63df41-Paper.pdf)]
    * Title: Optimization and Generalization Analysis of Transduction through Gradient Boosting and Application to Multi-scale Graph Neural Networks
    * Year: `2020`
    * Authors: Kenta Oono, Taiji Suzuki
    * Abstract: It is known that the current graph neural networks (GNNs) are difficult to make themselves deep due to the problem known as over-smoothing. Multi-scale GNNs are a promising approach for mitigating the over-smoothing problem. However, there is little explanation of why it works empirically from the viewpoint of learning theory. In this study, we derive the optimization and generalization guarantees of transductive learning algorithms that include multi-scale GNNs. Using the boosting theory, we prove the convergence of the training error under weak learning-type conditions. By combining it with generalization gap bounds in terms of transductive Rademacher complexity, we show that a test error bound of a specific type of multi-scale GNNs that decreases corresponding to the number of node aggregations under some conditions. Our results offer theoretical explanations for the effectiveness of the multi-scale structure against the over-smoothing problem. We apply boosting algorithms to the training of multi-scale GNNs for real-world node prediction tasks. We confirm that its performance is comparable to existing GNNs, and the practical behaviors are consistent with theoretical observations. Code is available at https://github.com/delta2323/GB-GNN.
count=1
* Fair regression via plug-in estimator and recalibration with statistical guarantees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/ddd808772c035aed516d42ad3559be5f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/ddd808772c035aed516d42ad3559be5f-Paper.pdf)]
    * Title: Fair regression via plug-in estimator and recalibration with statistical guarantees
    * Year: `2020`
    * Authors: Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, Massimiliano Pontil
    * Abstract: We study the problem of learning an optimal regression function subject to a fairness constraint. It requires that, conditionally on the sensitive feature, the distribution of the function output remains the same. This constraint naturally extends the notion of demographic parity, often used in classification, to the regression setting. We tackle this problem by leveraging on a proxy-discretized version, for which we derive an explicit expression of the optimal fair predictor. This result naturally suggests a two stage approach, in which we first estimate the (unconstrained) regression function from a set of labeled data and then we recalibrate it with another set of unlabeled data. The recalibration step can be efficiently performed via a smooth optimization. We derive rates of convergence of the proposed estimator to the optimal fair predictor both in terms of the risk and fairness constraint. Finally, we present numerical experiments illustrating that the proposed method is often superior or competitive with state-of-the-art methods.
count=1
* Transferable Calibration with Lower Bias and Variance in Domain Adaptation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/df12ecd077efc8c23881028604dbb8cc-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/df12ecd077efc8c23881028604dbb8cc-Paper.pdf)]
    * Title: Transferable Calibration with Lower Bias and Variance in Domain Adaptation
    * Year: `2020`
    * Authors: Ximei Wang, Mingsheng Long, Jianmin Wang, Michael Jordan
    * Abstract: Domain Adaptation (DA) enables transferring a learning machine from a labeled source domain to an unlabeled target one. While remarkable advances have been made, most of the existing DA methods focus on improving the target accuracy at inference. How to estimate the predictive uncertainty of DA models is vital for decision-making in safety-critical scenarios but remains the boundary to explore. In this paper, we delve into the open problem of Calibration in DA, which is extremely challenging due to the coexistence of domain shift and the lack of target labels. We first reveal the dilemma that DA models learn higher accuracy at the expense of well-calibrated probabilities. Driven by this finding, we propose Transferable Calibration (TransCal) to achieve more accurate calibration with lower bias and variance in a unified hyperparameter-free optimization framework. As a general post-hoc calibration method, TransCal can be easily applied to recalibrate existing DA methods. Its efficacy has been justified both theoretically and empirically.
count=1
* A Limitation of the PAC-Bayes Framework
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/ec79d4bed810ed64267d169b0d37373e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/ec79d4bed810ed64267d169b0d37373e-Paper.pdf)]
    * Title: A Limitation of the PAC-Bayes Framework
    * Year: `2020`
    * Authors: Roi Livni, Shay Moran
    * Abstract: PAC-Bayes is a useful framework for deriving generalization bounds which was introduced by McAllester ('98). This framework has the flexibility of deriving distribution- and algorithm-dependent bounds, which are often tighter than VC-related uniform convergence bounds. In this manuscript we present a limitation for the PAC-Bayes framework. We demonstrate an easy learning task which is not amenable to a PAC-Bayes analysis. Specifically, we consider the task of linear classification in 1D; it is well-known that this task is learnable using just $O(\log(1/\delta)/\epsilon)$ examples. 	On the other hand, we show that this fact can not be proved using a PAC-Bayes analysis: for any algorithm that learns 1-dimensional linear classifiers there exists a (realizable) distribution for which the PAC-Bayes bound is arbitrarily large.
count=1
* Why Normalizing Flows Fail to Detect Out-of-Distribution Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/hash/ecb9fe2fbb99c31f567e9823e884dbec-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2020/file/ecb9fe2fbb99c31f567e9823e884dbec-Paper.pdf)]
    * Title: Why Normalizing Flows Fail to Detect Out-of-Distribution Data
    * Year: `2020`
    * Authors: Polina Kirichenko, Pavel Izmailov, Andrew G. Wilson
    * Abstract: Detecting out-of-distribution (OOD) data is crucial for robust machine learning systems. Normalizing flows are flexible deep generative models that often surprisingly fail to distinguish between in- and out-of-distribution data: a flow trained on pictures of clothing assigns higher likelihood to handwritten digits. We investigate why normalizing flows perform poorly for OOD detection. We demonstrate that flows learn local pixel correlations and generic image-to-latent-space transformations which are not specific to the target image datasets, focusing on flows based on coupling layers. We show that by modifying the architecture of flow coupling layers we can bias the flow towards learning the semantic structure of the target data, improving OOD detection. Our investigation reveals that properties that enable flows to generate high-fidelity images can have a detrimental effect on OOD detection.
count=1
* Flattening a Hierarchical Clustering through Active Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/03793ef7d06ffd63d34ade9d091f1ced-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/03793ef7d06ffd63d34ade9d091f1ced-Paper.pdf)]
    * Title: Flattening a Hierarchical Clustering through Active Learning
    * Year: `2019`
    * Authors: Fabio Vitale, Anand Rajagopalan, Claudio Gentile
    * Abstract: We investigate active learning by pairwise similarity over the leaves of trees originating from hierarchical clustering procedures. In the realizable setting, we provide a full characterization of the number of queries needed to achieve perfect reconstruction of the tree cut. In the non-realizable setting, we rely on known important-sampling procedures to obtain regret and query complexity bounds. Our algorithms come with theoretical guarantees on the statistical error and, more importantly, lend themselves to {\em linear-time} implementations in the relevant parameters of the problem. We discuss such implementations, prove running time guarantees for them, and present preliminary experiments on real-world datasets showing the compelling practical performance of our algorithms as compared to both passive learning and simple active learning baselines.
count=1
* Correlation Priors for Reinforcement Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/1bd2caf96a17d892c2c7e9959549cfc7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/1bd2caf96a17d892c2c7e9959549cfc7-Paper.pdf)]
    * Title: Correlation Priors for Reinforcement Learning
    * Year: `2019`
    * Authors: Bastian Alt, Adrian Šošić, Heinz Koeppl
    * Abstract: Many decision-making problems naturally exhibit pronounced structures inherited from the characteristics of the underlying environment. In a Markov decision process model, for example, two distinct states can have inherently related semantics or encode resembling physical state configurations. This often implies locally correlated transition dynamics among the states. In order to complete a certain task in such environments, the operating agent usually needs to execute a series of temporally and spatially correlated actions. Though there exists a variety of approaches to capture these correlations in continuous state-action domains, a principled solution for discrete environments is missing. In this work, we present a Bayesian learning framework based on Pólya-Gamma augmentation that enables an analogous reasoning in such cases. We demonstrate the framework on a number of common decision-making related problems, such as imitation learning, subgoal extraction, system identification and Bayesian reinforcement learning. By explicitly modeling the underlying correlation structures of these problems, the proposed approach yields superior predictive performance compared to correlation-agnostic models, even when trained on data sets that are an order of magnitude smaller in size.
count=1
* Exploring Algorithmic Fairness in Robust Graph Covering Problems
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/1d7c2aae840867027b7edd17b6aaa0e9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/1d7c2aae840867027b7edd17b6aaa0e9-Paper.pdf)]
    * Title: Exploring Algorithmic Fairness in Robust Graph Covering Problems
    * Year: `2019`
    * Authors: Aida Rahmattalabi, Phebe Vayanos, Anthony Fulginiti, Eric Rice, Bryan Wilder, Amulya Yadav, Milind Tambe
    * Abstract: Fueled by algorithmic advances, AI algorithms are increasingly being deployed in settings subject to unanticipated challenges with complex social effects. Motivated by real-world deployment of AI driven, social-network based suicide prevention and landslide risk management interventions, this paper focuses on a robust graph covering problem subject to group fairness constraints. We show that, in the absence of fairness constraints, state-of-the-art algorithms for the robust graph covering problem result in biased node coverage: they tend to discriminate individuals (nodes) based on membership in traditionally marginalized groups. To remediate this issue, we propose a novel formulation of the robust covering problem with fairness constraints and a tractable approximation scheme applicable to real world instances. We provide a formal analysis of the price of group fairness (PoF) for this problem, where we show that uncertainty can lead to greater PoF. We demonstrate the effectiveness of our approach on several real-world social networks. Our method yields competitive node coverage while significantly improving group fairness relative to state-of-the-art methods.
count=1
* TAB-VCR: Tags and Attributes based VCR Baselines
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/1fa6269f58898f0e809575c9a48747ef-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/1fa6269f58898f0e809575c9a48747ef-Paper.pdf)]
    * Title: TAB-VCR: Tags and Attributes based VCR Baselines
    * Year: `2019`
    * Authors: Jingxiang Lin, Unnat Jain, Alexander Schwing
    * Abstract: Reasoning is an important ability that we learn from a very early age. Yet, reasoning is extremely hard for algorithms. Despite impressive recent progress that has been reported on tasks that necessitate reasoning, such as visual question answering and visual dialog, models often exploit biases in datasets. To develop models with better reasoning abilities, recently, the new visual commonsense reasoning(VCR) task has been introduced. Not only do models have to answer questions, but also do they have to provide a reason for the given answer. The proposed baseline achieved compelling results, leveraging a meticulously designed model composed of LSTM modules and attention nets. Here we show that a much simpler model obtained by ablating and pruning the existing intricate baseline can perform better with half the number of trainable parameters. By associating visual features with attribute information and better text to image grounding, we obtain further improvements for our simpler & effective baseline, TAB-VCR. We show that this approach results in a 5.3%, 4.4% and 6.5% absolute improvement over the previous state-of-the-art on question answering, answer justification and holistic VCR. Webpage: https://deanplayerljx.github.io/tabvcr/
count=1
* Learning to Screen
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/30d411fdc0e6daf092a74354094359bb-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/30d411fdc0e6daf092a74354094359bb-Paper.pdf)]
    * Title: Learning to Screen
    * Year: `2019`
    * Authors: Alon Cohen, Avinatan Hassidim, Haim Kaplan, Yishay Mansour, Shay Moran
    * Abstract: Imagine a large firm with multiple departments that plans a large recruitment. Candidates arrive one-by-one, and for each candidate the firm decides, based on her data (CV, skills, experience, etc), whether to summon her for an interview. The firm wants to recruit the best candidates while minimizing the number of interviews. We model such scenarios as an assignment problem between items (candidates) and categories (departments): the items arrive one-by-one in an online manner, and upon processing each item the algorithm decides, based on its value and the categories it can be matched with, whether to retain or discard it (this decision is irrevocable). The goal is to retain as few items as possible while guaranteeing that the set of retained items contains an optimal matching. We consider two variants of this problem: (i) in the first variant it is assumed that the $n$ items are drawn independently from an unknown distribution $D$. (ii) In the second variant it is assumed that before the process starts, the algorithm has an access to a training set of $n$ items drawn independently from the same unknown distribution (e.g.\ data of candidates from previous recruitment seasons). We give tight bounds on the minimum possible number of retained items in each of these variants. These results demonstrate that one can retain exponentially less items in the second variant (with the training set). Our algorithms and analysis utilize ideas and techniques from statistical learning theory and from discrete algorithms.
count=1
* Machine Learning Estimation of Heterogeneous Treatment Effects with Instruments
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/3b2acfe2e38102074656ed938abf4ac3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/3b2acfe2e38102074656ed938abf4ac3-Paper.pdf)]
    * Title: Machine Learning Estimation of Heterogeneous Treatment Effects with Instruments
    * Year: `2019`
    * Authors: Vasilis Syrgkanis, Victor Lei, Miruna Oprescu, Maggie Hei, Keith Battocchi, Greg Lewis
    * Abstract: We consider the estimation of heterogeneous treatment effects with arbitrary machine learning methods in the presence of unobserved confounders with the aid of a valid instrument. Such settings arise in A/B tests with an intent-to-treat structure, where the experimenter randomizes over which user will receive a recommendation to take an action, and we are interested in the effect of the downstream action. We develop a statistical learning approach to the estimation of heterogeneous effects, reducing the problem to the minimization of an appropriate loss function that depends on a set of auxiliary models (each corresponding to a separate prediction task). The reduction enables the use of all recent algorithmic advances (e.g. neural nets, forests). We show that the estimated effect model is robust to estimation errors in the auxiliary models, by showing that the loss satisfies a Neyman orthogonality criterion. Our approach can be used to estimate projections of the true effect model on simpler hypothesis spaces. When these spaces are parametric, then the parameter estimates are asymptotically normal, which enables construction of confidence sets. We applied our method to estimate the effect of membership on downstream webpage engagement for a major travel webpage, using as an instrument an intent-to-treat A/B test among 4 million users, where some users received an easier membership sign-up process. We also validate our method on synthetic data and on public datasets for the effects of schooling on income.
count=1
* Differentially Private Distributed Data Summarization under Covariate Shift
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/3c88c1db16b9523b4dcdcd572aa1e16a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/3c88c1db16b9523b4dcdcd572aa1e16a-Paper.pdf)]
    * Title: Differentially Private Distributed Data Summarization under Covariate Shift
    * Year: `2019`
    * Authors: Kanthi Sarpatwar, Karthikeyan Shanmugam, Venkata Sitaramagiridharganesh Ganapavarapu, Ashish Jagmohan, Roman Vaculin
    * Abstract: We envision Artificial Intelligence marketplaces to be platforms where consumers, with very less data for a target task, can obtain a relevant model by accessing many private data sources with vast number of data samples. One of the key challenges is to construct a training dataset that matches a target task without compromising on privacy of the data sources. To this end, we consider the following distributed data summarizataion problem. Given K private source datasets denoted by $[D_i]_{i\in [K]}$ and a small target validation set $D_v$, which may involve a considerable covariate shift with respect to the sources, compute a summary dataset $D_s\subseteq \bigcup_{i\in [K]} D_i$ such that its statistical distance from the validation dataset $D_v$ is minimized. We use the popular Maximum Mean Discrepancy as the measure of statistical distance. The non-private problem has received considerable attention in prior art, for example in prototype selection (Kim et al., NIPS 2016). Our work is the first to obtain strong differential privacy guarantees while ensuring the quality guarantees of the non-private version. We study this problem in a Parsimonious Curator Privacy Model, where a trusted curator coordinates the summarization process while minimizing the amount of private information accessed. Our central result is a novel protocol that (a) ensures the curator does not access more than $O(K^{\frac{1}{3}}|D_s| + |D_v|)$ points (b) has formal privacy guarantees on the leakage of information between the data owners and (c) closely matches the best known non-private greedy algorithm. Our protocol uses two hash functions, one inspired by the Rahimi-Recht random features method and the second leverages state of the art differential privacy mechanisms. We introduce a novel ``noiseless'' differentially private auctioning protocol, which may be of independent interest. Apart from theoretical guarantees, we demonstrate the efficacy of our protocol using real-world datasets.
count=1
* Bootstrapping Upper Confidence Bound
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/412758d043dd247bddea07c7ec558c31-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/412758d043dd247bddea07c7ec558c31-Paper.pdf)]
    * Title: Bootstrapping Upper Confidence Bound
    * Year: `2019`
    * Authors: Botao Hao, Yasin Abbasi Yadkori, Zheng Wen, Guang Cheng
    * Abstract: Upper Confidence Bound (UCB) method is arguably the most celebrated one used in online decision making with partial information feedback. Existing techniques for constructing confidence bounds are typically built upon various concentration inequalities, which thus lead to over-exploration. In this paper, we propose a non-parametric and data-dependent UCB algorithm based on the multiplier bootstrap. To improve its finite sample performance, we further incorporate second-order correction into the above construction. In theory, we derive both problem-dependent and problem-independent regret bounds for multi-armed bandits under a much weaker tail assumption than the standard sub-Gaussianity. Numerical results demonstrate significant regret reductions by our method, in comparison with several baselines in a range of multi-armed and linear bandit problems.
count=1
* Model Selection for Contextual Bandits
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/433371e69eb202f8e7bc8ec2c8d48021-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/433371e69eb202f8e7bc8ec2c8d48021-Paper.pdf)]
    * Title: Model Selection for Contextual Bandits
    * Year: `2019`
    * Authors: Dylan J. Foster, Akshay Krishnamurthy, Haipeng Luo
    * Abstract: We introduce the problem of model selection for contextual bandits, where a learner must adapt to the complexity of the optimal policy while balancing exploration and exploitation. Our main result is a new model selection guarantee for linear contextual bandits. We work in the stochastic realizable setting with a sequence of nested linear policy classes of dimension $d_1 < d_2 < \ldots$, where the $m^\star$-th class contains the optimal policy, and we design an algorithm that achieves $\tilde{O}l(T^{2/3}d^{1/3}_{m^\star})$ regret with no prior knowledge of the optimal dimension $d_{m^\star}$. The algorithm also achieves regret $\tilde{O}(T^{3/4} + \sqrt{Td_{m^\star}})$, which is optimal for $d_{m^{\star}}\geq{}\sqrt{T}$. This is the first model selection result for contextual bandits with non-vacuous regret for all values of $d_{m^\star}$, and to the best of our knowledge is the first positive result of this type for any online learning setting with partial information. The core of the algorithm is a new estimator for the gap in the best loss achievable by two linear policy classes, which we show admits a convergence rate faster than the rate required to learn the parameters for either class.
count=1
* Learning Sample-Specific Models with Low-Rank Personalized Regression
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/52d2752b150f9c35ccb6869cbf074e48-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/52d2752b150f9c35ccb6869cbf074e48-Paper.pdf)]
    * Title: Learning Sample-Specific Models with Low-Rank Personalized Regression
    * Year: `2019`
    * Authors: Ben Lengerich, Bryon Aragam, Eric P. Xing
    * Abstract: Modern applications of machine learning (ML) deal with increasingly heterogeneous datasets comprised of data collected from overlapping latent subpopulations. As a result, traditional models trained over large datasets may fail to recognize highly predictive localized effects in favour of weakly predictive global patterns. This is a problem because localized effects are critical to developing individualized policies and treatment plans in applications ranging from precision medicine to advertising. To address this challenge, we propose to estimate sample-specific models that tailor inference and prediction at the individual level. In contrast to classical ML models that estimate a single, complex model (or only a few complex models), our approach produces a model personalized to each sample. These sample-specific models can be studied to understand subgroup dynamics that go beyond coarse-grained class labels. Crucially, our approach does not assume that relationships between samples (e.g. a similarity network) are known a priori. Instead, we use unmodeled covariates to learn a latent distance metric over the samples. We apply this approach to financial, biomedical, and electoral data as well as simulated data and show that sample-specific models provide fine-grained interpretations of complicated phenomena without sacrificing predictive accuracy compared to state-of-the-art models such as deep neural networks.
count=1
* Imitation-Projected Programmatic Reinforcement Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/5a44a53b7d26bb1e54c05222f186dcfb-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/5a44a53b7d26bb1e54c05222f186dcfb-Paper.pdf)]
    * Title: Imitation-Projected Programmatic Reinforcement Learning
    * Year: `2019`
    * Authors: Abhinav Verma, Hoang Le, Yisong Yue, Swarat Chaudhuri
    * Abstract: We study the problem of programmatic reinforcement learning, in which policies are represented as short programs in a symbolic language. Programmatic policies can be more interpretable, generalizable, and amenable to formal verification than neural policies; however, designing rigorous learning approaches for such policies remains a challenge. Our approach to this challenge - a meta-algorithm called PROPEL - is based on three insights. First, we view our learning task as optimization in policy space, modulo the constraint that the desired policy has a programmatic representation, and solve this optimization problem using a form of mirror descent that takes a gradient step into the unconstrained policy space and then projects back onto the constrained space. Second, we view the unconstrained policy space as mixing neural and programmatic representations, which enables employing state-of-the-art deep policy gradient approaches. Third, we cast the projection step as program synthesis via imitation learning, and exploit contemporary combinatorial methods for this task. We present theoretical convergence results for PROPEL and empirically evaluate the approach in three continuous control domains. The experiments show that PROPEL can significantly outperform state-of-the-art approaches for learning programmatic policies.
count=1
* Copula Multi-label Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/5d2c2cee8ab0b9a36bd1ed7196bd6c4a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/5d2c2cee8ab0b9a36bd1ed7196bd6c4a-Paper.pdf)]
    * Title: Copula Multi-label Learning
    * Year: `2019`
    * Authors: Weiwei Liu
    * Abstract: A formidable challenge in multi-label learning is to model the interdependencies between labels and features. Unfortunately, the statistical properties of existing multi-label dependency modelings are still not well understood. Copulas are a powerful tool for modeling dependence of multivariate data, and achieve great success in a wide range of applications, such as finance, econometrics and systems neuroscience. This inspires us to develop a novel copula multi-label learning paradigm for modeling label and feature dependencies. The copula based paradigm enables to reveal new statistical insights in multi-label learning. In particular, the paper first leverages the kernel trick to construct continuous distribution in the output space, and then estimates our proposed model semiparametrically where the copula is modeled parametrically, while the marginal distributions are modeled nonparametrically. Theoretically, we show that our estimator is an unbiased and consistent estimator and follows asymptotically a normal distribution. Moreover, we bound the mean squared error of estimator. The experimental results from various domains validate the superiority of our proposed approach.
count=1
* Sample Efficient Active Learning of Causal Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/5ee5605917626676f6a285fa4c10f7b0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/5ee5605917626676f6a285fa4c10f7b0-Paper.pdf)]
    * Title: Sample Efficient Active Learning of Causal Trees
    * Year: `2019`
    * Authors: Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Kocaoglu, Enric Boix Adsera, Guy Bresler
    * Abstract: We consider the problem of experimental design for learning causal graphs that have a tree structure. We propose an adaptive framework that determines the next intervention based on a Bayesian prior updated with the outcomes of previous experiments, focusing on the setting where observational data is cheap (assumed infinite) and interventional data is expensive. While information greedy approaches are popular in active learning, we show that in this setting they can be exponentially suboptimal (in the number of interventions required), and instead propose an algorithm that exploits graph structure in the form of a centrality measure. If infinite interventional data is available, we show that the algorithm requires a number of interventions less than or equal to a factor of 2 times the minimum achievable number. We show that the algorithm and the associated theory can be adapted to the setting where each performed intervention yields finitely many samples. Several extensions are also presented, to the case where a specified set of nodes cannot be intervened on, to the case where $K$ interventions are scheduled at once, and to the fully adaptive case where each experiment yields only one sample. In the case of finite interventional data, through simulated experiments we show that our algorithms outperform different adaptive baseline algorithms.
count=1
* Gradient Information for Representation and Modeling
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/6d9c547cf146054a5a720606a7694467-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/6d9c547cf146054a5a720606a7694467-Paper.pdf)]
    * Title: Gradient Information for Representation and Modeling
    * Year: `2019`
    * Authors: Jie Ding, Robert Calderbank, Vahid Tarokh
    * Abstract: Motivated by Fisher divergence, in this paper we present a new set of information quantities which we refer to as gradient information. These measures serve as surrogates for classical information measures such as those based on logarithmic loss, Kullback-Leibler divergence, directed Shannon information, etc. in many data-processing scenarios of interest, and often provide significant computational advantage, improved stability and robustness. As an example, we apply these measures to the Chow-Liu tree algorithm, and demonstrate remarkable performance and significant computational reduction using both synthetic and real data.
count=1
* Recovering Bandits
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/9a093d729036a5bd4736e03c5d634501-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/9a093d729036a5bd4736e03c5d634501-Paper.pdf)]
    * Title: Recovering Bandits
    * Year: `2019`
    * Authors: Ciara Pike-Burke, Steffen Grunewalder
    * Abstract: We study the recovering bandits problem, a variant of the stochastic multi-armed bandit problem where the expected reward of each arm varies according to some unknown function of the time since the arm was last played. While being a natural extension of the classical bandit problem that arises in many real-world settings, this variation is accompanied by significant difficulties. In particular, methods need to plan ahead and estimate many more quantities than in the classical bandit setting. In this work, we explore the use of Gaussian processes to tackle the estimation and planing problem. We also discuss different regret definitions that let us quantify the performance of the methods. To improve computational efficiency of the methods, we provide an optimistic planning approximation. We complement these discussions with regret bounds and empirical studies.
count=1
* Partially Encrypted Deep Learning using Functional Encryption
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/9d28de8ff9bb6a3fa41fddfdc28f3bc1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/9d28de8ff9bb6a3fa41fddfdc28f3bc1-Paper.pdf)]
    * Title: Partially Encrypted Deep Learning using Functional Encryption
    * Year: `2019`
    * Authors: Théo Ryffel, David Pointcheval, Francis Bach, Edouard Dufour-Sans, Romain Gay
    * Abstract: Machine learning on encrypted data has received a lot of attention thanks to recent breakthroughs in homomorphic encryption and secure multi-party computation. It allows outsourcing computation to untrusted servers without sacrificing privacy of sensitive data. We propose a practical framework to perform partially encrypted and privacy-preserving predictions which combines adversarial training and functional encryption. We first present a new functional encryption scheme to efficiently compute quadratic functions so that the data owner controls what can be computed but is not involved in the calculation: it provides a decryption key which allows one to learn a specific function evaluation of some encrypted data. We then show how to use it in machine learning to partially encrypt neural networks with quadratic activation functions at evaluation time and we provide a thorough analysis of the information leaks based on indistinguishability of data items of the same label. Last, since several encryption schemes cannot deal with the last thresholding operation used for classification, we propose a training method to prevent selected sensitive features from leaking which adversarially optimizes the network against an adversary trying to identify these features. This is of great interest for several existing works using partially encrypted machine learning as it comes with almost no cost on the model's accuracy and significantly improves data privacy.
count=1
* Integer Discrete Flows and Lossless Compression
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/9e9a30b74c49d07d8150c8c83b1ccf07-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/9e9a30b74c49d07d8150c8c83b1ccf07-Paper.pdf)]
    * Title: Integer Discrete Flows and Lossless Compression
    * Year: `2019`
    * Authors: Emiel Hoogeboom, Jorn Peters, Rianne van den Berg, Max Welling
    * Abstract: Lossless compression methods shorten the expected representation size of data without loss of information, using a statistical model. Flow-based models are attractive in this setting because they admit exact likelihood optimization, which is equivalent to minimizing the expected number of bits per message. However, conventional flows assume continuous data, which may lead to reconstruction errors when quantized for compression. For that reason, we introduce a flow-based generative model for ordinal discrete data called Integer Discrete Flow (IDF): a bijective integer map that can learn rich transformations on high-dimensional data. As building blocks for IDFs, we introduce a flexible transformation layer called integer discrete coupling. Our experiments show that IDFs are competitive with other flow-based generative models. Furthermore, we demonstrate that IDF based compression achieves state-of-the-art lossless compression rates on CIFAR10, ImageNet32, and ImageNet64. To the best of our knowledge, this is the first lossless compression method that uses invertible neural networks.
count=1
* Beyond Online Balanced Descent: An Optimal Algorithm for Smoothed Online Optimization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/9f36407ead0629fc166f14dde7970f68-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/9f36407ead0629fc166f14dde7970f68-Paper.pdf)]
    * Title: Beyond Online Balanced Descent: An Optimal Algorithm for Smoothed Online Optimization
    * Year: `2019`
    * Authors: Gautam Goel, Yiheng Lin, Haoyuan Sun, Adam Wierman
    * Abstract: We study online convex optimization in a setting where the learner seeks to minimize the sum of a per-round hitting cost and a movement cost which is incurred when changing decisions between rounds. We prove a new lower bound on the competitive ratio of any online algorithm in the setting where the costs are $m$-strongly convex and the movement costs are the squared $\ell_2$ norm. This lower bound shows that no algorithm can achieve a competitive ratio that is $o(m^{-1/2})$ as $m$ tends to zero. No existing algorithms have competitive ratios matching this bound, and we show that the state-of-the-art algorithm, Online Balanced Decent (OBD), has a competitive ratio that is $\Omega(m^{-2/3})$. We additionally propose two new algorithms, Greedy OBD (G-OBD) and Regularized OBD (R-OBD) and prove that both algorithms have an $O(m^{-1/2})$ competitive ratio. The result for G-OBD holds when the hitting costs are quasiconvex and the movement costs are the squared $\ell_2$ norm, while the result for R-OBD holds when the hitting costs are $m$-strongly convex and the movement costs are Bregman Divergences. Further, we show that R-OBD simultaneously achieves constant, dimension-free competitive ratio and sublinear regret when hitting costs are strongly convex.
count=1
* Accurate Layerwise Interpretable Competence Estimation
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/a11da6bd58b95b334f8cd49f00918f16-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/a11da6bd58b95b334f8cd49f00918f16-Paper.pdf)]
    * Title: Accurate Layerwise Interpretable Competence Estimation
    * Year: `2019`
    * Authors: Vickram Rajendran, William LeVine
    * Abstract: Estimating machine learning performance “in the wild” is both an important and unsolved problem. In this paper, we seek to examine, understand, and predict the pointwise competence of classification models. Our contributions are twofold: First, we establish a statistically rigorous definition of competence that generalizes the common notion of classifier confidence; second, we present the ALICE (Accurate Layerwise Interpretable Competence Estimation) Score, a pointwise competence estimator for any classifier. By considering distributional, data, and model uncertainty, ALICE empirically shows accurate competence estimation in common failure situations such as class-imbalanced datasets, out-of-distribution datasets, and poorly trained models. Our contributions allow us to accurately predict the competence of any classification model given any input and error function. We compare our score with state-of-the-art confidence estimators such as model confidence and Trust Score, and show significant improvements in competence prediction over these methods on datasets such as DIGITS, CIFAR10, and CIFAR100.
count=1
* Attribution-Based Confidence Metric For Deep Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/bc1ad6e8f86c42a371aff945535baebb-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/bc1ad6e8f86c42a371aff945535baebb-Paper.pdf)]
    * Title: Attribution-Based Confidence Metric For Deep Neural Networks
    * Year: `2019`
    * Authors: Susmit Jha, Sunny Raj, Steven Fernandes, Sumit K. Jha, Somesh Jha, Brian Jalaian, Gunjan Verma, Ananthram Swami
    * Abstract: We propose a novel confidence metric, namely, attribution-based confidence (ABC) for deep neural networks (DNNs). ABC metric characterizes whether the output of a DNN on an input can be trusted. DNNs are known to be brittle on inputs outside the training distribution and are, hence, susceptible to adversarial attacks. This fragility is compounded by a lack of effectively computable measures of model confidence that correlate well with the accuracy of DNNs. These factors have impeded the adoption of DNNs in high-assurance systems. The proposed ABC metric addresses these challenges. It does not require access to the training data, the use of ensembles, or the need to train a calibration model on a held-out validation set. Hence, the new metric is usable even when only a trained model is available for inference. We mathematically motivate the proposed metric and evaluate its effectiveness with two sets of experiments. First, we study the change in accuracy and the associated confidence over out-of-distribution inputs. Second, we consider several digital and physically realizable attacks such as FGSM, CW, DeepFool, PGD, and adversarial patch generation methods. The ABC metric is low on out-of-distribution data and adversarial examples, where the accuracy of the model is also low. These experiments demonstrate the effectiveness of the ABC metric to make DNNs more trustworthy and resilient.
count=1
* Crowdsourcing via Pairwise Co-occurrences: Identifiability and Algorithms
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/c0e19ce0dbabbc0d17a4f8d4324cc8e3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/c0e19ce0dbabbc0d17a4f8d4324cc8e3-Paper.pdf)]
    * Title: Crowdsourcing via Pairwise Co-occurrences: Identifiability and Algorithms
    * Year: `2019`
    * Authors: Shahana Ibrahim, Xiao Fu, Nikolaos Kargas, Kejun Huang
    * Abstract: The data deluge comes with high demands for data labeling. Crowdsourcing (or, more generally, ensemble learning) techniques aim to produce accurate labels via integrating noisy, non-expert labeling from annotators. The classic Dawid-Skene estimator and its accompanying expectation maximization (EM) algorithm have been widely used, but the theoretical properties are not fully understood. Tensor methods were proposed to guarantee identification of the Dawid-Skene model, but the sample complexity is a hurdle for applying such approaches---since the tensor methods hinge on the availability of third-order statistics that are hard to reliably estimate given limited data. In this paper, we propose a framework using pairwise co-occurrences of the annotator responses, which naturally admits lower sample complexity. We show that the approach can identify the Dawid-Skene model under realistic conditions. We propose an algebraic algorithm reminiscent of convex geometry-based structured matrix factorization to solve the model identification problem efficiently, and an identifiability-enhanced algorithm for handling more challenging and critical scenarios. Experiments show that the proposed algorithms outperform the state-of-art algorithms under a variety of scenarios.
count=1
* Error Correcting Output Codes Improve Probability Estimation and Adversarial Robustness of Deep Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/cd61a580392a70389e27b0bc2b439f49-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/cd61a580392a70389e27b0bc2b439f49-Paper.pdf)]
    * Title: Error Correcting Output Codes Improve Probability Estimation and Adversarial Robustness of Deep Neural Networks
    * Year: `2019`
    * Authors: Gunjan Verma, Ananthram Swami
    * Abstract: Modern machine learning systems are susceptible to adversarial examples; inputs which clearly preserve the characteristic semantics of a given class, but whose classification is (usually confidently) incorrect. Existing approaches to adversarial defense generally rely on modifying the input, e.g. quantization, or the learned model parameters, e.g. via adversarial training. However, recent research has shown that most such approaches succumb to adversarial examples when different norms or more sophisticated adaptive attacks are considered. In this paper, we propose a fundamentally different approach which instead changes the way the output is represented and decoded. This simple approach achieves state-of-the-art robustness to adversarial examples for L 2 and L ∞ based adversarial perturbations on MNIST and CIFAR10. In addition, even under strong white-box attacks, we find that our model often assigns adversarial examples a low probability; those with high probability are usually interpretable, i.e. perturbed towards the perceptual boundary between the original and adversarial class. Our approach has several advantages: it yields more meaningful probability estimates, is extremely fast during training and testing, requires essentially no architectural changes to existing discriminative learning pipelines, is wholly complementary to other defense approaches including adversarial training, and does not sacrifice benign test set performance
count=1
* GNNExplainer: Generating Explanations for Graph Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/d80b7040b773199015de6d3b4293c8ff-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/d80b7040b773199015de6d3b4293c8ff-Paper.pdf)]
    * Title: GNNExplainer: Generating Explanations for Graph Neural Networks
    * Year: `2019`
    * Authors: Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, Jure Leskovec
    * Abstract: Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs.GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models, and explaining predictions made by GNNs remains unsolved. Here we propose GNNExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GNNExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GNNExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms baselines by 17.1% on average. GNNExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.
count=1
* Towards Hardware-Aware Tractable Learning of Probabilistic Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/e77910ebb93b511588557806310f78f1-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/e77910ebb93b511588557806310f78f1-Paper.pdf)]
    * Title: Towards Hardware-Aware Tractable Learning of Probabilistic Models
    * Year: `2019`
    * Authors: Laura I. Galindez Olascoaga, Wannes Meert, Nimish Shah, Marian Verhelst, Guy Van den Broeck
    * Abstract: Smart portable applications increasingly rely on edge computing due to privacy and latency concerns. But guaranteeing always-on functionality comes with two major challenges: heavily resource-constrained hardware; and dynamic application conditions. Probabilistic models present an ideal solution to these challenges: they are robust to missing data, allow for joint predictions and have small data needs. In addition, ongoing efforts in field of tractable learning have resulted in probabilistic models with strict inference efficiency guarantees. However, the current notions of tractability are often limited to model complexity, disregarding the hardware's specifications and constraints. We propose a novel resource-aware cost metric that takes into consideration the hardware's properties in determining whether the inference task can be efficiently deployed. We use this metric to evaluate the performance versus resource trade-off relevant to the application of interest, and we propose a strategy that selects the device-settings that can optimally meet users' requirements. We showcase our framework on a mobile activity recognition scenario, and on a variety of benchmark datasets representative of the field of tractable learning and of the applications of interest.
count=1
* Verified Uncertainty Calibration
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/f8c0c968632845cd133308b1a494967f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/f8c0c968632845cd133308b1a494967f-Paper.pdf)]
    * Title: Verified Uncertainty Calibration
    * Year: `2019`
    * Authors: Ananya Kumar, Percy S. Liang, Tengyu Ma
    * Abstract: Applications such as weather forecasting and personalized medicine demand models that output calibrated probability estimates---those representative of the true likelihood of a prediction. Most models are not calibrated out of the box but are recalibrated by post-processing model outputs. We find in this work that popular recalibration methods like Platt scaling and temperature scaling are (i) less calibrated than reported, and (ii) current techniques cannot estimate how miscalibrated they are. An alternative method, histogram binning, has measurable calibration error but is sample inefficient---it requires $O(B/\epsilon^2)$ samples, compared to $O(1/\epsilon^2)$ for scaling methods, where $B$ is the number of distinct probabilities the model can output. To get the best of both worlds, we introduce the scaling-binning calibrator, which first fits a parametric function that acts like a baseline for variance reduction and then bins the function values to actually ensure calibration. This requires only $O(1/\epsilon^2 + B)$ samples. We then show that methods used to estimate calibration error are suboptimal---we prove that an alternative estimator introduced in the meteorological community requires fewer samples ($O(\sqrt{B})$ instead of $O(B)$). We validate our approach with multiclass calibration experiments on CIFAR-10 and ImageNet, where we obtain a 35\% lower calibration error than histogram binning and, unlike scaling methods, guarantees on true calibration.
count=1
* Fair Algorithms for Clustering
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/fc192b0c0d270dbf41870a63a8c76c2f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/fc192b0c0d270dbf41870a63a8c76c2f-Paper.pdf)]
    * Title: Fair Algorithms for Clustering
    * Year: `2019`
    * Authors: Suman Bera, Deeparnab Chakrabarty, Nicolas Flores, Maryam Negahbani
    * Abstract: We study the problem of finding low-cost {\em fair clusterings} in data where each data point may belong to many protected groups. Our work significantly generalizes the seminal work of Chierichetti \etal (NIPS 2017) as follows. - We allow the user to specify the parameters that define fair representation. More precisely, these parameters define the maximum over- and minimum under-representation of any group in any cluster. - Our clustering algorithm works on any $\ell_p$-norm objective (e.g. $k$-means, $k$-median, and $k$-center). Indeed, our algorithm transforms any vanilla clustering solution into a fair one incurring only a slight loss in quality. - Our algorithm also allows individuals to lie in multiple protected groups. In other words, we do not need the protected groups to partition the data and we can maintain fairness across different groups simultaneously. Our experiments show that on established data sets, our algorithm performs much better in practice than what our theoretical results suggest.
count=1
* On Tractable Computation of Expected Predictions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/fccc64972a9468a11f125cadb090e89e-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/fccc64972a9468a11f125cadb090e89e-Paper.pdf)]
    * Title: On Tractable Computation of Expected Predictions
    * Year: `2019`
    * Authors: Pasha Khosravi, YooJung Choi, Yitao Liang, Antonio Vergari, Guy Van den Broeck
    * Abstract: Computing expected predictions of discriminative models is a fundamental task in machine learning that appears in many interesting applications such as fairness, handling missing values, and data analysis. Unfortunately, computing expectations of a discriminative model with respect to a probability distribution defined by an arbitrary generative model has been proven to be hard in general. In fact, the task is intractable even for simple models such as logistic regression and a naive Bayes distribution. In this paper, we identify a pair of generative and discriminative models that enables tractable computation of expectations, as well as moments of any order, of the latter with respect to the former in case of regression. Specifically, we consider expressive probabilistic circuits with certain structural constraints that support tractable probabilistic inference. Moreover, we exploit the tractable computation of high-order moments to derive an algorithm to approximate the expectations for classification scenarios in which exact computations are intractable. Our framework to compute expected predictions allows for handling of missing data during prediction time in a principled and accurate way and enables reasoning about the behavior of discriminative models. We empirically show our algorithm to consistently outperform standard imputation techniques on a variety of datasets. Finally, we illustrate how our framework can be used for exploratory data analysis.
count=1
* A Benchmark for Interpretability Methods in Deep Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/hash/fe4b8556000d0f0cae99daa5c5c5a410-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2019/file/fe4b8556000d0f0cae99daa5c5c5a410-Paper.pdf)]
    * Title: A Benchmark for Interpretability Methods in Deep Neural Networks
    * Year: `2019`
    * Authors: Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, Been Kim
    * Abstract: We propose an empirical measure of the approximate accuracy of feature importance estimates in deep neural networks. Our results across several large-scale image classification datasets show that many popular interpretability methods produce estimates of feature importance that are not better than a random designation of feature importance. Only certain ensemble based approaches---VarGrad and SmoothGrad-Squared---outperform such a random assignment of importance. The manner of ensembling remains critical, we show that some approaches do no better then the underlying method but carry a far higher computational burden.
count=1
* Scalable Hyperparameter Transfer Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/14c879f3f5d8ed93a09f6090d77c2cc3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/14c879f3f5d8ed93a09f6090d77c2cc3-Paper.pdf)]
    * Title: Scalable Hyperparameter Transfer Learning
    * Year: `2018`
    * Authors: Valerio Perrone, Rodolphe Jenatton, Matthias W. Seeger, Cedric Archambeau
    * Abstract: Bayesian optimization (BO) is a model-based approach for gradient-free black-box function optimization, such as hyperparameter optimization. Typically, BO relies on conventional Gaussian process (GP) regression, whose algorithmic complexity is cubic in the number of evaluations. As a result, GP-based BO cannot leverage large numbers of past function evaluations, for example, to warm-start related BO runs. We propose a multi-task adaptive Bayesian linear regression model for transfer learning in BO, whose complexity is linear in the function evaluations: one Bayesian linear regression model is associated to each black-box function optimization problem (or task), while transfer learning is achieved by coupling the models through a shared deep neural net. Experiments show that the neural net learns a representation suitable for warm-starting the black-box optimization problems and that BO runs can be accelerated when the target black-box function (e.g., validation loss) is learned together with other related signals (e.g., training loss). The proposed method was found to be at least one order of magnitude faster that methods recently published in the literature.
count=1
* Uplift Modeling from Separate Labels
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/198dd5fb9c43b2d29a548f8c77e85cf9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/198dd5fb9c43b2d29a548f8c77e85cf9-Paper.pdf)]
    * Title: Uplift Modeling from Separate Labels
    * Year: `2018`
    * Authors: Ikko Yamane, Florian Yger, Jamal Atif, Masashi Sugiyama
    * Abstract: Uplift modeling is aimed at estimating the incremental impact of an action on an individual's behavior, which is useful in various application domains such as targeted marketing (advertisement campaigns) and personalized medicine (medical treatments). Conventional methods of uplift modeling require every instance to be jointly equipped with two types of labels: the taken action and its outcome. However, obtaining two labels for each instance at the same time is difficult or expensive in many real-world problems. In this paper, we propose a novel method of uplift modeling that is applicable to a more practical setting where only one type of labels is available for each instance. We show a mean squared error bound for the proposed estimator and demonstrate its effectiveness through experiments.
count=1
* Multi-value Rule Sets for Interpretable Classification with Feature-Efficient Representations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/32bbf7b2bc4ed14eb1e9c2580056a989-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/32bbf7b2bc4ed14eb1e9c2580056a989-Paper.pdf)]
    * Title: Multi-value Rule Sets for Interpretable Classification with Feature-Efficient Representations
    * Year: `2018`
    * Authors: Tong Wang
    * Abstract: We present the Multi-value Rule Set (MRS) for interpretable classification with feature efficient presentations. Compared to rule sets built from single-value rules, MRS adopts a more generalized form of association rules that allows multiple values in a condition. Rules of this form are more concise than classical single-value rules in capturing and describing patterns in data. Our formulation also pursues a higher efficiency of feature utilization, which reduces possible cost in data collection and storage. We propose a Bayesian framework for formulating an MRS model and develop an efficient inference method for learning a maximum a posteriori, incorporating theoretically grounded bounds to iteratively reduce the search space and improve the search efficiency. Experiments on synthetic and real-world data demonstrate that MRS models have significantly smaller complexity and fewer features than baseline models while being competitive in predictive accuracy.
count=1
* Confounding-Robust Policy Improvement
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/3a09a524440d44d7f19870070a5ad42f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/3a09a524440d44d7f19870070a5ad42f-Paper.pdf)]
    * Title: Confounding-Robust Policy Improvement
    * Year: `2018`
    * Authors: Nathan Kallus, Angela Zhou
    * Abstract: We study the problem of learning personalized decision policies from observational data while accounting for possible unobserved confounding in the data-generating process. Unlike previous approaches that assume unconfoundedness, i.e., no unobserved confounders affected both treatment assignment and outcomes, we calibrate policy learning for realistic violations of this unverifiable assumption with uncertainty sets motivated by sensitivity analysis in causal inference. Our framework for confounding-robust policy improvement optimizes the minimax regret of a candidate policy against a baseline or reference "status quo" policy, over an uncertainty set around nominal propensity weights. We prove that if the uncertainty set is well-specified, robust policy learning can do no worse than the baseline, and only improve if the data supports it. We characterize the adversarial subproblem and use efficient algorithmic solutions to optimize over parametrized spaces of decision policies such as logistic treatment assignment. We assess our methods on synthetic data and a large clinical trial, demonstrating that confounded selection can hinder policy learning and lead to unwarranted harm, while our robust approach guarantees safety and focuses on well-evidenced improvement.
count=1
* The Cluster Description Problem - Complexity Results, Formulations and Approximations
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/3fd60983292458bf7dee75f12d5e9e05-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/3fd60983292458bf7dee75f12d5e9e05-Paper.pdf)]
    * Title: The Cluster Description Problem - Complexity Results, Formulations and Approximations
    * Year: `2018`
    * Authors: Ian Davidson, Antoine Gourru, S Ravi
    * Abstract: Consider the situation where you are given an existing $k$-way clustering $\pi$. A challenge for explainable AI is to find a compact and distinct explanations of each cluster which in this paper is using instance-level descriptors/tags from a common dictionary. Since the descriptors/tags were not given to the clustering method, this is not a semi-supervised learning situation. We show that the \emph{feasibility} problem of just testing whether any distinct description (not the most compact) exists is generally intractable for just two clusters. This means that unless \textbf{P} = \cnp, there cannot exist an efficient algorithm for the cluster description problem. Hence, we explore ILP formulations for smaller problems and a relaxed but restricted setting that leads to a polynomial time algorithm for larger problems. We explore several extension to the basic setting such as the ability to ignore some instances and composition constraints on the descriptions of the clusters. We show our formulation's usefulness on Twitter data where the communities were found using social connectivity (i.e. \texttt{follower} relation) but the explanation of the communities is based on behavioral properties of the nodes (i.e. hashtag usage) not available to the clustering method.
count=1
* Object-Oriented Dynamics Predictor
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/713fd63d76c8a57b16fc433fb4ae718a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/713fd63d76c8a57b16fc433fb4ae718a-Paper.pdf)]
    * Title: Object-Oriented Dynamics Predictor
    * Year: `2018`
    * Authors: Guangxiang Zhu, Zhiao Huang, Chongjie Zhang
    * Abstract: Generalization has been one of the major challenges for learning dynamics models in model-based reinforcement learning. However, previous work on action-conditioned dynamics prediction focuses on learning the pixel-level motion and thus does not generalize well to novel environments with different object layouts. In this paper, we present a novel object-oriented framework, called object-oriented dynamics predictor (OODP), which decomposes the environment into objects and predicts the dynamics of objects conditioned on both actions and object-to-object relations. It is an end-to-end neural network and can be trained in an unsupervised manner. To enable the generalization ability of dynamics learning, we design a novel CNN-based relation mechanism that is class-specific (rather than object-specific) and exploits the locality principle. Empirical results show that OODP significantly outperforms previous methods in terms of generalization over novel environments with various object layouts. OODP is able to learn from very few environments and accurately predict dynamics in a large number of unseen environments. In addition, OODP learns semantically and visually interpretable dynamics models.
count=1
* Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/8562ae5e286544710b2e7ebe9858833b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/8562ae5e286544710b2e7ebe9858833b-Paper.pdf)]
    * Title: Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
    * Year: `2018`
    * Authors: Gamaleldin Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot, Alexey Kurakin, Ian Goodfellow, Jascha Sohl-Dickstein
    * Abstract: Machine learning models are vulnerable to adversarial examples: small changes to images can cause computer vision models to make mistakes such as identifying a school bus as an ostrich. However, it is still an open question whether humans are prone to similar mistakes. Here, we address this question by leveraging recent techniques that transfer adversarial examples from computer vision models with known parameters and architecture to other models with unknown parameters and architecture, and by matching the initial processing of the human visual system. We find that adversarial examples that strongly transfer across computer vision models influence the classifications made by time-limited human observers.
count=1
* Rectangular Bounding Process
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/8ce87bdda85cd44f14de9afb86491884-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/8ce87bdda85cd44f14de9afb86491884-Paper.pdf)]
    * Title: Rectangular Bounding Process
    * Year: `2018`
    * Authors: Xuhui Fan, Bin Li, Scott SIsson
    * Abstract: Stochastic partition models divide a multi-dimensional space into a number of rectangular regions, such that the data within each region exhibit certain types of homogeneity. Due to the nature of their partition strategy, existing partition models may create many unnecessary divisions in sparse regions when trying to describe data in dense regions. To avoid this problem we introduce a new parsimonious partition model -- the Rectangular Bounding Process (RBP) -- to efficiently partition multi-dimensional spaces, by employing a bounding strategy to enclose data points within rectangular bounding boxes. Unlike existing approaches, the RBP possesses several attractive theoretical properties that make it a powerful nonparametric partition prior on a hypercube. In particular, the RBP is self-consistent and as such can be directly extended from a finite hypercube to infinite (unbounded) space. We apply the RBP to regression trees and relational models as a flexible partition prior. The experimental results validate the merit of the RBP {in rich yet parsimonious expressiveness} compared to the state-of-the-art methods.
count=1
* Deep Neural Networks with Box Convolutions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/8e489b4966fe8f703b5be647f1cbae63-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/8e489b4966fe8f703b5be647f1cbae63-Paper.pdf)]
    * Title: Deep Neural Networks with Box Convolutions
    * Year: `2018`
    * Authors: Egor Burkov, Victor Lempitsky
    * Abstract: Box filters computed using integral images have been part of the computer vision toolset for a long time. Here, we show that a convolutional layer that computes box filter responses in a sliding manner can be used within deep architectures, whereas the dimensions and the offsets of the sliding boxes in such a layer can be learned as part of an end-to-end loss minimization. Crucially, the training process can make the size of the boxes in such a layer arbitrarily large without incurring extra computational cost and without the need to increase the number of learnable parameters. Due to its ability to integrate information over large boxes, the new layer facilitates long-range propagation of information and leads to the efficient increase of the receptive fields of downstream units in the network. By incorporating the new layer into existing architectures for semantic segmentation, we are able to achieve both the increase in segmentation accuracy as well as the decrease in the computational cost and the number of learnable parameters.
count=1
* A Game-Theoretic Approach to Recommendation Systems with Strategic Content Providers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/a9a1d5317a33ae8cef33961c34144f84-Paper.pdf)]
    * Title: A Game-Theoretic Approach to Recommendation Systems with Strategic Content Providers
    * Year: `2018`
    * Authors: Omer Ben-Porat, Moshe Tennenholtz
    * Abstract: We introduce a game-theoretic approach to the study of recommendation systems with strategic content providers. Such systems should be fair and stable. Showing that traditional approaches fail to satisfy these requirements, we propose the Shapley mediator. We show that the Shapley mediator satisfies the fairness and stability requirements, runs in linear time, and is the only economically efficient mechanism satisfying these properties.
count=1
* Nonparametric learning from Bayesian models with randomized objective functions
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/b4d168b48157c623fbd095b4a565b5bb-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/b4d168b48157c623fbd095b4a565b5bb-Paper.pdf)]
    * Title: Nonparametric learning from Bayesian models with randomized objective functions
    * Year: `2018`
    * Authors: Simon Lyddon, Stephen Walker, Chris C. Holmes
    * Abstract: Bayesian learning is built on an assumption that the model space contains a true reflection of the data generating mechanism. This assumption is problematic, particularly in complex data environments. Here we present a Bayesian nonparametric approach to learning that makes use of statistical models, but does not assume that the model is true. Our approach has provably better properties than using a parametric model and admits a Monte Carlo sampling scheme that can afford massive scalability on modern computer architectures. The model-based aspect of learning is particularly attractive for regularizing nonparametric inference when the sample size is small, and also for correcting approximate approaches such as variational Bayes (VB). We demonstrate the approach on a number of examples including VB classifiers and Bayesian random forests.
count=1
* REFUEL: Exploring Sparse Features in Deep Reinforcement Learning for Fast Disease Diagnosis
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/b5a1d925221b37e2e399f7b319038ba0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/b5a1d925221b37e2e399f7b319038ba0-Paper.pdf)]
    * Title: REFUEL: Exploring Sparse Features in Deep Reinforcement Learning for Fast Disease Diagnosis
    * Year: `2018`
    * Authors: Yu-Shao Peng, Kai-Fu Tang, Hsuan-Tien Lin, Edward Chang
    * Abstract: This paper proposes REFUEL, a reinforcement learning method with two techniques: {\em reward shaping} and {\em feature rebuilding}, to improve the performance of online symptom checking for disease diagnosis. Reward shaping can guide the search of policy towards better directions. Feature rebuilding can guide the agent to learn correlations between features. Together, they can find symptom queries that can yield positive responses from a patient with high probability. Experimental results justify that the two techniques in REFUEL allows the symptom checker to identify the disease more rapidly and accurately.
count=1
* Online Learning of Quantum States
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/c1a3d34711ab5d85335331ca0e57f067-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/c1a3d34711ab5d85335331ca0e57f067-Paper.pdf)]
    * Title: Online Learning of Quantum States
    * Year: `2018`
    * Authors: Scott Aaronson, Xinyi Chen, Elad Hazan, Satyen Kale, Ashwin Nayak
    * Abstract: Suppose we have many copies of an unknown n-qubit state $\rho$. We measure some copies of $\rho$ using a known two-outcome measurement E_1, then other copies using a measurement E_2, and so on. At each stage t, we generate a current hypothesis $\omega_t$ about the state $\rho$, using the outcomes of the previous measurements. We show that it is possible to do this in a way that guarantees that $|\trace(E_i \omega_t) - \trace(E_i\rho)|$, the error in our prediction for the next measurement, is at least $eps$ at most $O(n / eps^2) $\ times. Even in the non-realizable setting---where there could be arbitrary noise in the measurement outcomes---we show how to output hypothesis states that incur at most $O(\sqrt {Tn}) $ excess loss over the best possible state on the first $T$ measurements. These results generalize a 2007 theorem by Aaronson on the PAC-learnability of quantum states, to the online and regret-minimization settings. We give three different ways to prove our results---using convex optimization, quantum postselection, and sequential fat-shattering dimension---which have different advantages in terms of parameters and portability.
count=1
* The Price of Fair PCA: One Extra dimension
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/cc4af25fa9d2d5c953496579b75f6f6c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/cc4af25fa9d2d5c953496579b75f6f6c-Paper.pdf)]
    * Title: The Price of Fair PCA: One Extra dimension
    * Year: `2018`
    * Authors: Samira Samadi, Uthaipon Tantipongpipat, Jamie H. Morgenstern, Mohit Singh, Santosh Vempala
    * Abstract: We investigate whether the standard dimensionality reduction technique of PCA inadvertently produces data representations with different fidelity for two different populations. We show on several real-world data sets, PCA has higher reconstruction error on population A than on B (for example, women versus men or lower- versus higher-educated individuals). This can happen even when the data set has a similar number of samples from A and B. This motivates our study of dimensionality reduction techniques which maintain similar fidelity for A and B. We define the notion of Fair PCA and give a polynomial-time algorithm for finding a low dimensional representation of the data which is nearly-optimal with respect to this measure. Finally, we show on real-world data sets that our algorithm can be used to efficiently generate a fair low dimensional representation of the data.
count=1
* KONG: Kernels for ordered-neighborhood graphs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/d0fb963ff976f9c37fc81fe03c21ea7b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/d0fb963ff976f9c37fc81fe03c21ea7b-Paper.pdf)]
    * Title: KONG: Kernels for ordered-neighborhood graphs
    * Year: `2018`
    * Authors: Moez Draief, Konstantin Kutzkov, Kevin Scaman, Milan Vojnovic
    * Abstract: We present novel graph kernels for graphs with node and edge labels that have ordered neighborhoods, i.e. when neighbor nodes follow an order. Graphs with ordered neighborhoods are a natural data representation for evolving graphs where edges are created over time, which induces an order. Combining convolutional subgraph kernels and string kernels, we design new scalable algorithms for generation of explicit graph feature maps using sketching techniques. We obtain precise bounds for the approximation accuracy and computational complexity of the proposed approaches and demonstrate their applicability on real datasets. In particular, our experiments demonstrate that neighborhood ordering results in more informative features. For the special case of general graphs, i.e. graphs without ordered neighborhoods, the new graph kernels yield efficient and simple algorithms for the comparison of label distributions between graphs.
count=1
* Efficient Loss-Based Decoding on Graphs for Extreme Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/e7e69cdf28f8ce6b69b4e1853ee21bab-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/e7e69cdf28f8ce6b69b4e1853ee21bab-Paper.pdf)]
    * Title: Efficient Loss-Based Decoding on Graphs for Extreme Classification
    * Year: `2018`
    * Authors: Itay Evron, Edward Moroshko, Koby Crammer
    * Abstract: In extreme classification problems, learning algorithms are required to map instances to labels from an extremely large label set. We build on a recent extreme classification framework with logarithmic time and space (LTLS), and on a general approach for error correcting output coding (ECOC) with loss-based decoding, and introduce a flexible and efficient approach accompanied by theoretical bounds. Our framework employs output codes induced by graphs, for which we show how to perform efficient loss-based decoding to potentially improve accuracy. In addition, our framework offers a tradeoff between accuracy, model size and prediction time. We show how to find the sweet spot of this tradeoff using only the training data. Our experimental study demonstrates the validity of our assumptions and claims, and shows that our method is competitive with state-of-the-art algorithms.
count=1
* Proximal Graphical Event Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/f1ababf130ee6a25f12da7478af8f1ac-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/f1ababf130ee6a25f12da7478af8f1ac-Paper.pdf)]
    * Title: Proximal Graphical Event Models
    * Year: `2018`
    * Authors: Debarun Bhattacharjya, Dharmashankar Subramanian, Tian Gao
    * Abstract: Event datasets include events that occur irregularly over the timeline and are prevalent in numerous domains. We introduce proximal graphical event models (PGEM) as a representation of such datasets. PGEMs belong to a broader family of models that characterize relationships between various types of events, where the rate of occurrence of an event type depends only on whether or not its parents have occurred in the most recent history. The main advantage over the state of the art models is that they are entirely data driven and do not require additional inputs from the user, which can require knowledge of the domain such as choice of basis functions or hyperparameters in graphical event models. We theoretically justify our learning of optimal windows for parental history and the choices of parental sets, and the algorithm are sound and complete in terms of parent structure learning. We present additional efficient heuristics for learning PGEMs from data, demonstrating their effectiveness on synthetic and real datasets.
count=1
* Optimization over Continuous and Multi-dimensional Decisions with Observational Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/f337d999d9ad116a7b4f3d409fcc6480-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/f337d999d9ad116a7b4f3d409fcc6480-Paper.pdf)]
    * Title: Optimization over Continuous and Multi-dimensional Decisions with Observational Data
    * Year: `2018`
    * Authors: Dimitris Bertsimas, Christopher McCord
    * Abstract: We consider the optimization of an uncertain objective over continuous and multi-dimensional decision spaces in problems in which we are only provided with observational data. We propose a novel algorithmic framework that is tractable, asymptotically consistent, and superior to comparable methods on example problems. Our approach leverages predictive machine learning methods and incorporates information on the uncertainty of the predicted outcomes for the purpose of prescribing decisions. We demonstrate the efficacy of our method on examples involving both synthetic and real data sets.
count=1
* Modern Neural Networks Generalize on Small Data Sets
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/hash/fface8385abbf94b4593a0ed53a0c70f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2018/file/fface8385abbf94b4593a0ed53a0c70f-Paper.pdf)]
    * Title: Modern Neural Networks Generalize on Small Data Sets
    * Year: `2018`
    * Authors: Matthew Olson, Abraham Wyner, Richard Berk
    * Abstract: In this paper, we use a linear program to empirically decompose fitted neural networks into ensembles of low-bias sub-networks. We show that these sub-networks are relatively uncorrelated which leads to an internal regularization process, very much like a random forest, which can explain why a neural network is surprisingly resistant to overfitting. We then demonstrate this in practice by applying large neural networks, with hundreds of parameters per training observation, to a collection of 116 real-world data sets from the UCI Machine Learning Repository. This collection of data sets contains a much smaller number of training examples than the types of image classification tasks generally studied in the deep learning literature, as well as non-trivial label noise. We show that even in this setting deep neural nets are capable of achieving superior classification accuracy without overfitting.
count=1
* Query Complexity of Clustering with Side Information
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/03e7ef47cee6fa4ae7567394b99912b7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/03e7ef47cee6fa4ae7567394b99912b7-Paper.pdf)]
    * Title: Query Complexity of Clustering with Side Information
    * Year: `2017`
    * Authors: Arya Mazumdar, Barna Saha
    * Abstract: Suppose, we are given a set of $n$ elements to be clustered into $k$ (unknown) clusters, and an oracle/expert labeler that can interactively answer pair-wise queries of the form, ``do two elements $u$ and $v$ belong to the same cluster?''. The goal is to recover the optimum clustering by asking the minimum number of queries. In this paper, we provide a rigorous theoretical study of this basic problem of query complexity of interactive clustering, and give strong information theoretic lower bounds, as well as nearly matching upper bounds. Most clustering problems come with a similarity matrix, which is used by an automated process to cluster similar points together. To improve accuracy of clustering, a fruitful approach in recent years has been to ask a domain expert or crowd to obtain labeled data interactively. Many heuristics have been proposed, and all of these use a similarity function to come up with a querying strategy. Even so, there is a lack systematic theoretical study. Our main contribution in this paper is to show the dramatic power of side information aka similarity matrix on reducing the query complexity of clustering. A similarity matrix represents noisy pair-wise relationships such as one computed by some function on attributes of the elements. A natural noisy model is where similarity values are drawn independently from some arbitrary probability distribution $f_+$ when the underlying pair of elements belong to the same cluster, and from some $f_-$ otherwise. We show that given such a similarity matrix, the query complexity reduces drastically from $\Theta(nk)$ (no similarity matrix) to $O(\frac{k^2\log{n}}{\cH^2(f_+\|f_-)})$ where $\cH^2$ denotes the squared Hellinger divergence. Moreover, this is also information-theoretic optimal within an $O(\log{n})$ factor. Our algorithms are all efficient, and parameter free, i.e., they work without any knowledge of $k, f_+$ and $f_-$, and only depend logarithmically with $n$.
count=1
* FALKON: An Optimal Large Scale Kernel Method
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/05546b0e38ab9175cd905eebcc6ebb76-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/05546b0e38ab9175cd905eebcc6ebb76-Paper.pdf)]
    * Title: FALKON: An Optimal Large Scale Kernel Method
    * Year: `2017`
    * Authors: Alessandro Rudi, Luigi Carratino, Lorenzo Rosasco
    * Abstract: Kernel methods provide a principled way to perform non linear, nonparametric learning. They rely on solid functional analytic foundations and enjoy optimal statistical properties. However, at least in their basic form, they have limited applicability in large scale scenarios because of stringent computational requirements in terms of time and especially memory. In this paper, we take a substantial step in scaling up kernel methods, proposing FALKON, a novel algorithm that allows to efficiently process millions of points. FALKON is derived combining several algorithmic principles, namely stochastic subsampling, iterative solvers and preconditioning. Our theoretical analysis shows that optimal statistical accuracy is achieved requiring essentially $O(n)$ memory and $O(n\sqrt{n})$ time. An extensive experimental analysis on large scale datasets shows that, even with a single machine, FALKON outperforms previous state of the art solutions, which exploit parallel/distributed architectures.
count=1
* Introspective Classification with Convolutional Nets
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/11b921ef080f7736089c757404650e40-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/11b921ef080f7736089c757404650e40-Paper.pdf)]
    * Title: Introspective Classification with Convolutional Nets
    * Year: `2017`
    * Authors: Long Jin, Justin Lazarow, Zhuowen Tu
    * Abstract: We propose introspective convolutional networks (ICN) that emphasize the importance of having convolutional neural networks empowered with generative capabilities. We employ a reclassification-by-synthesis algorithm to perform training using a formulation stemmed from the Bayes theory. Our ICN tries to iteratively: (1) synthesize pseudo-negative samples; and (2) enhance itself by improving the classification. The single CNN classifier learned is at the same time generative --- being able to directly synthesize new samples within its own discriminative model. We conduct experiments on benchmark datasets including MNIST, CIFAR-10, and SVHN using state-of-the-art CNN architectures, and observe improved classification results.
count=1
* f-GANs in an Information Geometric Nutshell
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/2f2b265625d76a6704b08093c652fd79-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/2f2b265625d76a6704b08093c652fd79-Paper.pdf)]
    * Title: f-GANs in an Information Geometric Nutshell
    * Year: `2017`
    * Authors: Richard Nock, Zac Cranko, Aditya K. Menon, Lizhen Qu, Robert C. Williamson
    * Abstract: Nowozin \textit{et al} showed last year how to extend the GAN \textit{principle} to all $f$-divergences. The approach is elegant but falls short of a full description of the supervised game, and says little about the key player, the generator: for example, what does the generator actually converge to if solving the GAN game means convergence in some space of parameters? How does that provide hints on the generator's design and compare to the flourishing but almost exclusively experimental literature on the subject? In this paper, we unveil a broad class of distributions for which such convergence happens --- namely, deformed exponential families, a wide superset of exponential families ---. We show that current deep architectures are able to factorize a very large number of such densities using an especially compact design, hence displaying the power of deep architectures and their concinnity in the $f$-GAN game. This result holds given a sufficient condition on \textit{activation functions} --- which turns out to be satisfied by popular choices. The key to our results is a variational generalization of an old theorem that relates the KL divergence between regular exponential families and divergences between their natural parameters. We complete this picture with additional results and experimental insights on how these results may be used to ground further improvements of GAN architectures, via (i) a principled design of the activation functions in the generator and (ii) an explicit integration of proper composite losses' link function in the discriminator.
count=1
* Sparse Embedded $k$-Means Clustering
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/3214a6d842cc69597f9edf26df552e43-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/3214a6d842cc69597f9edf26df552e43-Paper.pdf)]
    * Title: Sparse Embedded $k$-Means Clustering
    * Year: `2017`
    * Authors: Weiwei Liu, Xiaobo Shen, Ivor Tsang
    * Abstract: The $k$-means clustering algorithm is a ubiquitous tool in data mining and machine learning that shows promising performance. However, its high computational cost has hindered its applications in broad domains. Researchers have successfully addressed these obstacles with dimensionality reduction methods. Recently, [1] develop a state-of-the-art random projection (RP) method for faster $k$-means clustering. Their method delivers many improvements over other dimensionality reduction methods. For example, compared to the advanced singular value decomposition based feature extraction approach, [1] reduce the running time by a factor of $\min \{n,d\}\epsilon^2 log(d)/k$ for data matrix $X \in \mathbb{R}^{n\times d} $ with $n$ data points and $d$ features, while losing only a factor of one in approximation accuracy. Unfortunately, they still require $\mathcal{O}(\frac{ndk}{\epsilon^2log(d)})$ for matrix multiplication and this cost will be prohibitive for large values of $n$ and $d$. To break this bottleneck, we carefully build a sparse embedded $k$-means clustering algorithm which requires $\mathcal{O}(nnz(X))$ ($nnz(X)$ denotes the number of non-zeros in $X$) for fast matrix multiplication. Moreover, our proposed algorithm improves on [1]'s results for approximation accuracy by a factor of one. Our empirical studies corroborate our theoretical findings, and demonstrate that our approach is able to significantly accelerate $k$-means clustering, while achieving satisfactory clustering performance.
count=1
* Self-Normalizing Neural Networks
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/5d44ee6f2c3f71b73125876103c8f6c4-Paper.pdf)]
    * Title: Self-Normalizing Neural Networks
    * Year: `2017`
    * Authors: Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter
    * Abstract: Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. For FNNs we considered (i) ReLU networks without normalization, (ii) batch normalization, (iii) layer normalization, (iv) weight normalization, (v) highway networks, (vi) residual networks. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep.
count=1
* Doubly Stochastic Variational Inference for Deep Gaussian Processes
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/8208974663db80265e9bfe7b222dcb18-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/8208974663db80265e9bfe7b222dcb18-Paper.pdf)]
    * Title: Doubly Stochastic Variational Inference for Deep Gaussian Processes
    * Year: `2017`
    * Authors: Hugh Salimbeni, Marc Deisenroth
    * Abstract: Deep Gaussian processes (DGPs) are multi-layer generalizations of GPs, but inference in these models has proved challenging. Existing approaches to inference in DGP models assume approximate posteriors that force independence between the layers, and do not work well in practice. We present a doubly stochastic variational inference algorithm, which does not force independence between layers. With our method of inference we demonstrate that a DGP model can be used effectively on data ranging in size from hundreds to a billion points. We provide strong empirical evidence that our inference scheme for DGPs works well in practice in both classification and regression.
count=1
* From Parity to Preference-based Notions of Fairness in Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/82161242827b703e6acf9c726942a1e4-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/82161242827b703e6acf9c726942a1e4-Paper.pdf)]
    * Title: From Parity to Preference-based Notions of Fairness in Classification
    * Year: `2017`
    * Authors: Muhammad Bilal Zafar, Isabel Valera, Manuel Rodriguez, Krishna Gummadi, Adrian Weller
    * Abstract: The adoption of automated, data-driven decision making in an ever expanding range of applications has raised concerns about its potential unfairness towards certain social groups. In this context, a number of recent studies have focused on defining, detecting, and removing unfairness from data-driven decision systems. However, the existing notions of fairness, based on parity (equality) in treatment or outcomes for different social groups, tend to be quite stringent, limiting the overall decision making accuracy. In this paper, we draw inspiration from the fair-division and envy-freeness literature in economics and game theory and propose preference-based notions of fairness -- given the choice between various sets of decision treatments or outcomes, any group of users would collectively prefer its treatment or outcomes, regardless of the (dis)parity as compared to the other groups. Then, we introduce tractable proxies to design margin-based classifiers that satisfy these preference-based notions of fairness. Finally, we experiment with a variety of synthetic and real-world datasets and show that preference-based fairness allows for greater decision accuracy than parity-based fairness.
count=1
* An Empirical Study on The Properties of Random Bases for Kernel Methods
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/92af93f73faf3cefc129b6bc55a748a9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/92af93f73faf3cefc129b6bc55a748a9-Paper.pdf)]
    * Title: An Empirical Study on The Properties of Random Bases for Kernel Methods
    * Year: `2017`
    * Authors: Maximilian Alber, Pieter-Jan Kindermans, Kristof Schütt, Klaus-Robert Müller, Fei Sha
    * Abstract: Kernel machines as well as neural networks possess universal function approximation properties. Nevertheless in practice their ways of choosing the appropriate function class differ. Specifically neural networks learn a representation by adapting their basis functions to the data and the task at hand, while kernel methods typically use a basis that is not adapted during training. In this work, we contrast random features of approximated kernel machines with learned features of neural networks. Our analysis reveals how these random and adaptive basis functions affect the quality of learning. Furthermore, we present basis adaptation schemes that allow for a more compact representation, while retaining the generalization properties of kernel machines.
count=1
* Fair Clustering Through Fairlets
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/978fce5bcc4eccc88ad48ce3914124a2-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/978fce5bcc4eccc88ad48ce3914124a2-Paper.pdf)]
    * Title: Fair Clustering Through Fairlets
    * Year: `2017`
    * Authors: Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, Sergei Vassilvitskii
    * Abstract: We study the question of fair clustering under the {\em disparate impact} doctrine, where each protected class must have approximately equal representation in every cluster. We formulate the fair clustering problem under both the k-center and the k-median objectives, and show that even with two protected classes the problem is challenging, as the optimum solution can violate common conventions---for instance a point may no longer be assigned to its nearest cluster center! En route we introduce the concept of fairlets, which are minimal sets that satisfy fair representation while approximately preserving the clustering objective. We show that any fair clustering problem can be decomposed into first finding good fairlets, and then using existing machinery for traditional clustering algorithms. While finding good fairlets can be NP-hard, we proceed to obtain efficient approximation algorithms based on minimum cost flow. We empirically demonstrate the \emph{price of fairness} by quantifying the value of fair clustering on real-world datasets with sensitive attributes.
count=1
* On Fairness and Calibration
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/b8b9c74ac526fffbeb2d39ab038d1cd7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf)]
    * Title: On Fairness and Calibration
    * Year: `2017`
    * Authors: Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, Kilian Q. Weinberger
    * Abstract: The machine learning community has become increasingly concerned with the potential for bias and discrimination in predictive models. This has motivated a growing line of work on what it means for a classification procedure to be "fair." In this paper, we investigate the tension between minimizing error disparity across different population groups while maintaining calibrated probability estimates. We show that calibration is compatible only with a single error constraint (i.e. equal false-negatives rates across groups), and show that any algorithm that satisfies this relaxation is no better than randomizing a percentage of predictions for an existing classifier. These unsettling findings, which extend and generalize existing results, are empirically confirmed on several datasets.
count=1
* Minimizing a Submodular Function from Samples
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/c75b6f114c23a4d7ea11331e7c00e73c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/c75b6f114c23a4d7ea11331e7c00e73c-Paper.pdf)]
    * Title: Minimizing a Submodular Function from Samples
    * Year: `2017`
    * Authors: Eric Balkanski, Yaron Singer
    * Abstract: In this paper we consider the problem of minimizing a submodular function from training data. Submodular functions can be efficiently minimized and are conse- quently heavily applied in machine learning. There are many cases, however, in which we do not know the function we aim to optimize, but rather have access to training data that is used to learn the function. In this paper we consider the question of whether submodular functions can be minimized in such cases. We show that even learnable submodular functions cannot be minimized within any non-trivial approximation when given access to polynomially-many samples. Specifically, we show that there is a class of submodular functions with range in [0, 1] such that, despite being PAC-learnable and minimizable in polynomial-time, no algorithm can obtain an approximation strictly better than 1/2 − o(1) using polynomially-many samples drawn from any distribution. Furthermore, we show that this bound is tight using a trivial algorithm that obtains an approximation of 1/2.
count=1
* Inferring Generative Model Structure with Static Analysis
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/cedebb6e872f539bef8c3f919874e9d7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/cedebb6e872f539bef8c3f919874e9d7-Paper.pdf)]
    * Title: Inferring Generative Model Structure with Static Analysis
    * Year: `2017`
    * Authors: Paroma Varma, Bryan D. He, Payal Bajaj, Nishith Khandwala, Imon Banerjee, Daniel Rubin, Christopher Ré
    * Abstract: Obtaining enough labeled data to robustly train complex discriminative models is a major bottleneck in the machine learning pipeline. A popular solution is combining multiple sources of weak supervision using generative models. The structure of these models affects the quality of the training labels, but is difficult to learn without any ground truth labels. We instead rely on weak supervision sources having some structure by virtue of being encoded programmatically. We present Coral, a paradigm that infers generative model structure by statically analyzing the code for these heuristics, thus significantly reducing the amount of data required to learn structure. We prove that Coral's sample complexity scales quasilinearly with the number of heuristics and number of relations identified, improving over the standard sample complexity, which is exponential in n for learning n-th degree relations. Empirically, Coral matches or outperforms traditional structure learning approaches by up to 3.81 F1 points. Using Coral to model dependencies instead of assuming independence results in better performance than a fully supervised model by 3.07 accuracy points when heuristics are used to label radiology data without ground truth labels.
count=1
* Adaptive Classification for Prediction Under a Budget
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/d9ff90f4000eacd3a6c9cb27f78994cf-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/d9ff90f4000eacd3a6c9cb27f78994cf-Paper.pdf)]
    * Title: Adaptive Classification for Prediction Under a Budget
    * Year: `2017`
    * Authors: Feng Nan, Venkatesh Saligrama
    * Abstract: We propose a novel adaptive approximation approach for test-time resource-constrained prediction motivated by Mobile, IoT, health, security and other applications, where constraints in the form of computation, communication, latency and feature acquisition costs arise. We learn an adaptive low-cost system by training a gating and prediction model that limits utilization of a high-cost model to hard input instances and gates easy-to-handle input instances to a low-cost model. Our method is based on adaptively approximating the high-cost model in regions where low-cost models suffice for making highly accurate predictions. We pose an empirical loss minimization problem with cost constraints to jointly train gating and prediction models. On a number of benchmark datasets our method outperforms state-of-the-art achieving higher accuracy for the same cost.
count=1
* Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/df0aab058ce179e4f7ab135ed4e641a9-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/df0aab058ce179e4f7ab135ed4e641a9-Paper.pdf)]
    * Title: Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search
    * Year: `2017`
    * Authors: Luigi Acerbi, Wei Ji Ma
    * Abstract: Computational models in fields such as computational neuroscience are often evaluated via stochastic simulation or numerical approximation. Fitting these models implies a difficult optimization problem over complex, possibly noisy parameter landscapes. Bayesian optimization (BO) has been successfully applied to solving expensive black-box problems in engineering and machine learning. Here we explore whether BO can be applied as a general tool for model fitting. First, we present a novel hybrid BO algorithm, Bayesian adaptive direct search (BADS), that achieves competitive performance with an affordable computational overhead for the running time of typical models. We then perform an extensive benchmark of BADS vs. many common and state-of-the-art nonconvex, derivative-free optimizers, on a set of model-fitting problems with real data and models from six studies in behavioral, cognitive, and computational neuroscience. With default settings, BADS consistently finds comparable or better solutions than other methods, including `vanilla' BO, showing great promise for advanced BO techniques, and BADS in particular, as a general model-fitting tool.
count=1
* Deep Supervised Discrete Hashing
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/hash/e94f63f579e05cb49c05c2d050ead9c0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2017/file/e94f63f579e05cb49c05c2d050ead9c0-Paper.pdf)]
    * Title: Deep Supervised Discrete Hashing
    * Year: `2017`
    * Authors: Qi Li, Zhenan Sun, Ran He, Tieniu Tan
    * Abstract: With the rapid growth of image and video data on the web, hashing has been extensively studied for image or video search in recent years. Benefiting from recent advances in deep learning, deep hashing methods have achieved promising results for image retrieval. However, there are some limitations of previous deep hashing methods (e.g., the semantic information is not fully exploited). In this paper, we develop a deep supervised discrete hashing algorithm based on the assumption that the learned binary codes should be ideal for classification. Both the pairwise label information and the classification information are used to learn the hash codes within one stream framework. We constrain the outputs of the last layer to be binary codes directly, which is rarely investigated in deep hashing algorithm. Because of the discrete nature of hash codes, an alternating minimization method is used to optimize the objective function. Experimental results have shown that our method outperforms current state-of-the-art methods on benchmark datasets.
count=1
* Budgeted stream-based active learning via adaptive submodular maximization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/07cdfd23373b17c6b337251c22b7ea57-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/07cdfd23373b17c6b337251c22b7ea57-Paper.pdf)]
    * Title: Budgeted stream-based active learning via adaptive submodular maximization
    * Year: `2016`
    * Authors: Kaito Fujii, Hisashi Kashima
    * Abstract: Active learning enables us to reduce the annotation cost by adaptively selecting unlabeled instances to be labeled. For pool-based active learning, several effective methods with theoretical guarantees have been developed through maximizing some utility function satisfying adaptive submodularity. In contrast, there have been few methods for stream-based active learning based on adaptive submodularity. In this paper, we propose a new class of utility functions, policy-adaptive submodular functions, and prove this class includes many existing adaptive submodular functions appearing in real world problems. We provide a general framework based on policy-adaptive submodularity that makes it possible to convert existing pool-based methods to stream-based methods and give theoretical guarantees on their performance. In addition we empirically demonstrate their effectiveness comparing with existing heuristics on common benchmark datasets.
count=1
* Efficient state-space modularization for planning: theory, behavioral and neural signatures
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/10907813b97e249163587e6246612e21-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/10907813b97e249163587e6246612e21-Paper.pdf)]
    * Title: Efficient state-space modularization for planning: theory, behavioral and neural signatures
    * Year: `2016`
    * Authors: Daniel McNamee, Daniel M. Wolpert, Mate Lengyel
    * Abstract: Even in state-spaces of modest size, planning is plagued by the “curse of dimensionality”. This problem is particularly acute in human and animal cognition given the limited capacity of working memory, and the time pressures under which planning often occurs in the natural environment. Hierarchically organized modular representations have long been suggested to underlie the capacity of biological systems to efficiently and flexibly plan in complex environments. However, the principles underlying efficient modularization remain obscure, making it difficult to identify its behavioral and neural signatures. Here, we develop a normative theory of efficient state-space representations which partitions an environment into distinct modules by minimizing the average (information theoretic) description length of planning within the environment, thereby optimally trading off the complexity of planning across and within modules. We show that such optimal representations provide a unifying account for a diverse range of hitherto unrelated phenomena at multiple levels of behavior and neural representation.
count=1
* beta-risk: a New Surrogate Risk for Learning from Weakly Labeled Data
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/1e8c391abfde9abea82d75a2d60278d4-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/1e8c391abfde9abea82d75a2d60278d4-Paper.pdf)]
    * Title: beta-risk: a New Surrogate Risk for Learning from Weakly Labeled Data
    * Year: `2016`
    * Authors: Valentina Zantedeschi, Rémi Emonet, Marc Sebban
    * Abstract: During the past few years, the machine learning community has paid attention to developping new methods for learning from weakly labeled data. This field covers different settings like semi-supervised learning, learning with label proportions, multi-instance learning, noise-tolerant learning, etc. This paper presents a generic framework to deal with these weakly labeled scenarios. We introduce the beta-risk as a generalized formulation of the standard empirical risk based on surrogate margin-based loss functions. This risk allows us to express the reliability on the labels and to derive different kinds of learning algorithms. We specifically focus on SVMs and propose a soft margin beta-svm algorithm which behaves better that the state of the art.
count=1
* RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/231141b34c82aa95e48810a9d1b33a79-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/231141b34c82aa95e48810a9d1b33a79-Paper.pdf)]
    * Title: RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism
    * Year: `2016`
    * Authors: Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz, Walter Stewart
    * Abstract: Accuracy and interpretability are two dominant features of successful predictive models. Typically, a choice must be made in favor of complex black box models such as recurrent neural networks (RNN) for accuracy versus less accurate but more interpretable traditional models such as logistic regression. This tradeoff poses challenges in medicine where both accuracy and interpretability are important. We addressed this challenge by developing the REverse Time AttentIoN model (RETAIN) for application to Electronic Health Records (EHR) data. RETAIN achieves high accuracy while remaining clinically interpretable and is based on a two-level neural attention model that detects influential past visits and significant clinical variables within those visits (e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR data in a reverse time order so that recent clinical visits are likely to receive higher attention. RETAIN was tested on a large health system EHR dataset with 14 million visits completed by 263K patients over an 8 year period and demonstrated predictive accuracy and computational scalability comparable to state-of-the-art methods such as RNN, and ease of interpretability comparable to traditional models.
count=1
* Tractable Operations for Arithmetic Circuits of Probabilistic Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/5a7f963e5e0504740c3a6b10bb6d4fa5-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/5a7f963e5e0504740c3a6b10bb6d4fa5-Paper.pdf)]
    * Title: Tractable Operations for Arithmetic Circuits of Probabilistic Models
    * Year: `2016`
    * Authors: Yujia Shen, Arthur Choi, Adnan Darwiche
    * Abstract: We consider tractable representations of probability distributions and the polytime operations they support. In particular, we consider a recently proposed arithmetic circuit representation, the Probabilistic Sentential Decision Diagram (PSDD). We show that PSDD supports a polytime multiplication operator, while they do not support a polytime operator for summing-out variables. A polytime multiplication operator make PSDDs suitable for a broader class of applications compared to arithmetic circuits, which do not in general support multiplication. As one example, we show that PSDD multiplication leads to a very simple but effective compilation algorithm for probabilistic graphical models: represent each model factor as a PSDD, and then multiply them.
count=1
* Large Margin Discriminant Dimensionality Reduction in Prediction Space
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/632cee946db83e7a52ce5e8d6f0fed35-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/632cee946db83e7a52ce5e8d6f0fed35-Paper.pdf)]
    * Title: Large Margin Discriminant Dimensionality Reduction in Prediction Space
    * Year: `2016`
    * Authors: Mohammad Saberian, Jose Costa Pereira, Can Xu, Jian Yang, Nuno Nvasconcelos
    * Abstract: In this paper we establish a duality between boosting and SVM, and use this to derive a novel discriminant dimensionality reduction algorithm. In particular, using the multiclass formulation of boosting and SVM we note that both use a combination of mapping and linear classification to maximize the multiclass margin. In SVM this is implemented using a pre-defined mapping (induced by the kernel) and optimizing the linear classifiers. In boosting the linear classifiers are pre-defined and the mapping (predictor) is learned through combination of weak learners. We argue that the intermediate mapping, e.g. boosting predictor, is preserving the discriminant aspects of the data and by controlling the dimension of this mapping it is possible to achieve discriminant low dimensional representations for the data. We use the aforementioned duality and propose a new method, Large Margin Discriminant Dimensionality Reduction (LADDER) that jointly learns the mapping and the linear classifiers in an efficient manner. This leads to a data-driven mapping which can embed data into any number of dimensions. Experimental results show that this embedding can significantly improve performance on tasks such as hashing and image/scene classification.
count=1
* Boosting with Abstention
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/7634ea65a4e6d9041cfd3f7de18e334a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/7634ea65a4e6d9041cfd3f7de18e334a-Paper.pdf)]
    * Title: Boosting with Abstention
    * Year: `2016`
    * Authors: Corinna Cortes, Giulia DeSalvo, Mehryar Mohri
    * Abstract: We present a new boosting algorithm for the key scenario of binary classification with abstention where the algorithm can abstain from predicting the label of a point, at the price of a fixed cost. At each round, our algorithm selects a pair of functions, a base predictor and a base abstention function. We define convex upper bounds for the natural loss function associated to this problem, which we prove to be calibrated with respect to the Bayes solution. Our algorithm benefits from general margin-based learning guarantees which we derive for ensembles of pairs of base predictor and abstention functions, in terms of the Rademacher complexities of the corresponding function classes. We give convergence guarantees for our algorithm along with a linear-time weak-learning algorithm for abstention stumps. We also report the results of several experiments suggesting that our algorithm provides a significant improvement in practice over two confidence-based algorithms.
count=1
* On Regularizing Rademacher Observation Losses
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/9bf31c7ff062936a96d3c8bd1f8f2ff3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper.pdf)]
    * Title: On Regularizing Rademacher Observation Losses
    * Year: `2016`
    * Authors: Richard Nock
    * Abstract: It has recently been shown that supervised learning linear classifiers with two of the most popular losses, the logistic and square loss, is equivalent to optimizing an equivalent loss over sufficient statistics about the class: Rademacher observations (rados). It has also been shown that learning over rados brings solutions to two prominent problems for which the state of the art of learning from examples can be comparatively inferior and in fact less convenient: protecting and learning from private examples, learning from distributed datasets without entity resolution. Bis repetita placent: the two proofs of equivalence are different and rely on specific properties of the corresponding losses, so whether these can be unified and generalized inevitably comes to mind. This is our first contribution: we show how they can be fit into the same theory for the equivalence between example and rado losses. As a second contribution, we show that the generalization unveils a surprising new connection to regularized learning, and in particular a sufficient condition under which regularizing the loss over examples is equivalent to regularizing the rados (i.e. the data) in the equivalent rado loss, in such a way that an efficient algorithm for one regularized rado loss may be as efficient when changing the regularizer. This is our third contribution: we give a formal boosting algorithm for the regularized exponential rado-loss which boost with any of the ridge, lasso, \slope, l_\infty, or elastic nets, using the same master routine for all. Because the regularized exponential rado-loss is the equivalent of the regularized logistic loss over examples we obtain the first efficient proxy to the minimisation of the regularized logistic loss over examples using such a wide spectrum of regularizers. Experiments with a readily available code display that regularization significantly improves rado-based learning and compares favourably with example-based learning.
count=1
* Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/be3159ad04564bfb90db9e32851ebf9c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/be3159ad04564bfb90db9e32851ebf9c-Paper.pdf)]
    * Title: Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning
    * Year: `2016`
    * Authors: Gang Niu, Marthinus Christoffel du Plessis, Tomoya Sakai, Yao Ma, Masashi Sugiyama
    * Abstract: In PU learning, a binary classifier is trained from positive (P) and unlabeled (U) data without negative (N) data. Although N data is missing, it sometimes outperforms PN learning (i.e., ordinary supervised learning). Hitherto, neither theoretical nor experimental analysis has been given to explain this phenomenon. In this paper, we theoretically compare PU (and NU) learning against PN learning based on the upper bounds on estimation errors. We find simple conditions when PU and NU learning are likely to outperform PN learning, and we prove that, in terms of the upper bounds, either PU or NU learning (depending on the class-prior probability and the sizes of P and N data) given infinite U data will improve on PN learning. Our theoretical findings well agree with the experimental results on artificial and benchmark data even when the experimental setup does not match the theoretical assumptions exactly.
count=1
* Optimizing affinity-based binary hashing using auxiliary coordinates
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/c5ff2543b53f4cc0ad3819a36752467b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/c5ff2543b53f4cc0ad3819a36752467b-Paper.pdf)]
    * Title: Optimizing affinity-based binary hashing using auxiliary coordinates
    * Year: `2016`
    * Authors: Ramin Raziperchikolaei, Miguel A. Carreira-Perpinan
    * Abstract: In supervised binary hashing, one wants to learn a function that maps a high-dimensional feature vector to a vector of binary codes, for application to fast image retrieval. This typically results in a difficult optimization problem, nonconvex and nonsmooth, because of the discrete variables involved. Much work has simply relaxed the problem during training, solving a continuous optimization, and truncating the codes a posteriori. This gives reasonable results but is quite suboptimal. Recent work has tried to optimize the objective directly over the binary codes and achieved better results, but the hash function was still learned a posteriori, which remains suboptimal. We propose a general framework for learning hash functions using affinity-based loss functions that uses auxiliary coordinates. This closes the loop and optimizes jointly over the hash functions and the binary codes so that they gradually match each other. The resulting algorithm can be seen as an iterated version of the procedure of optimizing first over the codes and then learning the hash function. Compared to this, our optimization is guaranteed to obtain better hash functions while being not much slower, as demonstrated experimentally in various supervised datasets. In addition, our framework facilitates the design of optimization algorithms for arbitrary types of loss and hash functions.
count=1
* The Power of Optimization from Samples
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/c8758b517083196f05ac29810b924aca-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/c8758b517083196f05ac29810b924aca-Paper.pdf)]
    * Title: The Power of Optimization from Samples
    * Year: `2016`
    * Authors: Eric Balkanski, Aviad Rubinstein, Yaron Singer
    * Abstract: We consider the problem of optimization from samples of monotone submodular functions with bounded curvature. In numerous applications, the function optimized is not known a priori, but instead learned from data. What are the guarantees we have when optimizing functions from sampled data? In this paper we show that for any monotone submodular function with curvature c there is a (1 - c)/(1 + c - c^2) approximation algorithm for maximization under cardinality constraints when polynomially-many samples are drawn from the uniform distribution over feasible sets. Moreover, we show that this algorithm is optimal. That is, for any c < 1, there exists a submodular function with curvature c for which no algorithm can achieve a better approximation. The curvature assumption is crucial as for general monotone submodular functions no algorithm can obtain a constant-factor approximation for maximization under a cardinality constraint when observing polynomially-many samples drawn from any distribution over feasible sets, even when the function is statistically learnable.
count=1
* Unified Methods for Exploiting Piecewise Linear Structure in Convex Optimization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/cb2c2041d9763d84d7d655e81178f444-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/cb2c2041d9763d84d7d655e81178f444-Paper.pdf)]
    * Title: Unified Methods for Exploiting Piecewise Linear Structure in Convex Optimization
    * Year: `2016`
    * Authors: Tyler B. Johnson, Carlos Guestrin
    * Abstract: We develop methods for rapidly identifying important components of a convex optimization problem for the purpose of achieving fast convergence times. By considering a novel problem formulation—the minimization of a sum of piecewise functions—we describe a principled and general mechanism for exploiting piecewise linear structure in convex optimization. This result leads to a theoretically justified working set algorithm and a novel screening test, which generalize and improve upon many prior results on exploiting structure in convex optimization. In empirical comparisons, we study the scalability of our methods. We find that screening scales surprisingly poorly with the size of the problem, while our working set algorithm convincingly outperforms alternative approaches.
count=1
* Incremental Boosting Convolutional Neural Network for Facial Action Unit Recognition
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/d09bf41544a3365a46c9077ebb5e35c3-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/d09bf41544a3365a46c9077ebb5e35c3-Paper.pdf)]
    * Title: Incremental Boosting Convolutional Neural Network for Facial Action Unit Recognition
    * Year: `2016`
    * Authors: Shizhong Han, Zibo Meng, AHMED-SHEHAB KHAN, Yan Tong
    * Abstract: Recognizing facial action units (AUs) from spontaneous facial expressions is still a challenging problem. Most recently, CNNs have shown promise on facial AU recognition. However, the learned CNNs are often overfitted and do not generalize well to unseen subjects due to limited AU-coded training images. We proposed a novel Incremental Boosting CNN (IB-CNN) to integrate boosting into the CNN via an incremental boosting layer that selects discriminative neurons from the lower layer and is incrementally updated on successive mini-batches. In addition, a novel loss function that accounts for errors from both the incremental boosted classifier and individual weak classifiers was proposed to fine-tune the IB-CNN. Experimental results on four benchmark AU databases have demonstrated that the IB-CNN yields significant improvement over the traditional CNN and the boosting CNN without incremental learning, as well as outperforming the state-of-the-art CNN-based methods in AU recognition. The improvement is more impressive for the AUs that have the lowest frequencies in the databases.
count=1
* An urn model for majority voting in classification ensembles
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/hash/d1a21da7bca4abff8b0b61b87597de73-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2016/file/d1a21da7bca4abff8b0b61b87597de73-Paper.pdf)]
    * Title: An urn model for majority voting in classification ensembles
    * Year: `2016`
    * Authors: Victor Soto, Alberto Suárez, Gonzalo Martinez-Muñoz
    * Abstract: In this work we analyze the class prediction of parallel randomized ensembles by majority voting as an urn model. For a given test instance, the ensemble can be viewed as an urn of marbles of different colors. A marble represents an individual classifier. Its color represents the class label prediction of the corresponding classifier. The sequential querying of classifiers in the ensemble can be seen as draws without replacement from the urn. An analysis of this classical urn model based on the hypergeometric distribution makes it possible to estimate the confidence on the outcome of majority voting when only a fraction of the individual predictions is known. These estimates can be used to speed up the prediction by the ensemble. Specifically, the aggregation of votes can be halted when the confidence in the final prediction is sufficiently high. If one assumes a uniform prior for the distribution of possible votes the analysis is shown to be equivalent to a previous one based on Dirichlet distributions. The advantage of the current approach is that prior knowledge on the possible vote outcomes can be readily incorporated in a Bayesian framework. We show how incorporating this type of problem-specific knowledge into the statistical analysis of majority voting leads to faster classification by the ensemble and allows us to estimate the expected average speed-up beforehand.
count=1
* Learning Bayesian Networks with Thousands of Variables
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/2b38c2df6a49b97f706ec9148ce48d86-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/2b38c2df6a49b97f706ec9148ce48d86-Paper.pdf)]
    * Title: Learning Bayesian Networks with Thousands of Variables
    * Year: `2015`
    * Authors: Mauro Scanagatta, Cassio P. de Campos, Giorgio Corani, Marco Zaffalon
    * Abstract: We present a method for learning Bayesian networks from data sets containingthousands of variables without the need for structure constraints. Our approachis made of two parts. The first is a novel algorithm that effectively explores thespace of possible parent sets of a node. It guides the exploration towards themost promising parent sets on the basis of an approximated score function thatis computed in constant time. The second part is an improvement of an existingordering-based algorithm for structure optimization. The new algorithm provablyachieves a higher score compared to its original formulation. On very large datasets containing up to ten thousand nodes, our novel approach consistently outper-forms the state of the art.
count=1
* On-the-Job Learning with Bayesian Decision Theory
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/333222170ab9edca4785c39f55221fe7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/333222170ab9edca4785c39f55221fe7-Paper.pdf)]
    * Title: On-the-Job Learning with Bayesian Decision Theory
    * Year: `2015`
    * Authors: Keenon Werling, Arun Tejasvi Chaganty, Percy S. Liang, Christopher D. Manning
    * Abstract: Our goal is to deploy a high-accuracy system starting with zero training examples. We consider an “on-the-job” setting, where as inputs arrive, we use real-time crowdsourcing to resolve uncertainty where needed and output our prediction when confident. As the model improves over time, the reliance on crowdsourcing queries decreases. We cast our setting as a stochastic game based on Bayesian decision theory, which allows us to balance latency, cost, and accuracy objectives in a principled way. Computing the optimal policy is intractable, so we develop an approximation based on Monte Carlo Tree Search. We tested our approach on three datasets-- named-entity recognition, sentiment classification, and image classification. On the NER task we obtained more than an order of magnitude reduction in cost compared to full human annotation, while boosting performance relative to the expert provided labels. We also achieve a 8% F1 improvement over having a single human label the whole set, and a 28% F1 improvement over online learning.
count=1
* Precision-Recall-Gain Curves: PR Analysis Done Right
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/33e8075e9970de0cfea955afd4644bb2-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/33e8075e9970de0cfea955afd4644bb2-Paper.pdf)]
    * Title: Precision-Recall-Gain Curves: PR Analysis Done Right
    * Year: `2015`
    * Authors: Peter Flach, Meelis Kull
    * Abstract: Precision-Recall analysis abounds in applications of binary classification where true negatives do not add value and hence should not affect assessment of the classifier's performance. Perhaps inspired by the many advantages of receiver operating characteristic (ROC) curves and the area under such curves for accuracy-based performance assessment, many researchers have taken to report Precision-Recall (PR) curves and associated areas as performance metric. We demonstrate in this paper that this practice is fraught with difficulties, mainly because of incoherent scale assumptions -- e.g., the area under a PR curve takes the arithmetic mean of precision values whereas the $F_{\beta}$ score applies the harmonic mean. We show how to fix this by plotting PR curves in a different coordinate system, and demonstrate that the new Precision-Recall-Gain curves inherit all key advantages of ROC curves. In particular, the area under Precision-Recall-Gain curves conveys an expected $F_1$ score on a harmonic scale, and the convex hull of a Precision-Recall-Gain curve allows us to calibrate the classifier's scores so as to determine, for each operating point on the convex hull, the interval of $\beta$ values for which the point optimises $F_{\beta}$. We demonstrate experimentally that the area under traditional PR curves can easily favour models with lower expected $F_1$ score than others, and so the use of Precision-Recall-Gain curves will result in better model selection.
count=1
* Parallelizing MCMC with Random Partition Trees
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/40008b9a5380fcacce3976bf7c08af5b-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/40008b9a5380fcacce3976bf7c08af5b-Paper.pdf)]
    * Title: Parallelizing MCMC with Random Partition Trees
    * Year: `2015`
    * Authors: Xiangyu Wang, Fangjian Guo, Katherine A. Heller, David B. Dunson
    * Abstract: The modern scale of data has brought new challenges to Bayesian inference. In particular, conventional MCMC algorithms are computationally very expensive for large data sets. A promising approach to solve this problem is embarrassingly parallel MCMC (EP-MCMC), which first partitions the data into multiple subsets and runs independent sampling algorithms on each subset. The subset posterior draws are then aggregated via some combining rules to obtain the final approximation. Existing EP-MCMC algorithms are limited by approximation accuracy and difficulty in resampling. In this article, we propose a new EP-MCMC algorithm PART that solves these problems. The new algorithm applies random partition trees to combine the subset posterior draws, which is distribution-free, easy to resample from and can adapt to multiple scales. We provide theoretical justification and extensive experiments illustrating empirical performance.
count=1
* Tractable Learning for Complex Probability Queries
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/bb7946e7d85c81a9e69fee1cea4a087c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/bb7946e7d85c81a9e69fee1cea4a087c-Paper.pdf)]
    * Title: Tractable Learning for Complex Probability Queries
    * Year: `2015`
    * Authors: Jessa Bekker, Jesse Davis, Arthur Choi, Adnan Darwiche, Guy Van den Broeck
    * Abstract: Tractable learning aims to learn probabilistic models where inference is guaranteed to be efficient. However, the particular class of queries that is tractable depends on the model and underlying representation. Usually this class is MPE or conditional probabilities $\Pr(\xs|\ys)$ for joint assignments~$\xs,\ys$. We propose a tractable learner that guarantees efficient inference for a broader class of queries. It simultaneously learns a Markov network and its tractable circuit representation, in order to guarantee and measure tractability. Our approach differs from earlier work by using Sentential Decision Diagrams (SDD) as the tractable language instead of Arithmetic Circuits (AC). SDDs have desirable properties, which more general representations such as ACs lack, that enable basic primitives for Boolean circuit compilation. This allows us to support a broader class of complex probability queries, including counting, threshold, and parity, in polytime.
count=1
* Scalable Semi-Supervised Aggregation of Classifiers
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/ce78d1da254c0843eb23951ae077ff5f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/ce78d1da254c0843eb23951ae077ff5f-Paper.pdf)]
    * Title: Scalable Semi-Supervised Aggregation of Classifiers
    * Year: `2015`
    * Authors: Akshay Balsubramani, Yoav Freund
    * Abstract: We present and empirically evaluate an efficient algorithm that learns to aggregate the predictions of an ensemble of binary classifiers. The algorithm uses the structure of the ensemble predictions on unlabeled data to yield significant performance improvements. It does this without making assumptions on the structure or origin of the ensemble, without parameters, and as scalably as linear learning. We empirically demonstrate these performance gains with random forests.
count=1
* Adaptive Stochastic Optimization: From Sets to Paths
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/hash/df6d2338b2b8fce1ec2f6dda0a630eb0-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2015/file/df6d2338b2b8fce1ec2f6dda0a630eb0-Paper.pdf)]
    * Title: Adaptive Stochastic Optimization: From Sets to Paths
    * Year: `2015`
    * Authors: Zhan Wei Lim, David Hsu, Wee Sun Lee
    * Abstract: Adaptive stochastic optimization optimizes an objective function adaptively under uncertainty. Adaptive stochastic optimization plays a crucial role in planning and learning under uncertainty, but is, unfortunately, computationally intractable in general. This paper introduces two conditions on the objective function, the marginal likelihood rate bound and the marginal likelihood bound, which enable efficient approximate solution of adaptive stochastic optimization. Several interesting classes of functions satisfy these conditions naturally, e.g., the version space reduction function for hypothesis learning. We describe Recursive Adaptive Coverage (RAC), a new adaptive stochastic optimization algorithm that exploits these conditions, and apply it to two planning tasks under uncertainty. In constrast to the earlier submodular optimization approach, our algorithm applies to adaptive stochastic optimization algorithm over both sets and paths.
count=1
* The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/390e982518a50e280d8e2b535462ec1f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/390e982518a50e280d8e2b535462ec1f-Paper.pdf)]
    * Title: The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification
    * Year: `2014`
    * Authors: Been Kim, Cynthia Rudin, Julie A. Shah
    * Abstract: We present the Bayesian Case Model (BCM), a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes, the ``quintessential observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. Simultaneously, BCM pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in interpretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants' understanding when using explanations produced by BCM, compared to those given by prior art.
count=1
* Partition-wise Linear Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/4e87337f366f72daa424dae11df0538c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/4e87337f366f72daa424dae11df0538c-Paper.pdf)]
    * Title: Partition-wise Linear Models
    * Year: `2014`
    * Authors: Hidekazu Oiwa, Ryohei Fujimaki
    * Abstract: Region-specific linear models are widely used in practical applications because of their non-linear but highly interpretable model representations. One of the key challenges in their use is non-convexity in simultaneous optimization of regions and region-specific models. This paper proposes novel convex region-specific linear models, which we refer to as partition-wise linear models. Our key ideas are 1) assigning linear models not to regions but to partitions (region-specifiers) and representing region-specific linear models by linear combinations of partition-specific models, and 2) optimizing regions via partition selection from a large number of given partition candidates by means of convex structured regularizations. In addition to providing initialization-free globally-optimal solutions, our convex formulation makes it possible to derive a generalization bound and to use such advanced optimization techniques as proximal methods and decomposition of the proximal maps for sparsity-inducing regularizations. Experimental results demonstrate that our partition-wise linear models perform better than or are at least competitive with state-of-the-art region-specific or locally linear models.
count=1
* The Large Margin Mechanism for Differentially Private Maximization
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/5751ec3e9a4feab575962e78e006250d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/5751ec3e9a4feab575962e78e006250d-Paper.pdf)]
    * Title: The Large Margin Mechanism for Differentially Private Maximization
    * Year: `2014`
    * Authors: Kamalika Chaudhuri, Daniel J. Hsu, Shuang Song
    * Abstract: A basic problem in the design of privacy-preserving algorithms is the \emph{private maximization problem}: the goal is to pick an item from a universe that (approximately) maximizes a data-dependent function, all under the constraint of differential privacy. This problem has been used as a sub-routine in many privacy-preserving algorithms for statistics and machine learning. Previous algorithms for this problem are either range-dependent---i.e., their utility diminishes with the size of the universe---or only apply to very restricted function classes. This work provides the first general purpose, range-independent algorithm for private maximization that guarantees approximate differential privacy. Its applicability is demonstrated on two fundamental tasks in data mining and machine learning.
count=1
* (Almost) No Label No Cry
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/a8baa56554f96369ab93e4f3bb068c22-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/a8baa56554f96369ab93e4f3bb068c22-Paper.pdf)]
    * Title: (Almost) No Label No Cry
    * Year: `2014`
    * Authors: Giorgio Patrini, Richard Nock, Paul Rivera, Tiberio Caetano
    * Abstract: In Learning with Label Proportions (LLP), the objective is to learn a supervised classifier when, instead of labels, only label proportions for bags of observations are known. This setting has broad practical relevance, in particular for privacy preserving data processing. We first show that the mean operator, a statistic which aggregates all labels, is minimally sufficient for the minimization of many proper scoring losses with linear (or kernelized) classifiers without using labels. We provide a fast learning algorithm that estimates the mean operator via a manifold regularizer with guaranteed approximation bounds. Then, we present an iterative learning algorithm that uses this as initialization. We ground this algorithm in Rademacher-style generalization bounds that fit the LLP setting, introducing a generalization of Rademacher complexity and a Label Proportion Complexity measure. This latter algorithm optimizes tractable bounds for the corresponding bag-empirical risk. Experiments are provided on fourteen domains, whose size ranges up to 300K observations. They display that our algorithms are scalable and tend to consistently outperform the state of the art in LLP. Moreover, in many cases, our algorithms compete with or are just percents of AUC away from the Oracle that learns knowing all labels. On the largest domains, half a dozen proportions can suffice, i.e. roughly 40K times less than the total number of labels.
count=1
* Self-Paced Learning with Diversity
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/c60d060b946d6dd6145dcbad5c4ccf6f-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/c60d060b946d6dd6145dcbad5c4ccf6f-Paper.pdf)]
    * Title: Self-Paced Learning with Diversity
    * Year: `2014`
    * Authors: Lu Jiang, Deyu Meng, Shoou-I Yu, Zhenzhong Lan, Shiguang Shan, Alexander Hauptmann
    * Abstract: Self-paced learning (SPL) is a recently proposed learning regime inspired by the learning process of humans and animals that gradually incorporates easy to more complex samples into training. Existing methods are limited in that they ignore an important aspect in learning: diversity. To incorporate this information, we propose an approach called self-paced learning with diversity (SPLD) which formalizes the preference for both easy and diverse samples into a general regularizer. This regularization term is independent of the learning objective, and thus can be easily generalized into various learning tasks. Albeit non-convex, the optimization of the variables included in this SPLD regularization term for sample selection can be globally solved in linearithmic time. We demonstrate that our method significantly outperforms the conventional SPL on three real-world datasets. Specifically, SPLD achieves the best MAP so far reported in literature on the Hollywood2 and Olympic Sports datasets.
count=1
* Searching for Higgs Boson Decay Modes with Deep Learning
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/e1d5be1c7f2f456670de3d53c7b54f4a-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/e1d5be1c7f2f456670de3d53c7b54f4a-Paper.pdf)]
    * Title: Searching for Higgs Boson Decay Modes with Deep Learning
    * Year: `2014`
    * Authors: Peter J. Sadowski, Daniel Whiteson, Pierre Baldi
    * Abstract: Particle colliders enable us to probe the fundamental nature of matter by observing exotic particles produced by high-energy collisions. Because the experimental measurements from these collisions are necessarily incomplete and imprecise, machine learning algorithms play a major role in the analysis of experimental data. The high-energy physics community typically relies on standardized machine learning software packages for this analysis, and devotes substantial effort towards improving statistical power by hand crafting high-level features derived from the raw collider measurements. In this paper, we train artificial neural networks to detect the decay of the Higgs boson to tau leptons on a dataset of 82 million simulated collision events. We demonstrate that deep neural network architectures are particularly well-suited for this task with the ability to automatically discover high-level features from the data and increase discovery significance.
count=1
* Efficient Optimization for Average Precision SVM
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/hash/eb86d510361fc23b59f18c1bc9802cc6-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2014/file/eb86d510361fc23b59f18c1bc9802cc6-Paper.pdf)]
    * Title: Efficient Optimization for Average Precision SVM
    * Year: `2014`
    * Authors: Pritish Mohapatra, C.V. Jawahar, M. Pawan Kumar
    * Abstract: The accuracy of information retrieval systems is often measured using average precision (AP). Given a set of positive (relevant) and negative (non-relevant) samples, the parameters of a retrieval system can be estimated using the AP-SVM framework, which minimizes a regularized convex upper bound on the empirical AP loss. However, the high computational complexity of loss-augmented inference, which is required for learning an AP-SVM, prohibits its use with large training datasets. To alleviate this deficiency, we propose three complementary approaches. The first approach guarantees an asymptotic decrease in the computational complexity of loss-augmented inference by exploiting the problem structure. The second approach takes advantage of the fact that we do not require a full ranking during loss-augmented inference. This helps us to avoid the expensive step of sorting the negative samples according to their individual scores. The third approach approximates the AP loss over all samples by the AP loss over difficult samples (for example, those that are incorrectly classified by a binary SVM), while ensuring the correct classification of the remaining samples. Using the PASCAL VOC action classification and object detection datasets, we show that our approaches provide significant speed-ups during training without degrading the test accuracy of AP-SVM.
count=1
* Regression-tree Tuning in a Streaming Setting
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/2a9d121cd9c3a1832bb6d2cc6bd7a8a7-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/2a9d121cd9c3a1832bb6d2cc6bd7a8a7-Paper.pdf)]
    * Title: Regression-tree Tuning in a Streaming Setting
    * Year: `2013`
    * Authors: Samory Kpotufe, Francesco Orabona
    * Abstract: We consider the problem of maintaining the data-structures of a partition-based regression procedure in a setting where the training data arrives sequentially over time. We prove that it is possible to maintain such a structure in time $O(\log n)$ at any time step $n$ while achieving a nearly-optimal regression rate of $\tilde{O}(n^{-2/(2+d)})$ in terms of the unknown metric dimension $d$. Finally we prove a new regression lower-bound which is independent of a given data size, and hence is more appropriate for the streaming setting.
count=1
* Symbolic Opportunistic Policy Iteration for Factored-Action MDPs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/7d771e0e8f3633ab54856925ecdefc5d-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/7d771e0e8f3633ab54856925ecdefc5d-Paper.pdf)]
    * Title: Symbolic Opportunistic Policy Iteration for Factored-Action MDPs
    * Year: `2013`
    * Authors: Aswin Raghavan, Roni Khardon, Alan Fern, Prasad Tadepalli
    * Abstract: We address the scalability of symbolic planning under uncertainty with factored states and actions. Prior work has focused almost exclusively on factored states but not factored actions, and on value iteration (VI) compared to policy iteration (PI). Our ﬁrst contribution is a novel method for symbolic policy backups via the application of constraints, which is used to yield a new efﬁcient symbolic imple- mentation of modiﬁed PI (MPI) for factored action spaces. While this approach improves scalability in some cases, naive handling of policy constraints comes with its own scalability issues. This leads to our second and main contribution, symbolic Opportunistic Policy Iteration (OPI), which is a novel convergent al- gorithm lying between VI and MPI. The core idea is a symbolic procedure that applies policy constraints only when they reduce the space and time complexity of the update, and otherwise performs full Bellman backups, thus automatically adjusting the backup per state. We also give a memory bounded version of this algorithm allowing a space-time tradeoff. Empirical results show signiﬁcantly improved scalability over the state-of-the-art.
count=1
* Variational Planning for Graph-based MDPs
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/hash/83adc9225e4deb67d7ce42d58fe5157c-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2013/file/83adc9225e4deb67d7ce42d58fe5157c-Paper.pdf)]
    * Title: Variational Planning for Graph-based MDPs
    * Year: `2013`
    * Authors: Qiang Cheng, Qiang Liu, Feng Chen, Alexander T. Ihler
    * Abstract: Markov Decision Processes (MDPs) are extremely useful for modeling and solving sequential decision making problems. Graph-based MDPs provide a compact representation for MDPs with large numbers of random variables. However, the complexity of exactly solving a graph-based MDP usually grows exponentially in the number of variables, which limits their application. We present a new variational framework to describe and solve the planning problem of MDPs, and derive both exact and approximate planning algorithms. In particular, by exploiting the graph structure of graph-based MDPs, we propose a factored variational value iteration algorithm in which the value function is first approximated by the multiplication of local-scope value functions, then solved by minimizing a Kullback-Leibler (KL) divergence. The KL divergence is optimized using the belief propagation algorithm, with complexity exponential in only the cluster size of the graph. Experimental comparison on different models shows that our algorithm outperforms existing approximation algorithms at finding good policies.
count=1
* Mandatory Leaf Node Prediction in Hierarchical Multilabel Classification
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/f899139df5e1059396431415e770c6dd-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/f899139df5e1059396431415e770c6dd-Paper.pdf)]
    * Title: Mandatory Leaf Node Prediction in Hierarchical Multilabel Classification
    * Year: `2012`
    * Authors: Wei Bi, James Kwok
    * Abstract: In hierarchical classification, the prediction paths may be required to always end at leaf nodes. This is called mandatory leaf node prediction (MLNP) and is particularly useful when the leaf nodes have much stronger semantic meaning than the internal nodes. However, while there have been a lot of MLNP methods in hierarchical multiclass classification, performing MLNP in hierarchical multilabel classification is much more difficult. In this paper, we propose a novel MLNP algorithm that (i) considers the global hierarchy structure; and (ii) can be used on hierarchies of both trees and DAGs. We show that one can efficiently maximize the joint posterior probability of all the node labels by a simple greedy algorithm. Moreover, this can be further extended to the minimization of the expected symmetric loss. Experiments are performed on a number of real-world data sets with tree- and DAG-structured label hierarchies. The proposed method consistently outperforms other hierarchical and flat multilabel classification methods.
count=1
* Label Ranking with Partial Abstention based on Thresholded Probabilistic Models
    [[abs-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/hash/fe2d010308a6b3799a3d9c728ee74244-Abstract.html)]
    [[pdf-NeurIPS](https://papers.nips.cc/paper_files/paper/2012/file/fe2d010308a6b3799a3d9c728ee74244-Paper.pdf)]
    * Title: Label Ranking with Partial Abstention based on Thresholded Probabilistic Models
    * Year: `2012`
    * Authors: Weiwei Cheng, Eyke Hüllermeier, Willem Waegeman, Volkmar Welker
    * Abstract: Several machine learning methods allow for abstaining from uncertain predictions. While being common for settings like conventional classification, abstention has been studied much less in learning to rank. We address abstention for the label ranking setting, allowing the learner to declare certain pairs of labels as being incomparable and, thus, to predict partial instead of total orders. In our method, such predictions are produced via thresholding the probabilities of pairwise preferences between labels, as induced by a predicted probability distribution on the set of all rankings. We formally analyze this approach for the Mallows and the Plackett-Luce model, showing that it produces proper partial orders as predictions and characterizing the expressiveness of the induced class of partial orders. These theoretical results are complemented by experiments demonstrating the practical usefulness of the approach.
