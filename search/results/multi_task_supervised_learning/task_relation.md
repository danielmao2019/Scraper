52 https://arxiv.org/pdf/1707.08114.pdf
44 https://arxiv.org/pdf/1506.02117.pdf
44 https://papers.nips.cc/paper_files/paper/2017/file/03e0704b5690a2dee1861dc3ad3316c9-Paper.pdf
31 https://openaccess.thecvf.com/content/ICCV2021W/DeepMTL/papers/Gurulingan_UniNet_A_Unified_Scene_Understanding_Network_and_Exploring_Multi-Task_Relationships_ICCVW_2021_paper.pdf
29 https://arxiv.org/pdf/2202.03091.pdf
27 https://arxiv.org/pdf/1612.04022.pdf
21 https://arxiv.org/pdf/1203.3536.pdf
16 https://arxiv.org/pdf/1905.07553.pdf
16 http://proceedings.mlr.press/v119/standley20a/standley20a.pdf
14 https://openaccess.thecvf.com/content/CVPR2024/papers/Nishi_Joint-Task_Regularization_for_Partially_Labeled_Multi-Task_Learning_CVPR_2024_paper.pdf
13 https://arxiv.org/pdf/2310.16241.pdf
13 https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Split_To_Learn_Gradient_Split_for_Multi-Task_Human_Image_Analysis_WACV_2023_paper.pdf
12 https://openaccess.thecvf.com/content/ICCV2021/papers/Sun_Task_Switching_Network_for_Multi-Task_Learning_ICCV_2021_paper.pdf
11 https://arxiv.org/pdf/2303.07666.pdf
10 https://openaccess.thecvf.com/content/ICCV2021/papers/Bruggemann_Exploring_Relational_Context_for_Multi-Task_Dense_Prediction_ICCV_2021_paper.pdf
8 https://arxiv.org/pdf/2004.13379.pdf
8 https://arxiv.org/pdf/1904.03011.pdf
8 https://arxiv.org/pdf/2111.10952.pdf
7 https://openaccess.thecvf.com/content/WACV2022/papers/Haurum_Multi-Task_Classification_of_Sewer_Pipe_Defects_and_Properties_Using_a_WACV_2022_paper.pdf
6 https://arxiv.org/pdf/1706.05098.pdf
6 https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Multi-Task_Dense_Prediction_via_Mixture_of_Low-Rank_Experts_CVPR_2024_paper.pdf
5 http://proceedings.mlr.press/v48/leeb16.pdf
5 https://openaccess.thecvf.com/content_cvpr_2018/papers/Mejjati_Multi-Task_Learning_by_CVPR_2018_paper.pdf
5 https://arxiv.org/pdf/2303.14582.pdf
5 https://arxiv.org/pdf/1903.12117.pdf
5 https://openaccess.thecvf.com/content_ICCV_2019/papers/Strezoski_Many_Task_Learning_With_Task_Routing_ICCV_2019_paper.pdf
4 https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Michelle_Guo_Focus_on_the_ECCV_2018_paper.pdf
4 https://arxiv.org/pdf/2203.14949.pdf
4 https://openaccess.thecvf.com/content/CVPR2022/papers/Raychaudhuri_Controllable_Dynamic_Multi-Task_Architectures_CVPR_2022_paper.pdf
4 https://arxiv.org/pdf/2312.13514.pdf
3 https://arxiv.org/pdf/2005.00944.pdf
3 https://arxiv.org/pdf/1702.08303.pdf
3 https://aclanthology.org/E17-2026.pdf
3 https://arxiv.org/pdf/1804.08328.pdf
3 https://openaccess.thecvf.com/content_cvpr_2018/papers/Zamir_Taskonomy_Disentangling_Task_CVPR_2018_paper.pdf
3 https://arxiv.org/pdf/1807.06708.pdf
3 https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Xiangyun_Zhao_A_Modulation_Module_ECCV_2018_paper.pdf
2 https://arxiv.org/pdf/2010.05874.pdf
2 https://arxiv.org/pdf/1912.12854.pdf
2 https://papers.nips.cc/paper_files/paper/2019/file/685bfde03eb646c27ed565881917c71c-Paper.pdf
2 https://arxiv.org/pdf/2010.15413.pdf
2 https://arxiv.org/pdf/2109.04617.pdf
2 https://papers.nips.cc/paper_files/paper/2021/file/e77910ebb93b511588557806310f78f1-Paper.pdf
2 https://arxiv.org/pdf/2307.03374.pdf
2 https://arxiv.org/pdf/2305.00441.pdf
2 https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.pdf
2 https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.pdf
2 https://papers.nips.cc/paper_files/paper/2021/file/f5ac21cd0ef1b88e9848571aeb53551a-Paper.pdf
2 http://jmlr.org/papers/volume11/cavallanti10a/cavallanti10a.pdf
2 https://openaccess.thecvf.com/content_CVPR_2020/papers/Zamir_Robust_Learning_Through_Cross-Task_Consistency_CVPR_2020_paper.pdf
2 https://arxiv.org/pdf/2212.06645.pdf
2 https://arxiv.org/pdf/2310.02575.pdf
2 https://openaccess.thecvf.com/content/WACV2021/papers/Goel_QuadroNet_Multi-Task_Learning_for_Real-Time_Semantic_Depth_Aware_Instance_Segmentation_WACV_2021_paper.pdf
2 https://papers.nips.cc/paper_files/paper/2020/file/d37eb50d868361ea729bb4147eb3c1d8-Paper.pdf
1 https://arxiv.org/pdf/2010.06808.pdf
1 https://papers.nips.cc/paper_files/paper/2020/file/16002f7a455a94aa4e91cc34ebdb9f2d-Paper.pdf
1 https://arxiv.org/pdf/1810.04650.pdf
1 https://papers.nips.cc/paper_files/paper/2018/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf
1 https://arxiv.org/pdf/1711.02257.pdf
1 http://proceedings.mlr.press/v80/chen18a/chen18a.pdf
1 https://arxiv.org/pdf/2308.12029.pdf
1 https://arxiv.org/pdf/2306.03792.pdf
1 https://arxiv.org/pdf/1904.08492.pdf
1 https://arxiv.org/pdf/2106.11401.pdf
1 https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870506.pdf
1 https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_Going_Beyond_Multi-Task_Dense_Prediction_with_Synergy_Embedding_Models_CVPR_2024_paper.pdf
1 https://arxiv.org/pdf/1604.01335.pdf
1 https://arxiv.org/pdf/1705.08142.pdf
1 https://arxiv.org/pdf/1206.6417.pdf
1 https://arxiv.org/pdf/1904.02920.pdf
1 https://arxiv.org/pdf/2302.11289.pdf
1 https://arxiv.org/pdf/1904.11740.pdf
1 https://openaccess.thecvf.com/content_CVPR_2019/papers/Dwivedi_Representation_Similarity_Analysis_for_Efficient_Task_Taxonomy__Transfer_Learning_CVPR_2019_paper.pdf
1 http://proceedings.mlr.press/v28/romera-paredes13.pdf
1 https://arxiv.org/pdf/2008.10292.pdf
1 https://arxiv.org/pdf/1910.04915.pdf
1 https://arxiv.org/pdf/1908.09597.pdf
1 https://papers.nips.cc/paper_files/paper/2022/file/b653f34d576d1790481e3797cb740214-Paper-Conference.pdf
1 https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.pdf
1 https://papers.nips.cc/paper_files/paper/2022/file/4a9eaf6dff3fdac9ab1aaf4c0fe2d563-Paper-Conference.pdf
1 https://arxiv.org/pdf/1604.01474.pdf
1 https://openaccess.thecvf.com/content/CVPR2024/papers/Ye_DiffusionMTL_Learning_Multi-Task_Denoising_Diffusion_Model_from_Partially_Annotated_Data_CVPR_2024_paper.pdf
1 https://arxiv.org/pdf/1206.6486.pdf
1 https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470154.pdf
1 https://link.springer.com/content/pdf/10.1007/978-3-319-10599-4_7.pdf
1 https://arxiv.org/pdf/2106.09017.pdf
1 http://proceedings.mlr.press/v139/wang21ad/wang21ad.pdf
1 https://arxiv.org/pdf/2306.12232.pdf
1 https://arxiv.org/pdf/2007.00339.pdf
1 https://arxiv.org/pdf/2108.04353.pdf
1 https://arxiv.org/pdf/2301.13501.pdf
1 https://proceedings.mlr.press/v202/dimitriadis23a/dimitriadis23a.pdf
1 https://arxiv.org/pdf/2301.01572.pdf
1 https://arxiv.org/pdf/2312.03248.pdf
1 https://arxiv.org/pdf/2311.18664.pdf
1 https://arxiv.org/pdf/2401.01219.pdf
1 https://arxiv.org/pdf/2407.12632.pdf
1 https://openaccess.thecvf.com/content/WACV2021/papers/Zhang_Facial_Emotion_Recognition_With_Noisy_Multi-Task_Annotations_WACV_2021_paper.pdf
1 https://papers.nips.cc/paper_files/paper/2022/file/ece182f93af26c64187ba3f7dfd4309a-Paper-Conference.pdf
