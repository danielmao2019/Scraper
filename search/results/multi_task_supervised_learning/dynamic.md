83 https://arxiv.org/pdf/2306.05061.pdf
51 https://arxiv.org/pdf/2203.14949.pdf
45 https://openaccess.thecvf.com/content/CVPR2022/papers/Raychaudhuri_Controllable_Dynamic_Multi-Task_Architectures_CVPR_2022_paper.pdf
44 https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Michelle_Guo_Focus_on_the_ECCV_2018_paper.pdf
34 https://arxiv.org/pdf/2211.10270.pdf
30 https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.pdf
24 https://arxiv.org/pdf/2307.15345.pdf
23 https://arxiv.org/pdf/2202.03091.pdf
21 https://arxiv.org/pdf/2302.09352.pdf
20 https://arxiv.org/pdf/2302.11362.pdf
15 https://arxiv.org/pdf/1806.10293.pdf
15 https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.pdf
14 https://arxiv.org/pdf/1803.04062.pdf
14 https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.pdf
13 https://arxiv.org/pdf/1904.03292.pdf
13 https://arxiv.org/pdf/1711.01239.pdf
13 https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Multi-Task_Dense_Prediction_via_Mixture_of_Low-Rank_Experts_CVPR_2024_paper.pdf
12 https://arxiv.org/pdf/2106.09017.pdf
11 https://arxiv.org/pdf/1810.11910.pdf
11 https://arxiv.org/pdf/1609.07088.pdf
10 https://arxiv.org/pdf/2010.15413.pdf
10 https://arxiv.org/pdf/2301.13501.pdf
9 https://arxiv.org/pdf/2303.06856.pdf
9 https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_Dynamic_Neural_Network_for_Multi-Task_Learning_Searching_Across_Diverse_Network_CVPR_2023_paper.pdf
8 https://arxiv.org/pdf/2306.03792.pdf
8 https://papers.nips.cc/paper_files/paper/2013/file/f33ba15effa5c10e873bf3842afb46a6-Paper.pdf
8 https://arxiv.org/pdf/2101.06720.pdf
7 https://arxiv.org/pdf/1707.08114.pdf
7 https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.pdf
6 https://arxiv.org/pdf/2004.13379.pdf
6 https://arxiv.org/pdf/1604.01685.pdf
6 https://arxiv.org/pdf/1711.02257.pdf
6 https://arxiv.org/pdf/1803.10704.pdf
6 https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_End-To-End_Multi-Task_Learning_With_Attention_CVPR_2019_paper.pdf
6 https://arxiv.org/pdf/1611.05377.pdf
6 https://arxiv.org/pdf/2304.08594.pdf
6 https://openaccess.thecvf.com/content/CVPR2023W/ECV/papers/Neseem_AdaMTL_Adaptive_Input-Dependent_Inference_for_Efficient_Multi-Task_Learning_CVPRW_2023_paper.pdf
6 https://arxiv.org/pdf/2203.14448.pdf
6 https://arxiv.org/pdf/1910.07104.pdf
6 https://arxiv.org/pdf/2210.08217.pdf
6 https://arxiv.org/pdf/1806.08730.pdf
6 https://arxiv.org/pdf/2306.12232.pdf
6 https://arxiv.org/pdf/2106.06129.pdf
6 https://proceedings.mlr.press/v202/dimitriadis23a/dimitriadis23a.pdf
6 https://link.springer.com/content/pdf/10.1007/s11263-012-0582-z.pdf
5 https://papers.nips.cc/paper_files/paper/2022/file/580c4ec4738ff61d5862a122cdf139b6-Paper-Conference.pdf
5 https://arxiv.org/pdf/2111.10603.pdf
5 https://arxiv.org/pdf/2110.14048.pdf
5 https://papers.nips.cc/paper_files/paper/2021/file/9d27fdf2477ffbff837d73ef7ae23db9-Paper.pdf
5 http://proceedings.mlr.press/v80/chen18a/chen18a.pdf
5 https://arxiv.org/pdf/1904.08492.pdf
5 https://arxiv.org/pdf/2109.04617.pdf
5 https://papers.nips.cc/paper_files/paper/2021/file/e77910ebb93b511588557806310f78f1-Paper.pdf
5 https://openaccess.thecvf.com/content_cvpr_2017/papers/Lu_Fully-Adaptive_Feature_Sharing_CVPR_2017_paper.pdf
5 https://arxiv.org/pdf/2302.11289.pdf
5 https://arxiv.org/pdf/2307.03374.pdf
5 https://arxiv.org/pdf/2006.01895.pdf
5 https://arxiv.org/pdf/2007.02693.pdf
5 https://arxiv.org/pdf/1805.08576.pdf
5 https://arxiv.org/pdf/2103.04056.pdf
5 https://openaccess.thecvf.com/content/WACV2021/papers/Parsa_A_Multi-Task_Learning_Approach_for_Human_Activity_Segmentation_and_Ergonomics_WACV_2021_paper.pdf
4 https://arxiv.org/pdf/2308.12029.pdf
4 https://arxiv.org/pdf/1912.12854.pdf
4 https://papers.nips.cc/paper_files/paper/2020/file/e1228be46de6a0234ac22ded31417bc7-Paper.pdf
4 https://arxiv.org/pdf/1904.02920.pdf
4 https://arxiv.org/pdf/2008.10292.pdf
4 https://arxiv.org/pdf/1911.12423.pdf
4 https://papers.nips.cc/paper_files/paper/2020/file/634841a6831464b64c072c8510c7f35c-Paper.pdf
4 https://arxiv.org/pdf/2006.09762.pdf
4 https://arxiv.org/pdf/2305.00441.pdf
4 https://arxiv.org/pdf/1604.01474.pdf
4 https://openaccess.thecvf.com/content/WACV2023/papers/Jacob_Online_Knowledge_Distillation_for_Multi-Task_Learning_WACV_2023_paper.pdf
4 https://arxiv.org/pdf/1909.11763.pdf
4 https://arxiv.org/pdf/2212.06817.pdf
4 https://arxiv.org/pdf/2106.13237.pdf
4 https://arxiv.org/pdf/2104.08212.pdf
4 https://arxiv.org/pdf/1809.11100.pdf
4 https://arxiv.org/pdf/1908.03265.pdf
4 https://arxiv.org/pdf/2312.08881.pdf
4 https://arxiv.org/pdf/2312.02916.pdf
4 https://arxiv.org/pdf/2310.03925.pdf
4 https://openaccess.thecvf.com/content/WACV2022/papers/Haurum_Multi-Task_Classification_of_Sewer_Pipe_Defects_and_Properties_Using_a_WACV_2022_paper.pdf
3 https://papers.nips.cc/paper_files/paper/2022/file/4f301ae934f396086bfefd1139039dbd-Paper-Conference.pdf
3 https://arxiv.org/pdf/2010.05874.pdf
3 https://arxiv.org/pdf/1810.04650.pdf
3 https://papers.nips.cc/paper_files/paper/2018/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf
3 https://arxiv.org/pdf/2202.01017.pdf
3 https://arxiv.org/pdf/2308.02066.pdf
3 https://arxiv.org/pdf/2103.02631.pdf
3 https://arxiv.org/pdf/1904.08918.pdf
3 https://openaccess.thecvf.com/content_CVPR_2019/papers/Maninis_Attentive_Single-Tasking_of_Multiple_Tasks_CVPR_2019_paper.pdf
3 https://arxiv.org/pdf/1904.03011.pdf
3 https://arxiv.org/pdf/1904.11740.pdf
3 https://openaccess.thecvf.com/content_CVPR_2019/papers/Dwivedi_Representation_Similarity_Analysis_for_Efficient_Task_Taxonomy__Transfer_Learning_CVPR_2019_paper.pdf
3 https://arxiv.org/pdf/1908.04339.pdf
3 https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650681.pdf
3 https://arxiv.org/pdf/2001.06902.pdf
3 https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490511.pdf
3 https://papers.nips.cc/paper_files/paper/2022/file/b653f34d576d1790481e3797cb740214-Paper-Conference.pdf
3 https://arxiv.org/pdf/1908.04339.pdf
3 https://arxiv.org/pdf/2210.12624.pdf
3 https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.pdf
3 https://openaccess.thecvf.com/content/CVPR2024/papers/Ye_DiffusionMTL_Learning_Multi-Task_Denoising_Diffusion_Model_from_Partially_Annotated_Data_CVPR_2024_paper.pdf
3 http://proceedings.mlr.press/v139/wang21ad/wang21ad.pdf
3 https://arxiv.org/pdf/2307.08850.pdf
3 https://arxiv.org/pdf/2006.07438.pdf
2 https://arxiv.org/pdf/1706.05098.pdf
2 https://arxiv.org/pdf/1106.0245.pdf
2 https://arxiv.org/pdf/2310.13746.pdf
2 https://arxiv.org/pdf/1705.07115.pdf
2 https://papers.nips.cc/paper_files/paper/2019/file/685bfde03eb646c27ed565881917c71c-Paper.pdf
2 https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Hierarchical_Prompt_Learning_for_Multi-Task_Learning_CVPR_2023_paper.pdf
2 https://openaccess.thecvf.com/content/WACV2023/papers/Lopes_Cross-Task_Attention_Mechanism_for_Dense_Multi-Task_Learning_WACV_2023_paper.pdf
2 https://arxiv.org/pdf/1905.07553.pdf
2 http://proceedings.mlr.press/v119/standley20a/standley20a.pdf
2 https://arxiv.org/pdf/1702.08303.pdf
2 https://aclanthology.org/E17-2026.pdf
2 https://arxiv.org/pdf/1902.03545.pdf
2 https://openaccess.thecvf.com/content_ICCV_2019/papers/Achille_Task2Vec_Task_Embedding_for_Meta-Learning_ICCV_2019_paper.pdf
2 https://arxiv.org/pdf/1611.01144.pdf
2 https://openaccess.thecvf.com/content/WACV2023/papers/Vu_Toward_Edge-Efficient_Dense_Predictions_With_Synergistic_Multi-Task_Neural_Architecture_Search_WACV_2023_paper.pdf
2 https://arxiv.org/pdf/1910.04915.pdf
2 https://arxiv.org/pdf/1908.09597.pdf
2 https://papers.nips.cc/paper_files/paper/2021/file/f5ac21cd0ef1b88e9848571aeb53551a-Paper.pdf
2 https://openaccess.thecvf.com/content/WACV2021/papers/Chelaramani_Multi-Task_Knowledge_Distillation_for_Eye_Disease_Prediction_WACV_2021_paper.pdf
2 https://openaccess.thecvf.com/content/CVPR2024/papers/Nishi_Joint-Task_Regularization_for_Partially_Labeled_Multi-Task_Learning_CVPR_2024_paper.pdf
2 http://www.jmlr.org/papers/volume4/bakker03a/bakker03a.pdf
2 https://arxiv.org/pdf/2102.07121.pdf
2 https://arxiv.org/pdf/1203.3536.pdf
2 https://arxiv.org/pdf/2212.00955.pdf
2 https://arxiv.org/pdf/2209.09385.pdf
2 https://arxiv.org/pdf/1906.11228.pdf
2 https://arxiv.org/pdf/2007.00339.pdf
2 https://arxiv.org/pdf/2108.04353.pdf
2 https://arxiv.org/pdf/2310.02575.pdf
2 https://arxiv.org/pdf/2308.02408.pdf
2 https://arxiv.org/pdf/2312.03731.pdf
2 https://arxiv.org/pdf/2311.18618.pdf
2 https://arxiv.org/pdf/2311.14981.pdf
2 https://arxiv.org/pdf/2407.12632.pdf
2 https://arxiv.org/pdf/2203.16708.pdf
2 https://openaccess.thecvf.com/content_CVPR_2019/papers/Atapour-Abarghouei_Veritatem_Dies_Aperit_-_Temporally_Consistent_Depth_Prediction_Enabled_by_CVPR_2019_paper.pdf
2 https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.pdf
2 https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Split_To_Learn_Gradient_Split_for_Multi-Task_Human_Image_Analysis_WACV_2023_paper.pdf
1 https://link.springer.com/content/pdf/10.1023/A:1007379606734.pdf
1 https://arxiv.org/pdf/1412.1353.pdf
1 https://arxiv.org/pdf/2010.06808.pdf
1 https://papers.nips.cc/paper_files/paper/2020/file/16002f7a455a94aa4e91cc34ebdb9f2d-Paper.pdf
1 https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Achievement-Based_Training_Progress_Balancing_for_Multi-Task_Learning_ICCV_2023_paper.pdf
1 https://arxiv.org/pdf/1603.07027.pdf
1 https://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf
1 https://arxiv.org/pdf/1912.06844.pdf
1 https://arxiv.org/pdf/1708.02550.pdf
1 https://arxiv.org/pdf/1705.08142.pdf
1 https://openaccess.thecvf.com/content_ICCVW_2019/papers/CoView/Seong_Video_Multitask_Transformer_Network_ICCVW_2019_paper.pdf
1 https://openaccess.thecvf.com/content/ICCV2021/papers/Bruggemann_Exploring_Relational_Context_for_Multi-Task_Dense_Prediction_ICCV_2021_paper.pdf
1 https://papers.nips.cc/paper_files/paper/2022/file/f50f282a3093d36471008b045bd478af-Paper-Conference.pdf
1 https://arxiv.org/pdf/2303.14582.pdf
1 https://arxiv.org/pdf/1803.03745.pdf
1 https://arxiv.org/pdf/1701.08734.pdf
1 https://arxiv.org/pdf/1805.04409.pdf
1 https://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.pdf
1 https://papers.nips.cc/paper_files/paper/2022/file/4a9eaf6dff3fdac9ab1aaf4c0fe2d563-Paper-Conference.pdf
1 https://arxiv.org/pdf/1907.04472.pdf
1 https://arxiv.org/pdf/1806.08028.pdf
1 https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470154.pdf
1 https://arxiv.org/pdf/1812.02224.pdf
1 https://arxiv.org/pdf/2003.12641.pdf
1 https://arxiv.org/pdf/2010.03017.pdf
1 https://aclanthology.org/2020.emnlp-main.359.pdf
1 https://arxiv.org/pdf/1905.12588.pdf
1 https://arxiv.org/pdf/2308.16891.pdf
1 https://arxiv.org/pdf/2202.02005.pdf
1 https://arxiv.org/pdf/1802.10567.pdf
1 https://arxiv.org/pdf/1611.01587.pdf
1 http://jmlr.org/papers/volume11/cavallanti10a/cavallanti10a.pdf
1 https://arxiv.org/pdf/1605.06391.pdf
1 http://proceedings.mlr.press/v119/mahapatra20a/mahapatra20a.pdf
1 https://arxiv.org/pdf/2110.00874.pdf
1 https://openaccess.thecvf.com/content/ICCV2021W/DeepMTL/papers/Gurulingan_UniNet_A_Unified_Scene_Understanding_Network_and_Exploring_Multi-Task_Relationships_ICCVW_2021_paper.pdf
1 https://arxiv.org/pdf/2212.06645.pdf
1 https://arxiv.org/pdf/2310.09278.pdf
1 https://arxiv.org/pdf/2305.20056.pdf
1 https://arxiv.org/pdf/2301.01572.pdf
1 https://arxiv.org/pdf/2312.16340.pdf
1 https://arxiv.org/pdf/2312.15751.pdf
1 https://arxiv.org/pdf/2312.13514.pdf
1 https://arxiv.org/pdf/2312.10346.pdf
1 https://arxiv.org/pdf/2312.07281.pdf
1 https://arxiv.org/pdf/2312.06795.pdf
1 https://arxiv.org/pdf/2401.01219.pdf
1 https://arxiv.org/pdf/2003.08813.pdf
1 https://arxiv.org/pdf/1904.00699.pdf
1 https://openaccess.thecvf.com/content/WACV2022/papers/Beal_Billion-Scale_Pretraining_With_Vision_Transformers_for_Multi-Task_Visual_Representations_WACV_2022_paper.pdf
1 https://openaccess.thecvf.com/content/WACV2022/papers/Wang_Semi-Supervised_Multi-Task_Learning_for_Semantics_and_Depth_WACV_2022_paper.pdf
1 https://openaccess.thecvf.com/content/WACV2021/papers/Goel_QuadroNet_Multi-Task_Learning_for_Real-Time_Semantic_Depth_Aware_Instance_Segmentation_WACV_2021_paper.pdf
1 https://openaccess.thecvf.com/content/WACV2021/papers/Zhang_Facial_Emotion_Recognition_With_Noisy_Multi-Task_Annotations_WACV_2021_paper.pdf
