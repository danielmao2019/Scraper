XAI = {
    # 'survey': [
    #     [R2] Explanations in Autonomous Driving: A Survey
    #     "https://arxiv.org/abs/2103.05154",
    #     [R5] A Systematic Review of Explainable Artificial Intelligence in Terms of Different Application Domains and Tasks
    #     "https://www.mdpi.com/2076-3417/12/3/1353"
    #     [R7] Explainability of Deep Vision-Based Autonomous Driving Systems: Review and Challenges
    #     "https://arxiv.org/abs/2101.05307",
    #     [R8] Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI
    #     "https://arxiv.org/abs/1910.10045",
    #     "https://ieeexplore.ieee.org/document/8466590",
    # ],
    # 'perception': [
    #     "https://arxiv.org/abs/1512.04150",  # Learning Deep Features for Discriminative Localization
    #     "https://arxiv.org/abs/1802.08129",  # Multimodal Explanations: Justifying Decisions and Pointing to the Evidence
    #     "https://arxiv.org/abs/1709.04577",  # DeepVoting: A Robust and Explainable Deep Network for Semantic Part Detection under Partial Occlusion
    # ],
    # 'saliency': [
    #     [R22] VisualBackProp: Efficient Visualization of CNNs for Autonomous Driving
    #     "https://ieeexplore.ieee.org/document/8461053",
    #     [R37] Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car
    #     "https://arxiv.org/abs/1704.07911",
    #     [R42] OD-XAI: Explainable AI-Based Semantic Object Detection for Autonomous Vehicles
    #     "https://www.mdpi.com/2076-3417/12/11/5310",
    #     [R46] Explainable AI in Scene Understanding for Autonomous Vehicles in Unstructured Traffic Environments on Indian Roads Using the Inception U-Net Model with Grad-CAM Visualization
    #     "https://www.mdpi.com/1424-8220/22/24/9677",
    #     [R47] Adaptation of Grad-CAM Method to Neural Network Architecture for LiDAR Pointcloud Object Detection
    #     "https://www.mdpi.com/1996-1073/15/13/4681",
    #     [R34] Raising context awareness in motion forecasting
    #     "https://arxiv.org/abs/2109.08048",  # how is this related to explainability???
    #     [R48] Conditional Affordance Learning for Driving in Urban Environments
    #     "https://arxiv.org/abs/1806.06498",
    #     [R49] Deep learning-based robust positioning for all-weather autonomous driving
    #     "https://www.nature.com/articles/s42256-022-00520-5",
    # ],
    # 'attention': [
    #     [R15] Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention
    #     "https://arxiv.org/abs/1703.10631",
    #     [R21] Attentional Bottleneck: Towards an Interpretable Deep Driving Network
    #     "https://arxiv.org/abs/2005.04298",
    #     [R38] Explaining Autonomous Driving by Learning End-to-End Visual Attention
    #     "https://arxiv.org/abs/2006.03347",
    #     [R39] Visual Explanation by Attention Branch Network for End-to-end Learning-based Self-driving
    #     "https://ieeexplore.ieee.org/document/8813900",
    #     [R41] Deep Object-Centric Policies for Autonomous Driving
    #     "https://arxiv.org/abs/1811.05432",
    #     [R28] Advisable Learning for Self-Driving Vehicles by Internalizing Observation-to-Action Rules
    #     "https://ieeexplore.ieee.org/abstract/document/9157238",
    #     [R35] Towards Explainable Motion Prediction using Heterogeneous Graph Representations
    #     "https://arxiv.org/abs/2212.03806",
    #     [R27] Toward explainable and advisable model for self-driving cars
    #     "https://onlinelibrary.wiley.com/doi/full/10.1002/ail2.56",
    # Explainable and Advisable Learning for Self-driving Vehicles
    # "https://escholarship.org/uc/item/1b97h2dg"
    # Pay Attention via Binarization: Enhancing Explainability of Neural Networks via Binarization of Activation
    # "https://ieeexplore.ieee.org/document/9937289"
    # Explainable Deep Driving by Visualizing Causal Attention
    # "https://link.springer.com/chapter/10.1007/978-3-319-98131-4_8"
    # Pay Attention via Quantization: Enhancing Explainability of Neural Networks via Quantized Activation
    # "https://ieeexplore.ieee.org/document/10092762"
    # ],
    # 'evaluation_methods': [
    # Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?
    # "https://arxiv.org/abs/2010.04119",
    # A Benchmark for Interpretability Methods in Deep Neural Networks
    # "https://arxiv.org/abs/1806.10758",
    # Evaluating the visualization of what a Deep Neural Network has learned
    # "https://arxiv.org/abs/1509.06321",
    # Notions of explainability and evaluation approaches for explainable artificial intelligence
    # "https://www.sciencedirect.com/science/article/pii/S1566253521001093",
    # An Evaluation of the Human-Interpretability of Explanation
    # "https://arxiv.org/abs/1902.00006",
    # Understanding the decisions of CNNs: An in-model approach
    # "https://www.sciencedirect.com/science/article/pii/S0167865520301240",
    # Measuring the Quality of Explanations: The System Causability Scale (SCS). Comparing Human and Machine Explanations
    # "https://arxiv.org/abs/1912.09024",
    # Evaluation Metrics in Explainable Artificial Intelligence (XAI)
    # "https://link.springer.com/chapter/10.1007/978-3-031-20319-0_30",
    # XAI Evaluation: Evaluating Black-Box Model Explanations for Prediction
    # "https://ieeexplore.ieee.org/document/9472817",
    # Evaluating human understanding in XAI systems
    # "https://hfast.mie.utoronto.ca/wp-content/uploads/HCXAI2021_paper_25.pdf",
    # Better Metrics for Evaluating Explainable Artificial Intelligence
    # "https://www.ifaamas.org/Proceedings/aamas2021/pdfs/p45.pdf",
    # A Trustworthy View on XAI Method Evaluation
    # "https://www.techrxiv.org/articles/preprint/A_Trustworthy_View_on_XAI_Method_Evaluation/21067438",
    # The Effects of Meaningful and Meaningless Explanations on Trust and Perceived System Accuracy in Intelligent Systems
    # "https://ojs.aaai.org/index.php/HCOMP/article/view/5284",
    # ],
    # 'evaluation_surveys': [
    # From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI
    # "https://arxiv.org/abs/2201.08164",
    # A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems
    # "https://arxiv.org/abs/1811.11839",
    # XAI Systems Evaluation: A Review of Human and Computer-Centred Methods
    # "https://www.mdpi.com/2076-3417/12/19/9423",
    # Evaluating the Quality of Machine Learning Explanations: A Survey on Methods and Metrics
    # "https://www.mdpi.com/2079-9292/10/5/593",
    # ]
}
