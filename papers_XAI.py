XAI = {
    # 'survey': [
    #     "https://arxiv.org/abs/2103.05154",  # Explanations in Autonomous Driving
    #     "https://arxiv.org/abs/2101.05307",  # Explainability of Deep Vision-Based Autonomous Driving Systems: Review and Challenges
    #     "https://arxiv.org/abs/1910.10045",  # Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI
    #     "https://ieeexplore.ieee.org/document/8466590",
    # ],
    # 'perception': [
    #     "https://arxiv.org/abs/1512.04150",  # Learning Deep Features for Discriminative Localization
    #     "https://arxiv.org/abs/1802.08129",  # Multimodal Explanations: Justifying Decisions and Pointing to the Evidence
    #     "https://arxiv.org/abs/1709.04577",  # DeepVoting: A Robust and Explainable Deep Network for Semantic Part Detection under Partial Occlusion
    # ],
    # 'saliency': [
    #     [R22] VisualBackProp: Efficient Visualization of CNNs for Autonomous Driving
    #     "https://ieeexplore.ieee.org/document/8461053",
    #     [R34] Raising context awareness in motion forecasting
    #     "https://arxiv.org/abs/2109.08048",  # how is this related to explainability???
    #     [R37] Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car
    #     "https://arxiv.org/abs/1704.07911",
    #     [R42] OD-XAI: Explainable AI-Based Semantic Object Detection for Autonomous Vehicles
    #     "https://www.mdpi.com/2076-3417/12/11/5310",
    #     [R46] Explainable AI in Scene Understanding for Autonomous Vehicles in Unstructured Traffic Environments on Indian Roads Using the Inception U-Net Model with Grad-CAM Visualization
    #     "https://www.mdpi.com/1424-8220/22/24/9677",
    #     [R47] Adaptation of Grad-CAM Method to Neural Network Architecture for LiDAR Pointcloud Object Detection
    #     "https://www.mdpi.com/1996-1073/15/13/4681",
    #     [R48] Conditional Affordance Learning for Driving in Urban Environments
    #     "https://arxiv.org/abs/1806.06498",
    #     [R49] Deep learning-based robust positioning for all-weather autonomous driving
    #     "https://www.nature.com/articles/s42256-022-00520-5",
    # ],
    # 'attention': [
    #     [R15] Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention
    #     "https://arxiv.org/abs/1703.10631",
    #     [R21] Attentional Bottleneck: Towards an Interpretable Deep Driving Network
    #     "https://arxiv.org/abs/2005.04298",
    #     [R27]
    #     "https://onlinelibrary.wiley.com/doi/full/10.1002/ail2.56",
    #     [R28] Advisable Learning for Self-Driving Vehicles by Internalizing Observation-to-Action Rules
    #     "https://ieeexplore.ieee.org/abstract/document/9157238",
    #     [R35] Towards Explainable Motion Prediction using Heterogeneous Graph Representations
    #     "https://arxiv.org/abs/2212.03806",
    #     [R38] Explaining Autonomous Driving by Learning End-to-End Visual Attention
    #     "https://arxiv.org/abs/2006.03347",
    #     [R39] Visual Explanation by Attention Branch Network for End-to-end Learning-based Self-driving
    #     "https://ieeexplore.ieee.org/document/8813900",
    #     [R41] Deep Object-Centric Policies for Autonomous Driving
    #     "https://arxiv.org/abs/1811.05432",
    # ],
}
